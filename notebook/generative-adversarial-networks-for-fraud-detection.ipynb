{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import recall_score\n",
    "import torch\n",
    "#from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro P5000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if Cuda is running\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's randomize the data, just to be sure not to get any pathological ordering effects that might harm the performane of Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124011</th>\n",
       "      <td>77147.0</td>\n",
       "      <td>-1.437314</td>\n",
       "      <td>-0.672735</td>\n",
       "      <td>0.925002</td>\n",
       "      <td>-0.728117</td>\n",
       "      <td>-0.498919</td>\n",
       "      <td>-1.088232</td>\n",
       "      <td>0.098312</td>\n",
       "      <td>0.294362</td>\n",
       "      <td>-1.763211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>-0.254662</td>\n",
       "      <td>0.569343</td>\n",
       "      <td>0.599137</td>\n",
       "      <td>-0.909906</td>\n",
       "      <td>0.070153</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>149.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182926</th>\n",
       "      <td>125586.0</td>\n",
       "      <td>-1.188026</td>\n",
       "      <td>0.648003</td>\n",
       "      <td>0.195708</td>\n",
       "      <td>-2.300317</td>\n",
       "      <td>-1.876858</td>\n",
       "      <td>0.483442</td>\n",
       "      <td>-0.257970</td>\n",
       "      <td>-4.314653</td>\n",
       "      <td>1.394378</td>\n",
       "      <td>...</td>\n",
       "      <td>3.773234</td>\n",
       "      <td>-1.129681</td>\n",
       "      <td>-1.190132</td>\n",
       "      <td>0.066215</td>\n",
       "      <td>0.806729</td>\n",
       "      <td>0.669240</td>\n",
       "      <td>0.580496</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>392.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>2364.0</td>\n",
       "      <td>1.571567</td>\n",
       "      <td>-0.852696</td>\n",
       "      <td>-0.411170</td>\n",
       "      <td>-1.735533</td>\n",
       "      <td>-0.574247</td>\n",
       "      <td>-0.298426</td>\n",
       "      <td>-0.606201</td>\n",
       "      <td>-0.165091</td>\n",
       "      <td>-2.384797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546954</td>\n",
       "      <td>-1.269700</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>-0.896239</td>\n",
       "      <td>0.433003</td>\n",
       "      <td>-0.425964</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10848</th>\n",
       "      <td>18552.0</td>\n",
       "      <td>-0.265284</td>\n",
       "      <td>0.081207</td>\n",
       "      <td>1.595559</td>\n",
       "      <td>-1.671107</td>\n",
       "      <td>-0.359368</td>\n",
       "      <td>-0.158713</td>\n",
       "      <td>-0.188054</td>\n",
       "      <td>0.271057</td>\n",
       "      <td>2.710338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102560</td>\n",
       "      <td>0.673973</td>\n",
       "      <td>0.126516</td>\n",
       "      <td>-0.065758</td>\n",
       "      <td>-1.159539</td>\n",
       "      <td>-1.066871</td>\n",
       "      <td>0.283226</td>\n",
       "      <td>0.230268</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250966</th>\n",
       "      <td>155148.0</td>\n",
       "      <td>-1.071928</td>\n",
       "      <td>0.594211</td>\n",
       "      <td>-0.352817</td>\n",
       "      <td>-0.819417</td>\n",
       "      <td>1.439513</td>\n",
       "      <td>0.755137</td>\n",
       "      <td>0.594540</td>\n",
       "      <td>0.448423</td>\n",
       "      <td>0.063034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085680</td>\n",
       "      <td>0.088365</td>\n",
       "      <td>0.361190</td>\n",
       "      <td>-0.336159</td>\n",
       "      <td>-1.006584</td>\n",
       "      <td>0.176926</td>\n",
       "      <td>-0.098098</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "124011   77147.0 -1.437314 -0.672735  0.925002 -0.728117 -0.498919 -1.088232   \n",
       "182926  125586.0 -1.188026  0.648003  0.195708 -2.300317 -1.876858  0.483442   \n",
       "2807      2364.0  1.571567 -0.852696 -0.411170 -1.735533 -0.574247 -0.298426   \n",
       "10848    18552.0 -0.265284  0.081207  1.595559 -1.671107 -0.359368 -0.158713   \n",
       "250966  155148.0 -1.071928  0.594211 -0.352817 -0.819417  1.439513  0.755137   \n",
       "\n",
       "              V7        V8        V9  ...         V21       V22       V23  \\\n",
       "124011  0.098312  0.294362 -1.763211  ...   -0.032172 -0.254662  0.569343   \n",
       "182926 -0.257970 -4.314653  1.394378  ...    3.773234 -1.129681 -1.190132   \n",
       "2807   -0.606201 -0.165091 -2.384797  ...   -0.546954 -1.269700  0.009546   \n",
       "10848  -0.188054  0.271057  2.710338  ...    0.102560  0.673973  0.126516   \n",
       "250966  0.594540  0.448423  0.063034  ...   -0.085680  0.088365  0.361190   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "124011  0.599137 -0.909906  0.070153  0.017838  0.001861  149.20      0  \n",
       "182926  0.066215  0.806729  0.669240  0.580496  0.090244  392.00      0  \n",
       "2807   -0.896239  0.433003 -0.425964  0.000977 -0.003500   19.75      0  \n",
       "10848  -0.065758 -1.159539 -1.066871  0.283226  0.230268   11.85      0  \n",
       "250966 -0.336159 -1.006584  0.176926 -0.098098  0.001136   14.75      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reindex(np.random.permutation(data.index))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.174225e-15</td>\n",
       "      <td>3.429687e-16</td>\n",
       "      <td>-1.386421e-15</td>\n",
       "      <td>2.073779e-15</td>\n",
       "      <td>9.939598e-16</td>\n",
       "      <td>1.493625e-15</td>\n",
       "      <td>-5.931037e-16</td>\n",
       "      <td>1.318317e-16</td>\n",
       "      <td>-2.414318e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.416845e-16</td>\n",
       "      <td>-3.515296e-16</td>\n",
       "      <td>2.727492e-16</td>\n",
       "      <td>4.482012e-15</td>\n",
       "      <td>5.203181e-16</td>\n",
       "      <td>1.689590e-15</td>\n",
       "      <td>-3.712632e-16</td>\n",
       "      <td>-1.159267e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.174225e-15  3.429687e-16 -1.386421e-15  2.073779e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.939598e-16  1.493625e-15 -5.931037e-16  1.318317e-16 -2.414318e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.416845e-16 -3.515296e-16  2.727492e-16  4.482012e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.203181e-16  1.689590e-15 -3.712632e-16 -1.159267e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
    "classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class')['Class'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Data is hihgly imbalance. 284315 Normal transaction vs 492 Fraud transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run with Normalising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 30)\n",
      "xtest shape\n",
      "(85443, 30)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the training data and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit classifier to a model\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85287,     4],\n",
       "       [   45,   107]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85291\n",
      "          1       0.96      0.70      0.81       152\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999427\n",
      "Area under the curve : 0.851950\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run with Over Sampling data using SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.127897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.221892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   -0.349671  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.349231  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   -0.127897  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   -0.053373  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.221892  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data2['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data2 = data2.drop(['Time','Amount'],axis=1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284807, 30)\n",
      "Shape of y: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data.ix[:, data.columns != 'Class'])\n",
    "y = np.array(data.ix[:, data.columns == 'Class'])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 30)\n",
      "xtest shape\n",
      "(85443, 30)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over Sampling data using SMOTE\n",
    "smote = SMOTE(random_state=2)\n",
    "X_train_resample, y_train_resample = smote.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_resample, y_train_resample.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85274,    17],\n",
       "       [   26,   126]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confision Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85291\n",
      "          1       0.88      0.83      0.85       152\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999497\n",
      "Area under the curve : 0.914374\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run with GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Custom DataLoader\n",
    "class FraudDataset(Dataset):\n",
    "    \n",
    "    # Initialize the data\n",
    "    def __init__(self):\n",
    "        data = pd.read_csv(\"creditcard.csv\")\n",
    "        data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "        data = data.drop(['Time','Amount'],axis=1)\n",
    "        \n",
    "        # Rearrange columns to the right order\n",
    "        cols = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
    "        'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'normAmount', 'Class']\n",
    "        data = data[cols]\n",
    "        \n",
    "        fraud_data = data.loc[data['Class']==1]\n",
    "        fraud_data = fraud_data.drop('Class', 1)\n",
    "        self.len = fraud_data.shape[0]\n",
    "        \n",
    "        self.fraud_data = torch.FloatTensor(np.array(fraud_data))\n",
    "        \n",
    "        #self.X = np.array(data.loc[:, data.columns != 'Class'])\n",
    "        #self.y = np.array(data.loc[:, data.columns == 'Class'])\n",
    "        \n",
    "        #self.X = torch.FloatTensor(self.X)\n",
    "        #self.y = torch.FloatTensor(self.y)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.fraud_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FraudDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=5,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator's paragrams\n",
    "g_input_size = 29     # Random noise dimension\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1   \n",
    "g_learning_rate = 0.0002\n",
    "\n",
    "#Discriminator's paragrams\n",
    "d_input_size = 29   # Minibatch size\n",
    "d_hidden_size = 50  # Discriminator complexity\n",
    "d_output_size = 1   # Single dimension for 'real' vs. 'fake'\n",
    "d_learning_rate = 0.0002\n",
    "\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "num_epochs = 50\n",
    "print_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ELU (Exponential Linear Unit) function tends to converge cost to zero faster and produce more accurate results\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.map2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.map3(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "discriminator = Discriminator(input_size=d_input_size, hidden_size=d_hidden_size, output_size=d_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these 2 lines to run on GPU\n",
    "#generator.cuda()\n",
    "#discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(disc):\n",
    "    h=0.1\n",
    "    x_min, x_max = data[:, 0].min() - .5, data[:, 0].max() + .5\n",
    "    y_min, y_max = data[:, 1].min() - .5, data[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    x_test = np.c_[xx.ravel(), yy.ravel()]\n",
    "    y_hat_test = disc.forward_with_sigmoid(Variable(torch.from_numpy(x_test).float()))\n",
    "\n",
    "    plt.pcolormesh(xx, yy, y_hat_test.data.numpy().reshape(xx.shape), cmap=plt.cm.Paired)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=y*20, alpha=0.1, cmap=plt.cm.flag, s=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Binary Cross Entropy loss\n",
    "BCE_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizers\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=d_learning_rate/2, betas=(beta_1, beta_2))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=g_learning_rate, betas=(beta_1, beta_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Discriminator Loss: 1.357, Generator Loss: 0.621\n",
      "Epoch 11 - Discriminator Loss: 0.308, Generator Loss: 1.745\n",
      "Epoch 21 - Discriminator Loss: 0.158, Generator Loss: 2.720\n",
      "Epoch 31 - Discriminator Loss: 0.324, Generator Loss: 3.045\n",
      "Epoch 41 - Discriminator Loss: 0.567, Generator Loss: 3.625\n"
     ]
    }
   ],
   "source": [
    "# Training DCGANs\n",
    "for epoch in range(num_epochs):\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    synthentic_data = []\n",
    "    for i, fraud_data in enumerate(train_loader):\n",
    "        # Updating the weights of the Discriminator\n",
    "        discriminator.zero_grad() # Initialize gradients of the Discriminator to 0\n",
    "        \n",
    "        mini_batch = fraud_data.size()[0]\n",
    "        \n",
    "        # Wrap data in PyTorch Variable\n",
    "        d_real_data = Variable(fraud_data[0])\n",
    "        y_real = Variable(torch.ones(1))\n",
    "        y_fake = Variable(torch.zeros(1))\n",
    "\n",
    "        # Training the Discriminator with real data\n",
    "        d_real_result = discriminator(d_real_data) # Forward propagate this real data into the neural network\n",
    "        d_real_loss = BCE_loss(d_real_result, y_real) # Compute the loss between the prediction and actual\n",
    "        d_real_loss.backward()\n",
    "    \n",
    "        # Inject fake data to the generator\n",
    "        d_gen_input = Variable(torch.randn(minibatch_size, g_input_size))\n",
    "        d_fake_data = generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        \n",
    "        # Train the Discriminator with a fake data generated by the Generator\n",
    "        d_fake_result = discriminator(d_fake_data.t())\n",
    "        d_fake_loss = BCE_loss(d_fake_result, y_fake)  # zeros = fake\n",
    "        d_fake_loss.backward()\n",
    "        \n",
    "        # Combine discriminator loss from real data and fake data\n",
    "        d_train_loss = d_real_loss + d_fake_loss\n",
    "        \n",
    "        #d_train_loss.backward()\n",
    "        d_optimizer.step()     # Apply SGD to update the weight\n",
    "        d_losses.append(d_train_loss.data[0])\n",
    "        \n",
    "        # Update the weight of the Generator \n",
    "        generator.zero_grad()\n",
    "        gen_input = Variable(torch.randn(minibatch_size, g_input_size))  \n",
    "        g_fake_data = generator(gen_input)\n",
    "        \n",
    "        dg_fake_result = discriminator(g_fake_data.t())\n",
    "        g_loss = BCE_loss(dg_fake_result, y_real)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        g_losses.append(g_loss.data[0])\n",
    "        \n",
    "        synthentic_data.append(d_fake_data.t())\n",
    "        \n",
    "    if epoch % print_interval == 0:       \n",
    "        print('Epoch {} - Discriminator Loss: {:.3f}, Generator Loss: {:.3f}'.format((epoch + 1), \n",
    "                          torch.mean(torch.FloatTensor(d_losses)), torch.mean(torch.FloatTensor(g_losses))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1a864b00>]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXmYHOV9579vVfU1t2Y00ugWkkASBgNGXMYGGx8Q8LU2voOdXQgb1lfW3iR24my8z8bOJnZix16HDbETfGBjYmOCjQI2Bky4BBIgBEhCEtKMjhnNffZVx7t/VL3V1VXV1TXT3dNd07/P8+iZq6f1TlfXr771/R0v45yDIAiCiA5SvRdAEARBzA8K3ARBEBGDAjdBEETEoMBNEAQRMShwEwRBRAwK3ARBEBGDAjdBEETEoMBNEAQRMShwEwRBRAylFk+6fPlyvnHjxlo8NUEQxJJkz549o5zz3jCPrUng3rhxI3bv3l2LpyYIgliSMMb6wz6WrBKCIIiIQYGbIAgiYlDgJgiCiBgUuAmCICIGBW6CIIiIQYGbIAgiYlDgJgiCiBgUuImyjM7mcP+Lg/VeBkEQFhS4ibL8dM8J3HLHs8iqer2XQhAEKHATIcipBjgHVN2o91IIggAFbiIEumFYH3mdV0IQBECBmwiBZgVsVafATRCNAAVuoixCaWsGWSUE0QhQ4CbKIhS3RoqbIBoCCtxEWQqKmwI3QTQCFLiJsgiLRKOqEoJoCChwE2URFgkpboJoDChwE2Uhj5sgGgsK3ERZhMetUlUJQTQEFLiJsgjFTQ04BNEYUOAmyiI6J6nlnSAaAwrcRFns5CR53ATREFDgJsqik1VCEA0FBW6iLIVZJWSVEEQjQIGbKAt1ThJEY0GBmyiLUNoUuAmiMaDATZTFVtxklRBEQ0CBmygLdU4SRGMROnAzxmTG2HOMsV/WckFE40GdkwTRWMxHcX8GwP5aLYRoXKhzkiAai1CBmzG2FsB1AL5T2+UQjUihc5ICN0E0AmEV9zcA/DEAulduQjRKThINxsnJDCbT+Xovo26UDdyMsXcAGOac7ynzuJsZY7sZY7tHRkaqtkCi/lAdN9Fo3PDdXfjqAwfrvYy6EUZxXw7gXYyxYwDuBHAVY+yH7gdxzm/jnO/gnO/o7e2t8jKJekKzSohGIqfpODo6h8mMWu+l1I2ygZtz/gXO+VrO+UYAHwLwEOf8d2u+MqJhsLcuo6oSogE4OZEB54CqNe/7keq4ibKQVUI0Ev3jaQDNPTtHmc+DOeePAHikJishGhZKThKNxMCYCNzNKyRIcRNl0XUxHbB5TxSicRiwFHe+iYUEBW6iLNSAQzQS/WNklVDgJspS8Lib90QhGoeB8TkAFLgJIhCNOieJBoFzblslqta870cK3EQghsEhHBKySoh6MzKTQ1alzaspcBOB6LwQrJv5RCEaA1EKuLwtTslJgiiFs1uSOieJeiMSk5t725paSFDgJgJxJiSpAYeoNwPjaUgMOGN5a1PnXChwE4E4fW2qKiHqzcDYHFZ1ptASV6jlnSBK4VTZZJUQ9aZ/PI0NPS2IKYw8boIoBSluopE4Pp7G+u4WxGWJPG6CKAUpbqJRmM1pGJ3NY31PC2KyBIM3b4kqBW4iEN0RrNUmPUmIxkAMl1rfbQZuoHlLVClwE4E47RGdrBKijoiOyQ3drYjJDEDzDpqiwE0EopNVQjQIYkbJ+p4WxBVLcTdpZQkFbiIQUSurSKxpb0uJxqB/LI3OVAydqZjDKmlOMUGBmwhEKO6EIjVtIohoDAasUkAA5HHXewFEYyM87mRMblp1QzQGA1YpIADyuOu9AKKxESo7GZOpjpuoK4NTWazuSgEA4qS4CaI0GlklRAPAOUdeM5C0kpK2VdKkM7kpcBM2IzM5nJhIF33P9rjJKiHqiHgfKlbAjlkBnKwSoun58n0v41M/fq7oe5ptlUi0yztRN4RoEErb9ripHJBodiYzKqYyatH3RNNNUpFprCtRN1TrfSgCNnncBGGh6oanyUZ8nYxJFLiJuiEabQqKmwI3QQAwEz3uE0FzVJXoBgfnFLyJxUezPW5TcVPgJgiLnG6UDNwJKxlEqjva7OmfwK2PHKn3MuZN3qW444qo427O9yMFbsJG1QxP5YjuaMABaF5J1PnF3lP4xoOv1HsZ80YIhoLHbb4faVYJ0fTk/RS3XrBKgEKSiIgmed1ATjNgROzOSVQ02R63pbjJKiGaHr/kpO6ySnRS3JFGWA5ZTa/zSuaHqNdWJEpOAhS4CQeqZiCvG0UJSGdyEiDFHXVEoMvkoxW4Nb3YKhGBmzxuoukRqsbZ2q67Ajd53NHGDtxqtAK36rJKqI6bICzEbbQzQemuKqF5JdHGtkoiF7jd5YCWx03JSaLZESeH6rNdmW2VNKnCWSoIayGTj9ZxFO87obRliYGx5n0/UuAmbIRV4lQxqqNzEqA67qiTt5KS6bxW55XMDzFSWAyZYowhJkvkcRPNjW5w2wZxWiWFqhLyuJcC4thGzePOa8XJScBU36S4S8AYSzLGnmaM7WWMvcQY+1+LsTBicXGeAM7PndMBza+b80RZKohjGzWPWzOKk5Pm5827D6oS4jE5AFdxzmcZYzEAjzHG/p1z/lSN10YsIvkSgVs3DMgSs29RaSZ3tBHJyagpbs011lV8ToG7BNws6p21voxZ/+jsXWI4fW2nj60Z3AzcknmLSlUl0SZv13FHK+AVGnAKVklMlmwLpdkI5XEzxmTG2PMAhgH8mnO+y+cxNzPGdjPGdo+MjFR7nUSNcSpu53B6XedQHIGbNlOINlGt4/ZT3HGleRV3qMDNOdc55+cDWAvgYsbYOT6PuY1zvoNzvqO3t7fa6yRqjHPvPrfiVpxWCSnuSBPdOu7ijRTE5xS4Q8A5nwTwCIBrarIaom6U9rg5FFlyWCXNeaIsFUSOImrlgOI9qZDHDSBcVUkvY6zL+jwF4K0ADtR6YcTi4rRH3H63mZwU09hIcUcZOzkZMY9bvO/irsDdrHXcYapKVgH4HmNMhhno7+Kc/7K2yyIWm6JyQKdVohtQJGZ7i1THHW3ykfW4heJ21XE3act7mKqSFwBcsAhrIepIUeDWiq0SWWKQRXKSrJLIwjmPbB236ldVojDk1OZ8P1LnJAGg2CpxBmeRnIxJpLijjmZwiIm9URvrqhocMZmBseJyQPK4iaamqBzQ1fLu9LhJcUcXZ5CLolXiLAUEmtvjpsBNAHCNctWL1bciFapKaMhUdHHeVUVOcVv9BE5oVgnR9BRVlXjKAQt13GSVRJd8hBW36qu4qY6baHLUElZJoQGnuTdnXQo476qWRuBu3qoSCtwEAFdyUvdWlYjkJM0qiS7iGMsSi5xVoum8qBQQAGIKedxEk1Oqc1LTORRJcpQDNueJshQQx7UjqUSuHDCvG0XNNwB53AThmsfttErMsa4xskoij1DcnalY5KwSX8VNHjfR7JRKTmpWcpIxswmHrJLoIu6qOqzAzXl0jqVmlPC4KXATzYzbHhEIjxswvVGaVRJdRCKvIxkD50AuQom9vM6LBkwBInDzSF2AqgUFbgJAoZIk4ZpxrDnqZ2MSo3ncEUYo7s5UDEC0ark13UDcZZXElebdlYkCNwHAtErisoS4LBUlKnXDTE4C5khNSk5GF9VhlQDRKglUdcN+HwqaOe9CgZsAYL7544oERWZFVolmGJCtE0SRGLW8RxhnchKIWuDmiCleq8T8WfO9JylwEwBEgwPzJHx0o2CVuIM6sXgcH09X7OUKO6wjZQ4FjZJVouoGYpK7qsQMX3kK3ESzktfMrL1I+Ag0R3JSkcgqqQcDY2lc8dWHsevoeEXP40xOAtEa7epXDhiXm9fjDrORAtEE5IVVIrEyirv51E29GZ3LgXNgZCZX0fN4kpMRCty+Le+K5XFHqDqmWlDgJgAUkpOyy8dWdQ5ZJCclRpsF1wGxWUCl5Xvu5GQ6SlZJiTpuoDk9bgrcBIBCcpIxhrzmrOM2CuWAsgS9CW9L641QyjmtskDrTk5GzSqJlbBKmtHjpsBNALCy9rIEiXl3wHE24FBVyeIjAm6+QsUd5TpuVTe8DThNXMdNgZsAIJKTZmu72+MWSkdxJS6JxUEo7YqtEutOqiNpVZVESHGrOvcdMmX+rPnEBAVuAkAhOQkUTnBAKG7z+zGaVVIXhNKudGPcvK5DlhhaE1EM3IZnBxzb427C5CSVAxIACln7mCxBNfyrSmSpeaex1ROhtPN6ZYFWtXzihCKBMSAbIatE823AMd+XzehxU+AmABSqSpwNOJzzoiFTMWp5rwtVU9xWrT5jDKmYHBnFzTlHPqgBhxQ30ayojjpu0R0pbJGiOm4K3IuOHbirkJxMWKo1FZMjUw5ovw/dHjclJ4lmx64qkbh96ymCdNGskia8La03IjlZqbJUtUItdDJCilsEZqrjLkCBmwBQuI2WObcVt+ZW3JJEs0rqQEFxV1jH7UhAt8TlyNRxi5yLu46bPG6i6fFreRfNNnbnpMyKEpfE4lBITlbeOSlUaiouR6aOWyuhuKkckGh6zOQkA2OF5KTmUjoKlQPWhVzVkpM8olaJ+Xd795ykckCiyRHJyZhjezIRpO3pgDJZJfWg0PJeeXIy7khOZiq8ECwWInB7h0w1b3KSAjcBwFXH7UpOFmaVUB13PRBKuxrJSbH9VyomI5PXKl7bYlBITpLHLSCrhIBhcLuqxODwlAMKj5t2ea8PVRsypRtIxhwed0SsEq2U4paa1+MmxU3YCce4IiEuM+R1A5xz36qSZjxJ6k1OrdKsEt1VDpiPxrEUFy73npOSxDzz45sFUtyEfSsalyUYRkFt61ZAlx1WCTXgLD4icFU8HdBRx52KRaccUCthlZjfa87BZ6S4CTsgxGRmd6epuldxy7R1WV2oZueks447o+oV72O5GBSqm7zhKiYzann3gzG2jjH2MGNsP2PsJcbYZxZjYcTiIW4144pclPDR9OKqkhhtXVYXclUK3Kpu2LXPqbgM3cptNDpiYw93OSBg2nvNaJWEUdwagM9xzrcDuBTAJxhjZ9d2WcRi4lTcQtVoulFQ3HLB4zY4bDuFWByq1TmpaoWZ1smYDCAao12F4nbP4wZQVAXVTJQN3JzzQc75s9bnMwD2A1hT64URi0deLyQnYw6rRHjciqNzEgDZJYtMtTZSyOuGvcFuSgTuCHRPFhpwSgXu5ns/zsvjZoxtBHABgF21WAxRH2yrRJbs4Kw6rJJCVYkI3M2ncOqJc+uySjxp55CpVNz8GAXFXaqOW3yvGeu4QwduxlgbgJ8B+EPO+bTPz29mjO1mjO0eGRmp5hqJGlOwSqSi+Q9+nZPmz5pP4dQTZ/KtkiCVc3VOAtFS3P7JSYla3kvBGIvBDNp3cM7v9nsM5/w2zvkOzvmO3t7eaq6RqDGqwypx2iFej9v8WK4Jh3OO//vQIRwbnavVkpsKp0WyULuEc16UnIyUx11iyBRAycmSMMYYgO8C2M85/7vaL4lYbETWXrS8m98zPJ2TdlAvc6JMZzV87Vev4L59g7VaclMhNnIWny8E3eDgvBD8WuJmC0cUarkLDThUxy0Io7gvB3ADgKsYY89b/66t8bqIRaSQnGS2IitS3KIcULQYl1HcIhjkIhAUokBOM9CejNmfLwRnAhqIllUSpLib1eMu2znJOX8MgPdSRywZhEcYl2Uosnkimx53ceek+KiXUTgiGEThNrzREfstticVjM/lF3wxVLXi4Bel5KR7vLCTmCxhNheNYVnVhDoniULyRynUcauaYd+COvecBFB2MwURDLIRGRvayAg12WEp7oWqy5y1Q7xQ3MkIKW5hD/mVA8apjptoVvKOrH3MDs7cs0lroTknnFUSBTXX6AhrpD1p3hwvdDOFwjwaVx13BI6RsOxKNuBo5HETTUjetkqkIsXtnVUSro47Q4G7aohj05YwA/dCFbeqFZfUpeLRCdyqrbh9rBKqKiGaFVuNKZLdJakZXo87ZleVUHJysSgobis5uUDF7U5OJpXoWCWqS0A4adbkJAVuAnmrpTouS4grYsiU/zxuIITituY8R0HNNTp5t1WywHkleZfiliSGZEyKRDmgOUecwaxMLoY8bqJpsVuKnYrbr3NSCqe4KTlZPUTA7bAC90LruN2KGxD7TjZ+4NYcG0C4oTpuIrJMzOUr+v1CcpI5NmB1zioRDTiFGu8gbI87ArfhjY5Q2JXWcauOPIbA3Hey8Y+RqnNfmwSglnciojx9dBw7vvwgTkykF/wcxcnJglViK27ZVQ5Y5tY0awWDbIVjSInqWSWqTxNLMi4jHQHFrQYpboU8biKCHBubg25wDE1lF/wcTg8x5rBKvB53uFkltlUSATXX6AiF3ZGy6rgXbJUU13ED1vZlEThGmrWRtR/kcRORZDqjAgDSFZyAzr0Ii62S4hkRir2rdsjA3YS3sNXGq7gXGLjtzsmC5RAVj1vVDd9SQMDaJ5WXFxNLDQrcEacagVt1jPsUQdq556SnHLBMVUmWPO6qkXPVcVc6qyThVNzxiARug/s23wDFQqOZoMAdcaaswJ1RFz6vIe+4FS3sgGNWlchSoQxLDmmVZNWCxx2FzWgbmUJysrLA7W7AAcy29yhcXFWttOK2p1lS4CaixHTWDNiVWiVC0cgSg8RMX1GzArfAua1ZECIYcF75dlvNjrBKEoqMuCJVkJz0Bu6WuByJOm7NKJ2cFC38zVZZQoE74tiKu0pWCVDYgFU3jKIyrLDzuJ233wvt9CNMnBZHQpGqXsddyQV/scjr3HfAFBBeTCw1KHBHHOFxz+UqC9zOpFVclpC3qkqcirswq6RcctJwfN74gaGRERe+uCIhocgVJCdLWCUROD6abtjK2o3T2msmys7jJhobobjTlXjcWrHiVmQGTedgrHg+hLNUMAhniVkUbsUbGadSTihSxdMB3cnJKBwfTed2RZMbkZwkj5uIFNPZyq2SvKvBQVglpuIuDuhA+M5J9+fE/LEVt2xZJQsMUH6KOxWToeq84dVqPrAcMFxT2FKDAnfEmapyHTdQmP+g67zIQikMmSofuFussaFRUHSNTF7XIUsMiiyZycmF7oCjG5AYiqyvloiMdtUMo3Q5oD2GmDxuIiLkNN0e5FRpcjJRlJxkUHUDqmEUneihk5N5Hcta4ubnDR4UGh1nxU9CkSqq43baYUBhw+C5Bt/6S9U4lQO6oMAdYaYzhRMunV/4yae6WooVWbLmcRcP93E25wSR03R0tVQ2P5owyWkGEjERuOWFV5Vo3pK61oSpuBs+cAeUAzZrcpICd4QR/jYAzFVslRTXa+c1bx03YwyyxMrPKsnr6G4lxV0NnIq70jput90gujFnK6hIWgyChkyJ+fEUuInIIPxtWWJVqOOW7a+FVaL7ZPMViQVuFsw5R0bV0WVZJeRxV0ax4q7AKtG8VklrIhpWiebKtTghxU1EDhG4V7QnKrJK8rpXcWuGt47b/lmAVZLXDRgc6LasElLclVHkcccW3oDjp1oLiruxA7c5ZCrYKslTcpKICqL5pq8zWVk5oOaTnNS42TnpUjrlrJKstW1ZQXE3lxKqNjmtcDcUl6ubnKyV4p5KqxibzVXt+VQ9YMgUKW4iatiBuyNZ0UB8txqLyRLUkoqbBZ4kQmELj5usksrIabp9Ua0sOemdaV2r5OSf3bMPn/rxc1V7Pk03Su6AE7cVNwVuIiKIAVN9nckKx7py3wYcd1UJYNZyB1klInB3pBQwRoG7UpzedCIWnJycSqslX2/Vp228VsnJwalsRRt7uFGDZpVQcpKIGlMZFQlFQlcqjrxmlK2vLoWn5V1i9nRAd3JSllhgA46wbFIxOTJ7GjYyOYeNVc4q+ch3nsJf33/A92d+yclUTIbEqq+4Z7OaLSoqhXMO1aBZJW4ocEeY6YyKzlTMvuVdiF3COfe2vFut1ZpPq3FMZoEbKYh9JpMxGcmYTPtOVogz/1AuOXliIoOTExnfn/klJxljaI0rVU9OzuY0zObU8g8MgW5wcI7yyUmaDkhEhamMio5UDCnRurwAdSuaaZyKJmYpbt3H41bKVJVkPYq7uZRQtXEmFROKDM3gvndWnHPM5jTMlFC6fslJwExQVltxT2dVZFWjKipY3N0F7TkJkOImIsR01lTcYubEQnxu8Yb3m8et+XrcwYpbeNypuIxETCLFXSFmctKqKgmYhJdRdegGL6me/TonATNBOVdBKakbcQEBTMskDCcnM/jgPz6Jibm852fiby1dx00bKRARYyqjoiOpIBUzk0wLqeX22xlFcSQnvYqbhUpOCsUdhV3EGxn3rBLxPTdCaZcK3H6dk4CZoKxmcnIur0PsVldK/bvZe3wSu46OY//gtOdn4r1WSnGbW+uR4iYixHRGK1LcC7FKRBBwKu64zOzNgr2dkxLUEMnJxfS4Vd3Af7tjD14+5T3xo07OkVQUH/0SlCJIzmT9veXFskqcKnsmpM8t1jzts3YRkEsNmWKMmSMayOMmooLwuCuxSvI+ijsWpLglBj0oOemwSharquTUZAY79w3hiSOjNf+/Fpui5KRlmfgN7hLBr5TKVTX/tvGqB25HsA6ruMWwNNEJ7MTvjtBN3Hq/NhMUuCOKYXDM2B53JVaJSE66pgPqHJrhbXxQLDVeCmGVmIpbWpTOyYm0ecL7nfhRp6iO2/a4vRdDYZHkNMPXSimluE2rpHqB21kGGNbjthV3xvv4glXir7jFzyhwE5FgNq/B4Kg4OVnKKjHLAb1zkM1ZJQHJSauKJKlIplWyCA04k2kzqbXUArdumHaVOznpdzF0qlu/QKwGJSfrbJWIYL9QxR0jxe2FMfbPjLFhxtiLi7EgIhxTlsrsSFanqsSdnATMoC77NOAEzSrJqDrisgRFlszk5CIEbnHCL7XA7b6oJgKqSooCpo9XnC+RnDStkuodI+dFI6xVMhMYuM33Wqk9J4HCGOJmIozivh3ANTVeBzFPRCKn0jpuv3IrEcTTed235T3IKsmqOpLWGNLF2kVclJEttcAt2tvjITxuZ2LPHTBFk5WvVRJXkNf97ZWFMBOwjlJMh0hOBlklcYUUtwfO+aMAxhdhLcQ8EEGqI6U4PO7qWCXiJMlquu+QqcDOSVW3LyTmLuK1P6Eml7jiTniqSkp73O7PgUL3ob9VsvD8iB8z2YUo7tLHT7zXgq0S8rgXDGPsZsbYbsbY7pGRkWo9LVECkcjpTMUgSwxxRUJaXXgdd9xVVQLAbDWWvGNdA2eVqDpSMTNwJxUJGVUH57W9jZ1cosnJXCmrJKAc0P054EhAl0hOAtWbyS2epzMVC932LtY77XP8hAVSqhwQII+7Ijjnt3HOd3DOd/T29lbraYkSiDd5R9LcsKAlvrDSO3+Pu3CSyL7JyeA67qQI3JbyXugM6bCI5KTfiR9lci7FLSwov9dztig5Wfw6iEAfpLir5XPPZDW0xmV0tcTmbZUEKe5S87gBUB03ER3Em73T2mmmNb6wJJO/VVI8KdCJOTkwuOXdDtyWJ1vrBKXTKqm1ul9MPFaJXPpCOJvT7A2a3QEzb99V+dVxy/bvV4PZrIa2pGKWGc4zOek3UVCIhFJDpgDz9Wm28cEUuCPKVEaFxMzkEmD6yZkFWCV5n5Zip7pxV5UocrBVknVYJcLrrrXPLawSVedLascdT3IyVtoqmc6qWNWZAhAQuAOskmqVBM7mNLQlFLQnlVCKm3MeWFVSblYJYNoyS+1uqxxhygF/DOBJAFsZYycYYzfWfllEOaYzKtqTMUiWIm6JyxUlJ51blymuSYFOFEkq73FbAVvc2te6skRYJUA0fO4fPHkMn/zRs2UfVzg2svUxODm5vC2OuCx51LMayiqpTuCezprvy7ZEDDMhnlMMx+pIKshrhkc5l5tVAgDLWuKYSHsHVC1lwlSVfJhzvopzHuOcr+Wcf3cxFkYEM2XN4hakYgsL3H4et/Nzt8etlNu6LO9Q3LHFs0qWt5lbpUUhcD9+eAwP7j9d1tZxK+V4meRkW0JBW1Lx1HEHNbHUIjnZnlTQ4bMOP0SSfe2yFuvr8GsXdLXGMDG3tGyycpBVElGmsxo6Uor9deXJSWcdd+FzP487cLNg1bA97oT1sZaK2zA4pjIq1nebJ34UAvf4XB5Z1SirSEW9trCuxMdSycn2Et6yuzrFSbUV96zjAhLmYiCC+9plps3jruW2h0yV2HMSALpb4sjrRkXb90UNCtwRxa24W+LKgmpxyyUnvR53mY0UVB2puPk7tuKu4Qk1nVXBObChpxVANAL36Jy5A/rwdPC+jEJxC29bkSXIEvO1SmayKtoSMV9v2a/kU2BvGFylYzRjXUDEOsqpYJGQXGMFbvfxU0NaJQCayi6hwB1RpjOqXQoIVOBx+5UDSs7PXeWAEoNaZiMFu45bBO4ajnYVickNPdFS3ABwejoX+Dg7Oek4NgnFu32ZbnDM5XVbcbuVvN/FufB8MmIyq6pVYl5AYtANXvZuq6C4hVVSvI5CA05pxS2qacR7oRmgwB1RvIp7gR635p0OGFccddyeBhwJnJsWhRvOeVHgFh9ruX2ZKAWMSuDWdMMOMKfLKW6RnLReR8AM3G6rRARdU+l666fLqdZqjXY1rB14xAUEKD8hUCjutSUUt3gNgsoBl7WS4iYiwnTWnMUtSMWVBc4qMeeRSJJ3Vgng43GLraJ8VHdOM8B5IdCIqpJaJifFySoUW6MH7nFHcCmnuG2lXHRRlTyzSkTgFmV47gaccvM+qrVh8GzeeQExA3e53d7LedyigimoAWeZpbjHfbY+qwW7j43XfdMOCtwRJKfpyKqGR3GLndnng6pzjxJzWiV+s0oA+PrcWce2Zc6PtUxOiimJ3a1xtCeVhq/ndQaX4Zlgxe2XVEwosmc6oAh+7UnT455PchIwA341FLf4f8UFBChfrSLuDtZ2WRdel90h3s9BLe/C414sq+QLd+/DX99/YFH+r1Io5R9CNBqFAVPFgRsA0qqOjgB14sbcRLb4pHBaJe6gLpKVfrXczo2CgYLyrqXiFjXcy1rikWjEGJ91BO6yHre3xt60SopfTztgCo/bSgoyZt3tfcx1AAAgAElEQVQdBSQnATGTu/JjVLBsTI8bKL2VmmA6o0KWGDpSClIx2WuV2GNdgxtwgMWzSk5NZjyCZrEhxR1BRAKnI1m47i50tKs57lMu+l44xe2z03jeX3HX1ioRM1sUdKZiDW+VjFmKe3lbIrTHXc4qEaq1PWmW4WkGL/LBg5KTgOlxV8MqEUG6bR4et6hCYYyZF163VaKbwkJchPxQZAkdSWVRFPdMVsVcXsfwTPBFt9ZQ4I4gIji5rRJg/qNdVc3wzLCIKQEedwjFLapJYjKDxGrb8j6VUdGeVKDIUjQC96x5wm9f1Y7TIaySmFycf0goktcqEUo3odhK1xkAyzWxVMsqmfGxSsq1vc9kVfuxHSnFpxzQf+ceN8ta44vicQ9NmcdsfC5f14mEFLgjiHMTBYGYyT3fE9BvwL6zzd1vs2DAP3CLAC3UP2PM3DC4xlaJ8DijELjH5/JgDNi6sh3D07nAOmdzo+Diu6GEIvsobofH7aN0ywXualWViCDdkVTQnrCskhAet3isaXV5K2KCbBJB1yK1vQ9OFS62o7P1U90UuCPIdIDinm+Q9FM0pUa8AoVmED/7w52cBMRmCrW1SkQdbxQC99iceaFZ1ZVCTjN8N8gV5DTdc1GNKxJyLqXn9Lj9koJhkpNVqSrJObx2W3GX8bizqt0B3JH0Hr+wiru7JbYoVsmQw94ql6OoJRS4I4h4g1bDKslrPlUlznncrs7J3vYEAOD0lPc23+1xA6ZCrKnidtSzRyJwz+bR3RrHCvE6BtglpuIufv0TioSc6/WcyWpgDGiNy7a3PFOkuINL6loTMubylW944awqkSWGlrgc0uN2KG6Px+19f/qxWIOmhhzv+3r63BS4F8jobA6/2X+6Lv/34FQWcVlCt2URAEAqZp6wmXm2vftaJQF13Gu6zHrbU36B2/a4C7+fintv7avJlMMq6UjFkPOZMNdIjM+ZgXtlRxJAcBOO37FJxGRP56QYpcoYcyjdwvsgTHJSdyU0F8JMVrUuIOYawox2FclJwDx+foo7qBRQ0NUSXxTFPTiVte3DcuWctYQCtw9HR+dwYiId+JjvP3EMN31/t+8Gp7Xm5GQGq7qSRUmrypKTpQO32+Pu6zQDzqnJjOe53MlJ83OpporbaZUIz7+RSwLH5nJY3hbHyg5TcQfdbudU77GJy97OyZmsZo8/6PApw1N1AxLzHktBtSYEzuQ0tMUV+31ptt+HsEqSheM3m9OKunJVgwc23wiWtZi/W61Nj0txejqLLb1tYAwYIcXdWHz6x8/hC3fvC3zMq6Nz4BwYGAsO8LXg1GQGq62h+YIFB27dQEwpPqFlyawGAbyKO6HIWN4Wx+CUN3BnXXXcgGmb1EoB6wbHdFZFl8MqAfx3C28UhOJe0W4p7iCrRDfsnIIgEfML3KodfP2CcDmfuHWBiW03YvcbgV/7vRPRIi/KWjuSCjgvvlvQwiruVtGEU1u7ZHAqi7XLUuhuiZNV0khwzvHqyCxeOjUd6Pn1WwF7YLw+gVtMUxOk7MA9v5NvPJ23s/pOxInuNyNiVWcKpybDedzJGlaVzFiTAbscVSVA47a9a7qBibSK7tYEUnEZ7UklWHFregnF7WrAyRXsBj+rJKd5LRcnrdVS3A7bAyhvlczmNXCOIo8b8JYyhvO4RRNObY/90FQGfZ1J9LYnKDnZSIzP5TGX1zE+l8dIiXIfzjmOjc0BWPzAreoGTk9nsbrLrbjNE2Y+ijur6jg2Ooetfe2en9mB2+f2enVX0ldx+1slcs3quMVJ6qwqARo3cIv1ik0fVnYkgz1uv3LAmHc64IxD6cZkCcmY5FHcQXZDYfuyyi6wwmsXtJeZye1sHAIKVpfz+Kk6DxwwJehehNGuWVXHRFpFX0cSKzqSGCGPu3FwBuKDQzO+j5lIq/abrn+RrZKhqSwMDqx1BW5ZYkgo0rw6Jw+dnoXBgW2+gZvZz+umpOJWzfI15+8ka2iViNviqARu0SDS3SoCd3D3ZN5HKScU2RrmVbgbNBV34a7JbVGoPklOJ/ZM7ip43M51mO33pY/FtGt0Q6dPjsK86IRLTgK1tUrEserrTGJFe4KskkYiTOAWahsAji+y4j5pJQXdihuY/2jX/UPmhLNtqzo8P1PKKO7ZnObxknOqUWSTAEAqVrsduMVIV49V0qBzmUXXpAjcK9qTgSe/n8UhygOd3ZNOjxswOyidAdOcR1NecVdulagejzuoHNCjuJPeC6+m86IRDKVY1iomBNbu2Ivmm1WdKfS2JzAyk/Mdb7wYUOB2IQJxZyqGAyUCd78VuM9Z04H+8Tnfx9QKUc3h9rgBsQtO+CB5YHAGqZhsb/vlRNxal1LcADDoUt2ZvF5UCggszOPWdMMOckHYijslKirMADAV0NRST8Sckp5Ws6JkRUcisHuyVB23+JnA7S27tw2bzemeC6qTam1fNpvV7M5NwGqlz+slt7pzdnwCQGeL1+POh0xOLsYuOG7FrRncFg+LDQVuFwPjafS2J/DatZ2lFfdoGowBl29ejlOT2UWdWXBywgzcq6yyPCepuIyMGv7kO3h6Gmf1tfsGZ3Gy+KkdofbdJYHOTRTsNS3AKvnqrw7iLX/327Kv62S6WHErsoTWuHfCXKMgrJIe4XG3J5F3bKzgJkhxi8qSvGYgpxlFAdOdFHx1ZBZnLG8tua5qJSedSVKxjqDn9SpuceF1KG4j2J8XJGMykjGpplaJUNxm4DbPv3rVclPgdnF8PIP13S3YurIdr5ye8VUL/WNzWN2ZwuYVbdAN7lvTXCtOTWWwvC1elAAUzMcq4Zxj/+AMtvv420AhOene5R0wrRKxFicZVfesK2ElJ8N25WVVHXc+fRyTaRVHR4PvZvw6SBu5e3LMmlMi1KHdhFPi5M/5KG73Tu/ONnOBc8PgrKrj2NgczipxnAGz4xKoLDmpWZv1tiWcXntw27s9c8dS3G0JBRLzsUpCKG7ATFDWsqpkaCqL9oQ5+XBFiDr8WkKB28XAeNoM3H3tyGlGkZ8tODaWxsblLdhgWQzzrSzhnOO6b/4Hbn/86LzXd3Iya3cvummJy0iHPPlGZnMYn8v7VpQAwVUlK9qTkCXmsUrMjYK9ihvw35ncj/teGLRP3P2DwbuMTKbz6EgqRXcMHT5t043C2GwOXamYvd5yJ39e032HTAGF19NtN4jPxfcPD5sJ6K0rSwduxapEmVvAZtMCEfTdHjcQXnEzxszj57C68iHLAQHRPVk7xT00lbUb0MTIgnolKClwO8hrBganMljX3YJtfWbCzs8u6R+bw4aeVqy39jmcb2XJoWGzTnzni0PzXuPJibRvYhKwPO6QVsmBQfPvEn+nm5htlXgDtywx9HUkvYo777VKhOcdttrlR08PYGNPC2Iyw/5Bf6tKMJlRbZtE0MiKe3wuj562hP31yvbgtvdgq8R8PZ2jVAXODYNfOW2+hlv72gLXVumgKdEh6WeVlKrlns6qiMtS0V2a+/iFnVUCmAnKWo52HZwuBO5eO3CTVVJ3Tk1mYHBgfXcLzlzZBonBk6CcSquYSKvY2NOCle1JxBVp3pUlT706BgDYe3zS00wRBOccpwIUd2oeVskBUVFSVnH7v0VWdSZDe9xAuJ3eDwxNY0//BH730g3YsqI9hOJW7cYLQSPvgjNmdU0KbMXto9o452bnZBmrxDlKVdBhJSc55zh4egZxWcKGntIeN1D5aFdbPbsuIEDpzRTcSVVz7TGfBpxwVkmt55UMTWXQZ9lbLXHTMqlX2zsFbgfC8ljf3YJkTMbGnlYcHCoOHqKKZENPKySJYd2y1LwV95NHzMCd0wy8eDL8pqMTaRUZVS+tuGNyaGV7YGgGfR1Je4dsN0Jp+3ncALCqK1U0mxiwPO64W3GH35nnR7sGEFckvO91a7F9Vbt9cSnFZDqPzggp7rHZHHocr3cyJqMjqfgqblXn4Nw70c9tlfh63Fbr+FxexytDM9jU21pWtbbGKwvcfuvw29TByXSmeMNrwHv8wjbgAGb3ZK2qSjTdwMhMrqgooJ613JEL3FlVr5mHKQL3um4zMG7ta/dYJcesIL3RUjAbelrn5XEbBseuo+N409ZeAMAzx8ZD/25QKSAwv+TkgcGZkv42UFB2pYbYr+5MYnAqW1THmvW1SsT2ZcEe91xOw93PnsR1567CstY4tvd14PR0LvDWdzJTmFMiqDRwZ1W9ZDVRpZhWSfGFplT3pKjT9k4HtKwStbTHLRKEs1kNr5yexVkB/nbhdyqzSmZtv9ovOWn+bHgmiwdfLkzU9FXcKcWnASdcmOpuiWMqo9aktnpkNgeDA32OGUG97QmMUHIyHH/6831417ceK1kbWgnHx9OIy5LtPW7r60D/eLpo/ke/Vekgap/Xd7dgYDwdumri0PAsxufyuPbcVdjU24rd8wjcovmmtFWihFK2qm7g8PAstq0KSFhJpTsnAbMkMK8Zdm0yAGQ1w6eO2/K4y5QE/mLvKczmNHz0kvUAgO1WU1CQXVLKKknn9QWXaN76yBFc983/KLsf5HzRrZrf7tZE0fdXdvg34QgrxGOVyKIBx3w9baWb8HrLg1MZnJzMBF6gBZVuGCzElN86xBq/ct9+3PT93fZr69y2TGBeeF1DpkJuzNvVEofBazNkrFAKWDh+ve0J8rjDkMnruP/FIRwbS+PRV0aq/vwD42ms7U7ZYym39rWDc7M1XHBsLI2+jqRdPbGuuwWzOS10GZLwty/b1IOLNnTjmWMToRWCqOEOqirJ60bZoHV0dA553cD2EolJwFEOWGKTVnHL6JxZ4pectKtKygTuu589iS0r2nDhhmUAzD0ZgdKBW0wGdFslfvMu5sO/vzgIzeB46MDwgn6/FBPpPDhHkVUCFJpw3Ijch3sjZ6/iLq7MAAp2xbMDkwAQSnFX6nEXdnh3bGAdkyFLDDNZFVNp1U7GP2y9ttOOcbQCr8c9D6vE7p5cmF2iGxy3PXrE17cWGyj0dRTOvXKdr7UkUoH7t6+MIJ3XoUgMd+waqPrzi1JAgUjcOW+dB8bnsKGn8BhREtjvUzbox5NHxrCmK4V13S246IxuTGVUHB6ZLf+LMK2SVEy2Z3O4CTvaVSRcgxR3TJEgMRTN/HZSaMIx39Ccc//kZIgt1YamsnimfxzvOm+1vZt3T1sCve2JkpUl0xlzMqCf4gbCBW73XdLR0Tm8Yl2knbf0C4Fzjv9y+zP40r0vATB3vgFQlJwEgD7LKnGrxHKKO+dITsZkVvQ4kah8tn8CQHApoKB6VkkhcDPG7Jrye54/ibxmoDUu4+GDw9bavYq7IxVD3rEZhmqEm1UCFBqxFlrL/dCBYXxl5wH842+PeH42ZLe7OzzujgTSeb0q277Nl0gF7p37BrGsJYYb33AGHjpw2ndCXSUcdwXu9d0tSMXkosqSY2Np298GYJcEhvG5TX97DJdu6gEAXLTRVJdhfe6Tkxms7krawc2NmBCYyevI5HV89YEDvhUvBwanoUgMm5aXLhGLSSxwRoRbcYtAUio5GeRx79w3CM6B6167quj721d1lExQFuaUzD9wZ/I6bvreM/jd7+4qCt4PvGQqwredvRKPHR6d18AuN88cm8BDB4bxg6f60T82h7E5U5m5Pe5rz10FzeD44VP9Rd8vtU9kwno984467vZkrOg9ITzu3f3jSMVkrC2RE3FSjaoSWWKeC7c5aErDj58ewLlrOvHuC9bgsUOjyGl60bZlAudmGLphJmjDJycrGzR159OmGLzn+ZOeu9ah6SziilT0fhO13PWoLIlM4M6qOn6z/zSufk0fPnrJBhgc+Mkzx6v2/FNpFdNZrShwSxLDWSvb8OyAaWfM5TSMzOSwYXnhMeuWWYE7RGXJK8MzmEiruHRTNwDzwtDbnsAzR8MFbnMOt3euiEAo7rm8hs/e9Ty+/fARfPm+/Z7HHRiawZYVbYET42KyFNix1t0aR0KR7ISp3yxu59dCcRsG9yjdX75wCttXdWBzb/GFZHtfOw6dnvW1fn79shlk13cXl7mV2wUnnddw4/eewYP7h/H44TE8emjU/tkDLw3hnDUd+PhlG5HTDDx+eNT3OcJw26NH0NViNtvc+siRQru7y+M+Z00nrjirF//82LGi0QClthtrsy7OorrJPUoVKFglp6dzOGtlW8m7Jiet1lyRhSb2nNunOWlPKth1dBwHhmbwwYvW4aqtKzCX1/HkkTGk87qvxw2YF95yu9O76a5AcQ9NZfHwwWG8dm0nRmfztp0jGJzKYlVnsWiy296rnA8JQ2QC938cGsVcXse1567C+p4WvPHM5fjJM8eh+ZzUusHx4smpeW1+WqgoKQ6M7z5/DZ4/Pomv7Nxvd1E6FXcqLmNFe6JIcZeazfGUVQYoFDdjDBdvNH3uMJyczGBNl3dGiXMtAPBXO/fj318cwvZVHbj/pSEcOl24Y5jOqnhuYMJO/pVCkaWSiUmx9tVdKXvvSRGY3YHbuSv8TFbFO771GD595/P2sTk5mcGzA5N4h0ttA6bizuuGp/X99HQWf//gIVy1bYXtiQuCFHc6r+G/3P4Mnnp1DH/zvtdiVWcS//DwYQDmyffcwCSuPrsPF5/RjfaEggcXuKfo4eEZPLh/GB+/bCM+fNE6/OzZE9h3YgqA1yoBgFuu3IzR2Rz+dc8J+3u5ElZJZ0sMbz97Jb7/RD8m03lzsJMr+Dm/PjOETQIU2t7TC5zkOJP1XkDEWk5aFt+7zl+N12/pQVyRcO/eUwDg43GbzzE+l8fhYdO2Cl3HbXncC1Hc/7r7OAwOfP2D56O3PVF0LABzc2xRwy3orWP3ZGQC9859g+hMxXDZZjPoffSS9RicyuKRg94k5d88cADv+NZj+NqvDoZ+fmcNt5P/fPlGfPyyDfjOY0fxl7801avT4xZf91uVJX/3q4N4zV88gH97/qTn/3jy1TGsXZYqujjs2LgMJyczZeedZFUdo7P5kolJoKC4H9w/jA/uWIc7broEqZiMf3ik4Nl99f6DmMqo+L3Xbwz8/9YuS3m2R3OzqjOJQWvdeyw/1V2Xm3LUcX/2rr14eXAav9h7yj5xd74wCAC47lxv4N5WIkH55fv2QzU4/uKdZ3t+x2+ms1jf9bc+iaePjuPrHzwfH7hoHW564ybsOjqOPf0T+JXlaV99Th/iioQrzurFbw4ML0iB/tOjR5FQJHzssg34r1duBgDc/sQxa06JNz9x6aZuXLC+C7c9esQWIoXkpPcU/dzbt2I2r+H//fZV34AptiIDwvnbQOUTAv38aqBQHnjda1ehIxlDS1zBZZt68ICVqCyluD/8T0/hHd96DACwvK34LqUU7QkFisTmnZw0DI6f7D6O12/uwebeNrz3gjV4+MAwRq0JlTnNnPfiHuxWz7b3UIGbMXYNY+wgY+wwY+zztV6Um5ym48GXT+PtZ6+0b5vesn0letsT+MFT/UXK+rFDo/jH376KNV0pfPvhI/i/Dx0K9X+UUtyMMfzFO1+Dd563Gk9aFSHuLrR13S04NjqHz921F9986DC6UjH80U9fwHMDBSU9MZfHrqPjttoWXLTRtE2Ez53T/G9XRTlSqeYboHDyXXJGN/73e85Bd2scH71kPe7dewoDY2ns6Z/AD3f142OXbcR567oCX48/uHIz7v3U5YGPWd1lbqgwMJbGn/58H85d04m3bF9R9Bjhcf/L40fx65dP44vXbcf567rwpXtfwuhsDr/cN4hz1nRgo8/0us29bYjJDC87AveTR8Zw795T+IMrNvl2A4oT/+fPncTtjx/FE0dG8dm7nsf7bn0CY3M5/OMNO/Du89cAAD588Tosa4nh1kcO44GXhnDG8lacucK0a9569gqMzOTwwsmpwNfAzfB0Fj9/7iTev2MtetoSWN2VwvUXrkVOM9CVivn6tYwx3HLlZhwfz+C+fYPIqrqdWHQrbsCsdnrP+Wtw+xNHMTCe9gQ/WWJ2MA8aLuVEvG6f/9kLeOLwaMm71dHZHB4/PIp/efwovnjPPnzzN4fw9NFxTKb9A7dYx4cuWmd/76ptpl0CwONxb1/VgQ/sWIsb33AG/vb952Hnp9+Id5+/OtTfwBhDV0ts3lbJ40dGcWIigw9dbJaiXn/hWmgGxz3PnYRucHz2J3sxPJPDNecUi4uulhjisoThmSw4N/MUn7nzuXnd6S8U7yvtgjEmA/g2gLcBOAHgGcbYvZzzl2u9OMFjh0Yxk9NwrUOVxWQJH7t0A/7216/gc3ftxZf/07nIqDo+e9fz2LKiDf/2icvx5/e8iK/96hUkFBnvu3Ct/YJ2+pxAA+NpdLfGfW/3JInhb99/HqYzKgbG057HbOhuxd0zJ3H3cyfxubedhY9csh7v/vbjuPkHe3DvJy/H8fEMPnPnc5jLaXjvBWuKfndbXzvaEgq+cPc+fP5n+5BRdWzoacH/fMfZeMv2lfbjypUCAsC5azrxxeu24/oL19pK7fev2ITvP9mPbz10CC+cmEJfRxL/4+qtZV9zWWKQpdIznAGzCWd4Jov/9qM9AIB/+OjrPEORYrIERWI4NZXFey9YgxvfcAauPKsX133zMXzijmex9/gkPv8723yfPyZL2LKi3Z6rklV1fOnel7CmK4Vb3rTF93fiioQPXbQOD+4/jS/9wnyLxmUJt7xpMz755i32xQ0wk7m/9/oz8PUHX4EsMdz0hjNsD/NNZ62AxIDf7D+N88tc5AS6wfFP//EqVMPATW/YZH//liu34K7dJ3xtEsFbt6/EmSva8L9/uR9fvOdFzGQ1rOlKeTx8wR++9Uz8Yu8pDE1n7btQJ6JKJKzifuv2lfjUVVtwx64BfOQ7u3DmijZcdEY3zlrRhnXdLXj++CQePjhc1OnbnlDsfSMB4M1WU5mTizYuw1RGLbK03rx1Bf4CZrVNR6r4XErGZPzN9eeFWrMfCxk0deczx9FlWVCAaS+dt64L/7r7BAbG07hv3yD+7NrtuOacvqLfY4yhtz2BI8Oz+IMf7sEDL53GG89cjoyq24UCtSLMs18M4DDn/FVrsXcCeDeAqgfuv77/AHrbEtjW146tfe0Ys1TqnU8PoD2p4PIty4se/4k3bwEH8PUHX8GBoRn0tJmzCm7/zxejNaHgb65/LbKaji/v3I8v7ywk6SRmJhb6OpM4f10XrjhrOY4Mz3rUtpO4IuFffu8i3yl3F21chpa4jL98zzl47+vWAgC++/GL8N5/eBzX3/qkPbjq7lsux7lrO4t+V5El/Om12/H88Ql0pmJoT8Zw795TuPF7u/Hmrb345FVb0NuWxKFhM3gFKe6YLOGmN24q+t7KjiTev2OtXT552w0X+l6cFsKqrhQMDrx4chq33XBhydevqyWGlR1JfOW954IxhjNXtuMzbz0TX33AtLL8bBLB9lXteOTgCD7/sxdw375BzGQ13HbDhZ4phE7+z/teC845hqaz2D84jTNXtJdc28dfvwG3PXoEc3kdb39N4cRc1hrHjo3d+NVLp3HlWb04PDyL4xNpJBQZbQkFrQkZM1kNY3N5jM3m8MrpWRwcmkFG1XHtuX1FdxDre1pwy5WboQcoMUli+Nzbz8Kf/Gwf3rZ9Jd77urW4bHNPyTzDhp5WfPCidbhj10BJbzmdV7CyI5zNkIrL+Nzbt+ITb96Ce58/hZ89ewL3vTCIH1mWk8SACzcswx9dvRUXrOvClpVt6G1LYCqjYtfRcTxzdBxvPMsbuG+4bCNuuGxj0ffW97Rgc28rjozMeTzuSjFHu+aRVXWMzOQwm9PQGlfQZk2RHJ/LY3Q2h5GZHAanshiczOBXLw3hhks3Fg27ev+Fa/HFe17EwdMzuPmKTfj9Kzb5/n+97Qk8uH8YMZnhz67djhvfcEaoZHClhDmD1wBwlm+cAHBJtRei6gZ+uueEb2nNyo4E/uSabR6/T5IYPv2WM3Humk58+s7n8PLgNP78HWfj7NVm4k2RJXzjgxfgqm2nMJtVIUkMhsExNpfH4FQWJybSuPOZAdz+xDEA8E2Quf8/v4Dx+i3L8eKXri46YFv72vHND1+A//qDPXjneavxl+85x3NbKPjIJevxEatjEABuedNmfO+JY/jGg4fwvluftL8vS8yeTjYf/uDKzbhr93FctW1FUXCqFJEP+P03nhH4vD+48RKs7kwVnRg3X7EJD7w0hKQiB14wz13TibufPYl7957CNef04QM71nnsJj8YY1jVmbJ36ylFV0scv3/FJuzcN4gLXMr6rdtX4Cs7D+D6/2ceA4kBbhdLkRiWtcaxaXkrPnTxOmxf1eF7IQpzl3PNOas8t+NBfOqqM/Hz5076vid62uLoaYuXLB0tRTIm4wMXrcMHLloHzjlGZnI4NpbGWSvbPJMYAfP1u/o1fbh6nu+rq7atwJGRo772SiV0tcTw6/2nse3P7w/1+IQiYWNPKz522Yai77/zvNX4+q9fwZu3rcDnr/G/IwTMi1kmr+Nr7z/PI8pqCSvnxzDG3g/gas75TdbXNwC4mHP+KdfjbgZwMwCsX7/+wv7+fs9zhWFkJoeDQzM4MDSNjmQMl2zqxvrulrJvwP6xOTz16hjef+G6eV3xsqqO3ccm8NSrY3jb2SvLer/zZS6nFd2ez4fR2Rye7Z/AVEbFVEbFmq4UfidAnQbRPzaHvs6kx8qoBN3geOTgMK44qzd0yZaTTF4HBw+8rcyqOnYdHbfuamp7++lmNqfh58+dxJquJLb0tmPNshQMbpaFzuY0tCdi6Eh5S+AWk+HpLDpbYp7jOjCWhiQBawPKR+vJyckMfvhUP/7o7VurqlCfPDKGnfsGsaI9gZWdSbRbZY6zWRWqzq0LWgK9bQms6kyiqyVW8vhlfTYGqSWMsT2c8x2hHhsicF8G4Euc86utr78AAJzzvyr1Ozt27OC7d+8Ov2KCIIgmZz6BO4xMegbAmYyxMxhjcQAfAufO2rQAAAR3SURBVHBvJQskCIIgFk7Ze0/OucYY+ySABwDIAP6Zc/5SzVdGEARB+BLKNOSc7wSws8ZrIQiCIEIQmc5JgiAIwoQCN0EQRMSgwE0QBBExKHATBEFEDArcBEEQEaNsA86CnpSxEQALa50ElgNY+AT76EJ/d3NBf3dzEebv3sA59w588aEmgbsSGGO7w3YPLSXo724u6O9uLqr9d5NVQhAEETEocBMEQUSMRgzct9V7AXWC/u7mgv7u5qKqf3fDedwEQRBEMI2ouAmCIIgAGiZw13tD4sWCMbaOMfYwY2w/Y+wlxthnrO93M8Z+zRg7ZH1cVu65oghjTGaMPccY+6X19RmMsV3W3/0Ta3TwkoMx1sUY+ylj7IB17C9rhmPOGPvv1vv8RcbYjxljyaV4zBlj/8wYG2aMvej4nu/xZSbftGLdC4yx1833/2uIwO3YkPh3AJwN4MOMsbPru6qaoQH4HOd8O4BLAXzC+ls/D+A3nPMzAfzG+nop8hkA+x1f/zWAr1t/9wSAG+uyqtrz9wDu55xvA3AezNdgSR9zxtgaAJ8GsINzfg7MsdAfwtI85rcDuMb1vVLH93cAnGn9uxnArfP9zxoicMOxITHnPA9AbEi85OCcD3LOn7U+n4F5Aq+B+fd+z3rY9wC8pz4rrB2MsbUArgPwHetrBuAqAD+1HrJU/+4OAFcA+C4AcM7znPNJNMExhzk6OsUYUwC0ABjEEjzmnPNHAYy7vl3q+L4bwPe5yVMAuhhj89qTsFECt9+GxGvqtJZFgzG2EcAFAHYBWMk5HwTM4A5gRf1WVjO+AeCPARjW1z0AJjnnmvX1Uj3umwCMAPgXyyb6DmOsFUv8mHPOTwL4GoABmAF7CsAeNMcxB0of34rjXaMEbr/dOpd0uQtjrA3AzwD8Ied8ut7rqTWMsXcAGOac73F+2+ehS/G4KwBeB+BWzvkFAOawxGwRPyxP990AzgCwGkArTJvAzVI85kFU/L5vlMB9AsA6x9drAZyq01pqDmMsBjNo38E5v9v69mlxu2R9HK7X+mrE5QDexRg7BtMKuwqmAu+ybqOBpXvcTwA4wTnfZX39U5iBfKkf87cCOMo5H+GcqwDuBvB6NMcxB0of34rjXaME7qbZkNjydb8LYD/n/O8cP7oXwMetzz8O4N8We221hHP+Bc75Ws75RpjH9yHO+UcBPAzgeuthS+7vBgDO+RCA44yxrda33gLgZSzxYw7TIrmUMdZive/F373kj7lFqeN7L4CPWdUllwKYEpZKaDjnDfEPwLUAXgFwBMCf1Xs9Nfw73wDztugFAM9b/66F6ff+BsAh62N3vddaw9fgTQB+aX2+CcDTAA4D+FcAiXqvr0Z/8/kAdlvH/R4Ay5rhmAP4XwAOAHgRwA8AJJbiMQfwY5g+vgpTUd9Y6vjCtEq+bcW6fTCrbub1/1HnJEEQRMRoFKuEIAiCCAkFboIgiIhBgZsgCCJiUOAmCIKIGBS4CYIgIgYFboIgiIhBgZsgCCJiUOAmCIKIGP8fpCByTCXcqGYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(d_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1a8ff828>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(g_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 2.8195,  2.1343,  0.3963, -3.4076,  1.1442, -1.3433,  0.2763,\n",
       "           2.0909, -0.4845, -1.7359,  3.1373,  1.0926, -3.6228, -2.2626,\n",
       "          -2.4189,  3.1554,  1.3601, -0.3009, -3.2146, -1.5514,  0.3045,\n",
       "           0.0922, -2.6943, -2.3708,  1.4809, -3.2463,  1.5680,  2.6763,\n",
       "          -2.2171]]),\n",
       " tensor([[ 1.8105, -0.9378, -0.5262, -2.8368, -3.1370,  1.7456, -2.7901,\n",
       "          -1.8285,  0.8825,  2.2305, -1.5074,  2.1570, -1.8866,  3.1639,\n",
       "          -0.8872,  1.0748,  2.8808,  2.6888,  0.5597,  2.2540, -2.6049,\n",
       "          -2.7951, -2.1277, -1.2360, -0.4711, -1.4338,  1.8291, -2.2124,\n",
       "           3.3894]]),\n",
       " tensor([[-2.6453, -3.3355, -0.9846, -2.4476,  0.5934, -0.3117,  0.4873,\n",
       "           2.3839,  0.7258, -0.5755, -2.6513,  0.8667,  2.1620, -1.5349,\n",
       "           0.8133,  0.6823,  0.8383,  3.0857, -3.9343,  3.5478, -0.2898,\n",
       "          -1.8000, -2.9396, -0.5896, -2.8530, -3.1375,  3.1373,  3.5685,\n",
       "           1.0524]]),\n",
       " tensor([[ 0.2264,  3.6978, -0.9605, -0.4865, -2.2705, -2.3710,  2.6645,\n",
       "          -0.2772, -0.0033,  2.1763, -0.4126, -4.0883,  2.5876, -2.5036,\n",
       "           1.2627, -2.6531,  0.2408, -0.0657,  2.2420,  3.3299, -2.3390,\n",
       "           2.1712, -3.3865, -1.0144, -1.0099, -1.8576,  0.8543,  0.2767,\n",
       "           0.7123]]),\n",
       " tensor([[-0.1293,  2.3566,  0.2186,  1.8371, -1.3132,  1.2922, -3.4181,\n",
       "          -0.4507,  3.4753,  0.0077, -0.4076,  2.9750, -1.0404,  1.1173,\n",
       "          -1.8064,  3.1954, -2.4931, -1.1975, -1.0389, -1.3059, -1.5062,\n",
       "           0.5289,  2.5160,  2.0628, -1.4823,  3.4101,  3.0848, -2.7094,\n",
       "          -1.5945]]),\n",
       " tensor([[ 1.2249, -2.9860,  1.3058, -0.8817, -0.7591,  2.9869, -1.2579,\n",
       "           0.5748,  3.2106,  2.4303, -3.3828, -3.3770,  1.8692, -3.3570,\n",
       "           3.1571, -2.2522,  0.0781, -1.7078, -0.9093, -3.7531, -2.8542,\n",
       "           1.4664,  0.9523, -3.3271, -2.5885, -0.1657,  2.4536, -3.2385,\n",
       "          -0.0279]]),\n",
       " tensor([[ 0.7863,  0.3376, -3.9614, -0.9856, -1.2776, -0.7425,  0.8843,\n",
       "           1.1341,  1.0618, -2.1418, -3.6293, -3.5785,  2.7031,  0.0603,\n",
       "           0.3262, -3.7479, -1.7196, -2.2706, -1.5628,  1.1186,  2.2543,\n",
       "           1.1107, -2.8967, -0.7478,  0.1262, -1.5769,  2.7310, -2.4059,\n",
       "           0.9425]]),\n",
       " tensor([[ 1.3508, -1.7440,  0.7948, -0.1196,  2.0501, -1.2068,  2.4530,\n",
       "          -1.8533, -1.8703,  0.2694, -0.8703,  2.4478,  1.5025, -0.0432,\n",
       "           1.2845,  1.5966, -3.5933, -0.1531, -1.1698, -2.0571, -1.9931,\n",
       "           3.6905,  3.1507, -0.5483,  2.6434,  2.5057, -0.3833, -1.6280,\n",
       "          -2.8406]]),\n",
       " tensor([[-2.9159, -0.4179,  2.9800, -1.3841,  2.1830, -2.2878, -1.4724,\n",
       "          -0.6390, -3.1109,  0.7271,  2.9074, -1.7922,  2.4780,  0.9447,\n",
       "           3.0638,  2.1082,  0.9255,  1.8803,  1.4956, -3.0770, -1.8571,\n",
       "           0.0456,  0.4289,  1.7849, -1.3654,  0.1663, -1.5276,  1.9349,\n",
       "           1.2081]]),\n",
       " tensor([[-1.4798, -1.3939, -1.1773,  2.8380,  1.1939, -2.7811,  0.5383,\n",
       "           1.8980,  3.1769, -1.9483, -1.7402,  1.4604, -1.3700,  3.0504,\n",
       "           1.2355,  0.2964, -0.9803, -2.6224,  3.2544, -0.2265,  3.6164,\n",
       "           3.4587, -0.7215, -3.4001, -1.3608,  0.3766, -2.4812,  0.1575,\n",
       "           2.5948]]),\n",
       " tensor([[ 0.0329, -3.2940,  2.6631,  1.3421, -1.9080, -0.5961, -3.8767,\n",
       "          -1.6826,  0.3327,  0.5644,  0.6890,  3.4904,  3.7649,  1.8024,\n",
       "          -3.4176, -0.9420,  2.0898, -1.1515,  0.7775,  1.1358,  3.1349,\n",
       "           1.2772,  1.1934,  1.4644, -2.8266, -3.6822, -2.8500,  1.0655,\n",
       "          -1.3650]]),\n",
       " tensor([[-0.4220,  3.1076, -1.5205, -1.1988,  3.7692,  3.4603, -1.1044,\n",
       "          -1.6683, -3.4748,  1.6740, -1.2091, -1.4299,  2.2202, -3.8853,\n",
       "          -1.1652, -3.0109,  3.7007,  1.9862, -2.9314, -1.6319,  3.3472,\n",
       "          -1.4058, -0.8393, -1.7158, -0.0769,  2.8587, -0.2465,  2.9698,\n",
       "          -1.2061]]),\n",
       " tensor([[ 3.3880,  0.0227,  2.6080, -1.9369,  3.5489, -0.7224,  3.3100,\n",
       "           1.3802, -1.6608,  1.7814, -0.9514,  2.9712,  2.6256, -1.9883,\n",
       "          -1.2229, -3.8877, -0.4390, -0.7540, -0.3458, -1.3820, -3.7819,\n",
       "          -1.3668, -2.3948,  1.7382, -0.3056, -3.5856, -1.2761,  3.7032,\n",
       "          -2.1358]]),\n",
       " tensor([[-0.1911,  0.9328,  0.9179,  1.0246, -0.3897, -1.5062,  0.4976,\n",
       "           0.4958,  2.6069, -0.6112, -2.7688, -0.0604,  1.3776,  1.3293,\n",
       "           1.2445,  1.3456,  0.5608,  3.0164,  0.7498, -1.5248,  2.5675,\n",
       "          -0.4569, -2.0190,  1.1112,  2.4013,  1.4269, -1.7969, -0.6844,\n",
       "           1.9227]]),\n",
       " tensor([[ 3.8800,  0.9384, -0.1973,  1.7953,  0.7551, -0.5104,  2.3811,\n",
       "          -2.5495, -0.8977, -0.7256,  2.2790,  2.9097, -2.1839, -2.1886,\n",
       "           1.1722,  2.3766,  1.0104,  3.2243, -0.2357, -1.7961,  2.4907,\n",
       "           0.3152,  1.7192,  1.3071, -3.3644,  1.2548, -1.1157,  0.6807,\n",
       "          -0.1041]]),\n",
       " tensor([[-0.9015, -3.1457,  1.7199,  1.8493, -1.8467,  1.9657, -1.0220,\n",
       "           0.2425,  1.5401, -2.5271, -0.9954, -2.3614,  2.3482,  1.6984,\n",
       "          -2.5146,  1.1516,  0.5869,  0.4973, -1.2156,  1.6661, -3.0986,\n",
       "          -3.3818,  1.0188, -1.1681, -1.2297, -0.6880,  1.0000,  1.5243,\n",
       "          -0.1476]]),\n",
       " tensor([[ 0.6156, -2.5817,  3.1928, -1.2495,  3.6628,  0.0880, -0.5961,\n",
       "           0.5468,  3.3508, -3.2548, -2.5782,  3.0239, -1.7405,  1.0668,\n",
       "           1.2146,  0.6198,  3.5342, -0.4872, -0.1922, -3.3095,  2.9301,\n",
       "           3.0039,  2.6431,  2.8847, -3.8468,  0.0040, -0.6651,  3.1810,\n",
       "           2.2985]]),\n",
       " tensor([[ 2.8524, -0.1877,  0.4791, -1.4379,  3.1415, -0.2858, -2.3485,\n",
       "           0.6262,  0.7771, -2.9398,  0.9859,  0.3889,  0.3769, -0.0702,\n",
       "          -0.1021,  2.0308, -3.2123,  2.8263, -2.2376,  0.7319, -1.1628,\n",
       "          -0.5146, -0.9657, -0.5777, -3.3991,  2.5845,  2.8127, -1.4702,\n",
       "           2.7999]]),\n",
       " tensor([[ 1.0985,  0.7372,  2.7749, -1.1126,  3.0484, -1.9225,  1.2055,\n",
       "          -1.1174,  0.8513, -2.0809,  0.2220, -2.6017,  0.0669, -0.8689,\n",
       "           1.2326, -2.8777,  0.7017,  3.5353,  3.8042, -1.1056, -2.8142,\n",
       "          -1.2817,  1.2473,  0.6393, -3.4757, -0.6144,  2.2008, -0.2866,\n",
       "           1.5271]]),\n",
       " tensor([[ 0.7767,  1.7257, -2.0317,  2.9191,  3.0103,  2.8899,  3.0584,\n",
       "          -0.2339, -2.3025,  2.7672,  2.0701,  2.7143,  0.4912, -1.5318,\n",
       "           2.0643,  2.4770,  1.4712,  0.4015,  2.0830,  3.7890,  3.9502,\n",
       "          -0.5668,  2.5875, -0.0101,  2.1317,  2.1970, -1.2600,  0.2504,\n",
       "          -3.4716]]),\n",
       " tensor([[-1.8586,  2.1639,  3.7160,  1.3955, -0.0260,  0.8145,  3.8210,\n",
       "          -3.1516,  0.7805,  1.4247, -3.1914, -0.6697, -2.7759, -0.0012,\n",
       "          -1.6188,  1.2365, -1.0876, -2.1863,  0.3864,  0.9796,  0.0523,\n",
       "           2.3033,  3.5356,  0.6230, -0.7535,  0.9910, -0.9856, -2.5816,\n",
       "           0.4964]]),\n",
       " tensor([[-0.1070, -3.0833,  1.0472, -1.3299,  0.3052, -1.3002, -2.3086,\n",
       "          -1.8794,  2.2115, -2.2614,  3.3110, -0.8845,  1.4590,  0.6179,\n",
       "           1.1347, -0.7410, -2.1425,  3.7534, -2.9806,  0.0869,  0.8605,\n",
       "          -2.4916, -0.5857,  3.3526, -0.9764,  2.2154,  1.3890,  2.9519,\n",
       "           0.3849]]),\n",
       " tensor([[-3.3408, -2.7672,  1.3553, -0.3298, -3.6388, -2.9550,  0.2213,\n",
       "           2.1256,  0.6846, -0.1043,  0.3112, -0.8041,  2.6298,  1.9364,\n",
       "          -0.3808,  3.6349,  2.9859,  0.2958, -1.7910,  2.5182,  0.9224,\n",
       "          -1.5866,  1.1802, -0.1593, -3.3169,  0.3609,  0.9540,  1.7332,\n",
       "           0.7093]]),\n",
       " tensor([[ 3.0713, -2.4125,  1.3332, -1.4454, -3.0600,  2.7066,  1.7023,\n",
       "          -0.9482, -0.8399,  0.8607,  1.6489, -2.9850, -2.5190,  1.7562,\n",
       "          -0.1273, -2.6208, -0.9161,  2.2631,  2.8939, -1.2639, -0.9448,\n",
       "          -1.0905, -0.6793,  0.2459, -0.5661,  1.8674,  3.0988, -1.8642,\n",
       "           2.1090]]),\n",
       " tensor([[-0.0228,  3.1318, -1.2294,  2.2225,  1.1721,  0.5094,  1.7548,\n",
       "           0.6285,  1.6419,  2.9187,  0.3782,  1.5308,  0.5826, -3.4699,\n",
       "          -0.8830,  0.0753,  1.9192,  2.7324, -2.4226,  2.5554, -0.1457,\n",
       "          -2.7145, -0.6348,  3.7480,  0.0215, -1.6227,  2.3616,  3.4927,\n",
       "           1.6984]]),\n",
       " tensor([[-2.2368, -3.2246,  3.2306,  3.3352,  2.0166, -3.0650,  1.7499,\n",
       "          -0.0020,  0.2748, -2.4340, -0.1164, -0.0755,  0.6094, -2.6393,\n",
       "           3.4465,  1.5024, -2.4185,  1.1883,  1.2865, -2.2189,  2.0150,\n",
       "           1.5876, -0.0025, -0.5828,  1.0615,  0.4327,  3.4500, -1.0771,\n",
       "           1.5260]]),\n",
       " tensor([[ 3.2618, -2.6952,  2.0664, -1.5756,  3.2171,  0.5564,  1.0492,\n",
       "          -1.7330, -3.0496, -0.1474, -1.1472, -0.8354, -2.1140, -2.4465,\n",
       "          -1.5727, -1.2667,  0.8220,  1.4141, -3.7442,  0.1939, -2.0622,\n",
       "           3.3776, -1.4444,  3.8993,  3.4880,  3.2711, -2.0119,  0.3463,\n",
       "           2.2694]]),\n",
       " tensor([[ 0.5935, -0.9618,  0.8029,  0.4037,  1.9183, -3.4609, -0.2125,\n",
       "           0.9562,  0.6342, -1.0370, -2.5104, -0.7502, -0.7340, -3.2829,\n",
       "          -0.9111, -0.0762,  1.0290,  0.4206,  2.9490,  3.2471,  0.5428,\n",
       "           0.9529,  1.4836, -2.5723, -0.4568, -0.1487, -0.9260,  2.2175,\n",
       "           2.1181]]),\n",
       " tensor([[-2.0187, -0.7253,  0.3927, -1.6130, -2.0645, -2.1453,  2.8523,\n",
       "          -0.9145,  2.9779,  3.2655, -1.0541,  0.6495,  0.7283, -2.1959,\n",
       "           0.8869,  3.0256,  0.5019,  2.0245, -0.7144,  1.5682, -1.5507,\n",
       "          -2.0838,  0.9178, -2.6795, -1.5682, -0.2433,  2.1058, -1.0990,\n",
       "          -1.4779]]),\n",
       " tensor([[ 2.4504,  0.4051, -1.9014, -2.3643,  2.3830,  0.1997, -1.8740,\n",
       "          -0.5489,  1.2585, -0.9549, -0.0425,  1.3964,  0.8370, -3.9854,\n",
       "          -3.5662, -0.7631, -2.2971,  0.3570, -3.3817, -2.3170,  1.3190,\n",
       "           2.2344,  3.7973,  0.7249,  1.9015,  1.7749,  0.5464,  1.8877,\n",
       "           2.3463]]),\n",
       " tensor([[ 3.4219,  1.2723,  1.9258,  0.7066, -1.0092, -3.5915, -0.2749,\n",
       "          -3.2902,  1.4326, -1.1241,  0.2114, -0.4269, -2.3133,  2.5776,\n",
       "          -2.3731,  0.6125, -2.4145,  1.6587, -2.9112,  3.5369,  1.4678,\n",
       "          -2.8248, -2.4608, -2.9836, -3.6370, -3.1744, -0.3525,  3.0361,\n",
       "          -3.1629]]),\n",
       " tensor([[-2.3367, -0.9752, -0.3107,  0.4422,  2.7840,  1.2473, -2.8469,\n",
       "           2.8746,  3.0405, -0.6859, -2.9386,  3.8961,  0.7378,  2.3005,\n",
       "          -0.0559, -2.1490, -2.0555, -0.3533, -1.4751, -2.5719, -2.8575,\n",
       "          -1.6153,  3.4767, -1.5725, -2.2884,  1.1926, -0.9909, -1.2619,\n",
       "          -0.0444]]),\n",
       " tensor([[-0.6782, -2.6886, -0.4446,  2.9721, -0.9453, -0.1949, -2.8737,\n",
       "           1.0574, -1.0454,  2.0714,  3.5026, -1.4512,  2.4522,  0.1834,\n",
       "           1.6127,  0.6603,  3.5580, -2.1055,  0.9286, -0.1595,  2.5760,\n",
       "           1.0714,  0.2355,  1.8619, -1.1418, -3.1048,  0.1966, -2.1390,\n",
       "          -2.7921]]),\n",
       " tensor([[-2.8679, -2.3241,  2.7662, -1.3729,  2.4614, -1.3218, -0.1518,\n",
       "           2.6364,  1.8260,  1.6186,  3.9408, -3.7273, -3.2095, -3.8425,\n",
       "           2.9715, -1.4830, -1.7148,  1.0031, -1.3203, -2.1923, -2.7837,\n",
       "          -0.5033,  2.6501, -2.3531,  3.8962, -1.2894, -3.1569,  2.7690,\n",
       "           2.5765]]),\n",
       " tensor([[-3.0112,  1.5444, -3.6067,  0.1361,  2.4755,  0.7515,  3.1772,\n",
       "           1.4321, -3.0423, -1.9245,  0.5055,  1.1048, -0.2113, -0.7175,\n",
       "           3.4311, -3.2040, -2.5843,  0.3386, -2.3846, -1.6588, -2.1905,\n",
       "           1.2373, -2.4105, -3.8755,  1.8074,  1.0847, -1.6483,  0.4947,\n",
       "          -0.1740]]),\n",
       " tensor([[-0.2215, -1.9549,  1.1554,  2.9384,  1.0171,  2.6736, -0.7669,\n",
       "           2.4520,  1.9666,  2.9289, -0.6254,  3.4641,  0.6906, -1.9750,\n",
       "          -0.1011,  2.7389,  1.3867, -0.5328,  0.0252, -1.9286,  1.7548,\n",
       "           2.5521,  2.5847,  3.0592, -3.1992,  2.9928,  1.2349,  0.7842,\n",
       "          -0.8553]]),\n",
       " tensor([[-3.8284,  1.0327,  0.1160,  1.6445, -3.1545,  0.7960, -1.3469,\n",
       "           2.3992,  1.0817, -2.3276,  0.2172, -3.8863,  2.3414,  1.3054,\n",
       "           1.0663,  3.8400, -3.0067,  1.5916,  0.2969, -0.4322, -1.4346,\n",
       "          -2.3032,  2.5604, -1.2508, -3.7780, -0.5483,  1.3251, -0.8008,\n",
       "           2.7576]]),\n",
       " tensor([[ 0.5109, -2.6069,  2.7061,  3.7915, -1.9144,  1.3528,  1.9180,\n",
       "          -3.2641,  0.6351, -0.2844,  1.7692,  0.8373, -0.1788, -1.7079,\n",
       "          -0.4009,  0.9636,  3.5794, -1.5839, -3.2284,  0.9532, -1.6272,\n",
       "           2.7653,  2.3599,  0.4489, -2.0940,  2.6012,  1.4926,  0.9611,\n",
       "          -1.8049]]),\n",
       " tensor([[ 0.5693, -3.6254,  1.7580, -2.5980,  1.7808,  3.8232,  2.3920,\n",
       "          -3.5802, -1.8096,  0.7870,  0.1994, -1.2829,  3.8467, -1.5297,\n",
       "           3.9380, -1.5897, -0.7837,  2.4817,  2.5788, -2.8485, -0.4036,\n",
       "           2.9069,  1.3752,  1.5291,  1.5995,  2.0495, -1.4027, -1.0809,\n",
       "           1.0763]]),\n",
       " tensor([[ 2.4703,  0.8178,  0.5535, -3.0365, -1.5980,  1.7672, -0.3995,\n",
       "           2.9641, -1.1377, -0.1955,  3.1791, -1.2545, -3.8521, -3.6877,\n",
       "           3.4744,  1.4076,  1.9187, -2.0302, -3.4036,  1.7719,  3.3097,\n",
       "          -2.5314,  2.8867, -2.1032, -0.5680,  1.2082, -1.1402, -1.7240,\n",
       "           1.2413]]),\n",
       " tensor([[-0.5737, -1.5943,  0.9250,  0.5843, -2.8438,  3.3910, -2.5107,\n",
       "          -0.3233,  2.4389,  1.6958,  1.8130,  0.1744,  3.3651, -1.0226,\n",
       "          -1.4926, -0.3829,  1.0159, -2.3529, -1.1287, -3.2963,  1.5465,\n",
       "          -1.4494,  3.4190, -0.8561, -3.9404, -0.3851, -0.4541,  0.6100,\n",
       "           3.2044]]),\n",
       " tensor([[ 0.4532,  1.3622, -2.4325,  2.0273,  1.0939, -2.4078,  0.0228,\n",
       "          -1.2846, -2.0394, -1.1191, -1.5717, -1.7822, -1.1055,  2.8018,\n",
       "          -0.2143, -1.8259,  2.4304,  1.3984,  0.2097,  2.8421,  2.3434,\n",
       "          -2.0096, -2.5893, -1.3063, -3.1164,  0.7751,  0.7372,  1.5799,\n",
       "          -2.3154]]),\n",
       " tensor([[-0.5437,  1.4717, -1.1761,  3.0836, -0.1469, -1.8222, -2.7820,\n",
       "          -1.5977, -1.3490,  1.1532,  0.2889,  1.5224,  1.9737, -0.2293,\n",
       "          -1.0210, -0.4049, -3.3328,  0.2533,  2.3546,  2.8787,  0.0096,\n",
       "          -3.2638, -1.3740,  0.6168,  3.7523,  0.3684, -2.0937, -1.2709,\n",
       "          -2.5126]]),\n",
       " tensor([[ 3.1433, -2.4714, -2.1823,  0.9842, -0.6195, -3.1103, -0.8589,\n",
       "           0.2360,  2.7088,  2.6701,  1.0426,  1.5781,  3.2343, -1.3162,\n",
       "          -2.3954,  0.1009,  3.1035,  0.1208,  0.5280, -0.7406, -3.2941,\n",
       "          -1.8785,  0.7324,  0.9015,  0.0053, -3.4425, -1.2038,  0.4036,\n",
       "          -2.1833]]),\n",
       " tensor([[ 0.6188,  3.4466,  2.6660, -1.5357, -2.0365,  1.6084,  2.2711,\n",
       "           0.7498,  3.2058,  3.9993, -0.7910, -2.1799, -2.6778, -3.8683,\n",
       "          -0.3918, -1.0546, -0.5572,  0.6187, -2.7833,  0.3717,  3.4119,\n",
       "          -0.2184, -0.3416,  1.9182, -2.6814,  1.4561, -3.6140,  1.0855,\n",
       "           2.1168]]),\n",
       " tensor([[-3.2425,  2.4821,  1.3535, -2.2738,  2.2669, -0.2739,  3.8365,\n",
       "          -0.7712,  1.7722, -3.5794,  0.8058,  2.0390,  1.3198,  2.6424,\n",
       "           1.1071, -2.6819, -2.4360,  3.6382,  3.0829, -0.8127,  0.0974,\n",
       "           3.4912,  2.5632,  2.8812,  2.4715,  0.3272,  1.4708,  2.9727,\n",
       "           1.3057]]),\n",
       " tensor([[ 0.4069,  1.4099, -2.6408,  0.0111,  1.1438, -0.9804, -3.2237,\n",
       "          -2.3519, -1.8910, -3.0382, -1.3221, -0.5910, -2.6068, -0.1529,\n",
       "           3.4138,  2.3929, -0.8032,  2.3406,  1.3806,  2.2173,  3.3711,\n",
       "          -3.0095, -3.4624, -0.0949,  1.6614, -1.2882,  1.4613, -2.6022,\n",
       "           0.2427]]),\n",
       " tensor([[ 0.5721, -3.3754, -0.8845,  1.7004, -2.3578,  3.7645,  1.8790,\n",
       "          -0.7478,  2.7641,  2.4673,  3.0411, -2.4265, -3.2212,  2.6452,\n",
       "           2.4937, -2.0959, -2.0067, -1.0110, -2.2814,  1.0877,  0.3494,\n",
       "          -0.7398, -1.7530, -0.9493, -2.7306, -3.6619,  3.0009,  0.6987,\n",
       "           3.0465]]),\n",
       " tensor([[ 1.5960, -3.2704,  1.7591,  1.6235,  2.5908,  1.1958, -1.7466,\n",
       "          -0.5324, -2.2371, -2.3394,  1.8712,  0.8316,  2.6118,  1.0342,\n",
       "          -0.1890,  1.2993,  2.7744, -2.0258,  3.8245, -2.6623,  1.3522,\n",
       "           3.5356, -1.9786,  0.1254,  0.6541,  0.1711, -1.5063,  1.9411,\n",
       "          -0.4920]]),\n",
       " tensor([[ 0.5844,  2.2002,  1.4108,  2.7565, -0.8613,  1.6825, -1.0322,\n",
       "          -0.5572,  0.1147,  0.5570, -0.7966,  2.3493, -2.9536,  1.4224,\n",
       "          -0.0251, -1.9805,  1.7685,  0.6450,  2.1265,  2.1374,  1.2762,\n",
       "          -0.5257, -2.6065, -3.0002,  3.6217,  3.7193, -1.6217,  1.9813,\n",
       "           2.8465]]),\n",
       " tensor([[ 1.7681,  0.5703,  1.7548,  0.3655,  1.8754,  0.9643,  1.1121,\n",
       "           2.6769,  2.4840, -3.3829, -0.6513,  3.6417,  2.9071,  3.7918,\n",
       "          -3.0016,  3.3814,  3.4196,  2.7131,  0.8081, -1.0865,  3.1341,\n",
       "          -2.8120, -3.2831, -0.0138, -0.4967,  0.5874,  2.3967,  1.0722,\n",
       "          -0.7127]]),\n",
       " tensor([[-1.5713, -2.1001, -1.7526, -0.0309,  2.8838,  2.5910,  2.8874,\n",
       "           3.3226,  3.5758, -1.1788, -0.3324,  3.1057, -1.0198,  1.8474,\n",
       "          -0.6830,  2.3082,  1.0275,  0.5827, -0.5588,  0.9411,  0.2770,\n",
       "          -3.0780, -1.2830,  0.5970, -1.1052,  0.5238,  1.4742,  0.6917,\n",
       "          -2.8055]]),\n",
       " tensor([[-2.5736,  2.2944, -2.3156, -2.0732,  1.2342, -3.8505,  2.1589,\n",
       "           3.0673, -3.6231,  1.0009, -1.4212, -1.9658,  2.1039,  0.5190,\n",
       "           2.3109,  1.5017, -2.9979,  1.1722, -1.0918,  1.2027, -2.4393,\n",
       "          -2.7009,  0.6691,  1.0444,  0.2299, -2.4262, -3.7951,  0.7434,\n",
       "          -2.3025]]),\n",
       " tensor([[-0.6773,  0.1517,  2.8377, -2.3536, -1.1962,  1.1808,  0.7746,\n",
       "          -3.7348, -1.8424, -1.4163,  1.1543,  2.7617, -2.0968, -0.6775,\n",
       "          -0.6388,  1.0290, -1.0714, -2.5755, -0.2073,  0.0842,  0.8112,\n",
       "          -1.2671,  0.0833,  1.1462, -2.6908, -0.1655,  3.3394, -2.8782,\n",
       "          -0.9620]]),\n",
       " tensor([[-0.4416, -3.6792, -1.7738, -2.3378,  2.7247, -1.3424,  1.6292,\n",
       "           0.9250, -1.5500, -2.2415, -0.5302,  3.8730,  1.4969, -2.5122,\n",
       "          -1.3975,  0.2729, -3.1532,  2.7643,  1.5629,  2.6246,  0.9727,\n",
       "           1.9915,  1.7307,  1.4031, -0.9778, -0.6097,  1.6723,  0.3112,\n",
       "          -3.0734]]),\n",
       " tensor([[ 0.0961,  2.1407,  2.4290,  1.3500, -0.8820,  2.6626, -2.9820,\n",
       "           2.5345, -0.9017, -0.8507, -0.8453,  2.1717,  1.1636,  3.2596,\n",
       "           2.1457,  1.8815, -1.3101,  0.2741,  1.2761, -2.7525, -1.8861,\n",
       "           2.5800, -2.5941,  0.4038,  2.8809, -2.3071, -1.2870,  0.1772,\n",
       "           0.0585]]),\n",
       " tensor([[ 3.5939,  0.8166,  3.1372,  1.1301, -2.9025,  2.1031,  0.9064,\n",
       "          -2.2730,  0.4924,  1.4707,  3.3764,  2.2343,  2.0549,  0.0813,\n",
       "          -2.5639, -0.2457, -2.7668, -1.1642, -3.1448, -1.2661, -3.2563,\n",
       "          -2.0455,  3.6425,  1.2311,  1.0967, -3.2701,  0.4915,  0.4143,\n",
       "          -0.2832]]),\n",
       " tensor([[-0.8009,  2.0666,  0.6083, -3.3217, -1.0120,  0.6772,  2.6314,\n",
       "          -2.9731, -2.3760, -1.4980,  0.6187,  1.1858, -0.1637,  0.9008,\n",
       "          -1.0328, -0.9009, -0.9982,  2.9529, -2.9210, -0.3985, -1.3338,\n",
       "           2.6107,  1.8981,  0.2426,  0.1778, -1.4021,  0.6555,  2.1926,\n",
       "          -0.0611]]),\n",
       " tensor([[ 2.3505,  2.2217, -1.3511,  3.9760, -2.3982,  2.0617,  2.5411,\n",
       "          -1.5756,  1.3770,  0.3507,  1.1186,  0.2871, -1.8892,  1.9024,\n",
       "          -0.3486, -0.9721,  0.4040,  2.3160, -0.9225,  2.4544,  0.6871,\n",
       "          -2.7371, -1.4608,  3.8272, -0.2329, -2.8667, -3.5266, -3.0466,\n",
       "          -2.3970]]),\n",
       " tensor([[ 1.9745,  0.9416,  0.8343,  0.4269,  2.1175,  0.3634, -2.0529,\n",
       "           0.0440, -3.4215,  0.3872,  1.1669,  3.4671, -0.8198, -0.9857,\n",
       "           0.3681,  1.0600, -0.5142, -3.8802,  0.1671,  1.1604, -0.0900,\n",
       "           0.1016, -3.9466, -3.2516,  1.4021,  3.0073,  1.0902,  0.7926,\n",
       "          -2.6914]]),\n",
       " tensor([[-0.4874, -0.0006, -2.2063,  2.7229, -2.2602, -1.2199,  3.5402,\n",
       "          -0.9824,  0.4522,  2.4883, -1.7219,  3.2931, -1.7763, -2.3249,\n",
       "           3.4808,  0.7056,  3.4828, -1.2692,  2.1954, -0.3723, -2.1728,\n",
       "          -1.2262, -1.1133, -2.4903,  3.5062,  0.4164,  1.5335, -0.5313,\n",
       "          -1.5383]]),\n",
       " tensor([[-3.9521, -1.3854,  2.1252,  3.1229, -2.1823,  2.1967,  0.0309,\n",
       "          -0.5243, -1.6578, -1.3067, -0.0036, -0.4589, -4.0327,  2.4740,\n",
       "           0.3800,  0.7749, -2.0526,  0.3491, -0.3349,  1.8026, -1.5848,\n",
       "          -2.8918, -2.2346, -2.4838, -0.8691,  3.0967,  0.0543,  3.1094,\n",
       "           1.1949]]),\n",
       " tensor([[ 2.5241, -1.4045, -1.5956, -0.6058, -2.0427,  0.6237, -1.5618,\n",
       "          -0.4368, -2.0654, -1.1403,  0.1081,  2.2183,  1.7472, -0.4065,\n",
       "           2.6131,  2.0318,  2.9164,  3.5828, -2.9365, -1.0932,  2.3521,\n",
       "          -0.1273, -0.7173, -0.9936,  0.8113,  0.7476,  3.1111, -0.1657,\n",
       "          -1.0250]]),\n",
       " tensor([[ 0.5588,  3.0682, -1.3116, -3.3699,  2.3598,  1.9796, -0.9948,\n",
       "           0.8554, -3.0073, -3.5101, -2.3262, -0.1828,  1.5039, -3.0750,\n",
       "           2.7965,  0.2600,  2.9825, -1.7323, -1.5623,  3.0254, -1.5768,\n",
       "          -1.9872,  2.8093,  2.2031, -2.5496,  2.3166, -3.5891,  3.6354,\n",
       "          -2.5447]]),\n",
       " tensor([[-0.4007,  0.9606, -3.2538, -0.0286,  3.2621,  3.1891, -0.5296,\n",
       "           0.4135, -2.0307,  1.9398, -0.1738, -1.9822,  0.3451, -0.0149,\n",
       "           2.5743, -3.2649,  1.8425, -1.9253,  1.1436,  2.7361,  2.9370,\n",
       "           3.6690, -0.9063, -3.3356,  1.3555,  1.2656,  2.9097,  2.9531,\n",
       "          -0.8164]]),\n",
       " tensor([[ 2.9451, -2.0159,  3.2144, -2.5122, -0.0450, -0.0794, -1.8567,\n",
       "          -1.0737,  1.5168, -0.5668,  2.7720,  0.2035, -0.1516, -3.7666,\n",
       "           2.6251,  0.0457, -2.4239,  2.2249, -1.1608,  1.7923,  3.1394,\n",
       "          -0.2228, -1.3846,  1.1227, -3.6803, -3.4341,  0.7335,  1.5465,\n",
       "          -0.6157]]),\n",
       " tensor([[-0.8687,  1.5287,  2.6723, -0.8060,  0.8863,  0.2382, -3.0465,\n",
       "           3.8647, -0.6166, -1.2245,  1.1345, -1.2743,  1.9635, -0.1514,\n",
       "          -0.8443,  1.7441,  2.0909, -2.8275, -1.6622, -1.9779,  0.4826,\n",
       "          -3.1146, -1.1769, -1.9539, -0.8035, -1.9260, -2.0374,  1.6105,\n",
       "          -1.5340]]),\n",
       " tensor([[-2.8970,  0.8389,  0.1899,  2.2863,  2.6563,  0.1713, -0.4310,\n",
       "          -3.0357, -0.5991, -2.4665,  1.2879, -0.9044,  0.2563, -2.1874,\n",
       "           0.8223,  1.6912, -2.9401,  0.2633,  1.9989,  1.5147, -0.6729,\n",
       "           0.8318, -0.4624, -1.0230, -3.8918, -1.0239, -2.7602,  1.3280,\n",
       "           0.1627]]),\n",
       " tensor([[ 0.3346, -1.7793, -0.2864,  1.8221, -0.9410,  3.5189,  0.4556,\n",
       "           2.4541,  2.4223,  2.5877,  0.7369,  0.4626, -1.7610,  0.8566,\n",
       "           1.4994,  0.2786, -1.1816, -1.0990,  2.4281,  2.8461, -3.2077,\n",
       "          -3.3189, -2.0398,  2.7500,  2.4845,  0.4050,  3.6040, -2.8017,\n",
       "          -3.5831]]),\n",
       " tensor([[-2.1805, -2.0156,  1.4706,  3.0797,  3.7361, -2.4846,  0.5335,\n",
       "          -3.3495, -1.6900, -1.3681,  0.9513,  2.5000, -1.6385, -1.8025,\n",
       "          -0.8659,  3.7557, -0.2617, -2.6363,  2.0804, -1.2622,  1.0330,\n",
       "          -0.9609,  1.2208,  1.6923, -2.1570,  0.5564, -0.5867,  3.3815,\n",
       "          -3.7314]]),\n",
       " tensor([[-1.5610, -1.8852,  1.0450,  1.7015, -3.5065, -2.2174, -2.9910,\n",
       "           2.2767,  0.0765, -0.3742, -3.3285, -0.2831, -2.8685,  0.3207,\n",
       "          -3.7014, -2.0405, -1.0403,  2.9028, -2.1573,  1.2235, -1.3295,\n",
       "           0.9184,  2.8271, -0.7802,  2.9602,  1.0018, -1.2927, -1.5408,\n",
       "           0.5568]]),\n",
       " tensor([[-1.2100,  2.7872, -1.2299, -1.3210, -0.0783, -0.6383,  3.6563,\n",
       "           2.2910,  3.4008, -2.8122,  1.9323,  1.0589, -1.1978, -3.0262,\n",
       "           2.8837,  0.5938, -2.2618, -1.5233,  0.7155,  2.8707, -1.4509,\n",
       "           1.7360,  0.1470,  3.9222,  0.2199,  0.3829,  1.2769,  3.4262,\n",
       "          -0.8396]]),\n",
       " tensor([[-1.3313, -1.1423,  1.1162,  2.8286, -3.4859,  2.9349,  3.5558,\n",
       "          -0.3095, -3.4518,  1.0733,  3.1249,  0.0077,  2.0044,  2.0752,\n",
       "           2.1450,  0.0954, -3.4298, -1.0294, -2.5548,  1.7605,  2.5014,\n",
       "          -1.2944,  2.3854,  2.2978,  0.3400, -3.4253, -3.1239, -2.3476,\n",
       "          -1.4606]]),\n",
       " tensor([[ 1.1168, -0.3472, -0.5136,  2.0665,  0.7451, -2.0336, -2.0614,\n",
       "           0.5110,  3.2061, -0.3196, -0.7120, -0.5335, -0.7509,  1.7029,\n",
       "           1.3175, -2.5562,  3.2425,  0.3096, -0.7965, -0.5234,  2.1136,\n",
       "           2.2623, -0.2503, -2.0842,  2.3593, -1.0598,  1.3648, -2.3670,\n",
       "          -4.1110]]),\n",
       " tensor([[-1.1484, -0.7756,  2.4522, -1.3532,  0.9094,  2.2942,  0.3884,\n",
       "          -0.0949, -0.8815, -3.3155,  1.0632,  0.9835, -2.0098,  1.5706,\n",
       "           0.7541, -0.5746, -3.0290, -0.4184, -0.7319, -3.6227,  2.5855,\n",
       "          -0.7187,  2.0605, -0.5565,  2.6613, -3.5608, -1.9898, -3.8297,\n",
       "          -2.5751]]),\n",
       " tensor([[ 0.5937, -2.6958,  2.0377,  2.3323, -0.9252, -4.0177,  3.5077,\n",
       "           1.0091,  2.5695, -0.3588, -2.4495, -2.4790,  0.5820,  1.8606,\n",
       "          -2.1341, -2.9790, -2.7835, -0.3502, -0.8395,  1.6400,  3.2968,\n",
       "           3.7443,  0.0760,  1.1414,  0.7458,  1.2994,  0.9383, -1.1622,\n",
       "          -2.0588]]),\n",
       " tensor([[ 3.2043, -0.7677,  2.1561,  2.0722, -3.2554,  1.8357,  0.3623,\n",
       "           1.1779,  1.2303, -3.5881, -1.5492, -1.0372,  3.8320, -0.9524,\n",
       "           0.8919,  3.2231, -0.9867,  0.3906,  3.3932, -0.2840,  0.7044,\n",
       "           1.9747, -2.0017, -2.5362,  1.1915, -2.8363,  0.1250,  0.0597,\n",
       "          -0.7272]]),\n",
       " tensor([[ 0.6733,  1.0457, -1.8870, -2.2338,  2.0518,  0.0613, -2.4594,\n",
       "          -3.3165,  2.8682,  2.9031,  3.6224, -2.4366, -2.2113,  1.0784,\n",
       "          -0.9027,  0.4927,  0.7212, -1.8110,  0.6765, -2.5942, -3.7727,\n",
       "           1.5924,  2.5834, -0.9599, -1.9267,  1.7801, -2.6205, -1.9266,\n",
       "          -2.2059]]),\n",
       " tensor([[-3.2298,  3.2160,  1.9110,  2.3580,  2.6538,  1.9305,  1.5302,\n",
       "          -1.3884, -0.9007, -2.8912, -0.5566,  0.0182, -0.8030, -2.6194,\n",
       "           0.2015, -0.7814, -1.0501, -1.5489,  2.9552,  0.6582,  1.3153,\n",
       "           2.1150, -2.2760,  1.4034,  0.3867, -2.8605,  0.1521,  2.6387,\n",
       "           0.8533]]),\n",
       " tensor([[ 0.7276, -1.6226, -2.3479,  1.6165,  0.3927,  0.7891,  1.9215,\n",
       "           2.0667, -1.9138,  2.1302, -2.1744,  1.0851, -0.2984, -2.0429,\n",
       "           0.8319, -3.7197, -2.2115,  2.5165, -1.3420,  2.0655, -0.3338,\n",
       "           0.3731,  1.0969, -2.6224, -3.7321,  1.0907,  2.7045, -3.4426,\n",
       "          -1.3293]]),\n",
       " tensor([[-2.5378,  0.3084,  0.0802, -2.5226, -1.7542,  2.6011, -1.6233,\n",
       "           1.0689, -1.3147,  1.9604, -1.3280,  2.5850,  1.5467, -2.4611,\n",
       "           1.3964, -0.5677,  0.0643,  2.9840,  3.2020, -3.1154, -2.7371,\n",
       "          -3.1156, -2.0625,  0.1230, -1.0765,  2.5993,  2.4583,  2.2959,\n",
       "           1.4252]]),\n",
       " tensor([[-1.9201, -3.1305,  2.6393, -2.9106, -2.8126,  2.3728, -1.6528,\n",
       "          -1.2899, -0.5403, -3.7850, -3.4616, -1.0411, -1.0210,  1.4836,\n",
       "           2.2560,  2.9949, -3.5010,  1.8057,  1.6509, -2.6355,  0.7487,\n",
       "          -3.4406,  0.8382,  1.4825,  1.8901,  1.5967, -0.1347,  1.4754,\n",
       "          -3.6749]]),\n",
       " tensor([[-1.5245, -1.9414,  3.8526,  3.2741, -1.4723,  0.1086,  2.0774,\n",
       "          -0.7377,  1.9485, -3.0052,  1.3647,  0.2953,  0.2823, -2.0768,\n",
       "           2.5431, -2.8440, -0.5732,  2.9276, -3.0561,  1.2791,  2.1819,\n",
       "           3.6666,  1.6040,  2.8624,  1.6536, -2.4680,  3.3439,  0.4506,\n",
       "          -2.4364]]),\n",
       " tensor([[ 3.1345, -3.1941, -0.3563,  0.2001, -1.5643, -0.7129,  2.6770,\n",
       "          -3.9021, -2.0189, -2.8817, -0.9977, -1.6907, -1.4123,  0.1007,\n",
       "           0.3640,  0.9575,  2.7842, -0.4451,  2.4204, -2.6334,  3.2506,\n",
       "          -0.4281, -1.1167,  1.7935,  0.1867,  2.3790,  0.0826,  0.6914,\n",
       "          -0.2031]]),\n",
       " tensor([[-0.3111,  1.2586,  0.4842, -1.0433,  0.5489,  1.3863,  0.8606,\n",
       "          -1.7211,  1.7009, -0.1921,  2.0562,  1.7892, -1.1205,  2.1696,\n",
       "           3.6476, -1.2422,  3.2632,  1.1726, -1.9228,  1.9500,  3.2847,\n",
       "           2.5939,  2.2426, -2.0914, -1.3842, -1.7201,  0.8336, -1.2500,\n",
       "           2.8062]]),\n",
       " tensor([[ 2.3723, -0.2916,  0.6234,  0.0774, -1.3777, -2.5664, -1.9012,\n",
       "          -3.3836, -0.6702,  1.8324,  1.5593,  2.1424,  1.0862,  2.5503,\n",
       "           0.7437,  3.1691,  1.1186, -2.6263, -1.5768, -3.5809, -2.7951,\n",
       "          -0.4930, -0.5218,  2.7966, -0.4590, -1.4773, -3.2662,  3.2091,\n",
       "           3.4997]]),\n",
       " tensor([[ 1.3133,  0.4571, -3.6835,  2.0437,  3.3154, -2.4445,  2.5553,\n",
       "           0.9088, -3.2142, -0.4289,  2.7695,  0.0283, -1.1660, -1.6385,\n",
       "           0.0528, -0.4014, -0.7101,  3.6365, -0.8735,  2.4714,  2.6891,\n",
       "          -4.1587,  1.6592, -3.6944, -0.6754,  0.7291,  1.6773, -0.2178,\n",
       "           1.8632]]),\n",
       " tensor([[-2.8143,  2.4960, -0.2791, -3.8101, -0.1664,  1.3521,  2.1646,\n",
       "           0.8707,  0.6106,  1.4619, -2.5663, -1.5071,  0.6321,  0.2884,\n",
       "          -2.7586, -2.3975,  0.1594, -0.1650, -0.0947, -3.2076,  2.0593,\n",
       "           1.9572,  1.3278, -1.2033, -1.7350,  2.5664,  1.4390,  2.8579,\n",
       "          -2.5360]]),\n",
       " tensor([[-1.5736, -3.0226,  2.8280,  1.9733,  0.8611, -3.5750, -0.6579,\n",
       "           3.4269,  2.8919, -1.6291,  0.7323,  0.7084, -0.7428,  2.3970,\n",
       "          -0.0691,  1.5781,  3.0458, -3.7524,  1.5664, -0.9663, -1.8906,\n",
       "          -1.2417,  3.4930,  0.3722, -2.4536, -2.8607,  0.2111, -3.0428,\n",
       "          -2.0813]]),\n",
       " tensor([[-0.1532, -4.3115,  0.4598, -3.8919, -0.6375,  0.3194, -0.5427,\n",
       "           3.2031, -3.6967, -1.9832,  2.8475,  0.4760,  2.9843, -0.6523,\n",
       "           0.4452, -0.6729, -1.0448,  2.2268, -1.0509, -3.5126, -2.5832,\n",
       "          -1.5426,  0.4117, -2.5231,  2.2419, -1.6550,  2.5990, -2.6749,\n",
       "          -2.4171]]),\n",
       " tensor([[ 1.2027, -0.8418,  1.3017, -3.9631, -3.6571, -1.6167,  0.1225,\n",
       "          -1.8067,  0.8748, -0.8783,  1.6236, -3.6131,  2.6741, -0.6557,\n",
       "           1.5595,  2.6667, -0.1956, -1.7203,  2.0049,  1.6791, -2.3059,\n",
       "           3.1953,  3.1951,  0.6757,  2.4989,  3.2383, -2.4936,  1.6392,\n",
       "          -2.0771]]),\n",
       " tensor([[-1.1625, -0.8762,  1.1360, -1.2302, -3.4827, -2.5379, -1.1619,\n",
       "          -1.9610, -0.9510,  3.0024, -0.2614, -1.0500, -0.7957, -2.1005,\n",
       "          -1.6423, -1.2156, -1.0462, -2.1039,  0.2915, -3.8492, -3.1064,\n",
       "           1.8119,  3.4354, -0.4208, -0.9777,  2.1776, -2.5655, -2.3201,\n",
       "          -0.0821]]),\n",
       " tensor([[ 3.3457, -1.9415,  0.2973,  2.5783, -0.7643, -1.9859,  1.8995,\n",
       "           2.5079,  1.8149,  0.7795,  0.1558,  1.0328,  2.0087,  2.0682,\n",
       "          -2.8198,  1.3591, -2.2763,  1.0494,  1.0861, -0.6040, -1.9866,\n",
       "           3.4761,  3.4788, -2.2216,  1.4430, -3.3375,  0.6485, -1.3269,\n",
       "          -2.6100]]),\n",
       " tensor([[-1.7576,  1.0013,  2.0609,  0.3662, -0.5638,  2.0961, -0.4878,\n",
       "          -3.3542, -1.0641, -1.9651,  2.2950, -2.2310, -0.0999, -3.0858,\n",
       "          -4.0689,  2.5615, -3.2775, -2.6531, -2.1190, -2.0370,  3.2318,\n",
       "           1.1214, -0.1997, -3.6826, -0.1561,  1.5892, -2.2019, -0.7678,\n",
       "          -2.0037]]),\n",
       " tensor([[-0.8496, -2.3227, -1.3883,  3.3045,  3.3157, -0.5840, -2.5162,\n",
       "           0.5014,  0.0295,  2.4242, -2.6541, -0.4313,  3.7435,  2.2545,\n",
       "           3.6169, -2.3838, -0.3691, -0.9820,  1.5839,  3.3364, -0.6663,\n",
       "          -1.0260, -1.0834, -1.8537, -2.3058,  0.4466,  1.8886,  1.4775,\n",
       "          -3.0763]]),\n",
       " tensor([[ 0.4650, -1.7322, -2.7763,  2.4599, -3.3696,  0.7707, -0.8544,\n",
       "          -1.0920, -0.6641, -3.5925, -2.2564,  1.5100,  0.2366, -0.8333,\n",
       "           2.8507,  3.5703, -0.2490, -1.9243, -2.9810, -4.0152, -0.2780,\n",
       "           2.2216, -1.1615, -3.0248, -2.7181, -0.4790, -3.7448,  2.2058,\n",
       "           2.0386]]),\n",
       " tensor([[-0.0975, -2.4831,  0.8319,  2.2717, -0.5505,  1.4788,  2.2057,\n",
       "          -2.0473, -2.1525,  1.8679,  1.8754, -3.5008, -0.6249,  2.4483,\n",
       "           0.3764, -0.8451, -1.6773, -0.9650,  1.5921, -2.0988,  3.1162,\n",
       "          -3.1069,  1.6322,  0.7104,  2.6609, -3.5975, -2.7708,  0.4540,\n",
       "           2.8402]]),\n",
       " tensor([[ 0.4859, -2.0258,  1.6018,  2.7687,  2.6223,  2.0089,  2.6877,\n",
       "           0.8161,  0.9837, -3.3392, -3.1580, -0.4083,  2.1935,  3.4779,\n",
       "          -1.8083,  1.3063, -0.2101,  1.2681,  0.8954, -2.3668,  3.1433,\n",
       "          -0.6615,  1.4597, -1.2192, -0.3214,  0.4162,  2.3303, -2.4067,\n",
       "          -0.9886]]),\n",
       " tensor([[ 3.0621,  0.5618,  1.4825,  1.4874, -1.4529,  0.4057,  2.0852,\n",
       "           1.5835, -0.5960,  1.2673, -0.0374, -1.7673, -1.6908, -0.5737,\n",
       "          -2.3317,  0.9709, -2.8829, -2.3259,  0.6651, -0.2357,  0.6558,\n",
       "          -0.8758, -2.5002,  0.3448, -0.6786,  1.1475,  0.5417, -0.2698,\n",
       "           1.6323]])]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can train and test model on the generated data\n",
    "synthentic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert array of tensor to tensors\n",
    "temp = torch.Tensor(99)\n",
    "synthentic_data = torch.cat(synthentic_data, out=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.819548</td>\n",
       "      <td>2.134313</td>\n",
       "      <td>0.396303</td>\n",
       "      <td>-3.407608</td>\n",
       "      <td>1.144204</td>\n",
       "      <td>-1.343344</td>\n",
       "      <td>0.276304</td>\n",
       "      <td>2.090934</td>\n",
       "      <td>-0.484520</td>\n",
       "      <td>-1.735902</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.551368</td>\n",
       "      <td>0.304499</td>\n",
       "      <td>0.092201</td>\n",
       "      <td>-2.694274</td>\n",
       "      <td>-2.370792</td>\n",
       "      <td>1.480898</td>\n",
       "      <td>-3.246330</td>\n",
       "      <td>1.567997</td>\n",
       "      <td>2.676290</td>\n",
       "      <td>-2.217108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.810511</td>\n",
       "      <td>-0.937760</td>\n",
       "      <td>-0.526174</td>\n",
       "      <td>-2.836814</td>\n",
       "      <td>-3.137003</td>\n",
       "      <td>1.745601</td>\n",
       "      <td>-2.790101</td>\n",
       "      <td>-1.828505</td>\n",
       "      <td>0.882506</td>\n",
       "      <td>2.230540</td>\n",
       "      <td>...</td>\n",
       "      <td>2.254020</td>\n",
       "      <td>-2.604851</td>\n",
       "      <td>-2.795063</td>\n",
       "      <td>-2.127733</td>\n",
       "      <td>-1.235977</td>\n",
       "      <td>-0.471068</td>\n",
       "      <td>-1.433751</td>\n",
       "      <td>1.829076</td>\n",
       "      <td>-2.212429</td>\n",
       "      <td>3.389443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.645329</td>\n",
       "      <td>-3.335547</td>\n",
       "      <td>-0.984599</td>\n",
       "      <td>-2.447587</td>\n",
       "      <td>0.593392</td>\n",
       "      <td>-0.311726</td>\n",
       "      <td>0.487287</td>\n",
       "      <td>2.383943</td>\n",
       "      <td>0.725841</td>\n",
       "      <td>-0.575544</td>\n",
       "      <td>...</td>\n",
       "      <td>3.547775</td>\n",
       "      <td>-0.289825</td>\n",
       "      <td>-1.799950</td>\n",
       "      <td>-2.939553</td>\n",
       "      <td>-0.589571</td>\n",
       "      <td>-2.853022</td>\n",
       "      <td>-3.137531</td>\n",
       "      <td>3.137279</td>\n",
       "      <td>3.568488</td>\n",
       "      <td>1.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.226392</td>\n",
       "      <td>3.697824</td>\n",
       "      <td>-0.960497</td>\n",
       "      <td>-0.486504</td>\n",
       "      <td>-2.270526</td>\n",
       "      <td>-2.370965</td>\n",
       "      <td>2.664451</td>\n",
       "      <td>-0.277218</td>\n",
       "      <td>-0.003282</td>\n",
       "      <td>2.176349</td>\n",
       "      <td>...</td>\n",
       "      <td>3.329890</td>\n",
       "      <td>-2.338981</td>\n",
       "      <td>2.171223</td>\n",
       "      <td>-3.386513</td>\n",
       "      <td>-1.014364</td>\n",
       "      <td>-1.009892</td>\n",
       "      <td>-1.857553</td>\n",
       "      <td>0.854266</td>\n",
       "      <td>0.276684</td>\n",
       "      <td>0.712277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.129275</td>\n",
       "      <td>2.356592</td>\n",
       "      <td>0.218571</td>\n",
       "      <td>1.837109</td>\n",
       "      <td>-1.313226</td>\n",
       "      <td>1.292196</td>\n",
       "      <td>-3.418064</td>\n",
       "      <td>-0.450702</td>\n",
       "      <td>3.475271</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.305886</td>\n",
       "      <td>-1.506234</td>\n",
       "      <td>0.528857</td>\n",
       "      <td>2.516010</td>\n",
       "      <td>2.062804</td>\n",
       "      <td>-1.482320</td>\n",
       "      <td>3.410080</td>\n",
       "      <td>3.084839</td>\n",
       "      <td>-2.709415</td>\n",
       "      <td>-1.594540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  2.819548  2.134313  0.396303 -3.407608  1.144204 -1.343344  0.276304   \n",
       "1  1.810511 -0.937760 -0.526174 -2.836814 -3.137003  1.745601 -2.790101   \n",
       "2 -2.645329 -3.335547 -0.984599 -2.447587  0.593392 -0.311726  0.487287   \n",
       "3  0.226392  3.697824 -0.960497 -0.486504 -2.270526 -2.370965  2.664451   \n",
       "4 -0.129275  2.356592  0.218571  1.837109 -1.313226  1.292196 -3.418064   \n",
       "\n",
       "         7         8         9     ...           19        20        21  \\\n",
       "0  2.090934 -0.484520 -1.735902    ...    -1.551368  0.304499  0.092201   \n",
       "1 -1.828505  0.882506  2.230540    ...     2.254020 -2.604851 -2.795063   \n",
       "2  2.383943  0.725841 -0.575544    ...     3.547775 -0.289825 -1.799950   \n",
       "3 -0.277218 -0.003282  2.176349    ...     3.329890 -2.338981  2.171223   \n",
       "4 -0.450702  3.475271  0.007671    ...    -1.305886 -1.506234  0.528857   \n",
       "\n",
       "         22        23        24        25        26        27        28  \n",
       "0 -2.694274 -2.370792  1.480898 -3.246330  1.567997  2.676290 -2.217108  \n",
       "1 -2.127733 -1.235977 -0.471068 -1.433751  1.829076 -2.212429  3.389443  \n",
       "2 -2.939553 -0.589571 -2.853022 -3.137531  3.137279  3.568488  1.052400  \n",
       "3 -3.386513 -1.014364 -1.009892 -1.857553  0.854266  0.276684  0.712277  \n",
       "4  2.516010  2.062804 -1.482320  3.410080  3.084839 -2.709415 -1.594540  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tensor to PD data frame\n",
    "synthentic_data_df = pd.DataFrame(data=synthentic_data.data.numpy());\n",
    "synthentic_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns of the synthentic dataset\n",
    "cols = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
    "        'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'normAmount']\n",
    "synthentic_data_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.819548</td>\n",
       "      <td>2.134313</td>\n",
       "      <td>0.396303</td>\n",
       "      <td>-3.407608</td>\n",
       "      <td>1.144204</td>\n",
       "      <td>-1.343344</td>\n",
       "      <td>0.276304</td>\n",
       "      <td>2.090934</td>\n",
       "      <td>-0.484520</td>\n",
       "      <td>-1.735902</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.551368</td>\n",
       "      <td>0.304499</td>\n",
       "      <td>0.092201</td>\n",
       "      <td>-2.694274</td>\n",
       "      <td>-2.370792</td>\n",
       "      <td>1.480898</td>\n",
       "      <td>-3.246330</td>\n",
       "      <td>1.567997</td>\n",
       "      <td>2.676290</td>\n",
       "      <td>-2.217108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.810511</td>\n",
       "      <td>-0.937760</td>\n",
       "      <td>-0.526174</td>\n",
       "      <td>-2.836814</td>\n",
       "      <td>-3.137003</td>\n",
       "      <td>1.745601</td>\n",
       "      <td>-2.790101</td>\n",
       "      <td>-1.828505</td>\n",
       "      <td>0.882506</td>\n",
       "      <td>2.230540</td>\n",
       "      <td>...</td>\n",
       "      <td>2.254020</td>\n",
       "      <td>-2.604851</td>\n",
       "      <td>-2.795063</td>\n",
       "      <td>-2.127733</td>\n",
       "      <td>-1.235977</td>\n",
       "      <td>-0.471068</td>\n",
       "      <td>-1.433751</td>\n",
       "      <td>1.829076</td>\n",
       "      <td>-2.212429</td>\n",
       "      <td>3.389443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.645329</td>\n",
       "      <td>-3.335547</td>\n",
       "      <td>-0.984599</td>\n",
       "      <td>-2.447587</td>\n",
       "      <td>0.593392</td>\n",
       "      <td>-0.311726</td>\n",
       "      <td>0.487287</td>\n",
       "      <td>2.383943</td>\n",
       "      <td>0.725841</td>\n",
       "      <td>-0.575544</td>\n",
       "      <td>...</td>\n",
       "      <td>3.547775</td>\n",
       "      <td>-0.289825</td>\n",
       "      <td>-1.799950</td>\n",
       "      <td>-2.939553</td>\n",
       "      <td>-0.589571</td>\n",
       "      <td>-2.853022</td>\n",
       "      <td>-3.137531</td>\n",
       "      <td>3.137279</td>\n",
       "      <td>3.568488</td>\n",
       "      <td>1.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.226392</td>\n",
       "      <td>3.697824</td>\n",
       "      <td>-0.960497</td>\n",
       "      <td>-0.486504</td>\n",
       "      <td>-2.270526</td>\n",
       "      <td>-2.370965</td>\n",
       "      <td>2.664451</td>\n",
       "      <td>-0.277218</td>\n",
       "      <td>-0.003282</td>\n",
       "      <td>2.176349</td>\n",
       "      <td>...</td>\n",
       "      <td>3.329890</td>\n",
       "      <td>-2.338981</td>\n",
       "      <td>2.171223</td>\n",
       "      <td>-3.386513</td>\n",
       "      <td>-1.014364</td>\n",
       "      <td>-1.009892</td>\n",
       "      <td>-1.857553</td>\n",
       "      <td>0.854266</td>\n",
       "      <td>0.276684</td>\n",
       "      <td>0.712277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.129275</td>\n",
       "      <td>2.356592</td>\n",
       "      <td>0.218571</td>\n",
       "      <td>1.837109</td>\n",
       "      <td>-1.313226</td>\n",
       "      <td>1.292196</td>\n",
       "      <td>-3.418064</td>\n",
       "      <td>-0.450702</td>\n",
       "      <td>3.475271</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.305886</td>\n",
       "      <td>-1.506234</td>\n",
       "      <td>0.528857</td>\n",
       "      <td>2.516010</td>\n",
       "      <td>2.062804</td>\n",
       "      <td>-1.482320</td>\n",
       "      <td>3.410080</td>\n",
       "      <td>3.084839</td>\n",
       "      <td>-2.709415</td>\n",
       "      <td>-1.594540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  2.819548  2.134313  0.396303 -3.407608  1.144204 -1.343344  0.276304   \n",
       "1  1.810511 -0.937760 -0.526174 -2.836814 -3.137003  1.745601 -2.790101   \n",
       "2 -2.645329 -3.335547 -0.984599 -2.447587  0.593392 -0.311726  0.487287   \n",
       "3  0.226392  3.697824 -0.960497 -0.486504 -2.270526 -2.370965  2.664451   \n",
       "4 -0.129275  2.356592  0.218571  1.837109 -1.313226  1.292196 -3.418064   \n",
       "\n",
       "         V8        V9       V10     ...           V20       V21       V22  \\\n",
       "0  2.090934 -0.484520 -1.735902     ...     -1.551368  0.304499  0.092201   \n",
       "1 -1.828505  0.882506  2.230540     ...      2.254020 -2.604851 -2.795063   \n",
       "2  2.383943  0.725841 -0.575544     ...      3.547775 -0.289825 -1.799950   \n",
       "3 -0.277218 -0.003282  2.176349     ...      3.329890 -2.338981  2.171223   \n",
       "4 -0.450702  3.475271  0.007671     ...     -1.305886 -1.506234  0.528857   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  normAmount  \n",
       "0 -2.694274 -2.370792  1.480898 -3.246330  1.567997  2.676290   -2.217108  \n",
       "1 -2.127733 -1.235977 -0.471068 -1.433751  1.829076 -2.212429    3.389443  \n",
       "2 -2.939553 -0.589571 -2.853022 -3.137531  3.137279  3.568488    1.052400  \n",
       "3 -3.386513 -1.014364 -1.009892 -1.857553  0.854266  0.276684    0.712277  \n",
       "4  2.516010  2.062804 -1.482320  3.410080  3.084839 -2.709415   -1.594540  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tensor to PD data frame\n",
    "#synthentic_data_df = pd.DataFrame(data=synthentic_data.data.numpy());\n",
    "synthentic_data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 1 to Class column since they're all synthetic generated fraud data\n",
    "synthentic_data_df['Class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "\n",
    "# Rearrange columns to the right order\n",
    "cols = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
    "        'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'normAmount', 'Class']\n",
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add newly generated fraud data to the original data set\n",
    "new_data = pd.concat([data, synthentic_data_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284906, 29)\n",
      "Shape of y: (284906, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(new_data.ix[:, data.columns != 'Class'])\n",
    "y = np.array(new_data.ix[:, data.columns == 'Class'])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199434, 29)\n",
      "xtest shape\n",
      "(85472, 29)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85286,    10],\n",
       "       [   42,   134]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
