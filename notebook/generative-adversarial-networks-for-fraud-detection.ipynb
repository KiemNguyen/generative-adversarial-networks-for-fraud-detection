{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import recall_score\n",
    "import torch\n",
    "#from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro P5000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if Cuda is running\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's randomize the data, just to be sure not to get any pathological ordering effects that might harm the performane of Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124011</th>\n",
       "      <td>77147.0</td>\n",
       "      <td>-1.437314</td>\n",
       "      <td>-0.672735</td>\n",
       "      <td>0.925002</td>\n",
       "      <td>-0.728117</td>\n",
       "      <td>-0.498919</td>\n",
       "      <td>-1.088232</td>\n",
       "      <td>0.098312</td>\n",
       "      <td>0.294362</td>\n",
       "      <td>-1.763211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>-0.254662</td>\n",
       "      <td>0.569343</td>\n",
       "      <td>0.599137</td>\n",
       "      <td>-0.909906</td>\n",
       "      <td>0.070153</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>149.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182926</th>\n",
       "      <td>125586.0</td>\n",
       "      <td>-1.188026</td>\n",
       "      <td>0.648003</td>\n",
       "      <td>0.195708</td>\n",
       "      <td>-2.300317</td>\n",
       "      <td>-1.876858</td>\n",
       "      <td>0.483442</td>\n",
       "      <td>-0.257970</td>\n",
       "      <td>-4.314653</td>\n",
       "      <td>1.394378</td>\n",
       "      <td>...</td>\n",
       "      <td>3.773234</td>\n",
       "      <td>-1.129681</td>\n",
       "      <td>-1.190132</td>\n",
       "      <td>0.066215</td>\n",
       "      <td>0.806729</td>\n",
       "      <td>0.669240</td>\n",
       "      <td>0.580496</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>392.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>2364.0</td>\n",
       "      <td>1.571567</td>\n",
       "      <td>-0.852696</td>\n",
       "      <td>-0.411170</td>\n",
       "      <td>-1.735533</td>\n",
       "      <td>-0.574247</td>\n",
       "      <td>-0.298426</td>\n",
       "      <td>-0.606201</td>\n",
       "      <td>-0.165091</td>\n",
       "      <td>-2.384797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546954</td>\n",
       "      <td>-1.269700</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>-0.896239</td>\n",
       "      <td>0.433003</td>\n",
       "      <td>-0.425964</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10848</th>\n",
       "      <td>18552.0</td>\n",
       "      <td>-0.265284</td>\n",
       "      <td>0.081207</td>\n",
       "      <td>1.595559</td>\n",
       "      <td>-1.671107</td>\n",
       "      <td>-0.359368</td>\n",
       "      <td>-0.158713</td>\n",
       "      <td>-0.188054</td>\n",
       "      <td>0.271057</td>\n",
       "      <td>2.710338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102560</td>\n",
       "      <td>0.673973</td>\n",
       "      <td>0.126516</td>\n",
       "      <td>-0.065758</td>\n",
       "      <td>-1.159539</td>\n",
       "      <td>-1.066871</td>\n",
       "      <td>0.283226</td>\n",
       "      <td>0.230268</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250966</th>\n",
       "      <td>155148.0</td>\n",
       "      <td>-1.071928</td>\n",
       "      <td>0.594211</td>\n",
       "      <td>-0.352817</td>\n",
       "      <td>-0.819417</td>\n",
       "      <td>1.439513</td>\n",
       "      <td>0.755137</td>\n",
       "      <td>0.594540</td>\n",
       "      <td>0.448423</td>\n",
       "      <td>0.063034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085680</td>\n",
       "      <td>0.088365</td>\n",
       "      <td>0.361190</td>\n",
       "      <td>-0.336159</td>\n",
       "      <td>-1.006584</td>\n",
       "      <td>0.176926</td>\n",
       "      <td>-0.098098</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "124011   77147.0 -1.437314 -0.672735  0.925002 -0.728117 -0.498919 -1.088232   \n",
       "182926  125586.0 -1.188026  0.648003  0.195708 -2.300317 -1.876858  0.483442   \n",
       "2807      2364.0  1.571567 -0.852696 -0.411170 -1.735533 -0.574247 -0.298426   \n",
       "10848    18552.0 -0.265284  0.081207  1.595559 -1.671107 -0.359368 -0.158713   \n",
       "250966  155148.0 -1.071928  0.594211 -0.352817 -0.819417  1.439513  0.755137   \n",
       "\n",
       "              V7        V8        V9  ...         V21       V22       V23  \\\n",
       "124011  0.098312  0.294362 -1.763211  ...   -0.032172 -0.254662  0.569343   \n",
       "182926 -0.257970 -4.314653  1.394378  ...    3.773234 -1.129681 -1.190132   \n",
       "2807   -0.606201 -0.165091 -2.384797  ...   -0.546954 -1.269700  0.009546   \n",
       "10848  -0.188054  0.271057  2.710338  ...    0.102560  0.673973  0.126516   \n",
       "250966  0.594540  0.448423  0.063034  ...   -0.085680  0.088365  0.361190   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "124011  0.599137 -0.909906  0.070153  0.017838  0.001861  149.20      0  \n",
       "182926  0.066215  0.806729  0.669240  0.580496  0.090244  392.00      0  \n",
       "2807   -0.896239  0.433003 -0.425964  0.000977 -0.003500   19.75      0  \n",
       "10848  -0.065758 -1.159539 -1.066871  0.283226  0.230268   11.85      0  \n",
       "250966 -0.336159 -1.006584  0.176926 -0.098098  0.001136   14.75      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reindex(np.random.permutation(data.index))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.174225e-15</td>\n",
       "      <td>3.429687e-16</td>\n",
       "      <td>-1.386421e-15</td>\n",
       "      <td>2.073779e-15</td>\n",
       "      <td>9.939598e-16</td>\n",
       "      <td>1.493625e-15</td>\n",
       "      <td>-5.931037e-16</td>\n",
       "      <td>1.318317e-16</td>\n",
       "      <td>-2.414318e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.416845e-16</td>\n",
       "      <td>-3.515296e-16</td>\n",
       "      <td>2.727492e-16</td>\n",
       "      <td>4.482012e-15</td>\n",
       "      <td>5.203181e-16</td>\n",
       "      <td>1.689590e-15</td>\n",
       "      <td>-3.712632e-16</td>\n",
       "      <td>-1.159267e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.174225e-15  3.429687e-16 -1.386421e-15  2.073779e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.939598e-16  1.493625e-15 -5.931037e-16  1.318317e-16 -2.414318e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.416845e-16 -3.515296e-16  2.727492e-16  4.482012e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.203181e-16  1.689590e-15 -3.712632e-16 -1.159267e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
    "classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class')['Class'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Data is hihgly imbalance. 284315 Normal transaction vs 492 Fraud transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run with Normalising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 30)\n",
      "xtest shape\n",
      "(85443, 30)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the training data and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit classifier to a model\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85287,     4],\n",
       "       [   45,   107]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85291\n",
      "          1       0.96      0.70      0.81       152\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999427\n",
      "Area under the curve : 0.851950\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run with Over Sampling data using SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.127897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.221892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   -0.349671  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.349231  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   -0.127897  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   -0.053373  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.221892  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data2['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data2 = data2.drop(['Time','Amount'],axis=1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284807, 30)\n",
      "Shape of y: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data.ix[:, data.columns != 'Class'])\n",
    "y = np.array(data.ix[:, data.columns == 'Class'])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 30)\n",
      "xtest shape\n",
      "(85443, 30)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over Sampling data using SMOTE\n",
    "smote = SMOTE(random_state=2)\n",
    "X_train_resample, y_train_resample = smote.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_resample, y_train_resample.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85274,    17],\n",
       "       [   26,   126]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confision Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85291\n",
      "          1       0.88      0.83      0.85       152\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999497\n",
      "Area under the curve : 0.914374\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run with DCGANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Custom DataLoader\n",
    "class FraudDataset(Dataset):\n",
    "    \n",
    "    # Initialize the data\n",
    "    def __init__(self):\n",
    "        data = pd.read_csv(\"creditcard.csv\")\n",
    "        data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "        data = data.drop(['Time','Amount'],axis=1)\n",
    "        \n",
    "        # Rearrange columns to the right order\n",
    "        cols = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
    "        'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'normAmount', 'Class']\n",
    "        data = data[cols]\n",
    "        \n",
    "        fraud_data = data.loc[data['Class']==1]\n",
    "        self.len = fraud_data.shape[0]\n",
    "        \n",
    "        self.fraud_data = torch.FloatTensor(np.array(fraud_data))\n",
    "        \n",
    "        #self.X = np.array(data.loc[:, data.columns != 'Class'])\n",
    "        #self.y = np.array(data.loc[:, data.columns == 'Class'])\n",
    "        \n",
    "        #self.X = torch.FloatTensor(self.X)\n",
    "        #self.y = torch.FloatTensor(self.y)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.fraud_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FraudDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=5,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator's paragrams\n",
    "g_input_size = 30     # Random noise dimension\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1   \n",
    "g_learning_rate = 0.0002\n",
    "\n",
    "#Discriminator's paragrams\n",
    "d_input_size = 30   # Minibatch size\n",
    "d_hidden_size = 50  # Discriminator complexity\n",
    "d_output_size = 1   # Single dimension for 'real' vs. 'fake'\n",
    "d_learning_rate = 0.0002\n",
    "\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "num_epochs = 50\n",
    "print_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ELU (Exponential Linear Unit) function tends to converge cost to zero faster and produce more accurate results\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.map2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.map3(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "discriminator = Discriminator(input_size=d_input_size, hidden_size=d_hidden_size, output_size=d_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these 2 lines to run on GPU\n",
    "#generator.cuda()\n",
    "#discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(disc):\n",
    "    h=0.1\n",
    "    x_min, x_max = data[:, 0].min() - .5, data[:, 0].max() + .5\n",
    "    y_min, y_max = data[:, 1].min() - .5, data[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    x_test = np.c_[xx.ravel(), yy.ravel()]\n",
    "    y_hat_test = disc.forward_with_sigmoid(Variable(torch.from_numpy(x_test).float()))\n",
    "\n",
    "    plt.pcolormesh(xx, yy, y_hat_test.data.numpy().reshape(xx.shape), cmap=plt.cm.Paired)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=y*20, alpha=0.1, cmap=plt.cm.flag, s=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Binary Cross Entropy loss\n",
    "BCE_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizers\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=d_learning_rate/2, betas=(beta_1, beta_2))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=g_learning_rate, betas=(beta_1, beta_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiem/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/Users/kiem/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/kiem/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Discriminator Loss: 1.218, Generator Loss: 0.747\n",
      "Epoch 11 - Discriminator Loss: 0.286, Generator Loss: 1.803\n",
      "Epoch 21 - Discriminator Loss: 0.100, Generator Loss: 3.107\n",
      "Epoch 31 - Discriminator Loss: 0.087, Generator Loss: 3.997\n",
      "Epoch 41 - Discriminator Loss: 0.147, Generator Loss: 4.737\n"
     ]
    }
   ],
   "source": [
    "# Training DCGANs\n",
    "for epoch in range(num_epochs):\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    synthentic_data = []\n",
    "    for i, fraud_data in enumerate(train_loader):\n",
    "        # Updating the weights of the Discriminator\n",
    "        discriminator.zero_grad() # Initialize gradients of the Discriminator to 0\n",
    "        \n",
    "        mini_batch = fraud_data.size()[0]\n",
    "        \n",
    "        # Wrap data in PyTorch Variable\n",
    "        d_real_data = Variable(fraud_data[0])\n",
    "        y_real = Variable(torch.ones(1))\n",
    "        y_fake = Variable(torch.zeros(1))\n",
    "\n",
    "        # Training the Discriminator with real data\n",
    "        d_real_result = discriminator(d_real_data) # Forward propagate this real data into the neural network\n",
    "        d_real_loss = BCE_loss(d_real_result, y_real) # Compute the loss between the prediction and actual\n",
    "        d_real_loss.backward()\n",
    "    \n",
    "        # Inject fake data to the generator\n",
    "        d_gen_input = Variable(torch.randn(minibatch_size, g_input_size))\n",
    "        d_fake_data = generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        \n",
    "        # Train the Discriminator with a fake data generated by the Generator\n",
    "        d_fake_result = discriminator(d_fake_data.t())\n",
    "        d_fake_loss = BCE_loss(d_fake_result, y_fake)  # zeros = fake\n",
    "        d_fake_loss.backward()\n",
    "        \n",
    "        # Combine discriminator loss from real data and fake data\n",
    "        d_train_loss = d_real_loss + d_fake_loss\n",
    "        \n",
    "        #d_train_loss.backward()\n",
    "        d_optimizer.step()     # Apply SGD to update the weight\n",
    "        d_losses.append(d_train_loss.data[0])\n",
    "        \n",
    "        # Update the weight of the Generator \n",
    "        generator.zero_grad()\n",
    "        gen_input = Variable(torch.randn(minibatch_size, g_input_size))  \n",
    "        g_fake_data = generator(gen_input)\n",
    "        \n",
    "        dg_fake_result = discriminator(g_fake_data.t())\n",
    "        g_loss = BCE_loss(dg_fake_result, y_real)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        g_losses.append(g_loss.data[0])\n",
    "        \n",
    "        synthentic_data.append(d_fake_data.t())\n",
    "        \n",
    "    if epoch % print_interval == 0:       \n",
    "        print('Epoch {} - Discriminator Loss: {:.3f}, Generator Loss: {:.3f}'.format((epoch + 1), \n",
    "                          torch.mean(torch.FloatTensor(d_losses)), torch.mean(torch.FloatTensor(g_losses)))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x109f694e0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(d_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x109fc3748>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsvXmwJfdZJXh+udz17fVqL5VKUmn1JmzZCNuB8QLTLI27YWBYjRkcappl2CIYliAYoqenmzB4oDF0jwGDAYNNgNkMeGnb2BhjW5Ily5JKJZWk2re3v3f3XH7zR+aX+cu8ud6bd6v6nQiHS6/urZfvvswvT57vfOdjnHNISEhISMw+lEkfgISEhIREMZAFXUJCQuIGgSzoEhISEjcIZEGXkJCQuEEgC7qEhITEDQJZ0CUkJCRuEMiCLiEhIXGDQBZ0CQkJiRsEsqBLSEhI3CDQxvnNVldX+YkTJ8b5LSUkJCRmHo8++ug653x/2uvGWtBPnDiBRx55ZJzfUkJCQmLmwRg7l+V1UnKRkJCQuEEgC7qEhITEDQJZ0CUkJCRuEMiCLiEhIXGDQBZ0CQkJiRsEsqBLSEhI3CCQBV1CQkLiBoEs6BISEjOHh89u4vTVvUkfxtRBFnQJCYmZw89/6Cv4zU88O+nDmDrIgi4hITFz2G4Z6Jn2pA9j6iALuoSExMxhr2PAtPmkD2PqIAu6hITETKFjWOiaNixZ0PsgC7qEhMRMYa9jAgBMSxb0MGRBl5CQmCnsdQwAkAw9ArKgS0hIzBR2iaHbsikahizoEhISMwXJ0OMhC7qEhMRMYbdNDF0W9DBkQZeQkJgpSIYeD1nQJSQkZgq7bkGXDL0fsqBLSEjMFMi2KBl6P2RBl5CQmCnstomhS5dLGLKgS+TCTtvAr3/sNExLXkwSk4HH0OVgUR9kQZfIhc88u4bf+uQZPHutMelDkbhJITX0eMiCLpELrd7k9MudtoH/8y+eQLNrjv17S0wPyLYoNfR+yIIukQutngUAMCagXz52fgsffOQCnri4M/bvLTE9kAw9HrKgS+QCFfRJsCPD1Ux7Ur+/qSFdLvGQBV0iF0hymUTSneEW8q5hjf1738x4/xfOYbPZm/RhePAZuryxh5Fa0Blj72WMXWeMPSl8bYUx9nHG2HPu/y+P9jAlpgXE0CdxMVFBlwx9fLi+28Ev/tWT+KvHLk36UAAAts3R6EqGHocsDP0PAfyb0Nd+DsAnOOd3AviE+98SNwFaXSro47+YaOVY15AFfVzoup/5RqM74SNx0OiZ4ByolVSpoUcgtaBzzj8DYDP05bcCeJ/75/cB+HcFH5fElKLlyh2TkVykhj5u0FPRtEguNFS0XCuBc4exS/gYVEM/yDm/AgDu/x+IeyFj7CHG2COMsUfW1tYG/HYS04KW97g7OclFaujjA7Hg9cZ0FHRqiC7XdQDS6RLGyJuinPP3cM4f4Jw/sH///lF/O4kRw7MtTrApKhn6+ECf+UZzOiQXkaEDUkcPY9CCfo0xdhgA3P+/XtwhSUwzSHKZxIXUvQE1dNOyp0afjgLduDemjaG7BV06XYIYtKD/LYAfcP/8AwD+ppjDkZh2kORiTIAl34gM/c8fuYg3vPOfvIzvaQNl9kzLTYcsi8s1R3KRDD2ILLbFPwPwrwDuZoxdZIz9EID/CuDrGWPPAfh6978lbgJMdrDIZejmjVPQr+600eiaePTc1qQPJRJ082z2LHSmoHfhSS51YuiyoIvQ0l7AOf/umL96c8HHIjEDaBs0+j9Bl8sNVNDp5vTFFzfxdXfHegsmBtHNtNHs4ehSdYJH0y+5SIYehJwUlcgFCsayJiB7eD50c/JMsSgQ6334bNgZPB0QpbVpkF12OwYquoKqrgKQDD0MWdAlMsOyuccoJ3Eh3YiSS8dt8H75ws5USBphiG6maWiM7nVMLFR0qAoDIDPRw5AFXSIz2kLBkQW9GHTcp42eZePLF7YnfDT9EBn6+pQw9PmKBk11Crp0uQQhC7pEZrSEHPJJbCyaBQ39tz91Bp985lrm13cMCwfmywCmU3YRC+bGFEyL7nVMLFQFhi4llwBkQZfIDHK4ABPOcpnigv7ez76Iv37scubXd00bBxcquPvgPL7w4vQVdMP0f8/TMP6/2zYwX9GhKcTQZUEXIQu6RGY0eyJDn0BBn4HR/45hYauVvfB1DAsVXcFrblvBl85tjfzJ59puB596JvscIC0y0VU2FZKLo6FrUBWndEmGHoQs6BKZ0Z4wQ5/2wSLOOdqGhZ129iGhjmGjoqt49W0raPYsPH1ld4RHCPzxv57DQ3/8SObXG+7T0MGFylQ0RR0NXTL0OMiCLpEZAcllgpOi0zr6b1gcNkduhl7WVLzmxAoAx48+SjS6JgyLZ2a2VDAPLVSmIs9lt2NioaoJGvp0nguTgizoEpnREiWXSTB0c7rjc8kFtN3KztC7po2KruDQYgXHV2qpjVHOOX77U2dwbqM50DGSNTJrdAN91ocWJ8/QO4aFnmljQWTo0rYYgCzoEpkRbIpOYLDImu7BItL29zpm5ieYrmGh4g7JvPrECh4+uwXO44vUZrOHd370ND78xJWBjrGds6BTwXQYei/x2EYNmhJ1NHTpcomCLOgSmUEFXWGTzXKZVtui6NPPqqN3TBtlzbkMX3nrEjabPVzcase+nqyDTcFCmusYc8YfG5YNxoADC2X0TNtb/zYJUDDXfEUXfOiyoIuQBV0iM0hyma/oE81Dn1bbYkfQ9rezFnSBoS9VnXwS8UkoDJI9kl6ThLwM3bA4dEXBvno58P0nAQrmcjR0p3TJwaIgZEGXyAwqInNlbSIMnZj5tDJ0cXR/O0NjlHPu2RYBeP+fFAFAXvBBmXJeDd20bOgqw74552YzycYoSS7zUkOPRWraooQEod1zik9ZUyaUh+5cvNPK0NuBgp7O0MkVU9Echk5MPbmgOwVVbFAPcox5JBdNVbA65zD0Sa6iI8lloaLDdrV8qaEHIRm6RGY0eyZqJSdHYyIM3b2JWDafiG0yDWIh3spQ0Km5S4XcY+gJN6wNj6EPKLn0ckouNoeuKh5Dn+S0qM/QNelDj4Es6BKZ0epZqJVUqIoyUQ0dmE7rYl7JhTT3slvIy1oWhu5q6ANLLvlkK8N0JJcVd6HEJCN0fQ1dZrnEQRZ0icxodZ2CrqtsIgMdhml7zGwadfRAUzQDQ6fCnUdy2RhSQyfJJSuzNV2GXtZUzFe0iUouex0TCgPqJRWa1xSVBV2ELOgSmdEyLFRLjgd4MqP/HPWy0/aZRh09oKG30wsfSS7lUFM0aRJ2c1iXS07JpWfZnkVwda480cRFGvtnjEFV5aRoFGRBl8iMds9EvaRCV5Sxuws45+hZNubcgj6dDN0plss1PZOGToze19Bdhp4wOLU5hA+dsmYAP6MlDaZlo6Q6ZWKlXpqo5LLnjv0DgC419EjIgj4gDMvGi+uDjV/PKppd0tDH3xSlC3e+Qgx9+qZFqVgeWqxiZ6CmaHbJpTmAy0V8qsm6E9awuMfQ99VLE/ehz5d1AJAaegxkQR8Qf/qF8/hffuMzA9vHZhFtV3LRVObFqo4LxMinWXIhxn1ooZwpoMtrirqTohVNCXw9DNvm2Gr1wJjzmrxOHzEtMytDNywbusvQ901YchEZuqehSx96ALKgD4jHL2yjZ9oDa5mziJYruWgTYOik+c5NcUHvGhbKmoLlWilfU9Rl5pqqQFNYLEPf7RiwbI7DCxUATk8jD0SNP/ukqA3dLZ6rcyVsNruwJ8SKSUMHIGjosqCLkAV9QJxyc6tvJobQ6lqollRo6vhti2RTnCPJZQojdJ0nGBVLtVIu2yI1Q50/q7EMndjxLSs1APl19EBBz+pyCUkuNs8ea1A0dtsGFtyCLn3o0ZAFfQD0TBvPrzUAZGc6sw7OOVqGo6E7DH28PzfdQOapKTqFn3vHsFDRVCzVdDR7VmrjNmxbBJziHtcU3eor6DkZegGSCzA5L/pex/R6KDIPPRqyoA+AF9YbXoGZlYL+zo8+gy+8sDHw+3uWDcvm7qTo+F0uRlhDn8I1dG3DRrWkYrnmsMi0xEWSjUhyAZzhojjJhRj68QEZuthIzhXORQzdnRadhBfdsjn2uiYWq67kwiRDj4Is6APglLAmbFDpYb3RDTCmUcK0bPzOPz2Pf3zy6sD/Rstlg8TQx30hhTX0cTD0s+tNfPt//1wmxwpA24cULNacwpcmu1DhpqYo4DD0ODlp02PoVQD5nS7tnuByCX1+5zda+Lbf+Ze+nzXA0N3ExUmM/+91/ClRAFAUNrEY52mGLOgD4Jkre96fB2Xo3/k//hX/7ZPPFXVIidhqGeB88EAnwG/A1WmwaMxPJr1wU3QMGvrjF7bx6LktPHt9L/3FcAq0yNDTtOZOyLZIf45j6F5BXx5Qcgk0RYOF8KnLO/jS+W28sN4IfN20OTRPcplc4uJu219uQdAURTL0EIYq6Iyxn2KMPcUYe5Ix9meMsUpRBzbNOHV1+IJ+dbeDa7udog4pEXQBNod4Imi7N4OqO/o/fobufD9qio6Doe+5ksZWRkbqaehurnna+8K2RcAt6DEa+kajh3pJ9XJV8t6gk1wu9HmGdf+em+UCAMu1EhibTCY6JS2S5AJgIvMQ046BCzpj7CiA/wPAA5zzlwJQAXxXUQc2zXjmyi4OudaxQSQXmthLGiApEt5ShCG2zTQFyWUSo/99PvQxfHb0mJ91R6jvcsnG0LuGhZKmQHEbfIDbFI2VXLpYmSt5n0HePJdOL76gk54fvlGatm9bVBWGkqpMxDK60w5KLoDjdLmZXGZZMKzkogGoMsY0ADUAl4c/pOnGRqOL63tdvOzYIoDBGHrPsl0JZDwFfb0xPEOnY62VNOdRd8ySC33O43S5NNy41ixDQoDDuCu64hf0lPd1TdsbJiJUUpqiK/WyV9BbBUoucev9DItD1/wbTkmdTBa+l7RYERj6hELiphkDF3TO+SUAvwbgPIArAHY45x8Lv44x9hBj7BHG2CNra2uDH+mU4LQrt7z86OAFveM2p8bVFPXXlg2hobvvnVRTdBI+dMrfzrVOTlMxV3byutOYfcewUBb0cyBdQ99XL6HmvicvQ0+UXMzo9X6GZXtTmQCgT2i5ibfcoipq6JMJiZtmDCO5LAN4K4DbABwBUGeMfV/4dZzz93DOH+CcP7B///7Bj3RCOLfRxJfOb3n/Tfr5Sz2Gnv+EogtrXJKLn6FdBEN3BovGrqG7haaqq1DYmBi6WzCzDAkBbkEvqWCMYSlDQJe4fo5QTpRcelipl6AoDLWSml9D71ETtr8oxzF00+IoCU8RusomUtBJcpEaejKGkVzeAuBFzvka59wA8CEAry3msKYH/+/Hn8X3/O7ncXnb2cT+zJVdrM6VcXiRNPT8JzcV9HFJLn5TdHCGTsWg5rLP8UsuzoVb0hSUtPHouMTQt5pZGbrtDQktVnXspEToiq8nVHQ1MniMc44Nl6EDjvSVd2sR3UBKEZO+cftaHYbuSy66qqBnjr+I7rYpC126XJIwTEE/D+BBxliNMcYAvBnAqWIOa3qw0zbQMWz86keeAQCcurqLew/Pe97cgQq6WxzbY2Lo643hGTrdDGq6Ck1lsDnGmulBnzMtWxhHfC41RbNq6E5T1Dkvlmul1BtBx7QClkWANPT+n40mT8nhMlcegKEbzvcrRcgmnuQifJ1z7i24IOiT0tDdHBexgSwZej+G0dC/AOAvAHwJwFfcf+s9BR1XJnRNCxe3WiP9HtRI/JvHL+MLL2zg2WsN3HNo3uv8z4LkstHwGTrng10A9DRRdTV0YLxTej2voDOXoY/+s/MllywLn51JWmLcSzU9g8vF7pNcHJdL/89Giy1WBIaeO8ulZ6Gqq5FFueeex+KNks5tsi3SnyfVFBXlFkBq6FEYyuXCOf9lzvk9nPOXcs6/n3M+1omD3//si/i6d/4TPj/ESHsaWj0TD96+goMLZfzUBx9Hz7Rxz6EFr/M/iPRAF+zYmqKuhm7zwVMK2z0LqsJQ1hRv0GSc7IiKSElVUB635JKBodNNulqigp4e0NUxLW+PKKGiqzAjlmCTbEbDPXNlbaDBoqr7hJVFcjFt/6mIMCmGvtM2Ag1RgBi6dLmImOlJ0eeuNWDaHP/xTx7Fhc3RMPVW18L++Qp+7hvvweUdZxDonoIkl5ZhDcyY82Cj0fO2zgyy6QZw2H1Ndxp+xNDHmYlOhUZXx6ehewy9baT+nrwxfldCWarqGVwu0QwdADqhn48a2yvu+H2trObuiXRcySWaoTvHH8h7cbVyLVTQexPwfu92zIBlEYA7sSwZuoiZLujnN1u4Y38dNgfe8b5HBl6cm4SmmwH+1lccxf23LEFXGU4emPMkl0FObmJzfAjGnBUdw0Kja+LospP/McwuSmKfVNCtMV5MnoaujUdD55xjr2NAUxh6pp3a7yArKvnKl+ul1OGxboxtEeiX4+gpi5qi9fIAkos7+BTlJafiHZBcbHoqCvnQJzBYFCm5qFJDD2OmC/q5jRYeuHUFv/09r8SZtQZ+6oOPF854nU33GhSF4be/95X43bc9gLKmDiW5iMVh1Dp6X4b2gE6XVs/yBlpUejoZkqH/y5l1/ONXrmR6rajnjkNy6Zo2DIt7N8JUC6IZlFyo+CQlLpJvXQT9d/i88Bm6W9BL6kDxubGSS4RtkYp+gKFrk7Mt9jN06XIJY2YLeqtnYr3RxfF9Nbz+zlX8+JtO4uNPX8Ml115YBDjnDkMvOxfZ0aUqvu7uAwD8FVgDDRYJF+uorYvUED1OCX0DOl1aPRNVlz3qSjHbYt718Wfxro8/m+m1VGhKJLmM+EZI+jkFYaXnsgSzzZe9xMX4gt41+yWXMkkuRr/kUtYU1NwbRr2s5U9bNOwEyaV/9N/0bqKT19B3O/0a+iQ2Z007ZragX9h0CjdlQ993eAFA9tyNLOiaNmzuOArCoM7/IJKLWNBHbV0MZ2gPOi3qMHSnmNBygWH0S9vmeObKbuYbmhPjysCYw9BHPVhE8h1F1aadV+1euCnqsMmkhqoTt5tRcmk4HnTm5oDXXZdLnidSSoOMLOgRTVHRWUSYhIbeNS10DDtaQ5dN0QBmtqCf22gC8AvVUgZGlBekUVIhE8EYc1IHB2qK2sKfR83Qw0sRBvt+zZ6zIBrwGdswj7sXt9po9qzMNxgxl7usxWeGFwXyoJNUleZ0oSYmMW6SXJLOx04EQ6eCHrZlUjAXoV7WcruWHMlFca2H0S4X8d+jG7Y4+j+JLBeKzl2s9dsWJUMPYmYL+nnX1UKFyruAUqbz8kAMpIqCpgx2co9VQ3cll1uGZOht1+UCiAx98Av71FVnSUjWwDBncw4VdHX0DD0kuaRZEP2xeldyqScvufB8632DRfGSCzlcAJ9k5DECkG0xiqFHjf4bkQx9/Bq6l+MSydBlQRcxswX9wmYL8xXNe7Rdyrj2Kw9Io6yX+hk6gEimkwVj1dCbPVR0BfvdfZCDJi62ehZqbhGhC3yYi4mWhPRMO1OB6AkMfRyDRbtU0FeooKetkwsW9KVqcoSup7nHMPQolws5XAB/BD7P9G/bzZrRE0b/u5EFPaShj9nl4iUtzpCGfvrqHv7Th58eiy1ZxMwW9PObLRxfqXmaYpZH3DAePbeZuPDWywAvRzP0qBHqLBBlllFr6OuNLvYFIlcH19CpIae6j+DDaOjPXPXX+GW5qfVM27PPlTVl5LZFYr4rtRLmylqqy8XT0N2CXHPtgXFSTdQ+UfG/oxm6KLnkY+iWzdEzbVT1aNtiVFPUiGqKauPX0OnmGrYtqsr4d9tmxUefuorf/+yLhRLMLJjZgn7OLeiEiq6ioiuZP0DL5vie3/0C3v2pM7GvaaUw9GEkF/c+NAbJpYfVuZJXaAZn6KYnPWkeQx+8qD4jbH3K0kcwLBu6JjL0UUsuznk0V9GwWNUz7welgswYw2JNj91HGrVP1Hm/Evh7+nOrZ4UKunuDziih0b/n2xbjmqL+9zU92+Jk89B3IrLQgelm6EQs45IzR4WZLOi2zXFxsx0o6AAyXXiE9UYXXdPGU5d2Y1/jb+mJZui6NtikWtuwPLYxesmli31zZS9ytT2Ahm7ZHB3D9hi6NqRtsdUzcXajiTv21wFk88aHm6KjZuhkW5wra1iu66lN0bYRbIoCwHIt/n0dI4WhC4U1PFQE+OdkVoYuRhPoaj+zjfKh9yIllwlo6BHbigBnwcW0ulyolzeuvCbCTBb0a3sd9Cwbx/cFC/pStZSZoVMc7qkru7E6l8fQI1wuAFm4BvOhr7iunHG4XMTI1UEYOhUDX3JxR/8HfNw9fXUPnAOvunUZQDYduGdyL75gLAy9a6LsRvUu10qZss0BBAaFkvJWfIYeN1jk/3xEUpYEl8ecx9Cz/T7FJ4io85aKdJTLJWxbnFRTNCqca1oZOj2Zxe2HHRVmsqCf3wg6XAiLtfT8DMIVN5dlr2vi4lb0MFIzxeWiDyq5CI/Po9TQOefYaPQ8u1u9rA6kobe8BdFB2+KgFxPJLa887hT0zAxd810uVkSAVZHY7ZiYr1DDPVvQVng/aDlhnZzfRI0bLPLfR08LouRAN9esDF2UXKJYdr5wLj7WZt9O2/BC2URMs8uFnsyk5JIB5zZjCnpVz8zQqaADwNNXomWXVoIPHRhOclmo6lDYaBl6o2uiZ9lYpUCnQRm6+556mKEP+Lj7zJVd1Esq7jo0DyCbDmxYflOUNujEPR11DGvorPZG18S8u+5uOUMUbscdqxdR0eOfJLoxkktZU8BYcAk2FfR5oaDnbXLT7INnWzRjCrolSi79DJ0++0GfzgbBbtvEQlXzDBCEaWbodL5IySUDLmy2oCoMR5aqga8v5Sno222U3IvnVExBb3ZNMIa+vA2CpgwmuVBIUlVXR8rQaaiIIlfrA6wtA8ReAo3+uwx9wIv61NU93HN4wVv4nEU2CGvoQP92HcB5Knnzr38av/J3Tw10bIS9juHJGnReJRWP6OTEeIbeCdkcCTQJK6YtkoZMNxjAJxlZb9BhDd0I/SxGRB66GaOhO68fH/N0xv71vq9Pc5YLSS7jWmJDmMmCfn6zhSNLlcCJBrhLBbJKLrsdHFuq4rbVOp6+HFPQexZquhp4jBYxaMe/664eq5a00RZ0L0ObIlfzZ2gDQNugBdFuOJcyuMuFc2fk/55D854dNJOGLgwWEUuMYr87bQOXttv4o8+fw5OXdnIfH6HR8Rn6Uq0Ezv3CGgUa2hGRFCJGj+JhGQHovxHsdfqbgiVVgaawzImL7YCG7kguomwSJblEhnMNERs9KHYjgrmA6WXonHOPoY86cyiMmS3oYbkFcC68tMhSwpXtNg4vVXDv4QVvajGMVs+M9aADw0ku1ZKCaklBZ4SSC62e21cvmKHnHCz63Jl1PHfN0c2v7HSw2zFxz+EFT8LJpKGbIkN33hfF0KkfwjnwK3/31MBa717H9Bj6cj1bLkuUYyWWoRvRDB2gNXRRkot/LjLGckXoij55XVXAud8D4Zx7T5rBwaLopigwniXdhN12HEMf/27bLNjrmt5nKzX0DDi/EV3Q6ZeexKQIV3Y6OLRQxX2HF3Bhs+110kU0u1asBx0Ywofu6q1VXR2pbZEkl9U5QUMfgKGL6+eAfOFcHcPCD/7hw/j3v/M5fOn8ljdQdO+hee/fyzRYZNkoaUENPWpalBadfP+Dt+Lhs1v42y9fTv23o+Bo6H5TFEiO0G1HFPSyFr1ODhBti1EMXQkUgr2uiYqu9D2R1ktqZsmlE5JcAP+GLOrhkaP/oSyX8HtGDWe5RT+xmlaGLs4eSA09BY2uiY1mzxvJFrGUIYMacLTB63tdHFmqeCmNNIouQhymicIgyXOcc+/xfOSSizsF62VoD7BYGPAll/oA4VxfeHETXdMGY8Dbfv+L+POHLwIA7jo0n0s2iNLQo+SMC+6O2Z/5hrvw0qML+C//8MxAP7OzlJiaosm5LEDcflA1vilKGnpEfybM7HfbRqAhSqiXtcw/WzvkcgH6p0NrJScjh55qPNuiIAvRHoBxjv/vRCy3ABwfergXMA3YlgU9O4iB3bpS7/s78ummORLWGl1YNsehRUdyAaIbo82uFetwAYCSlv+Rzxv5Lqmo6sqINfQeFiqax2irORidiLDkkiec69On11DWFPzdj70eq3MlfOSpqzi2XMVCRQdjzrBTpqaoaQd86EB0Qb+41cZCRcNSrYT/69++BFd3O/i9f34x2w/qgnPe53IBkmMlIhm6W9CjZJ+4wSJ6n9gU3YthqLWyhkbGJy4/PMxn+kZINyeJKVzoNaVfchmXhs45j5VcppWhi9JceJXgqDFzBT2csihiqZotQvfytmNZPLJYxcGFMpZremRBT2Pog0guopZZ1dWR2hbXG11PbgEchp01DEtEw7Nvhkf/0y+mTz97HQ/evg8nVuv4wENfgzv21/Ga21b8Y8rIMnsWF3zobkGP0CcvbLZwzE1IfODECu45NI8nLuZrjjZ7FjiH4HIhySVZQ49qigLRN5640X/ASVwMMPRONEOfyzFXEGyKhiUXt6C7Nw0q8HELLoDxaehtw4Jp88imqKoosOzxeuKzQCSU41oET4ivVlOKuKEiINvaLwC46nrQDy9VwBjDfUcWIr3ozZ6Fo8vxDD0qtS4N4qNvtTR62+K+OXFc3NesF6vZ7+XbLWewwx/9p3Cu5Iv6wmYLz6818b1ffSsA4NBiBR/5ya+FKviJaxmfGhwfeqgpGvH9L2y1vUgBwDknovojSWiEfN/zFQ0KS8s2j26KAiTHqH2vL6lKpIOqoqsBeSdOQ66VNGw0si1H77j5QWVN8SWXGIbeNW3Mw/nMFeY/kQHj19C9LPQYhg44zV0xb2bS2AkwdCm5xIJzjs89v47Fqt4Xdg/4AfhpU31XdhwnxOEFx8d+76EFnL6611egWt1khl4aYL+i6Aeu6tpI7+AbTSdpkZA30Imw0+5hsaZ7gx1ZGfpnnlsDAHztXfu9r+mhIlYraZlYJm0sAkSGHvzsOOe4uNXyMswBp1GepUkuotH1g7kAQFEYlmqlRIbe7vUXbTq0HIHgAAAgAElEQVTOqIu6a9jeVGgYfU3RGB/2XFnL3FSnRryzmCUom9CN0ZNc3AJv2HZfI3bckstOTHQuINpnp4uhU/O8qqsjX8QSxkwV9N/4n8/hU6fX8MNvuCPy7+fLDpNKY+hXdjqolVTvJLn38AK6po2z7hYkQrNXvMtFXIRQLcW7IIrAZjOaocc5Xd71sdN4x/se7vv6dsvwGs6Az4zSLqRPn17D0aVqgDGHkYeh9w0WhT779UYPHcPGsWV/4Gyhonu2v6zYjbAJps04dA0rfvtQxEXdjWD04vtEB0+shl5Sc/nQvZ2wIZbdp6FTQTd5REEfb1M0brkFMHxI3Kiw3XKG0uYrmmyKxuGvH7uE3/zEc/iOVx3DD7/h9sjXKArDQjV9uOjKThuHFise47zviNMYfSo0YJTqQ49IrUuDmKkxStuiZXOnoEctRYhh6H//lSt49NxW39e3W4bn9AB8ySXpQuqZNj73/AbecPf+vpFtEfVy+lMK5zywsagUo6GTw0V0QC1UtcElF+F3v5zG0CM0dC8KN4KhR02Weu/T1D6GHq2hZ18ULTZtw9OecU1R07b7pAw9JXahaNDTVaTLZUoZ+na7h8WqnjiHMCrMREH/4oub+Nm/eAIP3r6C//zvX5ZYILKM/1/e7uDIos/i7tg/B11lOCVYF53mIU9k6LrGcp/YAcnFtS2OoqlzebsNmwMHFyve12jjUBRD32r28PxaE9sRI+5brV5A4tKUYEGIwpfOb6HRNfEGQW6JgsPQk4sSfcYlLVlDJweUWNDnKzoaXTNXtosXnVsRC3o8UTAsG2bEOjk6ziiGHrUgmlDRFe8m0DNtdAw7cHMh1EoaOoadyW1EC6KBftkkrikqPhURxq2h78RE5wLTy9B3WgaW6zoqI3axRWGogs4YW2KM/QVj7BnG2CnG2NcUdWAEzjl+7WOncWy5iv/xfa/yLuo4LNZKgS7z2l4Xb/y1f8JXBKfD1Z0ODguFrqQpOL5Sw9l1X3IhFpvoQx9AcvHsaprqMbpRRMF++eI2AODlR5e8ryUx9McuOMyc837JaqcdlFwUhUFhyRfSp59dg6YwvPaOfYnHWS9pqaP/4YnFUoyGTlOiQclFA+fOcE5WkIYusuLFanziYvw6uSSG3i/R+O/zmV3U2D+BLLWtDEWj3UuXXEhi6noFnUMPNW3HraF7WegRkpPquXWma1p0q9XDUrXk/h7He2zDulx+E8BHOOf/K2OsBKDfejIkGGP43bc9gN224U3sJWEptOTiiYvbeHG9ib/80kW87NiiO1QULOiAM0252fTfR7ruXIrkYrsj1GpM3ksYPkNXUHUv6FYvXk8dFI+f30ZJU3DP4Xnva0mBTo+c9aWWrVZw3dl2ywhkcQPUP0go6KfX8KpblyOlAhHVDAyd9NpSioZ+cauFffVS4CZMhXCvEz2cEgVxuQXBWVYRt33ITzIUkczQ7djQt7JbCDjnkWP/BGpyN7tmpMYsIqihB+cIuu7/1z2Xi3N+iJHFhHGHc1E/Y5YY+nbbwOGlqvt0NSMMnTG2AOBrAfw+AHDOe5zz7aIOTMRiVY+cDI17rcgwX3RZ9yeeuQbOOa7tdWFz4HAoqXF1roz1pr9flJwXtYTBIm2Ak7sTaIo6//YoHssev7CNlx5ZCDwy17zFwv0F9NFzW6B70pZwY+sYFtqG1Xcz1VQGK4YZWTbH01d2A37zODjTq8mykzeCrqVo6JttHAudJ1ToyP6WBZEFvR6fE+R5yuM09Ij3JDdFff866f9xk6JAfJNbRNuwUSHJJXRDpBvmfKgpalo8MFQECD70MTVFd9oGakJcgYg8ERTjxI5rIijrykwNFt0OYA3AHzDGHmOM/R5jLN7OMCYshbKryblyYbON5643cNW1LB4KMfR9cyUv+wTwWWw9ybY4wONn0Ifu/NtZrIuff2EDP/3BxzPp7YZl48nLO7j/luXA1+lnCTN0w7Lx5Yvb3gYh8UklrimlKiyWoRPDS3q6IdRKmrPAOOEzDK9C01zJJ4qh37IcvFHTo3qexuhex0S9pAaeupYSpkXFRrcIYuiDNEUB54aVyNA911L6zcrJa3e+H2WzeJJLjIbei9LQx5yHHpe0CPhPC1kY+oXNFv6/Tz8/8icLSlpcrpVc2+KMMHQ4cs0rAfx3zvlXAWgC+LnwixhjDzHGHmGMPbK2tjbEt8sGaopSE+zsegtHXTb+P09dC0yJithXL2OnbXi/cI+hJzVF1fwMIehDp3Vj6b/0zzy7hg89dilTE/b01T10DBv3H18KfN0LwwoVgFNXdtExbHz9fQcBBCci6eYYllx0VYm9kLoJ0bBh1L1jiv8MqHjQDZQx1reGzrI5Lm23vSlRQp7ANkKj2+8qWa7FT4vG7weNn2jtmElNUf9GsJdg2/MYeganS0By0YJPll5TtOx8D8/lElHQR6Ghn11v4qW//FEvkVOEk4UeTQxUGnBLKeitnokfet/D+C//+Aze/cn4pfBZ8ei5LXzm2ehaRkmLS7XZc7lcBHCRc/4F97//Ak6BD4Bz/h7O+QOc8wf27092PBSBRTe7mpjNi+tNPHBiGS87uohPnLoemBIVQX5tkhs8hp7AMrVBGDpJLkJTNIt1kX6eLA3Uxy84ytdX3RIs6CVNQUlV+hg66edvvpcKul/8iJEuhyQXZ/1XXPAUuVLS+wK1DEXJCDF0wGG/4mP/td0ODIvjlpUwQycNPZ/kMhdixHRDiyro7RiGHrXwmZA2WAQ4N3qSiqIZeh7JJd7lEudDN20eiM513lu8hn5us4VG14y0zO62zdjeRxYNnXOOn//QV/Dc9QZedesy3v2pM/jyheGU4V/8q6/gbe/9In7+Q0/0GQwoadGxLc6Qy4VzfhXABcbY3e6X3gzg6UKOagiI4/8dw8LlnTZO7KvjTfccwJfOb+Gpyzuol9Q+G9iqW9ApQ9x3uSSEc9GFkaMp49jVnGnJPBo6MbUsk2ePX9jGSr0UcHsQahGJi4+e38LRpSpuX62jpCkBDZ0KWNSC3rgnEyoI2Rh6+tYi+vfCq9DE4RtyuNzSx9DzSy5iMBeB8lx2EiSXvv2gCZkzUfnpBO9GYNiJgzWeyyUDQ+8Ijfc+ySXG5dIz7cByC2A0WS70+b2w3uz7u50EySXLopU//vw5/M3jl/EzX38X3vv2V+PgfBk/9eePDzyhbdkcL643cWJfDR94+AK+5bc+G1iQQwRoqTYZl8uwPvQfB/B+xtgTAO4H8P8Mf0jDgex12+0ezm+2wDlw+/463nLvQXAO/MOTV3F4qdrnZV9xR+Rpyw+xniSGPkiUqMiUiNFlObl8hp7+2i9f2Mb9tyxF+vXrEZnoXzq3hVfdugzGGFZqpYCGvtOKllw0NX5BLx1jHAMVUcugA/dCTVGgfxsQedDDNzFinXmaorvCcgsC/fxRMw5i8JWIRIZuxrtcRIYe5Ykn0LmZZVF0kuRCEdD1CIZeipNczOI0dCroz19v9P1d3Po5IJ2hf/HFTfynDz+NN99zAD/ydSexWNXxzu94BV5Ya+JXP/LMQMd6ebuNrmnjh99wB97/jq9Go2PiJz7wmPf3RICWZ1ByAef8cVdOeTnn/N9xzvufmcYMsXlFDpcT++p46dEFHFwoo2fafZZFwJdcNnIwdE0ZTHKhC8tn6OkXZFbJZa9j4MxaA/eH5BZCLbS16NJ2G1d2Ol5DdLleCmnozp/7XC4J+xy7HkPPILlkWHIRti0C6NPQL2y1wBhwNFTQNVVBvaTmY+idflaYFM0ct32IjjeeoSc3Ramgz5W1SFusvyg6zcfvDD6FfehmiuRiWP2ToqrC3IZ4ccyTfo9RDH03JgudjgWI1tA//ewafuC9X8Sx5Rre9Z33e/lBrzu5ih983Qn84efO4oW1/htIGp5333P7/jm89o5VfM9XH8eZtYZHysSeE+XhjzMNciYmRfNAlFxoUOjEah2MMbzpHkcjjiroqy5DX28EGXraggsgX8dfZEo+Q0+/OGgwJk1yeeLiDjgHXhFX0MtaQEMn3ZIK+kpd79PQNYX1TcxqCeu/PIaeRXLJsCjaa4pq8Rr6xa02Ds5XIm8ieQO6Gt1+hl7VVZRUJdHlEi7QiuI0b8MM3XQLbNwNr+wxezuwaCOMmvu6NIYubisCfMmlF5fl4jVL+7NcAHg7SaPAOccv/fWT+Ok/fzzxmESQE+T8ZivwO7Vtjr1udI4NEB9B8eEnLuMd73sYJ1br+OB/eLAvyO+t9x8FgL7spix4fs15D+UT3X1wHpwDZ9ynix1PoiwF7Kfjwo1X0AUm9eJ6Eyv1klfk33zPAQDA4cV+bXmhqkFTGDaaPkOv6EriwFBJG8CHLkSpDqShp0gu1BC9/1h0Qa+XghnaXzq3hVpJxT2HnAGk5VopoKFvt52horB84zRFk10uaVO9gMjQ8zVF+xj6ZiuyZwDkD+iKaooyxrBY07HTjne5hJuigJNtHr4Jkzc5flJUlFziC7qisEwBXWFJKMrlojD0FSAx4VKEs6kr+pz/0y+exx9//hz++bn1xGMSQZ+fZXOc3/SL7KXtNjgHDiz0EzAg2of+kSev4Mf/7DHcf8sSPvDQgzgw3//egwsOebu22+37uzS8sNbAYlX3Bu/ucq+b065DZ0tsigpPWuPCjVfQiaG3enhxvYnbVn1r/OvvXMXrTu7D6+9c7XsfY8z1orsMvWcmetCBwSQX8VE7j20xq+Ty+IVt3L5aj4wXBty9ogIbfvzCNl5+bNFrfi3XSthsBTX0qEfeRNuilaMpmmE4xveh+8WlrCkBj+/FrXbs8FmegC7L5mj1rMgiuhgT/BanoQO0tSj4syUtiBa/TpJL0hToXFlLZ+i94A2nb2ORZaOkKYId1Dm+KNsi4EhJUef8Vy7u4Ff+9mmHGLlbwbJA/HzOXPcLukdOYp42tQgf+seeuoZ99RL+6H//6lipZnWuDMb8vQh58PxaA7fvr3sE59aVGkqagmfdgk5JiyVN8X6P43S63HAFvaypqJVUbLcMnN1o4sQ+v6BXdBXvf8eDePWJ6AnGffWyr6F3rcQpUWAIycWzjzl6ZJpLgVaiAckFnXOOx92GaBzEvaK2zfHctT3cc2jB+/vlegk7bcOTU7bbvcjIhSQd1fehp2vo1RwMvRSwLSqCNGDjyk67b6iIMF/JvuSiETElSliKKehJBTqcbQ4IawhjGLrojkmSXACnWZqWU9MOSS5euJrtSy5erIKqCBo690iLCF1V+pqiOy0DP/Knj2J1roQff9OdsLlvMEiD+Pk8L+jaj1/YRllTcPeh+ai3RbpcuqaNxaru/axR0FUFq3NlXN/LX9BfWGvijv1z3n9rqoKT++dw+qpb0N2kRUB80pKSy1BYrOq4stvBtd0ublvNHi+zb66Edc+Hns7QB5FcxKYoYww1XU3V0Fs9y2MhSZNnZzdaWNvrxurngMvQXTZ8abuNZs8KXDArNT0Q0LXVNLydmiJ0NX6fYy6Xi56c0Q7E+dB9KePcRhM2B27dFz2ovFDRMrtc9rrxNsGlWnSSZ8dwCmKUPFfWhmDopsPQk/Jw5jPISWGfvLPkggkuF9uTx0qaEmiK0jkuQo9Y7PJ///3TuLrTwbu/95W4+5BT8Nb2shZ0C7WSioMLZbyw5jP0L1/YxkuPLkY+JQDRLpduwsCWiIML5dySy17HwPW9Lm4P5fvffWjeY+g7Qu5RJccTeFG4YQs6DQ+cWM2eRuAEdDm/5FbPSnS4AMNILv6/W8mwhk58pE5i6L/1yedQ1hR8w0sOxr6mLrhc6CS866Bf0JfrNBHpFC5n43o0Q4/zofsul/TTS1MVlDUFrQSnD7FBPdwUdT/35641+n4OEQtV3etBpCHJJrhYLcUU9KTkxH6GnrRP1HlPSHKJmZQEnPyVRsrPJi5VITgs23e5iAu4Ay6XGIYe1tBPXd3F60+u4pXHl7F/3tGor2ct6G6uze2rcx5DNywbX7m0g1fE9IKAaJdL14wf2BJxcL6SW3J5wWuIzgW+ftfBeVzZ6WCnbThJi25BzyOpFoUbsqAv1XRv0OS2HAV9X93Pc2l2zUQPOjC8ywWAuyg6mWGJxSiuoJ+6sou/euwS3v66E5FNX0LNXVtm2xzPXKWC7p+g4RH3beEEFaGrSuqkaBamBLiLohMYejdCQxe13mevNcAYcPLAXOT7Fyo6djtmJvsY3TyjZA5na1FUUzR+SCiaobufTxxD1/xH9bjlFoT5ipbK0KNcOM7vz18S7WfNK8Lof7TLJUpD7xi25wijRuRaRgbcNWxUNAV3HKjjhbUGOOc4fXUPXbM/vkJElMula9iZiMTBxUpuyeWFdedmE97ARU8kz13bc00EzjVUlpJLMRCbISdiHsOjsDJXQqtnodUzMzH0QcagRQ0dcFweaQx9tyMy9OjXvvOjpzFf1vAjbziZ+G/VBWfNs9f2cHSpGigY1L3fbPbQM200e1YgC52Q5HIhhpfF5QKkL7mI8qGXBSb57PU93LJci9VN5yua1+xMA9084zT0Zs/qSxpsJxT0SA2dCmzMDU9TFWgKw3bLgGHxZA09Q1M0rKEDzrlLhbtn+s1PkaH3ElwuYRLTFiZRiaGvNbIydBtll6HvdkysN3penn+cWwuIZuhJGTkiDs5XsN7o5bp2n7/ehKowHF8JF3SnB3X62p6XtAgkD5aNCjdkQacx7QPz5VSWLYK86BuNXiYN3RvQyBGwL2rogPNLb6fcwUUGFhVb+vkXNvDJZ67jR954MtbdQhCzU05f3etrOHmSS7PnyQtRDF1T4tfv5fGhA+6wUwYNXbxBiLbFM9cauDOGnQNCQFcG2cVPN4xfQh6WXToR6+cIzjq54M+W1hR1/k71CuLQGnqvP2umT3IRNHQ6PtPmfYNFznv7NXQnDljxjn2+ouH6bjYGTHEYd7i/w+fXGnj8vBNfEc7mEeFr6EJTNCHFUgRZF7PKQoDD0I+7rhYRRxYrmCtrOH11z7P5AsKA2AgXwYdxYxZ09wPNI7cAwrRos5fN5UJRohnHoG2bOyPfIckl7ReeJLlwzvFf//EZHFqo4O2vPZF6DMTQd9sGXlhr9unOKzVfQyfP9WKEy0VLCufKkbYIkJUybziX4q4JtPHCegN3xujnQL6ArqS4Wn9oLSi7tBOKSFlX+n5naU1R5+8UryDGDdYAjtaftmIvKjxMlFwCTVHX5WLbHJYdN1ik9D+lhJa0HJgvZ2bodE2QlPHCWhNfvriNVxxbTFw3GeVDz94UdWShaxlvOoDD0KMWnjPGcNfBOTx6bstJWnQJZdLGqlHhhizoiwMXdGLo3WwM3T2hsgYV0S9WfPStltTEhiAQLEThIZUvnd/G4xe28RNvuTPT1iPSOZ+6vIueZXv6n3g8FV3BVqvnBw1FbYtJzHLxfc1ZUC+riXk2NNEoLlsgJnluownD4oE+QBheQFeGadHL221oCgss1yaQNhrF0GMllwiG3snwBFPWfIae5EOnYt9IuCF6NxDhvNNSJBfD7r+JEkpaUEPnnKNj2oEbxv75Mq5n1NCJoR9ZrKKiK3ji4jaeu95IdGvRzwCEXS4ZNXS3oGd9irBsjhc3mrh9f/R5dveheTx9xQnp6ne5SA19KBCTyuNwAeBdxNf3uoEmTxzCmRhpiHr0rZaSixnge6OBfg2dBqFednQx0zFQQt9j5x2NMsoZsuwGdG3FBHMByWmLDkvKfmqFh53CMCzHhSHeIMqaCsvm3mLvOw+kM3RRcvnLRy/iP/99fzjouQ1n4jScMggIwW+t7AU9mqGT5JLM0Mn2l6ahA8FzJIyo864kSi6WXwRLmoquZfftcRUR1tANy2Hz4lPKgflKdobufn6KwnDb6hz+4StXwHn8QBFhKJeLK7lkdbpc2mqjZ9qRDB1wriPqudONX7pcCgI98uRpiAK+5ELJffWskktGlwuNfIddLml38L2OAcYcrTlcHJKmFKNAjd7HLmxDYf0WLMAf/9/2kuMiJJekSdGMLIkgWimjYJj9zTmSCJ66vJvocAH8gih60f/my5fxR/96rk+qeHG9GUsE4rYWJWno5SiGnklyUb0ns7i0QcDX15PkpLZhQVNYgG3rglPFECZCScoikhJtWwxq6PTEEZZcru92MzmLxO1Nt++veyaAJMuieGziedgxrNhms4jlWgm6ynAto4b+/LofyhWFuwViJBl6wXjFLYt41a3LeODEcvqLBdRKGmolFefdgp7G0LWckgsxJZFBVPXkYgb4ca7ViDHyrpHeYBNBP9PTl3dwYrUeWVRW3MRFkhaiGq1awqRoz7QzWxYBNzAspSkaXlZMN4wnL+0kOlyA6Kbohc0WuqaNS9tt72ucc5wLTReLWPSimcMFPWGdnK72yWRZm6KEtElRwNmyFIewVRZwirIZMSlKdlCPoUfcmMM+9Kgb1P75MtqGlSnaV9yvSgTjxL6a16CPwzAMXVEYDsxXMmvo5EG/PeZmf5dgLqAnOTpHJUMfEseWa/jL//harLqaeB7smytlZ+ie5JKRoUc0p7LYFinPQ5yOJMRty4kD9QUMiwdYhQgnQtfAdsuAqrC+ZSAALYkuhqHXUm5qSbstn7y8k+hwAfyCSCzWsjkubjm/Y3HUfL3RQ7Nn4cS+6Oni+YoOxvxEPULYiiqCfN12iEUC8bZFIFjs03zoQNDaGkbHsAL6OeA8YYkj/p4PXfWbzYDfJxIR9qFTVkyAobuSRpZp0Y7gHSdJI00/B/pdLqZlw0pIsQzj4EJ2nf/5tQaWan4oVxirc2VPsiXJxUvblAV9cthXL+OCO5SUxtDzZkNH+YFpq0mSS4ES98p6v+SS5fFdhOjciZusXKnp2Gz2vFyKqOampkQHNAGOJprVg+4ck4a2YcV+Bj2zf9ECXbTbLSPR4UKvreiK1xS96q6rA/w4VMCPU701hoWpCsNCRY9g6On7QcXfG0UFKBHF0nuf++8pDH3RxSLmM2jozW7/TIVYlKOaoqanoadnuXjNfpGhz7lNxywFPYKhp8ktQD9DzzOhDDiN0auZGXoDt6/WExv9dD2JczAVWdAni311f2NP0oVESJIewohrigLJ1ibK5y6H1q4B2RpsIkTnTlzo0VLNGXHfaPQiHS6A83MnMvSMx+MckwrO4z8DcZKRIP53GkMHggFd5zda3tfPCFtyzgoLUeIQleeSPClKkbRW4PVpRYf+PeepIL6IZNHQmxH57qLkQq4kwC3olu1JKpE+9FCWix8tIDRFczD0rhAp/ZIjC/jVb38ZvvPVt6S+z2Po1uAFPavkcmGzHZsVRHj5LYvYP18OnJvjXkOXfermJgE1RgF/CCcJpYipuThENTDFNXRxTwR7HROrcyUYlh3ZFI0LhopCRVfAGMB5AkN3Hx3PbbRiB5VUlcXuUu2aFsoxgUpRqAkRulGfQVQut3jRxv0cIsSALpLUDsyXA5LLuY0WVIXF5qoD/YmLza4Jw+KxeStRjbEssRKkAyfp50A2DX0voqAHJRdf8vCaonb/dC4hTkOvhpqiQDpDdyyP/g2OMYb/7dXHE99DCDP0vE+rBxcq2OuYaPXM1KfxZi9+0QbhJ958J972NScCX6uWVOlDnyT2Cbp7JoaesL0ljPDmGPHPSTo65XmUopYlGFamJhCBMYZ6SUNJVWK1YmpGvbjeHIih9zI2pgj0OYuhYf/tE895DgkjQUNPc7gQFqo+Q7+w5RTu19+5GlhD9uJGE8eWq7HpfvTviJJL3HJqgr80wv/9OgmKycVBZOhJqJdUMJbM0BsRO1L7JRenOHo+dFdSibJvhjV0OnfFp7LFqo6SqqQy9J5lg/PsRVgEY47kaYUll4znXp5FF62uhWpK0a+VNBxdCpKBqDmEUUIW9BDEgZIsDD0ppCqMSMklg1eVCkBcFGvWhiihVlJxx4G5yIsV8KdF24YVmYUOOBq6ZfNIW1rupqi3KNr52d7/+XN418ef9ZhwLyIkiv79Y8vVRIcLgQK6AGfV2ZGlCu45NI/1hm/PPLfRTH2sXqqVAk1Raq7Gsfqy1s/Q97rxi48JpKGnsULGGObKyQFdzV7/BibHehg1KarCtLl3nmXxoUdtbGKMOcNFKQFYeWWSMMRMIT9yItv1cCjjtGjPdCSoLAQvjKgsn1FCFvQQVnMydGcMOp/kElXQk4KjKBM7vOkeSNZv43B8pYZXJ1g6xUGiqKEiwNcvo6ZFu3ltiy7zoWXZT112Ju4u7zjs1xBsdQQqAHclDBSJmK9o2HOZ9fnNFo6v1LwG3PNrTceyuN7CbTFPLYSlEEMn+SZuW5K4To6w287C0ElySS78QPqKvSiGrqmK5wqxbI6S6vy+qLDToFdcU5TeB/iFNGzDXJ0vpzL0vDJJGM6TonNN5I2cOJCxoBMRy0Lwwijr6S62IiELeggBDT3lEQtIXpgbRpTLhdhp3LRo17TQs2zX5RI9dZjVg074k3d8NX7pW+6L/XvRmrUUkYUO+I/iUZbNvJOiZA9tdh2nyyl3hPrKtnOhOT70sIbuvCfN4UIISC59Bb2BjWYPe10zA0N3mqLkyLm41UZVVyOjAsTjFH9vaZG4gF/g0hg6QImLKRp6H0NX0LO4b0/UfMkFgLenNLKghxa7ROWtA26eS0pBz1uEwwgy9Hyxzb7kklzQKZpjMIauJi6lKRqyoIewz01cLKlKJutdHsmFQrjEk7eSoqGLYVHhTff0vrySS0VXE3VicTI0naH3/+xdo9+VkgS6cbZ6Js5uND12eMW90KJ86GQNe8mRBWQBSS7NrhPPestKDceWqyipCp5fa+Cca1k8kbLharHqbHSitW8XtpyogDgnSiRD76Q32CoZm6L0mjiG3jNt9Ewbc6Wwhu4QEWpuioNFgF/Qo1wu9Foq6FFNUcCdFh0LQw83RbOde/MVHfWSmqqhkxQ4CEOvSsllslh1GXpa0iIhj+RCAVYF4/QAACAASURBVEbixS+6XKIQLOhRtkUrl0UwC6ol1Tuu2IKu9ifdEcRskCwgK2Wza3kBRwBwxZ3i7EVILres1PA3P/o6fPPLDmf6HgtVDT3T9myKx1dq0FQFt63W8fz1Bs6uO9JJWlyEF9Dl6vsXt9qJrpgwQ+ec52PoKVo74CcuRoEKcxRDNy27L7u+HCrocS4XwI+8aMdYZ/fPl7HZTM4c96dmBzuHVUUZmKED2ayL1KyvDXCMFV26XCYKcnikJS0Sckkuvf5VZV5Bj2XoTuGYL8do6KGUu6JAskvc5vREDd3I50MXF0U/dXkXmuI01K7siJJL/6n6iluWEodzRFBA15OXdwD4rpQ7DtTx/FoTZzeaUJgzZZwEf/zfaYxe2GwlvifM0Lumnbq0AvCbotkYeryGToU+SkM3LO4XdDVU0F2CEZ2HHs3Qwzdx2ly0nhDSlbaOLw2awgQfevZdtt4xLpRTC7rP0Aco6NLlMlnoqoLFqp66rUh8fWaXS4Q8UssjuUTkgnQibhJFgJh5rMslZrkH53xgDb3Vs/DU5V3ceXAet67UcIWaolb/pGheUGF88pLzBHDcbWLesX8O5zdbzvam5WqqVCQGdO20Dex2zMQlDOFJUZpWTWPe5RxN0SSXS1xBL7nxuWGGTp8zvS8unAvwl63QoFT45uptLkqQXfIOxoWhKsyL+h1Ej3cYerLkQgw9K8kTUdGV1DTVIiELegT2zZUy62XhMegktCMyNSopTVGPoXsuFytgFRTHposEMfQ4H3rUcgHAYew2z3dRVTTHS93smnj68g7uO7yAw0vVIEOPYIp5QAX0qcs7mC9rXmG+Y/8cLJvjc2c2MqVzLgkBXZdcD3oSQw8HNJF1Ml1Dp6ZoFpeLFrsEu5EguQA+kdBDGnorQXKh14gMPco66g0XJRTMOIdMVoiZQoPIN4dcyYVzjicv7eDr3vkp/PNza4HXkAMtLdspCo7kMkMaOmNMZYw9xhj7cBEHNA24Y/8cji5VMr1WXBSQhk6vn6Hn1dBtHpQ5wivtigI1RqOicwGfpYUll0F0TEVhqOkqzm60sN7o4SVHFnBksYIrO86FFjVYlBdUGJ+5uodbVmpeH4OcLntdM1NB99bQtXq44HrQ44aKAH/Yhgo6Fd60Qu0PFmVzuXRNu69hDvgZL1GSCyBo5VqwoDe6WSQXakbakUFj3vh/ouSS/3wRIbpcBpFvDixU0DVtfPbMOr7ndz+Psxstz2VF8DT0ARh6WVe9DVDjQBGj/z8B4BSAbHaDGcBvftf9mV9bGlJy0VUFusoyu1wAp2jSRTWIDz0LVuolMBZfUFQvizr4s+ddEE2olTU8fHYTgONcYcz5t2hZ9bAFfdEdze+Ztie3AE7+NiHLQhR/DZ3hbVJKborSpKgruSSsuBNx/y1L+LZXHk3cek+Y98b/TaxowRvwXozkQjdk0sr9pihZSBNsiyEN3VmS3f86cowlMfS8zpQwghr6IE1R5xh/6A8fwYGFMva6Zl/QmaehD2BbrAqSW5YBuGEx1FXCGDsG4JsB/F4xhzMdcHLRRyO5RP1SKwnDB3sCwyJdVfS1dkI7SovCt7/yGH7+G++JbTrqMU3RvAuiCfWS6kks9x1ZwOFFp0he2ekE4l0HhahFHxeGh+plDUcWnaexuCgEEWXNcQBttwxc2GxhTpBvol/vZOd0Qww9TRtfrOp413fen0lymXNfE5W4GOdyiZNW/MEiKujRS6IBfw9AHKkoaQpW6qXEadGo5Rh5EHS5BG9OWUDTogcWyvjAQw86/YiQY2gYhh5lWx0lhmXovwHgZwFkm+64AaGpflMmDe2eFZnRXtXj19DtdQzUSio0Velje5btuBRG0RR92bFFvOxY/Fq7OA3da0zlPCbKybh1Xw3zFR1HXMnr8nbb9aEPqaELhTE81XnHgTlc3umkDhURlmrOtOh2y0j0oAPOCLzoTvK3EBWXi+dnovfr6HGSC7HsMEMvhaSYyJ2ixNBNkaFHF+T9c8nDRd6ClgEll8CkqJtJkzWoDnDO8x9/00l812uO4+hSFfNlrZ+h9yzoKhuIVHjhbGOyLg5cCRhj3wLgOuf80ZTXPcQYe4Qx9sja2lrSS2cS4aCiJMTlrlQTllyIQU5hT3N3SHYzDLzlHgVo6IA/hUeDQodc1nxpux0YTR8UFV3xbgrHQwX95IE5aApLdKuIWHQTFy9uJVsWCeIaOnK5ZHGvZAVlokc5XYhthh0aZDsN+8095p5kWwytXuwa8dbZAwvJw0WdAayGIgKTojFafhLKmoqf+Ya7vVCtKE9/UhJqGohsjcvpMgy1ex2Ab2WMnQXwAQBvYoz9SfhFnPP3cM4f4Jw/sH///iG+3XRCU1k+ySWqoOtq7Aq2hhB9WvIYuvPaqLCvccFn6OH1aoNJLuQquu+wU9BX62XoKvPWAYZH//OCMeax9HBB/+E33IH3vv3VmW9CSzUd261e6lARQQxo2uuYqUsr8oJuDlHDRc2uiXpJ7ZPO+qWVoA+d/i090raYTUMHHOvi5e12rOTQGXL0PzApauZLHo1Cvdxf0OkzHASViHC2UWLgn55z/vOc82Oc8xMAvgvAJznn31fYkc0I8qYtRmnoR5aqXmpfGLvCVKEnubgnR8ezaY3ffarFuFwGbYr6DN2ReRSF4dBixVtGMawPHXCkCcbgyTmEgwsVfO1d2cnGUrWEc5stNLpmbCiXCDElk36fSTJNXpA+HmVdbHT6c1wAvyi3uiHJRWDoqsIieyhZNXQAeP3JVVzf6+Kt7/6XPvcI4Of+DPp5hBn6oG4ZQpSnvxVz3WbBzEguEg50YVFAGuIamCcPzOGF9WZkvniS5DJsDsYwoIGTPg19QMmFHmnFbJbDC1WfoRdQ0BeqOg4vVIa+6BeruqcLD8LQs1gR80B0uYQhPuGJIMmlEZJcRIYe17fomxQ1462z3/bKY/iDH3w1Nls9vPXd/4L3fe5s4O+7Rr6YiL6fI+BDzzfQFoX5CMml2UtfSBKHSsi2OmoUUtA55//EOf+WIv6tWYOYK52EpAbmyf1z6Jm2F8UqYq9jeFIBPU7SDSQu5W4c8Bl6MZLLrftquGN/3Ys0BYDDS5VCC/rJA3P4quPxscFZIbpashR0kaFnyXHJi7kEDT2uoJMOHudD75l2pNwCREguveSohzfefQAf/cmvxWtuW8Gv/N1T3vcEhrfdhrNchnVDzUU0RVsRO1mzwltwMibJRa6gGxJZJZcku9rJg85wy5nrjT4vdJChBzX0STZFtYJdLj/2xpP4D2+4PfC1Q4sVj/EP63IBgF//jlcgYh9HbiwGCnq65CIy9N12etJiXlR0FSVViS/oEd+PGHkrxuUCIDI/B/B/F9Q76mZI/Fypl/AtLz+Mz55Zx07b8BjvsAU97HIZ9lqYK+t9DL1lmDg4n23QMIyZZOg3M2h7S9TmHhG0fSdqlJ5WqD0nLCwmJEku7V7/pphxwZNcCnK5KArre8+RRZ/9Dsu8AKcxmjXMKwmUEb9Q0WLDy0RU9H4NvWjMxYz/Ry23AASXS8hvrqkK6CPSYj4rKvq9DE1REVELrbtD2m5VhXmkIsvy7TSQy0Wc7Gx1rYGicwG/oI9ryYUs6EPCYyspsgttio8qAAsVHQcXyoEN9IDjIGkbFubKoaaoWxyGnbIbBnGSy6BN0SgcXvRZURGSS1EgySVLQxRwfm+ihl6kB50Qpf0CDkOP0n+JfYebouKf4z5zUXIxLBumzTORCvq5Rb+8U4SHZei+5DJslDRZQOlGR38eJDoXEAeLptzlIuHA92Mn/8K8gh4zVXjywBzOXN8LfI0uUI+hh/S4YafshgHZFsON3EE19CgcFhn6NBV096acRT8HnDyPjsDQs0x/5kVc4mKja3pFSoQ3QNTrD+GiAhvbFBXCufI05n2GLhb04Rm6V9ALYuhAsMHsMPRhbYuSoc8EPLaS4kWnPZRx6YUn98/hzPVGQLrZC+V+9Esuk/OhU8Ms/GQy7NJfEYcFe2GcnjsJUHJjUiiXiLKmoGs4AU2NbvEuF8Bl6KGCzjmP1dB1YSJUV1nANpjO0P2nUj/+Nv33s1Dpb952h0wLdXpY7rLrnMvJo0DyFH2WnHPH5TLgYBHZHaVtcUbgndxZGXpcQT84j2bP8vJMAP/RtM+HTpKLOVgDsgioKjH0sMtluPQ8EfvqJY85FtEULQoU33BrhuwXwNfQGz0TnGeLxM2LubLeN/rfMZwl0FGSiyaEc4Wffui/tbiCrvhOmEEY+m47yNCHKcJqSHIZuilKNx2XoXdNGzYfbLkFIMYnS8llJhC2cMVhp+VsuIlbbHByv+90IeyFsrP7BosmytCjewddwwJjxRRgxpgXATBNksuhxQre+/YH8O2vOpbp9RXNWUwSfuIqEgsRGron2SVILq2u2dfvKHuOl+jfoaIwaAobQHIhDV2wLZrDrVDUFObJnUU0RedDDN3LQh+QoXtZPlJymQ1oGSWXnbaBiq7Envh3Huwv6F6wknshaKoCVWFTMVgUq6Fbzv7PoiYhqTE6TU1RAHjTPQcz53uUdQUd08qctDgI5iIWRccttwCC4Vzhz5YKfBxDp/c7BT2706qiqyhpSuBJYpD8FRFhhj70pGhIQyfP/DDRt0lpqkVjuq6SGUQeySXJ4ravXsJSTQ9YF/e6/QVAXBTdMZ3x7EkUOy3myWTYyb8wjrihSdNW0POgoqkwLO5ZV0fpchF7MH7SYv95J4ZuhRm6V9ATLJ40UNfOSSoWQjceR0MfYlJUHP0vIMslrKEPy9ABmkOQBX0mUMoouWy3DM+/HAXGGO48MIfnIyQX8RG9JESxtnujWRCdBVqsy2V465gIT3IZMpxrkqAiQ8uSR8LQyzosmweYILHMqNVp4g0yVnJJuDGXNAU9QXKplrKVkoWKHqGhDzcpalkcls1hWHwotg84y9gBX0MnF9CgGjrgPL1IDX1GkEdySRtCOXlgDs8J1sWogk6OCYD2iU7mVxgXzlVEnoYIYuhFNFknhYr7edDmnlG5XIDgkgtfQ+8/78SeRF9TNBNDV2CYtncDyfr7mQ8x9E7GoaQ4aKrD0HsFGQTo5kefY7sQhq6OjaHL0f8hkUdySRsTv2P/HLZaBjYaXeybK2O3Y6CkKYGLRcwFGXYoYxgkhXMVWdC/9RVHAM4ze76nESRH0G7NUbhcxIbjATffrOFKdlEaeqLk4jmLsmjo+SSX+Yru9RJMdyhpuCwXR0MfZJ9oFDRVQVVXvc+ONPRBs1wAmkOQDH0mEN7eEoedtpG4qgwA7jzoLH46c72BjmHh889vYF89KNOI22/itq2PA6rCwFj0pGiRN5nFqo7v/5oThcbNjhue5LI3BobeFRl6/LZ6kX3HNUWTC7qjodPTYtbzcKGqeS6XImYWyOVSpF1WXHJBGvowBb2ijU9Dlwx9SPjNwWIkFwA4fW0Pv/fZF/HEpR28+7tfGXhNWffjeoedshsWYkOKUETi3Y0G0nXXGl2UtHin0zCgxqc4hUmyQZTkwhhDSXV08H7JJXlS1Pk7571eUzTj73y+7DP0IlxaqsJgcwjSz/Dn3rwwdUsa+qDxuYDz8225tuVRQxb0IZFFcumZNlo9K3ZKlHBksYJ6ScU7P3oaex0Tv/KtL8E3v/xw4DWO5OJPik6qKQo4skvfxqICvMA3Goihr+11C09aJERr6AZUhcXe9HWVoWfFN0WTbIslzfnd+03RHAy9HWTow7pcAH+RcxE3S5Ght4tg6NLlMjvQM0guaTkuBMYY7jgwh72OiR994x34gdee6HtN2LY4CQ86IY6hF+lyuRFADP36XnckDhcgOhO92bVQL6mxcpUWo5Vnk1yUoG0xc1NUR9uwAvr7sC4XwJdGiiATYiY6rYYcdKcoMF6Xi2ToQyJuWbKItLF/Ed//4K04t9HCz3zDXZF/X9YUjz10DBv76hMs6CobeVP0RgAx9I1GF0cWB8vVTgM1WvcEDd2JXo4/58J7RAlZ4hYcdu8MFpVUJXMs8byQ55InByYO4c1LRcRgzJU1nG86i1VaPRNlTfEG6QaBdLnMEPygoiSG7uhnWQr6dzxwS+Lfl90xcmCyTVEguC2G0CvYtngjgBiozUfjQQf8xmdAQ+8akVnoBBrtj5Nc0hh6o2vmth0uCImLFFg1zBMdFVqKAS66KTrM+jnCOAu6vPKGBJ30SXtF8zD0NJR1JWBbzNqMGgV0lfVr6LIp2gdRFhuFwwVw5JNaSe3zoUc5XMT3AP1M3B/9j2elJcG2mEf2Exk6EZNhhoH8kDGXoRfUFPVcLkOsnyM40Q/StjgTyCK5eNuKavGTolkh2hbbE2foLHpSdIaHgEYBsciMwoNOCGeiN7oW5hIll2iGTpJLUiCaM1jEcz8lUjjdbltk6MOlLQJOyBhQYFO048QotHrWUENFgHPD6pl25BL4oiEL+pDIJrkUyNAFl8uw+xiHhZhFTZAul36Mg6EDzvm1KdjjGh0jMmmRoHuFO3gOUYHVYpZEA04+veHaFvMwbHEAqpuzoRoFf5VekU1RHabN0TVtZ1vREGP/gP/7744hE11eeUNCyyG5FGFZoyhOzp3lApOUXFQhupTguFzkaSVC/DxGpaEDTmLns9f86IhGN3qfKIEKuh7KySnFfD34Xr8pWsnD0CkTvWMUYlskl0uzyKaoIAu1esNLLtUxrqGTV96QKGWUXObLWqKvNyscDd2fjMtzMRUNTQm6XDjn6FlScglDZKCjSFok3Hd4Aec2Wl5jtNm1Eht69HRZjhssSmDopKG3c/ZxFoRF0Z5tccg8dEC0LQ5/7nmZ6F0Tza45lGUR8Bn6OBqjsqAPCU9ySWDou20jdrFFXpRUFaa7ygwY7nF1WFAwEsGwODgv5rH3RoKuMpDrbZQM/b4jTojLM1f3vHV3UTku/nGl+dBTwrksjm5O2Y+OZ7dt+LbFITcWAT5DL2Jyui5E6DoaejGSiyzoMwA6odI09CL0c8B/pCQZZ5Iaeti2WOSC6BsJztYa5/c0qklRALj3sFPQT13Z9VwfSRo6Fe7YPPTUpqjD0PNMK6sK85q3RYz+hxl6EZutvCGtruFILkPaFl96dAE/9433FGKKSIP0oQ8JysQwkiSXDMFcWUHFkgp61hzqUUBXgrbFIhdE32io6ArahjVShn5ooYLlmo6nL+/iG+47BCA5g4SKYfwKuqSmqKCh52TFToSuf00Mu1MUcGyLmsIKkTXFGIVWzxyaoZ88MI+TB+aHPq4skFdeAdBVljr6XxhDd5mex9AnKLmoodH/IhPvbjTQZzJKlwtjDPcdWcDTV3YTo3MJaZJLVh96XuvsfEXDbsdAx7CGLsKeD71rFkYkiKHvupJLdUgNfZwY+BNgjN3CGPsUY+wUY+wpxthPFHlgswQtZN8La2XbreIZOm19mWRTVFeD4VxFLRm4EUEstqgbexzuO7yAZ67uebMPibbFGMmFmqRpkovNqZDmOwcXKro3+j+sZOi7XIZbNi2CboJrbtzxsAx9nBjmyjMB/Azn/F4ADwL4UcbYfcUc1myBokQBJ8v8pb/8UTxxcRuA4/wosinap6FPmKFbUkPPhHEwdMBpjPZMG1++uAMgWXLRXbmiL8vFk1ySm6KA4/8elKEPu08UCKYtFmXhJYZ+bbcDAENr6OPEwJ8A5/wK5/xL7p/3AJwCcLSoA5sllATJ5ekruzBtji++uAnA8Z72LLt4yaVFTdHJjv6LOfA0yi1H//tBv6ckX3gRuO/wIgDgYff8y+RDDzHxA/MVMAYcWIgPEhMdMHlJxULVZ+jDynOqMFhUFEMvawp0lc0kQy/k7GKMnQDwVQC+EPF3DwF4CACOHz9exLebOoiSy+XtNgDg6cu7AIBtN5graUF0HhCb2vaaotPE0KWGHoeyrqJeUgtp2iXh9v11lDQFD591CnrSE4Ee0/w8vq+GL/7CW7B/vhz7XvGmPUhTlEb/h5XnNGH0P7zda1Aw5jhxPIZ+M2joBMbYHIC/BPCTnPPd8N9zzt/DOX+Ac/7A/v37h/12UwmamgOAS1tuQb/ifBRFjv0D/S6XyfrQlcBiDym5xKOsKSN1uBB0VcHdB+ex0XSIRCJDj3G5AEgs5vR9CPklF90N58oXGxCFAEMv8Lybq2i4tkcFfXYIylCfAGNMh1PM3885/1AxhzR7IE8uAFxyGfrzaw30TNuTRgprirqPldutyfvQtRBD70mGHovFqo7V+dH7kAGnMUpInhRNj8lNey8wgORScbJStltGAQzdf3+R591cWce1XVdyGTLLZZwY+FmCOWtQfh/AKc75u4o7pNmDGFJ1aasNTXG05TPXG540UjRDJ5fL5FfQRUgu0uXSh1/4pnu97T6jBk2MljQlsZ8R53LJgoCGPkBTFHB2rB5ZrOb+3iLExRNFnnfzZc0jKDeL5PI6AN8P4E2Mscfd/31TQcc1U3CagzY457i03caDt+8D4EzsjVpymWTx1ELhXCS5FDGtd6PhyFIVd+yfG8v3oonRJMsiIKYt5v99lQIMPd/7yfF1fbc7vMtFuLEUytCF3sOw8bnjxMBHyjn/LIDB9zLdQNBUBT3Txm7HRKNr4nUnV/Hw2U2curKLg65TIG2faFZ4kku7B8Ymq1eHV9CRy0Uy9MninsPOVGLapp0kDT0NAckl51MiMfR2AfHPo2LoYu9h2PjccWJ2bj1TjJLqjHVTQ/T4Sg13H5rHqau7qOgqFAbMFXSXFxl6RYtfADwOhJdES5fLdGChouP4Si3VIjmU5KIN3hQV82yGJSSaWNALbooSZqkpKgt6AdBVht2O7TVEjy5Xce+hBXzs6au4bbWOhaqeeYluGuji6xg2lgti/YNCi5sUlS6XieM7HziGnpW8IcdviuY/N4fyoQtun0IZeoFEguQqxibrJMsLWdALgOZGiV7acjaFH12q4t7D8/jgIxfw7LUGlgoc9xaL5SQbokAUQ5e2xWnBj73pztTXzJVVMDaYRlwK2Bbz+tCLK+iiy6XIITt6uqnpamFkbByQBb0AUFDRpe02SpqCffWS15h6/Pw27j1cXNJaaQjtsmiE89C7pg2FJWeASEwPvvUVR3HrvjqWBxjIETX03Fku1eIkl1ExdJJcZmnsH5Bpi4WAXC6Xtzs4ulSFojDc61rHepaNxQJzkJ1sbefXNumCrioKLJuDc6eoywXRs4VqSfUcWXkxzGBRVVe9QjzsuP7INHS3kM/S2D8gC3ohcLRkjovbbRxdcny1CxUdx5adPxedsOcX9Mn++sglQSy9aww/yi0xGygJ+0bzEgvGmOd0GfYcVtUR+dDd45ul6FxAFvRCQGmLl7b8gg74fuDFgvdIEquZOEN3LyaaFnUYujylbgboQ/jQAb8xOmzDUWToRTYv58rO8UmGfhOipDI0OibWG10cXe4v6EUFcxGoaE66KUpLhGn9Xk9KLjcNRIfMID0TYsDDsuqR+dClhn7zQnN96IAzEUi4z22Gjk5ymbSG3s/QZXTuzQEq6IOyYk9yGZqhjyrLRWroNy3Ex09Rcnn5sSVoCvO09KJAJ+6k9Woau6ZM9K5ZbOKdxPSC3FaDbszyJJchSYnoKCzy3KMbzizluADStlgIxCELsXgfWari0z/7RhxOWBQwCKiQT1pyIXYkNfSbD7rbFB20qUle9GHPF8aYNw8xCpfLLE2JApKhFwJi6AoDDi0GizfZGIvEtEgumudycTT0bgEbaCRmA3TOD0oqyItexDlM0l+R10OtpEJX2chXBhaN2TraKQWd3AcXKgNlS+cFFc2JM3T3yYQCurqWjeXyZOMIJMYDbcgiOu9JLsNfL5rC0EWxkgtjDO952wO499BC+ounCLKgFwCSXMSG6CgxLT50NcqHriVvupG4McAYQ0lVBm5qUkBXEU90RQ0phfHGuw8U+u+NA1JyKQDEyo+Oq6BPiQ+dfm6SXHqmjZKUXG4a6CoroCk6fAmi81D2b2RBLwReQS/YzRIHz2EwJbZFT3KRTdGbCrqmDDRUBABvvOcAHvra23Hban3o4/AYujz3pORSBEhLHh9Dn46CTlKTJ7lI2+JNBV1Vcue4EPbPl/EL33RvIccxrJ5/I0FefQWgNG7JZUomRVXPtui6XOSk6E2Flx1dDCyknhQogkKSCcnQC8HBhQo0heHkgfHsjKSiOemmKIVzGaLkIsO5bhq89+2vnvQhAPDnIYpuis4iZEEvAA/evoKHf/EtA+VKD4Jp8aGLo/+cc6cpKrPQJcYMqaH7kJ9AAWCMja2YA9OjodMS4g8/cQWtnrutSDJ0iTFDU5izWGWGNguNCpKhzyCmRXJ5yZEF/ODrTuAP/uUsnl9rAJALoiXGD1VhqOiTXZg+LZAFfQYxLZILYwy//G9fgrsOzuOX/vpJAPKxV2L80BQmzzsXsqDPIE4emMPBhTIOzE/HVOZ3v+Y4blut45f++kncfai4/akSElmgKkw+GbqQBX0G8eDt+/CFX3jLpA8jgAdv34eP//QbJn0YEjchNEWRvRsX8lOQkJCYaagKK3T93CxjqILOGPs3jLHTjLEzjLGfK+qgJCQkJLJCU5nclOViYMmFMaYC+G0AXw/gIoCHGWN/yzl/uqiDk5CQkEjDD77uBDqGPenDmAoMo6G/BsAZzvkLAMAY+wCAtwKQBV1CQmJseNM9Byd9CFODYZ5TjgK4IPz3RfdrEhISEhITwDAFPcrFz/texNhDjLFHGGOPrK2tDfHtJCQkJCSSMExBvwjgFuG/jwG4HH4R5/w9nPMH/v/27ic0riqK4/j3R6PVViStRtFWbApBLYK2ZBH/IFJd2CrWhYuKYBcFN4pVBFFcuRTEfyAFaatVpIixaChFkVhwZbRVqakpVlFrJZqItoqbNvBz8W4gxEzMdGbyMvedDzxm3s0L75ycyWHmzpu5tnu7uroaOF0IIYTZNNLQPwd6yHJErAAAA9RJREFUJHVLOhfYDAw0J6wQQgj1Ous3RW1PSHoY+BBYBOyyfaRpkYUQQqhLQ58Utb0f2N+kWEIIITQgrsYPIYRMREMPIYRMyP7PlYatO5k0Dvx0lr9+MfB7E8NpF5F3tVQ1b6hu7nPJ+0rb/3uZ4Lw29EZIOmi7t+w45lvkXS1VzRuqm3sz844plxBCyEQ09BBCyEQ7NfRXyw6gJJF3tVQ1b6hu7k3Lu23m0EMIIcyunZ6hhxBCmEVbNPSqrIwk6QpJBySNSDoiaVsaXy7pI0nH0u2ysmNtNkmLJH0paV/a75Y0lHJ+O31fUHYkdUrql3Q01f2GitT7sfQYH5a0R9J5OdZc0i5JY5KGp4zNWF8VXk597rCkdfWeb8E39CkrI20A1gD3SVpTblQtMwE8bvsaoA94KOX6JDBouwcYTPu52QaMTNl/Fngh5fwnsLWUqFrvJeAD21cD11H8DbKut6QVwCNAr+1rKb4LajN51vx14I5pY7XquwHoSduDwPZ6T7bgGzpTVkayfRqYXBkpO7ZHbX+R7v9N8c+9giLf3emw3cA95UTYGpJWAncCO9K+gPVAfzoku5wBJF0I3ALsBLB92vZJMq930gGcL6kDWAKMkmHNbX8C/DFtuFZ9NwFvuPAp0CnpsnrO1w4NvZIrI0laBawFhoBLbY9C0fSBS8qLrCVeBJ4AJheGvAg4aXsi7eda89XAOPBamm7aIWkpmdfb9i/Ac8BxikZ+CjhENWoOtevbcK9rh4Y+p5WRciLpAuBd4FHbf5UdTytJugsYs31o6vAMh+ZY8w5gHbDd9lrgHzKbXplJmjPeBHQDlwNLKaYbpsux5rNp+HHfDg19Tisj5ULSORTN/C3be9Pwb5MvvdLtWFnxtcBNwN2SfqSYTltP8Yy9M70ch3xrfgI4YXso7fdTNPic6w1wO/CD7XHbZ4C9wI1Uo+ZQu74N97p2aOiVWRkpzR3vBEZsPz/lRwPAlnR/C/D+fMfWKrafsr3S9iqK2n5s+37gAHBvOiyrnCfZ/hX4WdJVaeg24BsyrndyHOiTtCQ95ifzzr7mSa36DgAPpKtd+oBTk1Mzc2Z7wW/ARuBb4Hvg6bLjaWGeN1O8xDoMfJW2jRRzyoPAsXS7vOxYW5T/rcC+dH818BnwHfAOsLjs+FqU8/XAwVTz94BlVag38AxwFBgG3gQW51hzYA/F+wRnKJ6Bb61VX4opl1dSn/ua4iqgus4XnxQNIYRMtMOUSwghhDmIhh5CCJmIhh5CCJmIhh5CCJmIhh5CCJmIhh5CCJmIhh5CCJmIhh5CCJn4F0bCEd8KQIMFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(g_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.1541, -0.8050, -0.6093,  0.3721, -1.1224, -0.5287, -0.2201,\n",
       "          -1.1745, -0.2593, -0.3773, -0.0005, -0.4323, -0.6013, -0.6770,\n",
       "           0.5470,  0.4743, -0.7347, -0.2522, -1.5056, -0.8841, -0.1246,\n",
       "          -1.3534,  1.5431,  0.8280,  1.2502, -0.8687,  0.1873,  0.4434,\n",
       "          -0.8382,  0.6538]]),\n",
       " tensor([[-0.0019, -0.0309,  0.3246, -0.8050, -1.2943,  1.1473,  0.4631,\n",
       "           0.7142, -1.1541, -0.7595,  0.9256, -0.3528, -0.8918,  0.9535,\n",
       "          -1.1094, -0.7775, -0.9792,  1.2959,  1.1952,  0.3979, -1.0236,\n",
       "           0.2086,  0.1225,  0.9802, -0.2037,  0.8815, -0.1194,  0.4633,\n",
       "          -0.6676, -1.1684]]),\n",
       " tensor([[ 0.8780,  0.2278, -1.6239, -0.2630,  0.1067, -0.4418, -1.4109,\n",
       "           0.5251, -0.8711,  1.9728,  0.7223, -0.8288,  0.1645,  0.4023,\n",
       "          -0.3043, -0.5931,  0.6436,  0.0284,  0.0901, -0.0620,  1.0357,\n",
       "          -0.1210,  1.5536,  0.6308, -1.5492,  1.1485,  1.5627, -0.2437,\n",
       "          -1.3303, -0.2916]]),\n",
       " tensor([[-0.8346,  0.1855, -0.3877, -0.1133,  0.6010,  0.2535, -0.4074,\n",
       "           0.5732,  1.5600, -1.2876, -0.4700, -0.7891,  0.1128,  0.7390,\n",
       "           1.2076,  0.6922, -1.0873, -0.4765, -0.1472,  1.5919, -0.3065,\n",
       "           0.3255, -0.6881,  0.4592,  0.3264,  0.3254,  1.2940, -0.9768,\n",
       "           0.1481,  0.6466]]),\n",
       " tensor([[-0.0560,  1.1923,  0.6528,  0.1432, -0.2592,  0.4231,  1.0884,\n",
       "           0.7990, -0.1240,  0.9640, -1.4215, -0.1677, -0.6798, -1.0507,\n",
       "           1.6147,  0.1650,  1.1424, -0.7093,  1.2207,  0.3015,  1.1474,\n",
       "          -0.8587,  0.8341, -1.1097,  0.7473, -0.4313, -0.0897,  0.8062,\n",
       "           0.6924, -0.1388]]),\n",
       " tensor([[-0.7719,  0.0097, -0.7312, -0.1838,  0.7750,  0.3672,  1.4101,\n",
       "           0.1734, -0.9438,  1.4720, -0.3945, -0.9124, -0.7056, -0.7287,\n",
       "           0.3619, -1.5596, -1.3232,  0.9683,  1.4174,  0.8393,  0.3295,\n",
       "           0.1670,  0.3978, -0.0782, -0.1812,  1.2977,  1.2031,  0.2981,\n",
       "          -0.0407, -1.2315]]),\n",
       " tensor([[-0.8715,  1.0263, -1.5839, -0.0319,  1.5940, -0.0143,  1.3413,\n",
       "          -2.2563,  1.4433,  0.2050, -0.9155, -0.2703,  0.2554, -1.1114,\n",
       "           0.0081,  0.5036, -0.0312, -1.1121, -0.8139, -0.0785, -0.9102,\n",
       "           0.0211,  0.1651,  1.4504, -0.0446,  1.5220,  0.0342, -1.4661,\n",
       "          -1.2652, -0.2816]]),\n",
       " tensor([[-1.3164,  0.1186,  0.3102, -1.1813,  0.1208,  0.7281,  0.7382,\n",
       "          -0.3147,  0.4159,  0.6963, -0.6112, -0.6401, -1.0790, -0.5609,\n",
       "           0.7701,  0.4903, -0.1568,  0.3216,  0.1884, -0.1792,  0.5599,\n",
       "          -1.5726, -1.3581, -0.0006, -1.0099, -1.1066, -0.2174, -0.8621,\n",
       "           0.7838,  1.1756]]),\n",
       " tensor([[ 0.3846,  0.1236, -1.4387, -0.0787, -1.5930, -0.5805,  0.0593,\n",
       "           2.2911,  1.3189,  1.8215,  1.7995,  0.8168, -0.6667, -0.2975,\n",
       "          -1.4776, -1.2838,  0.3509,  0.0254,  1.1483, -0.6996,  0.8449,\n",
       "           1.2889,  0.8105, -0.2176,  0.8277, -0.2809, -0.3381, -0.1637,\n",
       "           0.3097, -0.3906]]),\n",
       " tensor([[-0.3282,  1.5135,  0.4460, -0.2530, -0.2535, -0.4572, -0.2386,\n",
       "           0.1105, -0.5851, -1.0422,  0.2641, -0.4512, -0.3265,  0.0695,\n",
       "           0.5323,  0.2522,  0.9365, -1.2171,  0.0890, -1.6677,  0.4341,\n",
       "          -0.8963,  1.4812, -0.4199, -1.0582, -0.9395, -0.7563, -0.0884,\n",
       "           0.0587, -1.2477]]),\n",
       " tensor([[-0.4721, -0.7661,  0.2007,  0.1938, -0.4390,  0.2589,  0.0148,\n",
       "          -0.6933, -1.0239, -0.3964, -1.3195, -1.8601,  0.0791, -0.2903,\n",
       "           0.2556,  0.9953, -0.6939,  1.3039,  0.5305,  0.4834,  1.0621,\n",
       "          -0.9272,  1.1600,  0.8904,  1.4982,  1.4271,  0.5369, -1.2397,\n",
       "          -0.1190, -1.2759]]),\n",
       " tensor([[ 0.9510,  0.3202,  1.1434,  1.9011,  0.6960,  1.3227,  1.5378,\n",
       "          -1.4723, -1.0406,  1.7483,  0.0531,  0.9498,  0.4458, -1.0718,\n",
       "           0.0401,  1.2558, -0.1011, -0.2505, -0.5038, -0.7498,  1.6130,\n",
       "          -0.0764, -0.5078,  0.6647, -0.0390,  1.0713,  1.5162,  0.3022,\n",
       "           0.5925,  0.5595]]),\n",
       " tensor([[ 0.2304, -1.1111,  0.0016, -0.1441, -0.0880,  0.1706,  0.4887,\n",
       "           1.4126, -0.9107, -0.7652,  0.3282,  0.4246,  0.9902,  1.7332,\n",
       "          -0.3395,  0.3081, -0.5688,  0.7709, -0.6980,  0.3231, -0.7502,\n",
       "          -1.9520, -0.0975,  1.2985, -1.7148,  0.1920, -0.4543,  0.1872,\n",
       "           1.0415,  0.3017]]),\n",
       " tensor([[ 1.1829, -0.3879, -0.0048, -0.4806, -1.3071, -0.2810,  0.8328,\n",
       "          -0.2443, -1.4916, -0.5573,  0.1011, -0.9851, -0.5452,  0.9503,\n",
       "          -0.2428, -0.9524,  1.1511,  0.2573,  0.8673, -0.8648, -0.4170,\n",
       "          -0.5944, -0.1140,  0.2811, -1.1303,  1.3898,  0.2817, -0.5090,\n",
       "           0.1724, -0.5768]]),\n",
       " tensor([[-1.6027, -2.0443,  1.8142,  0.0150, -1.1567,  0.0585, -0.9552,\n",
       "          -0.6445, -0.0132, -1.0387, -0.5409,  0.2752,  1.2116,  0.9438,\n",
       "          -0.0322, -0.4814, -0.8098, -0.2799,  0.6658,  0.0099,  0.9127,\n",
       "          -0.2713,  0.1401,  1.7614,  0.1526,  0.5038, -0.6165, -0.7320,\n",
       "           0.7974,  0.0498]]),\n",
       " tensor([[-0.9484, -0.5154, -0.7761, -1.0778, -1.1571,  0.3154, -1.0244,\n",
       "          -0.1411,  0.6433,  1.0549,  0.1975,  1.1796, -0.6173,  1.4040,\n",
       "           0.3751,  0.3514,  1.3367,  0.6368, -0.6537, -0.3548,  0.5100,\n",
       "           0.5513,  0.6545, -0.6553, -0.8802, -1.3628, -0.3547,  1.5861,\n",
       "          -0.7948, -0.5329]]),\n",
       " tensor([[-0.7369,  1.3864,  1.0007,  0.7921,  0.3835, -0.2061,  1.9202,\n",
       "           0.6986,  0.5364,  1.1792,  1.2559, -1.1746, -1.5435, -0.0970,\n",
       "           1.0664,  0.7665,  0.0899,  0.7520, -0.4917,  1.4229,  0.5743,\n",
       "           0.3504,  0.9587, -0.4209,  1.0027, -0.2641, -0.8948,  1.4871,\n",
       "           0.4735, -0.5476]]),\n",
       " tensor([[ 1.1075,  0.2216, -1.5333, -1.3069,  0.5954,  0.0474,  1.3455,\n",
       "           0.2528,  0.9637,  0.7108,  1.1920, -0.8745, -0.7200, -0.0100,\n",
       "          -0.6653, -0.5199, -0.2731,  0.5945,  0.2498, -1.0119,  1.6530,\n",
       "          -0.1059, -1.0120, -0.2996, -1.0090,  0.0791, -0.0135, -0.0503,\n",
       "           0.5341, -0.8334]]),\n",
       " tensor([[-1.9373,  0.3745,  0.4773,  0.0015, -1.4584, -1.4264,  0.6753,\n",
       "          -1.1921,  1.3988,  0.4754,  0.4076, -0.6370,  0.9019, -1.0217,\n",
       "           0.4809, -1.0952,  0.3901,  0.5163, -1.2106,  0.7503,  1.8844,\n",
       "           0.8386, -0.7073, -1.3739,  0.9769, -0.1375, -1.0752,  0.5447,\n",
       "           0.7939, -1.4325]]),\n",
       " tensor([[ 1.2926, -0.4996, -1.2468,  1.2615, -0.9146, -0.1372,  0.6417,\n",
       "           0.5717, -0.2553, -0.2549, -0.4674,  1.4597,  0.4697,  0.2925,\n",
       "          -0.3247, -1.1319,  0.8508, -0.3503, -0.5087,  1.1816,  0.6184,\n",
       "           1.5643, -0.0786,  1.1573,  0.5636,  0.6297, -0.2042, -0.6573,\n",
       "           0.0946, -1.9156]]),\n",
       " tensor([[ 0.3656, -0.4445,  0.6990,  0.2691,  0.1233, -1.1940,  1.0867,\n",
       "           0.0649, -2.3000,  1.5467, -1.3379, -0.8416, -0.2305,  0.0085,\n",
       "           0.6587,  0.0192,  0.7323,  0.2327, -0.3954, -0.7469,  0.4825,\n",
       "           0.5529,  1.3548,  1.2049,  1.1664,  0.0383,  0.9067,  0.3982,\n",
       "          -0.3852, -0.4921]]),\n",
       " tensor([[ 0.5299, -0.8530, -1.8763,  1.8015, -0.5093, -1.0854,  1.1626,\n",
       "          -0.2531, -0.8515, -0.3531, -0.6203, -0.2465,  0.9119, -1.1888,\n",
       "           1.1271, -0.2806, -1.5219,  0.2512, -1.2177, -0.4421,  1.0402,\n",
       "           1.0806, -1.4780,  0.9609, -0.5297,  0.9316, -0.5782, -0.8071,\n",
       "          -1.1266,  1.7190]]),\n",
       " tensor([[-0.3023, -0.4155, -0.5968,  0.9735,  0.3711,  2.2702,  0.5682,\n",
       "          -0.4846, -1.0813,  1.5673, -0.9815, -0.7635,  1.0487,  0.7385,\n",
       "          -0.9505, -1.1520, -0.1194, -0.0942,  0.2338,  0.6177,  0.6581,\n",
       "          -0.5589, -0.2145, -0.8459,  1.3499,  0.1232, -1.0494,  1.5011,\n",
       "           0.1030,  0.7188]]),\n",
       " tensor([[ 2.0495, -0.1715,  0.8036, -0.5744, -0.2129, -0.9342,  0.5427,\n",
       "          -0.0097, -1.1188, -0.4910,  0.6963, -0.3165, -0.1219, -0.8685,\n",
       "           0.3216,  0.6550,  0.0082,  0.1083,  0.6148, -0.6843,  1.1116,\n",
       "           0.1646,  1.3079,  0.3647, -1.2460, -1.5027, -0.2276, -0.5677,\n",
       "           1.7993, -0.8854]]),\n",
       " tensor([[-1.4685, -0.6804,  1.4113,  0.9486, -0.1667,  1.3593, -0.8132,\n",
       "           0.4707,  0.6259,  0.1926, -0.3525, -0.5709,  0.9270,  0.0702,\n",
       "          -0.4000, -0.3216,  0.3637, -1.5498,  0.5287, -0.2488,  1.0632,\n",
       "          -0.1918, -0.5438, -1.0465, -0.6669, -0.4535,  0.0646,  1.0213,\n",
       "          -0.6708, -0.4419]]),\n",
       " tensor([[ 0.5558, -1.8020, -0.6788, -0.2186, -0.5905, -0.4543,  1.3849,\n",
       "          -0.2074,  0.3622, -0.3043,  0.3376, -0.4370,  1.5427,  0.6198,\n",
       "          -0.6370,  1.1104, -0.4090,  0.8490, -0.0451,  1.4739, -0.8428,\n",
       "          -0.5318, -1.3582,  0.9186,  0.1666, -0.7456,  0.8174,  0.3976,\n",
       "          -0.9082,  1.5235]]),\n",
       " tensor([[-1.0569,  1.2313,  0.7151,  0.5245, -0.0943, -1.1316, -1.1602,\n",
       "          -0.2932,  0.1971,  1.8265,  0.6421, -1.4975, -1.8084, -0.6764,\n",
       "           0.3696,  1.3625,  0.4348,  1.0085, -0.2670,  0.2548,  1.3940,\n",
       "           0.5218,  0.7785,  0.8927, -0.2608,  0.7981, -0.4693,  0.0274,\n",
       "          -0.2973,  0.6905]]),\n",
       " tensor([[ 0.0695,  0.4072,  0.1682, -0.1805, -0.5333,  1.0960,  0.1977,\n",
       "           0.8115,  0.7838, -0.6188,  0.5480, -0.4968,  0.7756, -1.1635,\n",
       "          -1.4948, -0.1025,  0.4092,  1.2044,  0.9802,  0.3472, -0.5803,\n",
       "          -0.8539, -0.7347, -1.4401,  1.2496, -1.3494,  1.9836, -0.0509,\n",
       "           0.2104,  0.4253]]),\n",
       " tensor([[ 0.5582,  0.8995, -1.5516,  0.1939,  1.1870, -1.1452,  0.4156,\n",
       "           0.1148, -0.3770, -0.1701,  0.3712,  1.6655,  2.0182, -0.4884,\n",
       "           0.1336, -0.6321,  0.1077, -0.1070, -0.4601,  0.9302, -1.2533,\n",
       "          -0.5234,  0.2255, -0.3487,  0.6089,  1.1216,  0.2170, -0.0974,\n",
       "          -0.7098,  0.1672]]),\n",
       " tensor([[ 0.7830,  0.1160,  1.6584, -0.9440, -1.0498,  0.1685, -0.0287,\n",
       "          -0.1672,  0.1635,  1.5676,  1.5664,  0.1216, -0.5402,  1.9388,\n",
       "          -0.5269,  0.0241,  0.2318,  0.9317,  0.0857, -0.3950,  0.5146,\n",
       "          -0.8982,  0.0768,  1.0509, -1.1133, -1.6914, -0.7387, -0.0872,\n",
       "           1.5840, -0.8451]]),\n",
       " tensor([[-0.7007,  0.1556,  0.9494, -0.1593, -0.0208,  0.0271,  0.5231,\n",
       "          -1.2570, -0.0333, -0.9674, -0.2151,  0.7451, -0.5224,  1.7236,\n",
       "           0.3348,  1.0881,  0.1222, -0.1758,  1.0169,  0.2583,  0.5685,\n",
       "          -0.7077,  0.0623,  0.3048,  0.1052, -0.7661,  1.4372,  0.2289,\n",
       "          -0.7414, -0.4620]]),\n",
       " tensor([[ 0.2331,  0.7553, -0.0319,  0.8316, -0.4210, -0.9371, -0.1023,\n",
       "           0.4357,  0.6300, -0.8528, -0.9058, -1.6937, -0.6167,  0.5241,\n",
       "          -0.4348,  1.0563, -0.6640, -0.8344,  0.6096,  1.2845, -0.5327,\n",
       "           0.4896, -0.3312,  1.5546,  0.3194, -1.8700, -0.5780,  0.6920,\n",
       "           0.0813, -0.9079]]),\n",
       " tensor([[-0.9734,  1.1352,  0.5322, -1.5033,  1.1648,  0.2334,  0.5602,\n",
       "          -0.0624,  0.0503, -0.5759,  0.9632, -0.0024,  0.6848,  0.2716,\n",
       "          -0.5607, -0.8257, -0.9085, -0.1917, -0.1251,  0.4644, -0.8120,\n",
       "          -0.9158, -0.1060,  0.3000, -0.3987, -1.1748, -1.1879, -0.7462,\n",
       "           0.5687,  0.2685]]),\n",
       " tensor([[-0.8277, -0.3451, -0.5271, -0.7359,  1.2509, -0.0048, -0.2605,\n",
       "          -0.9929, -0.5367, -0.4522,  0.3237, -1.7647, -0.6853, -0.9115,\n",
       "           0.5649, -1.9666,  0.3756,  1.7234,  1.2490,  1.0160,  0.2882,\n",
       "          -0.6218, -0.5670,  0.7897,  0.1584,  1.0538,  1.1962, -0.8569,\n",
       "           0.8685, -1.1073]]),\n",
       " tensor([[-0.0806,  0.4285,  0.0071,  1.0744,  1.0941, -0.8103, -0.0386,\n",
       "          -0.0666,  0.3114, -2.0393,  0.5115, -0.2520, -0.3552, -0.4878,\n",
       "           1.6038,  0.7603, -0.5941, -0.3211,  0.5167,  0.0640,  0.9495,\n",
       "           0.1366, -0.2558, -0.9307,  0.3426, -0.9954, -0.5091, -1.0019,\n",
       "          -0.1386,  0.5377]]),\n",
       " tensor([[ 1.2138, -0.0865, -0.0546, -1.2208, -0.0368, -1.2876,  0.7975,\n",
       "          -0.1870, -1.1438,  1.3871, -0.1867,  0.2489, -1.2910,  0.9628,\n",
       "           0.7084, -0.6754, -1.1250,  0.1843, -0.1724,  1.0038, -0.4133,\n",
       "           1.7599, -1.0623,  0.5602,  0.7477, -0.2920, -0.4351, -0.1244,\n",
       "          -0.2698,  0.6189]]),\n",
       " tensor([[ 0.8963,  0.0430, -0.9060, -0.1920, -0.9800, -1.0235, -1.1907,\n",
       "           0.7110, -0.6620, -0.5464,  0.6123,  1.6086,  1.0688,  0.1071,\n",
       "          -1.3438,  1.8200, -0.1344,  0.9356, -0.5365,  0.2217, -1.1265,\n",
       "          -0.0079,  0.0618, -0.8402,  0.3343, -0.9035,  1.6127, -0.0412,\n",
       "           1.0461,  1.2822]]),\n",
       " tensor([[ 0.3981,  0.7194,  0.3680, -0.0458,  0.7081, -0.4396, -0.6966,\n",
       "           0.0856,  0.2656, -0.6859, -0.7165,  0.7209, -0.7020, -0.2649,\n",
       "           0.8997,  0.3583, -0.8297, -0.1572, -0.7905, -0.0179,  1.2104,\n",
       "          -1.1928,  2.2981,  1.6435, -0.3422, -0.2124, -1.1930, -0.2548,\n",
       "          -0.2809,  0.3664]]),\n",
       " tensor([[-0.2944,  1.1695,  0.4086,  0.3478,  1.6692, -0.4135,  0.4606,\n",
       "          -0.8217,  1.0707,  0.2359,  0.8566,  0.0686,  1.8916,  0.6119,\n",
       "          -0.2549,  0.0692,  0.7392,  0.2380, -0.0912,  0.1981, -0.9657,\n",
       "           0.6916, -0.5074, -0.3127, -0.8117, -0.1321, -1.2617,  1.5828,\n",
       "          -1.2458, -0.6172]]),\n",
       " tensor([[-0.2566, -0.4601,  1.5769, -1.8513, -0.2260, -0.3714, -0.4590,\n",
       "           0.2224,  0.4084,  1.2181,  0.7771, -0.2075,  1.7565,  1.3853,\n",
       "          -0.8149,  0.6310,  1.9706, -0.1312,  0.4885, -1.3235, -0.9114,\n",
       "           0.5991,  1.1790, -0.5475, -1.0951, -0.6404,  0.8339,  0.1806,\n",
       "          -0.5669,  1.2544]]),\n",
       " tensor([[ 0.1017, -0.5795,  0.7718, -0.3656, -0.5560,  0.4013, -0.2918,\n",
       "          -0.0315,  1.2007, -0.0913,  1.0268,  1.5758,  1.1708,  0.0830,\n",
       "          -0.6551, -0.0846,  1.0695, -0.2327,  1.5961, -0.5491, -0.5064,\n",
       "           1.1888, -0.2539, -1.0880,  0.6405,  1.2587,  0.0372,  0.8093,\n",
       "          -0.7750,  0.1765]]),\n",
       " tensor([[ 0.1953,  0.4156,  0.1246, -1.2069,  0.3936,  0.7561,  1.8135,\n",
       "          -0.6293,  0.1242, -1.0180, -1.0345, -0.1143, -0.9594,  0.4231,\n",
       "          -1.3498,  1.4717,  0.7844, -0.6012, -1.4291,  0.0655, -1.3862,\n",
       "          -1.3173, -0.4565,  0.6336,  0.1636,  0.5949, -0.2986,  0.1425,\n",
       "           1.2009,  0.3443]]),\n",
       " tensor([[-0.0985,  0.3506,  1.6026,  0.9988,  0.4864,  1.0727, -0.5877,\n",
       "          -0.6159,  0.2476,  1.2679,  0.5291, -1.9902,  0.1585,  0.7915,\n",
       "          -0.1182,  0.9919, -1.1228,  0.9003,  0.1929,  0.6779, -0.5571,\n",
       "           0.7978, -1.6680,  1.7941,  1.0669, -0.4311, -0.7425, -1.1130,\n",
       "           0.3749,  1.4313]]),\n",
       " tensor([[ 0.1212, -1.8494,  1.4264,  0.7745,  0.5647,  0.2289,  1.3804,\n",
       "          -0.0158,  1.3778, -1.1980, -1.1149,  0.4983, -0.9137,  0.1021,\n",
       "           0.2940,  0.4701,  0.2905,  1.2473,  0.5719,  0.4121, -0.3392,\n",
       "           0.6406,  1.2721,  1.2478,  0.4910, -1.5345,  0.9842, -0.2529,\n",
       "          -1.0255, -0.5008]]),\n",
       " tensor([[ 1.1719,  0.4977, -0.3388,  2.0658,  0.5903,  0.2399, -1.0566,\n",
       "           0.1871,  0.5261, -1.2214,  0.3941,  1.9124, -0.3380,  0.6389,\n",
       "           0.1376,  0.1699, -1.7931,  0.8915,  0.6281,  1.2666,  1.4706,\n",
       "           1.5342, -0.5290, -0.4478,  0.8017, -0.3614,  1.7689, -0.9406,\n",
       "           0.4845,  0.3832]]),\n",
       " tensor([[ 1.9266, -0.3789,  0.7992, -0.5713,  0.8362,  1.4545,  0.3337,\n",
       "          -1.0421, -0.0116, -0.9384,  1.1977,  1.5984, -0.5357, -0.5204,\n",
       "          -0.4495, -0.4130,  0.9031, -0.4678,  0.6155, -1.6975,  0.4832,\n",
       "           0.7393,  0.1018,  0.3726, -0.4180, -0.1835,  0.6989,  1.4796,\n",
       "           0.4189, -0.6927]]),\n",
       " tensor([[-0.8110, -1.7602,  1.0849,  0.4039,  0.1949, -1.1386,  0.2097,\n",
       "          -0.5293, -0.1838,  0.1112,  1.7384, -0.4300, -1.6510, -0.4238,\n",
       "           1.1021, -0.4248, -0.1327,  0.5513,  1.7160,  1.5322, -0.0482,\n",
       "           1.0904,  1.3490,  0.5566, -0.1135, -0.1976,  1.0411,  0.6893,\n",
       "          -0.1076, -0.1839]]),\n",
       " tensor([[-0.5625, -1.1222,  0.4434, -0.0156, -0.6498, -0.0078,  1.4439,\n",
       "           0.7319,  0.1717,  0.7752,  1.5033, -1.5153,  1.5754,  0.3920,\n",
       "           0.5080,  0.3546, -0.7016,  0.9325,  1.4823,  1.0225, -0.7829,\n",
       "          -0.0323, -1.1043,  1.2868,  0.0739, -1.1861,  0.7109,  0.2127,\n",
       "           2.1205, -0.9385]]),\n",
       " tensor([[ 0.5263,  0.5088, -0.2062,  1.2951, -0.5441,  1.7282,  0.5258,\n",
       "           0.9984,  0.4807, -0.9869, -0.5131, -0.3108, -0.2446, -0.9422,\n",
       "          -1.3811,  0.0707,  0.0723, -1.8195,  0.3575,  0.2508,  1.2498,\n",
       "          -0.3861,  0.4131, -1.5877,  0.4578, -0.6955, -0.1857,  1.1630,\n",
       "           0.9481, -0.3731]]),\n",
       " tensor([[-0.3534, -0.9881, -0.9652,  1.5866,  0.2031,  1.3669,  1.2393,\n",
       "          -1.2258, -0.9217, -0.1716,  0.1860,  0.1555, -0.6507, -0.7787,\n",
       "          -0.5858,  1.1692, -0.7925, -0.1571,  0.4123,  0.1262,  1.0547,\n",
       "           0.9623, -1.1212,  0.6320,  1.0101,  0.9098,  0.9643, -1.0183,\n",
       "           0.8282,  0.4172]]),\n",
       " tensor([[-1.1696, -1.4621, -0.5012, -1.0109,  0.9563,  1.4366, -0.9456,\n",
       "          -0.7433,  0.7543,  0.1492, -1.4190,  1.4108, -1.6309, -0.2587,\n",
       "           1.1418, -0.3898,  1.4637, -0.3373, -0.6978, -1.2445, -0.5956,\n",
       "           0.5499,  0.7974,  1.1727, -0.1450,  0.5015, -0.3292, -0.8671,\n",
       "           0.6090, -0.0783]]),\n",
       " tensor([[-0.2067,  0.4662,  0.6452,  0.0399, -0.2824,  0.9590,  0.0319,\n",
       "          -0.3685,  0.4433, -0.0088,  0.0802, -0.7029, -0.8831,  0.9194,\n",
       "           1.6446, -1.5449, -0.0335,  1.4561, -0.4117,  0.8981, -1.1332,\n",
       "           0.5690, -0.4991,  0.9650, -0.3232, -0.3003, -0.2599,  0.5796,\n",
       "          -0.5114,  0.1795]]),\n",
       " tensor([[-0.0255, -0.8723,  0.4955,  0.7859, -0.3802,  0.4679, -1.2869,\n",
       "          -0.5056, -0.2095, -0.3343,  0.0383,  0.9296,  0.2227,  0.4398,\n",
       "          -0.4300,  1.0664, -1.2621, -1.3272,  1.1231,  0.5214,  0.4346,\n",
       "          -0.2383,  0.8930, -0.0471,  0.5423, -0.0010,  0.0270, -0.4565,\n",
       "          -0.0975, -0.3074]]),\n",
       " tensor([[-0.7192,  1.6983,  0.6514, -0.0958, -0.9483,  0.2896,  0.5983,\n",
       "           0.8389, -0.1570, -0.0720, -1.3200, -0.2222,  0.7782, -0.9240,\n",
       "          -0.1122,  1.0836, -0.1755,  1.0112,  0.9626,  0.6782, -1.1933,\n",
       "          -0.0904, -0.5456,  2.0869,  0.1658, -0.7311, -0.0114, -0.4784,\n",
       "           0.9326, -0.4112]]),\n",
       " tensor([[ 1.7737, -1.5104,  0.3504, -1.3322,  2.1635,  0.6107,  0.4488,\n",
       "          -1.4875,  1.3698,  0.0943, -0.8685,  0.7188,  1.2182, -0.0073,\n",
       "           1.4365, -1.8092, -0.2396, -1.4167,  0.8750,  1.3987,  0.8048,\n",
       "           1.1552, -0.0383,  0.0560,  0.8179,  0.5963, -1.2412,  0.7660,\n",
       "           0.5406, -0.0756]]),\n",
       " tensor([[-0.7066,  1.5930, -1.8536, -0.7263, -0.4627, -0.4649, -0.9525,\n",
       "           0.3234,  0.1525, -0.6395,  0.1095,  0.3903, -0.9809,  1.3240,\n",
       "           0.0699,  1.0398, -0.2360,  0.8409, -0.5623,  0.8715, -0.1972,\n",
       "           0.9412,  0.4828,  1.4856, -0.6993, -1.5477, -0.4314,  1.5456,\n",
       "           0.8281,  0.7503]]),\n",
       " tensor([[-1.1910,  0.6899,  1.3955,  0.5846, -0.9037,  0.5083, -0.5015,\n",
       "          -0.6069, -0.2556, -0.3961, -1.2253, -0.1704, -1.2902, -0.8839,\n",
       "           1.0465, -0.0014, -0.3570,  1.3800, -0.5255,  0.1234,  0.2094,\n",
       "           0.5919, -1.1905, -2.0029, -0.0428,  0.4104,  1.2159, -1.0707,\n",
       "           0.3733,  0.0726]]),\n",
       " tensor([[-0.4617,  0.0905,  1.8441,  1.4726, -1.4128,  1.8432, -0.0608,\n",
       "           0.1241,  0.9581, -0.8238, -1.2061,  1.5310, -0.1082,  0.5773,\n",
       "          -0.4509, -0.0310,  0.2931, -0.4608,  0.1554,  1.2278,  0.9338,\n",
       "           1.5415, -0.4488,  0.5807, -0.6293,  0.2927,  0.3493, -0.6496,\n",
       "          -0.7745,  0.4786]]),\n",
       " tensor([[ 0.9064, -0.6251,  0.8768, -0.3450, -0.8574,  1.6439, -0.5163,\n",
       "           1.5659, -0.1325,  1.4706,  0.1860,  0.3863, -0.0078,  0.2455,\n",
       "          -1.7818,  2.2495,  0.1942, -1.1217,  0.5956,  0.2296,  0.3750,\n",
       "          -1.4667,  2.0379, -1.1284, -0.6048,  0.1864, -0.2199, -0.4812,\n",
       "          -1.2562,  1.5228]]),\n",
       " tensor([[ 0.7563,  0.8544, -0.8630, -0.3670, -0.1005, -0.1625,  1.5922,\n",
       "          -0.5562,  0.5970, -0.3862,  0.6618,  0.7410, -0.2341,  0.6095,\n",
       "          -1.5006,  0.1547, -0.3158,  0.0998, -1.1327, -0.1863, -0.6878,\n",
       "           0.0826,  1.3347, -0.3388,  1.0945, -0.4020, -0.2562,  0.9826,\n",
       "           0.3053, -0.4510]]),\n",
       " tensor([[-1.8289,  0.2366, -1.4870, -1.2139,  1.1136,  0.5931, -1.0540,\n",
       "          -0.7801, -1.2965, -0.3583,  1.5482, -1.2605,  0.6220,  0.7842,\n",
       "           0.8572,  1.3744, -1.7687,  0.1189, -0.8310, -0.1310, -0.2039,\n",
       "           0.6604, -1.4562,  0.9728, -0.5909, -0.6060, -0.3725,  0.0640,\n",
       "           0.4893, -0.7701]]),\n",
       " tensor([[ 0.5892,  0.9802, -0.3467,  0.9815, -1.0202,  0.6524,  1.8383,\n",
       "           0.5736, -0.5919,  0.9889, -1.2217,  1.3737,  0.2569, -1.0789,\n",
       "           1.2528, -0.5779, -0.0118, -0.3795, -1.3493, -0.4057, -0.1807,\n",
       "          -0.2251,  0.1293, -0.6894,  1.6252, -1.4340,  1.3766,  1.3962,\n",
       "           0.3372,  0.7576]]),\n",
       " tensor([[ 0.5863,  1.3816,  0.7764,  0.6379, -0.3222, -0.7448,  1.0891,\n",
       "           1.0473, -0.1326, -0.0992,  0.0405,  1.0816, -0.5681,  0.1777,\n",
       "          -0.5858,  1.6350,  0.3041,  1.7445, -0.9362,  0.0627, -1.2608,\n",
       "          -0.4090, -1.3955,  0.9521,  0.6574,  1.0926,  1.8734,  1.3852,\n",
       "          -0.0258, -0.0635]]),\n",
       " tensor([[ 0.9834, -0.3347, -0.4418,  1.1198,  0.3423, -0.1336, -0.2355,\n",
       "          -0.2354, -1.2773,  1.3454, -1.2369,  0.9726,  0.0586,  0.9042,\n",
       "          -0.7230, -1.0622,  0.1328, -0.8994,  1.4973, -1.3791, -0.7250,\n",
       "           0.4159, -1.3085, -0.5078,  1.5929, -0.2083,  0.3978,  1.3573,\n",
       "          -0.3807,  0.6437]]),\n",
       " tensor([[ 1.8252,  0.7426,  0.7495, -0.4073,  0.4876,  1.7068, -1.4183,\n",
       "           0.1697, -0.6862,  0.2487,  0.3548, -0.1830,  1.6356,  2.0242,\n",
       "          -0.7864, -0.1868,  0.6463,  0.7272,  1.1507,  0.4130,  0.3002,\n",
       "           0.1931, -0.6855, -0.9562, -1.0891,  1.0202, -0.8165,  0.0845,\n",
       "           0.7216,  0.1946]]),\n",
       " tensor([[ 0.7640,  1.4977,  0.0608,  1.1484, -0.3869, -1.1773,  0.1977,\n",
       "          -0.4137,  0.8171, -1.5439, -0.6829, -1.3819,  1.7956,  0.2013,\n",
       "          -1.1785, -0.5811, -0.0554,  1.1335, -1.0476,  0.6315,  0.3803,\n",
       "          -0.2156,  0.1547,  0.6828,  0.5932,  0.1600,  0.0927, -0.6926,\n",
       "          -1.1391,  0.0614]]),\n",
       " tensor([[-0.2026, -1.2397,  0.0648,  1.3620, -0.7345, -0.1419,  1.6386,\n",
       "           0.8164, -0.1157,  1.6956,  0.0508,  1.1345,  0.7461,  1.5671,\n",
       "          -1.1129,  0.1963, -0.3420,  0.7087,  0.5793,  0.7317,  0.5497,\n",
       "           0.1404, -0.1004,  0.7784,  0.3775, -0.1598, -0.6462, -1.9871,\n",
       "           0.4618, -0.4146]]),\n",
       " tensor([[ 0.1427,  1.0105,  0.2972, -0.1120,  1.3963, -0.0467, -1.6074,\n",
       "           1.4111,  1.9060, -0.8424, -0.5740,  0.7516,  0.7159,  0.2776,\n",
       "          -0.7197,  0.1815, -2.1649,  0.7177, -0.1260,  0.2375,  1.5596,\n",
       "          -0.3108,  1.7491,  0.0150,  0.7357,  1.2606, -1.0327, -1.1535,\n",
       "           0.4856,  0.4791]]),\n",
       " tensor([[ 1.5518, -0.9836, -0.8421,  0.1562,  0.7868,  0.1048,  0.8498,\n",
       "           1.0124,  0.4226,  0.9992, -0.8144,  0.0003,  1.5815, -0.1369,\n",
       "           0.9302, -1.3541,  1.9105,  0.5936, -0.5135, -1.4003, -1.9427,\n",
       "          -0.3723,  0.6329, -0.7203,  0.3588,  0.9865,  0.9196, -0.3248,\n",
       "          -0.7004,  1.5473]]),\n",
       " tensor([[ 1.2214, -1.1341,  0.0946,  0.6299,  1.5351,  0.1828,  1.7442,\n",
       "           0.0241,  0.5839,  0.2559, -1.3359, -0.2292,  0.5394,  0.7352,\n",
       "           1.1170,  0.8824, -0.3087,  0.3905, -0.4790, -0.0318,  1.8563,\n",
       "           0.1003,  0.2762,  0.9479, -0.2942, -0.9354, -0.4081,  0.6809,\n",
       "           0.8494, -0.7575]]),\n",
       " tensor([[ 0.9798, -0.3293,  0.7907, -1.7265,  0.5095, -0.6418, -0.4199,\n",
       "          -0.3437,  0.1990, -0.0799, -0.7919,  2.1615,  0.0602, -1.1631,\n",
       "          -0.2205,  0.1359, -0.8686,  0.8265, -0.0422, -0.1083,  0.5834,\n",
       "           1.5295, -0.5960,  0.9472,  0.4341,  1.6706,  0.7412, -0.1686,\n",
       "           0.2340,  1.6028]]),\n",
       " tensor([[ 0.4605, -1.0059,  0.9483, -0.7343, -0.4267,  0.7236, -0.2732,\n",
       "           0.5702,  0.4164,  0.8836,  0.0016,  0.2264, -0.3392,  0.6581,\n",
       "           1.0280, -0.3324, -1.2026,  0.2132, -0.9908,  1.2782,  1.0553,\n",
       "          -0.0447, -0.6364,  1.0411, -1.0164, -0.0213, -1.3595,  0.3980,\n",
       "           1.6238,  0.1080]]),\n",
       " tensor([[ 0.5071,  0.2696, -0.0533,  0.5840,  1.4198, -0.1657, -0.9392,\n",
       "          -0.9067,  0.7563, -0.9824, -0.9904, -0.7625,  1.1815,  0.7578,\n",
       "           0.1454,  1.3570, -1.2999, -0.3456,  1.7251, -0.4772,  0.5652,\n",
       "          -0.8621,  0.6246,  0.7546,  0.5439, -0.6037, -1.1120, -2.0032,\n",
       "           0.4590,  0.2910]]),\n",
       " tensor([[ 1.1277,  1.0942, -0.3850,  0.6974,  0.1542,  0.2754, -0.2925,\n",
       "          -0.3873,  0.5031,  0.8132,  1.1764,  0.4700, -0.9201, -0.4289,\n",
       "           0.3698,  1.0455,  0.4646, -0.5981,  1.3722,  0.1316, -1.4070,\n",
       "           0.4223, -0.9894,  0.6257, -1.1954, -0.8886, -1.3812,  1.6329,\n",
       "           0.4504, -0.9212]]),\n",
       " tensor([[-0.9506,  0.2977, -1.0805,  0.0553,  0.4107, -0.5441, -0.7826,\n",
       "          -0.9815,  0.9220, -0.3750,  0.5636,  0.1482,  0.6306,  0.1585,\n",
       "           0.7805, -0.7924, -0.8522, -1.7985,  1.1655, -0.6082,  0.3763,\n",
       "          -0.6593,  0.5210, -0.1699,  0.2417, -1.4812,  1.4691,  0.1930,\n",
       "           1.6786,  0.3231]]),\n",
       " tensor([[ 0.1272, -0.9362, -0.8276,  1.1156,  1.8471, -0.0465, -0.1647,\n",
       "           0.3513, -0.4515, -1.7393, -0.4424,  0.0816, -0.2101,  0.6755,\n",
       "           0.3692,  0.4089, -0.6626, -1.2453,  0.9818,  1.5237, -0.1001,\n",
       "           0.3363, -0.8194,  0.5178,  0.7487, -1.6398,  0.4374,  0.3521,\n",
       "           0.2956, -0.1112]]),\n",
       " tensor([[-1.4632, -1.1127,  0.0606,  0.8109, -0.7258, -0.3473, -0.1495,\n",
       "          -0.1614, -0.0289, -0.1491, -0.4299, -0.5095,  1.1062, -0.4780,\n",
       "           0.9926,  0.6288, -1.3734,  0.6515,  1.2059, -1.0261, -0.6516,\n",
       "           0.5411,  0.7642,  0.4405,  1.6191, -1.3869, -0.8063, -0.9340,\n",
       "          -0.9466, -0.1813]]),\n",
       " tensor([[ 1.0561, -1.0709, -0.5714,  0.5893, -0.2825, -0.3939,  1.0825,\n",
       "          -0.8921,  1.4566,  0.7162, -0.0263, -0.8259, -0.4710,  0.7585,\n",
       "          -0.1590, -0.6176,  0.0998,  1.0527,  0.0579, -1.6127,  0.8918,\n",
       "          -0.0832,  0.7112, -1.2449, -0.0697, -0.4250,  1.1196, -0.8593,\n",
       "          -0.6889,  0.8497]]),\n",
       " tensor([[-1.7422,  0.4346,  0.6809, -1.0589,  1.1724,  1.7278,  0.9766,\n",
       "          -1.0162,  0.0839,  0.7524,  0.0657,  0.1892, -0.2834,  0.4866,\n",
       "          -0.0009,  0.9121,  0.2249,  0.6166,  1.0670, -0.5623, -0.3820,\n",
       "          -0.1080, -0.6516,  0.7725, -0.7879,  0.5763,  0.4411,  0.2116,\n",
       "           1.5012, -0.3091]]),\n",
       " tensor([[ 1.8084,  0.1367,  1.6656,  0.6128, -1.4413,  0.5309,  1.7322,\n",
       "           0.4220,  0.6928,  1.3976, -0.7744, -0.2919,  0.0392, -0.8870,\n",
       "          -1.8249, -1.1663, -0.2447,  0.2045, -0.7378, -1.5489,  0.1418,\n",
       "          -0.1393,  0.0894, -0.1360,  0.0455, -0.6207, -0.9976,  1.7428,\n",
       "          -0.1896,  0.0531]]),\n",
       " tensor([[ 1.3309, -0.9582, -0.2164, -0.1520, -0.1929, -1.3222,  0.4254,\n",
       "           0.2326,  0.4376,  0.5685, -0.9925, -0.7912,  2.0109, -0.6427,\n",
       "           0.0111, -0.9317,  0.1596,  1.3229, -0.9368,  0.7782, -1.1944,\n",
       "           0.7623,  0.1188,  0.2498,  0.6171, -0.2366,  0.5772, -0.8606,\n",
       "           1.0062,  0.1542]]),\n",
       " tensor([[-1.2783, -1.9666, -0.2285, -0.4592, -0.5647,  0.7318,  0.4561,\n",
       "           0.5629,  0.7257, -0.6871,  0.8081,  0.6964,  0.7598,  0.3609,\n",
       "           2.3299,  1.2145,  1.3690, -0.9994, -0.0396,  0.3494, -0.3325,\n",
       "           0.3725, -0.6533, -0.7328,  0.4187,  1.4987, -0.4587,  0.0297,\n",
       "           0.5106, -0.7977]]),\n",
       " tensor([[-1.9697, -1.4799, -0.9725,  0.3031, -0.3743, -0.7954,  0.9484,\n",
       "          -1.5593, -1.0375,  0.1201,  0.2336,  0.0998,  1.4227,  0.8734,\n",
       "           0.1567,  0.6154,  0.7730, -0.6888, -0.4496, -0.8351, -0.0767,\n",
       "           0.1997,  0.1475,  0.4104,  0.2249, -0.0933, -0.5065,  1.1902,\n",
       "           0.5589, -1.3229]]),\n",
       " tensor([[-1.1307, -0.2630,  1.2965,  0.3000, -1.5327, -0.8528, -0.5330,\n",
       "           0.8496, -0.5557, -1.5389, -0.0788, -0.4684,  0.0184,  0.7022,\n",
       "          -0.0575,  0.3654, -0.2034, -0.9384, -0.9274,  0.3839,  1.1439,\n",
       "           0.4564, -0.6043, -0.9319,  0.1434,  0.7116, -1.0722,  0.1863,\n",
       "           0.6779, -0.2194]]),\n",
       " tensor([[-0.9293, -0.1456, -0.3056,  0.5575, -1.2107,  0.1697, -0.3750,\n",
       "           2.1157, -0.2064, -0.6210,  0.4968, -0.1431,  0.1221,  0.4776,\n",
       "          -0.9886, -0.3524, -1.0492,  0.5349, -0.6460,  0.1022, -0.1387,\n",
       "          -1.9640, -1.0520,  0.6042, -0.4036, -0.0279, -0.1733,  0.2166,\n",
       "           0.6137,  1.0192]]),\n",
       " tensor([[ 0.0643, -0.0177,  0.1243,  1.3959, -0.4957,  0.2514,  0.0662,\n",
       "           0.2123, -0.5076, -1.1492, -0.2562,  1.1863, -0.0042, -0.1753,\n",
       "           0.7413, -1.4298, -1.0569,  1.1325,  0.0232,  0.7641, -0.2199,\n",
       "          -1.0657, -1.1569,  0.4575, -0.3140,  0.8706, -0.1645,  0.8807,\n",
       "          -0.7613,  0.2269]]),\n",
       " tensor([[-0.3899,  0.1200, -0.5165, -0.3221,  0.9234,  0.8811,  0.1753,\n",
       "           0.1581,  0.4574,  0.1833, -0.0014,  2.1484, -0.7421, -0.2710,\n",
       "           2.0533,  0.3158, -0.8149,  0.9495, -0.3315, -0.7682, -1.4453,\n",
       "          -0.5830,  1.6664, -1.4359, -0.4417, -1.0532, -1.1110,  1.3061,\n",
       "           1.9826,  0.0503]]),\n",
       " tensor([[ 0.7218,  1.2558,  1.1978,  0.5950,  0.1867, -0.1529,  0.4831,\n",
       "           0.2396,  1.1773,  0.8813, -0.4347, -0.0589, -0.3318,  0.9764,\n",
       "          -0.5798,  0.3428,  0.5996,  0.6827, -1.2507,  1.0887,  1.1377,\n",
       "          -1.7655, -0.1794, -1.1598,  0.8525,  1.3670, -0.7900, -0.1235,\n",
       "          -0.6776,  0.7136]]),\n",
       " tensor([[ 0.1838, -0.0464, -0.7375,  0.3391, -1.1609,  0.7849,  1.9397,\n",
       "           2.3039,  0.4600,  0.8099,  0.3198,  1.1144,  0.5117,  1.3601,\n",
       "           1.6957,  0.9632, -0.5006, -1.3572, -0.7072,  2.1331, -0.3173,\n",
       "           0.6380,  0.2131, -0.5928, -1.1902,  0.1411, -0.0738, -0.0750,\n",
       "           1.0444, -0.6452]]),\n",
       " tensor([[-0.8732,  0.4332,  0.8080,  1.4113,  0.1411,  0.2691, -0.2955,\n",
       "          -0.5920, -1.5116,  0.2879, -0.8102, -0.2169, -0.3758,  0.4419,\n",
       "          -1.6470,  1.8154,  1.7089, -0.1191, -1.3667, -1.2138, -0.2845,\n",
       "          -1.5360,  0.3303,  1.7063,  0.2077, -0.9087,  1.2011,  0.6612,\n",
       "          -1.1616, -0.0002]]),\n",
       " tensor([[ 0.9907, -0.3829,  0.0597, -0.7042,  0.3580,  1.0129,  0.8522,\n",
       "          -0.8567,  0.3428, -0.8682,  1.4705,  0.6411, -1.1230, -1.3802,\n",
       "          -1.2048,  0.0943,  0.7366,  1.1582,  0.9277,  0.4468,  1.7978,\n",
       "          -0.3412, -0.2606, -1.4068,  1.5180, -1.4642,  0.8369,  0.4162,\n",
       "           0.6724, -0.4466]]),\n",
       " tensor([[ 0.6254,  1.0280,  0.8021,  1.2798,  0.4774, -0.2224,  0.7814,\n",
       "          -0.7669, -0.2413, -1.2220, -0.1976, -1.5835, -0.2552, -0.7422,\n",
       "          -1.6624,  1.1452,  0.5884,  0.5479,  2.0347,  1.3904, -1.3126,\n",
       "          -1.4181, -0.5854, -0.3858, -0.9428,  0.0108,  0.0930,  1.6055,\n",
       "           0.1739, -1.6546]]),\n",
       " tensor([[-0.3057, -0.6499,  0.4408, -0.5644,  2.0015, -0.7717,  0.1610,\n",
       "           0.6558, -0.4153,  1.1330, -1.1115, -0.7441, -0.4971,  1.3097,\n",
       "          -0.5316, -0.8992,  0.7683,  0.3885,  0.6353, -0.1312,  0.6474,\n",
       "          -0.4153,  0.8178, -0.0084,  0.4688, -0.2805,  0.3597,  0.6165,\n",
       "          -0.7059, -1.2745]]),\n",
       " tensor([[-0.4055, -1.5381, -0.4512,  0.0665,  2.0196,  1.6067,  1.9122,\n",
       "          -0.8472, -0.4436, -0.3118,  1.7539, -1.0994, -0.9028, -1.4924,\n",
       "           0.3068,  0.0974, -0.9978,  0.3274, -0.2999, -0.4013,  0.0313,\n",
       "           0.8477, -0.6494,  0.2533, -0.0770,  0.8771, -0.0266, -0.9382,\n",
       "          -0.9324, -1.2189]]),\n",
       " tensor([[ 1.2881, -0.3613,  0.5005,  0.5353, -0.3447,  1.5980, -0.1206,\n",
       "          -0.1031, -0.5067,  1.6519,  0.4514,  1.0132,  0.4443,  0.7345,\n",
       "           0.6131, -1.6496, -0.8835,  0.2957, -1.3144,  0.4744,  0.5254,\n",
       "           1.6724,  0.7737,  0.1000,  1.9783, -0.5471,  0.6464, -0.7222,\n",
       "          -0.8927,  0.7053]]),\n",
       " tensor([[ 0.5609, -0.3910,  0.7285, -0.6431,  0.7997, -0.0428,  0.5986,\n",
       "          -1.3526, -0.2679, -0.6531,  0.0478,  0.4779,  0.9301,  0.1893,\n",
       "           0.6994,  0.4862,  0.2694, -0.6115,  0.7590,  0.6763, -0.9232,\n",
       "           0.5338, -0.6207, -0.0882,  0.7713,  0.0229,  0.3754,  0.4399,\n",
       "          -0.8397,  0.0812]]),\n",
       " tensor([[ 1.3196, -0.2786, -1.0531, -0.9831,  0.1414, -0.3382,  0.8673,\n",
       "          -0.3806,  0.7690,  1.7204, -0.9217, -0.7110,  0.7833, -0.2968,\n",
       "           0.7735,  0.6227,  0.9938,  0.4584, -1.1138, -0.9475, -0.2387,\n",
       "          -0.2104,  0.5462,  0.7534,  0.2544, -0.0727,  0.4670, -1.3261,\n",
       "          -0.7082,  1.5205]]),\n",
       " tensor([[ 0.6829, -1.8418, -0.9707,  0.2766,  0.3849, -1.8068,  0.2175,\n",
       "          -0.9951,  0.7298, -1.0071,  0.3545, -1.7835,  1.1237, -1.7218,\n",
       "           0.2206, -0.7394,  2.0537, -2.0955,  0.6195,  0.0539, -1.5222,\n",
       "           0.9438, -0.4963,  0.9485,  0.0864,  1.5399,  1.4378, -0.4891,\n",
       "          -0.5725,  0.3047]]),\n",
       " tensor([[-0.6984,  0.1000,  1.2722,  0.4350,  1.3683,  0.6451,  0.0435,\n",
       "          -0.6064, -1.1792,  1.2309, -0.0763,  1.2955, -0.8796,  1.2054,\n",
       "          -1.1614, -0.1761, -1.7560,  0.7774,  1.8294,  1.9021,  0.1363,\n",
       "           1.6618,  0.3612, -1.3724,  1.1359, -0.0472, -0.9216,  0.0792,\n",
       "           0.5141,  1.8069]])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can train and test model on the generated data\n",
    "synthentic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert array of tensor to tensors\n",
    "temp = torch.Tensor(99)\n",
    "synthentic_data = torch.cat(synthentic_data, out=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.154058</td>\n",
       "      <td>-0.805023</td>\n",
       "      <td>-0.609287</td>\n",
       "      <td>0.372057</td>\n",
       "      <td>-1.122445</td>\n",
       "      <td>-0.528706</td>\n",
       "      <td>-0.220063</td>\n",
       "      <td>-1.174472</td>\n",
       "      <td>-0.259316</td>\n",
       "      <td>-0.377251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124565</td>\n",
       "      <td>-1.353358</td>\n",
       "      <td>1.543099</td>\n",
       "      <td>0.827969</td>\n",
       "      <td>1.250208</td>\n",
       "      <td>-0.868746</td>\n",
       "      <td>0.187333</td>\n",
       "      <td>0.443387</td>\n",
       "      <td>-0.838185</td>\n",
       "      <td>0.653835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001935</td>\n",
       "      <td>-0.030889</td>\n",
       "      <td>0.324551</td>\n",
       "      <td>-0.804980</td>\n",
       "      <td>-1.294312</td>\n",
       "      <td>1.147315</td>\n",
       "      <td>0.463092</td>\n",
       "      <td>0.714175</td>\n",
       "      <td>-1.154135</td>\n",
       "      <td>-0.759521</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.023554</td>\n",
       "      <td>0.208640</td>\n",
       "      <td>0.122450</td>\n",
       "      <td>0.980193</td>\n",
       "      <td>-0.203689</td>\n",
       "      <td>0.881517</td>\n",
       "      <td>-0.119440</td>\n",
       "      <td>0.463349</td>\n",
       "      <td>-0.667569</td>\n",
       "      <td>-1.168444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878023</td>\n",
       "      <td>0.227793</td>\n",
       "      <td>-1.623895</td>\n",
       "      <td>-0.263034</td>\n",
       "      <td>0.106731</td>\n",
       "      <td>-0.441775</td>\n",
       "      <td>-1.410921</td>\n",
       "      <td>0.525050</td>\n",
       "      <td>-0.871109</td>\n",
       "      <td>1.972753</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035683</td>\n",
       "      <td>-0.121034</td>\n",
       "      <td>1.553571</td>\n",
       "      <td>0.630789</td>\n",
       "      <td>-1.549194</td>\n",
       "      <td>1.148516</td>\n",
       "      <td>1.562665</td>\n",
       "      <td>-0.243722</td>\n",
       "      <td>-1.330347</td>\n",
       "      <td>-0.291580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.834613</td>\n",
       "      <td>0.185503</td>\n",
       "      <td>-0.387738</td>\n",
       "      <td>-0.113327</td>\n",
       "      <td>0.600975</td>\n",
       "      <td>0.253523</td>\n",
       "      <td>-0.407366</td>\n",
       "      <td>0.573156</td>\n",
       "      <td>1.559968</td>\n",
       "      <td>-1.287621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306482</td>\n",
       "      <td>0.325508</td>\n",
       "      <td>-0.688057</td>\n",
       "      <td>0.459245</td>\n",
       "      <td>0.326428</td>\n",
       "      <td>0.325430</td>\n",
       "      <td>1.294043</td>\n",
       "      <td>-0.976792</td>\n",
       "      <td>0.148072</td>\n",
       "      <td>0.646601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.055959</td>\n",
       "      <td>1.192253</td>\n",
       "      <td>0.652752</td>\n",
       "      <td>0.143163</td>\n",
       "      <td>-0.259224</td>\n",
       "      <td>0.423089</td>\n",
       "      <td>1.088355</td>\n",
       "      <td>0.798973</td>\n",
       "      <td>-0.123981</td>\n",
       "      <td>0.963955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.147442</td>\n",
       "      <td>-0.858664</td>\n",
       "      <td>0.834118</td>\n",
       "      <td>-1.109651</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>-0.431315</td>\n",
       "      <td>-0.089733</td>\n",
       "      <td>0.806187</td>\n",
       "      <td>0.692386</td>\n",
       "      <td>-0.138840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.154058 -0.805023 -0.609287  0.372057 -1.122445 -0.528706 -0.220063   \n",
       "1 -0.001935 -0.030889  0.324551 -0.804980 -1.294312  1.147315  0.463092   \n",
       "2  0.878023  0.227793 -1.623895 -0.263034  0.106731 -0.441775 -1.410921   \n",
       "3 -0.834613  0.185503 -0.387738 -0.113327  0.600975  0.253523 -0.407366   \n",
       "4 -0.055959  1.192253  0.652752  0.143163 -0.259224  0.423089  1.088355   \n",
       "\n",
       "         7         8         9     ...           20        21        22  \\\n",
       "0 -1.174472 -0.259316 -0.377251    ...    -0.124565 -1.353358  1.543099   \n",
       "1  0.714175 -1.154135 -0.759521    ...    -1.023554  0.208640  0.122450   \n",
       "2  0.525050 -0.871109  1.972753    ...     1.035683 -0.121034  1.553571   \n",
       "3  0.573156  1.559968 -1.287621    ...    -0.306482  0.325508 -0.688057   \n",
       "4  0.798973 -0.123981  0.963955    ...     1.147442 -0.858664  0.834118   \n",
       "\n",
       "         23        24        25        26        27        28        29  \n",
       "0  0.827969  1.250208 -0.868746  0.187333  0.443387 -0.838185  0.653835  \n",
       "1  0.980193 -0.203689  0.881517 -0.119440  0.463349 -0.667569 -1.168444  \n",
       "2  0.630789 -1.549194  1.148516  1.562665 -0.243722 -1.330347 -0.291580  \n",
       "3  0.459245  0.326428  0.325430  1.294043 -0.976792  0.148072  0.646601  \n",
       "4 -1.109651  0.747253 -0.431315 -0.089733  0.806187  0.692386 -0.138840  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tensor to PD data frame\n",
    "synthentic_data_df = pd.DataFrame(data=synthentic_data.data.numpy());\n",
    "synthentic_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthentic_data_df.rename(columns={'0':'V1', '1':'V2', '2':'V3', '3':'V4', '4':'V5', '5':'V6', '6':'V7', '7':'V8', \n",
    "                                     '8':'V9', '9':'V10', '10':'V11', '11':'V12', '12':'V13', '13':'V14', '14':'V15', \n",
    "                                     '15':'V16', '16':'V17', '17':'V18', '18':'V19', '19':'V20', '20':'V21', '21':'V22',\n",
    "                                     '22':'V23', '23':'V24', '24':'V25', '25':'V26', '26':'V27', '27':'V28', \n",
    "                                     '29':'normAmount', '30':'Class'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.154058</td>\n",
       "      <td>-0.805023</td>\n",
       "      <td>-0.609287</td>\n",
       "      <td>0.372057</td>\n",
       "      <td>-1.122445</td>\n",
       "      <td>-0.528706</td>\n",
       "      <td>-0.220063</td>\n",
       "      <td>-1.174472</td>\n",
       "      <td>-0.259316</td>\n",
       "      <td>-0.377251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124565</td>\n",
       "      <td>-1.353358</td>\n",
       "      <td>1.543099</td>\n",
       "      <td>0.827969</td>\n",
       "      <td>1.250208</td>\n",
       "      <td>-0.868746</td>\n",
       "      <td>0.187333</td>\n",
       "      <td>0.443387</td>\n",
       "      <td>-0.838185</td>\n",
       "      <td>0.653835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001935</td>\n",
       "      <td>-0.030889</td>\n",
       "      <td>0.324551</td>\n",
       "      <td>-0.804980</td>\n",
       "      <td>-1.294312</td>\n",
       "      <td>1.147315</td>\n",
       "      <td>0.463092</td>\n",
       "      <td>0.714175</td>\n",
       "      <td>-1.154135</td>\n",
       "      <td>-0.759521</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.023554</td>\n",
       "      <td>0.208640</td>\n",
       "      <td>0.122450</td>\n",
       "      <td>0.980193</td>\n",
       "      <td>-0.203689</td>\n",
       "      <td>0.881517</td>\n",
       "      <td>-0.119440</td>\n",
       "      <td>0.463349</td>\n",
       "      <td>-0.667569</td>\n",
       "      <td>-1.168444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878023</td>\n",
       "      <td>0.227793</td>\n",
       "      <td>-1.623895</td>\n",
       "      <td>-0.263034</td>\n",
       "      <td>0.106731</td>\n",
       "      <td>-0.441775</td>\n",
       "      <td>-1.410921</td>\n",
       "      <td>0.525050</td>\n",
       "      <td>-0.871109</td>\n",
       "      <td>1.972753</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035683</td>\n",
       "      <td>-0.121034</td>\n",
       "      <td>1.553571</td>\n",
       "      <td>0.630789</td>\n",
       "      <td>-1.549194</td>\n",
       "      <td>1.148516</td>\n",
       "      <td>1.562665</td>\n",
       "      <td>-0.243722</td>\n",
       "      <td>-1.330347</td>\n",
       "      <td>-0.291580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.834613</td>\n",
       "      <td>0.185503</td>\n",
       "      <td>-0.387738</td>\n",
       "      <td>-0.113327</td>\n",
       "      <td>0.600975</td>\n",
       "      <td>0.253523</td>\n",
       "      <td>-0.407366</td>\n",
       "      <td>0.573156</td>\n",
       "      <td>1.559968</td>\n",
       "      <td>-1.287621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306482</td>\n",
       "      <td>0.325508</td>\n",
       "      <td>-0.688057</td>\n",
       "      <td>0.459245</td>\n",
       "      <td>0.326428</td>\n",
       "      <td>0.325430</td>\n",
       "      <td>1.294043</td>\n",
       "      <td>-0.976792</td>\n",
       "      <td>0.148072</td>\n",
       "      <td>0.646601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.055959</td>\n",
       "      <td>1.192253</td>\n",
       "      <td>0.652752</td>\n",
       "      <td>0.143163</td>\n",
       "      <td>-0.259224</td>\n",
       "      <td>0.423089</td>\n",
       "      <td>1.088355</td>\n",
       "      <td>0.798973</td>\n",
       "      <td>-0.123981</td>\n",
       "      <td>0.963955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.147442</td>\n",
       "      <td>-0.858664</td>\n",
       "      <td>0.834118</td>\n",
       "      <td>-1.109651</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>-0.431315</td>\n",
       "      <td>-0.089733</td>\n",
       "      <td>0.806187</td>\n",
       "      <td>0.692386</td>\n",
       "      <td>-0.138840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.154058 -0.805023 -0.609287  0.372057 -1.122445 -0.528706 -0.220063   \n",
       "1 -0.001935 -0.030889  0.324551 -0.804980 -1.294312  1.147315  0.463092   \n",
       "2  0.878023  0.227793 -1.623895 -0.263034  0.106731 -0.441775 -1.410921   \n",
       "3 -0.834613  0.185503 -0.387738 -0.113327  0.600975  0.253523 -0.407366   \n",
       "4 -0.055959  1.192253  0.652752  0.143163 -0.259224  0.423089  1.088355   \n",
       "\n",
       "         7         8         9     ...           20        21        22  \\\n",
       "0 -1.174472 -0.259316 -0.377251    ...    -0.124565 -1.353358  1.543099   \n",
       "1  0.714175 -1.154135 -0.759521    ...    -1.023554  0.208640  0.122450   \n",
       "2  0.525050 -0.871109  1.972753    ...     1.035683 -0.121034  1.553571   \n",
       "3  0.573156  1.559968 -1.287621    ...    -0.306482  0.325508 -0.688057   \n",
       "4  0.798973 -0.123981  0.963955    ...     1.147442 -0.858664  0.834118   \n",
       "\n",
       "         23        24        25        26        27        28        29  \n",
       "0  0.827969  1.250208 -0.868746  0.187333  0.443387 -0.838185  0.653835  \n",
       "1  0.980193 -0.203689  0.881517 -0.119440  0.463349 -0.667569 -1.168444  \n",
       "2  0.630789 -1.549194  1.148516  1.562665 -0.243722 -1.330347 -0.291580  \n",
       "3  0.459245  0.326428  0.325430  1.294043 -0.976792  0.148072  0.646601  \n",
       "4 -1.109651  0.747253 -0.431315 -0.089733  0.806187  0.692386 -0.138840  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthentic_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
