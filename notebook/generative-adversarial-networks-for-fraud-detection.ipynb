{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Cuda is running\n",
    "#torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's randomize the data, just to be sure not to get any pathological ordering effects that might harm the performane of Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230513</th>\n",
       "      <td>146360.0</td>\n",
       "      <td>-0.208103</td>\n",
       "      <td>0.969149</td>\n",
       "      <td>0.177749</td>\n",
       "      <td>-0.636113</td>\n",
       "      <td>0.372358</td>\n",
       "      <td>-1.085819</td>\n",
       "      <td>0.935908</td>\n",
       "      <td>-0.142743</td>\n",
       "      <td>0.221779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291806</td>\n",
       "      <td>-0.611120</td>\n",
       "      <td>0.088831</td>\n",
       "      <td>-0.036603</td>\n",
       "      <td>-0.470064</td>\n",
       "      <td>0.149911</td>\n",
       "      <td>0.356194</td>\n",
       "      <td>0.156509</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244122</th>\n",
       "      <td>152215.0</td>\n",
       "      <td>-0.381810</td>\n",
       "      <td>0.793184</td>\n",
       "      <td>-1.643861</td>\n",
       "      <td>-0.594889</td>\n",
       "      <td>3.970920</td>\n",
       "      <td>3.061948</td>\n",
       "      <td>0.804784</td>\n",
       "      <td>0.634344</td>\n",
       "      <td>-1.086486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234087</td>\n",
       "      <td>0.606717</td>\n",
       "      <td>-0.330229</td>\n",
       "      <td>0.715907</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.487421</td>\n",
       "      <td>0.096618</td>\n",
       "      <td>0.156967</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125501</th>\n",
       "      <td>77693.0</td>\n",
       "      <td>1.347283</td>\n",
       "      <td>0.365949</td>\n",
       "      <td>-0.277916</td>\n",
       "      <td>0.784055</td>\n",
       "      <td>0.451706</td>\n",
       "      <td>-0.157267</td>\n",
       "      <td>0.214748</td>\n",
       "      <td>-0.167423</td>\n",
       "      <td>0.014076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060893</td>\n",
       "      <td>-0.094913</td>\n",
       "      <td>-0.275241</td>\n",
       "      <td>-0.992829</td>\n",
       "      <td>0.889644</td>\n",
       "      <td>-0.242817</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.006721</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252710</th>\n",
       "      <td>155934.0</td>\n",
       "      <td>2.115246</td>\n",
       "      <td>-0.714078</td>\n",
       "      <td>-1.064718</td>\n",
       "      <td>-0.515877</td>\n",
       "      <td>-0.964142</td>\n",
       "      <td>-1.137007</td>\n",
       "      <td>-0.887510</td>\n",
       "      <td>-0.159398</td>\n",
       "      <td>0.117449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242640</td>\n",
       "      <td>0.752805</td>\n",
       "      <td>0.099681</td>\n",
       "      <td>-0.061078</td>\n",
       "      <td>-0.167754</td>\n",
       "      <td>-0.090491</td>\n",
       "      <td>0.024560</td>\n",
       "      <td>-0.009983</td>\n",
       "      <td>29.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234821</th>\n",
       "      <td>148131.0</td>\n",
       "      <td>-0.113680</td>\n",
       "      <td>0.516603</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>-1.053518</td>\n",
       "      <td>1.356753</td>\n",
       "      <td>-0.910457</td>\n",
       "      <td>1.117772</td>\n",
       "      <td>-0.532438</td>\n",
       "      <td>0.194099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278977</td>\n",
       "      <td>1.069340</td>\n",
       "      <td>-0.386627</td>\n",
       "      <td>0.636275</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>-0.488595</td>\n",
       "      <td>-0.169328</td>\n",
       "      <td>-0.168756</td>\n",
       "      <td>8.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "230513  146360.0 -0.208103  0.969149  0.177749 -0.636113  0.372358 -1.085819   \n",
       "244122  152215.0 -0.381810  0.793184 -1.643861 -0.594889  3.970920  3.061948   \n",
       "125501   77693.0  1.347283  0.365949 -0.277916  0.784055  0.451706 -0.157267   \n",
       "252710  155934.0  2.115246 -0.714078 -1.064718 -0.515877 -0.964142 -1.137007   \n",
       "234821  148131.0 -0.113680  0.516603  0.011401 -1.053518  1.356753 -0.910457   \n",
       "\n",
       "              V7        V8        V9  ...         V21       V22       V23  \\\n",
       "230513  0.935908 -0.142743  0.221779  ...   -0.291806 -0.611120  0.088831   \n",
       "244122  0.804784  0.634344 -1.086486  ...    0.234087  0.606717 -0.330229   \n",
       "125501  0.214748 -0.167423  0.014076  ...   -0.060893 -0.094913 -0.275241   \n",
       "252710 -0.887510 -0.159398  0.117449  ...    0.242640  0.752805  0.099681   \n",
       "234821  1.117772 -0.532438  0.194099  ...    0.278977  1.069340 -0.386627   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "230513 -0.036603 -0.470064  0.149911  0.356194  0.156509    3.58      0  \n",
       "244122  0.715907  0.000065 -0.487421  0.096618  0.156967    1.00      0  \n",
       "125501 -0.992829  0.889644 -0.242817  0.015100  0.006721    2.25      0  \n",
       "252710 -0.061078 -0.167754 -0.090491  0.024560 -0.009983   29.99      0  \n",
       "234821  0.636275  0.116438 -0.488595 -0.169328 -0.168756    8.94      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reindex(np.random.permutation(data.index))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.177546e-15</td>\n",
       "      <td>3.437553e-16</td>\n",
       "      <td>-1.432708e-15</td>\n",
       "      <td>2.110722e-15</td>\n",
       "      <td>9.891064e-16</td>\n",
       "      <td>1.555792e-15</td>\n",
       "      <td>-6.328667e-16</td>\n",
       "      <td>9.426197e-17</td>\n",
       "      <td>-2.399812e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.621594e-16</td>\n",
       "      <td>-3.420705e-16</td>\n",
       "      <td>2.585743e-16</td>\n",
       "      <td>4.472611e-15</td>\n",
       "      <td>5.261505e-16</td>\n",
       "      <td>1.674323e-15</td>\n",
       "      <td>-3.673287e-16</td>\n",
       "      <td>-1.223670e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.177546e-15  3.437553e-16 -1.432708e-15  2.110722e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.891064e-16  1.555792e-15 -6.328667e-16  9.426197e-17 -2.399812e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.621594e-16 -3.420705e-16  2.585743e-16  4.472611e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.261505e-16  1.674323e-15 -3.673287e-16 -1.223670e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAETCAYAAADge6tNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGdJJREFUeJzt3X+0XWV95/H3xwAVRAElIoZgUGNbZCpiirROW60VAq2CLpmCTkkdWjqKbbWdGdFlC9UyS2e12DJWWigZAX8gYlWq2EhRy9hBJSgDRHRIESUmhUiA8Pvnd/7Yz62Hy825J4F9T3Lyfq111jn7u5+997NDyOfuZz93n1QVkiT16Unj7oAkafIZNpKk3hk2kqTeGTaSpN4ZNpKk3hk2kqTeGTbSJiT5SpLf2oLtKsnz++jTDMc6JclHhqxfleTlc9EXaZgdxt0BaZgkNwJ7AQ8PlF9QVWvH06NtS1W9cLY2SRYB3wN2rKqH+u6Ttk9e2Whb8Oqq2nXg9ZigSeIPTlsp/9sIDBtto5IsasNVxyf5AfClVv9kkn9NckeSy5K8cGCbRw2LJfnNJF8dWH5Vku+0bT8IZMjx5yV5V5J/SXJnkiuTLJyh3a8m+VaSjUluSnLKwLonJ/lIkluT3J7kiiR7DfTthrbv7yV545A/jp2SnNvarkqyZOAYNyb5lfb54CQrW19uTnJaa3ZZe789yV1Jfi7Jk5K8O8n3k9zS9r/bwH6Pa+tuTfJH045zSpIL27ltBH6zHfvydp7rknwwyU4D+6skb0lyfTuP9yZ5XttmY5ILBttr22PYaFv3S8BPA4e15S8Ai4FnAt8EPjrKTpLsCXwKeDewJ/AvwMuGbPIHwLHAEcDTgP8E3DNDu7uB44DdgV8F3pzkqLZuGbAbsBB4BvCfgXuTPAU4HTi8qp4K/Dxw1ZC+vAY4vx3jIuCDm2j3l8BfVtXTgOcBF7T6L7b33duV4+XAb7bXK4DnArtO7TfJ/sCHgDcCe7dzWDDtWEcCF7Y+fZRuGPTtdH+2Pwe8EnjLtG2WAi8BDgH+G3BmO8ZC4AC6P29towwbbQs+034ivj3JZ6atO6Wq7q6qewGqanlV3VlV9wOnAC8a/Il8iCOAb1fVhVX1IPAXwL8Oaf9bwLur6rvV+b9Vdev0RlX1laq6pqoeqaqrgY/TBSTAg3Qh8/yqeriqrqyqjW3dI8ABSXauqnVVtWpIX75aVRdX1cPAecCLNtHuQeD5Sfasqruq6mtD9vlG4LSquqGq7gLeCRzThsReD/x9VX21qh4A/hiY/pDFy6vqM+28723n9rWqeqiqbgT+ZuDPYcr7q2pjO9drgS+2499B90PEi4f0V1s5w0bbgqOqavf2OmraupumPrShrfe1oa2NwI1t1Z4jHOPZg/uq7gm1N226OQvprn6GSvLSJF9Osj7JHXRXL1P9OQ9YAZyfZG2S/5Fkx6q6G/j11nZdks8n+akhhxkMxXuAJ2/iPsnxwAuA77Qhu18bss9nA98fWP4+3YSivXjsn9U9wPSgfdSfXZIXJPlcG+LcCPx3Hvvf5eaBz/fOsLzrkP5qK2fYaFs3+BP1G+iGb36FbmhnUatP3Xu5G9hloP2zBj6vowuQboMkg8szuIluKGo2H6Mb2lpYVbsBfz3Vn6p6sKr+pKr2pxsq+zW6ITeqakVVvYpumOo7wFkjHGuoqrq+qo6lG2J8P3BhG7Kb6dHva4HnDCzvCzxEFwDrgH2mViTZme4K7VGHm7Z8Bt15LG7DeO9iyD0xTR7DRpPkqcD9dD9l70L30/Ogq4DXJdkl3e/BHD+w7vPAC5O8rl0V/B6PDqPp/hZ4b5LF6fxMkun/4E71aUNV3ZfkYLpABCDJK5L8uyTzgI10w1wPJ9kryWtaENwP3MWjp35vkST/Mcn8qnoEuL2VHwbW0w3bPXeg+ceBtyfZL8mudH+Wn2hToy8EXp3k59tN+z9h9uB4ajvHu9pV2psf7/lo22LYaJKcSzfc80Pg28D0exIfAB6g++n8HAYmD1TVj4CjgffRhdVi4J+HHOs0uhvsX6T7R/RsYOcZ2r0FeE+SO+nubVwwsO5ZdP9wbwSuA/4J+Ajd/5d/SHd1sYHu3sb0m+lbYimwKslddJMFjqmq+9ow2KnAP7f7YocAy+mG+S6j+x2c+4DfBWj3VH6XblLCOuBO4Ba6YNyU/0IXtHfSXaV94gk4H21D4penSXo82pXP7XRDZN8bd3+0dfLKRtJmS/LqNhz5FODPgGv48YQM6TEMG0lb4ki6Yb61dEOOx5TDJBrCYTRJUu+8spEk9c6wkST1zqexNnvuuWctWrRo3N2QpG3KlVde+aOqmj9bO8OmWbRoEStXrhx3NyRpm5Lk+7O3chhNkjQHDBtJUu8MG0lS7wwbSVLvDBtJUu8MG0lS7wwbSVLvDBtJUu/8pc5tzKKTPj/uLkyUG9/3q+PugrRd8MpGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUu97CJsnCJF9Ocl2SVUl+v9VPSfLDJFe11xED27wzyeok301y2EB9aautTnLSQH2/JF9Pcn2STyTZqdV/oi2vbusX9XWekqTZ9Xll8xDwh1X108AhwIlJ9m/rPlBVB7bXxQBt3THAC4GlwIeSzEsyD/gr4HBgf+DYgf28v+1rMXAbcHyrHw/cVlXPBz7Q2kmSxqS3sKmqdVX1zfb5TuA6YMGQTY4Ezq+q+6vqe8Bq4OD2Wl1VN1TVA8D5wJFJAvwycGHb/hzgqIF9ndM+Xwi8srWXJI3BnNyzacNYLwa+3kpvTXJ1kuVJ9mi1BcBNA5utabVN1Z8B3F5VD02rP2pfbf0drf30fp2QZGWSlevXr39c5yhJ2rTewybJrsCngLdV1UbgDOB5wIHAOuDPp5rOsHltQX3Yvh5dqDqzqpZU1ZL58+cPPQ9J0pbrNWyS7EgXNB+tqr8DqKqbq+rhqnoEOItumAy6K5OFA5vvA6wdUv8RsHuSHabVH7Wvtn43YMMTe3aSpFH1ORstwNnAdVV12kB974FmrwWubZ8vAo5pM8n2AxYD3wCuABa3mWc70U0iuKiqCvgy8Pq2/TLgswP7WtY+vx74UmsvSRqDHWZvssVeBvwGcE2Sq1rtXXSzyQ6kG9a6EfgdgKpaleQC4Nt0M9lOrKqHAZK8FVgBzAOWV9Wqtr93AOcn+VPgW3ThRns/L8lquiuaY3o8T0nSLHoLm6r6KjPfO7l4yDanAqfOUL94pu2q6gZ+PAw3WL8POHpz+itJ6o9PEJAk9c6wkST1zrCRJPXOsJEk9c6wkST1zrCRJPXOsJEk9c6wkST1zrCRJPXOsJEk9c6wkST1zrCRJPXOsJEk9c6wkST1zrCRJPXOsJEk9c6wkST1zrCRJPXOsJEk9c6wkST1zrCRJPXOsJEk9c6wkST1zrCRJPXOsJEk9c6wkST1zrCRJPWut7BJsjDJl5Ncl2RVkt9v9acnuSTJ9e19j1ZPktOTrE5ydZKDBva1rLW/PsmygfpLklzTtjk9SYYdQ5I0Hn1e2TwE/GFV/TRwCHBikv2Bk4BLq2oxcGlbBjgcWNxeJwBnQBccwMnAS4GDgZMHwuOM1nZqu6WtvqljSJLGoLewqap1VfXN9vlO4DpgAXAkcE5rdg5wVPt8JHBudb4G7J5kb+Aw4JKq2lBVtwGXAEvbuqdV1eVVVcC50/Y10zEkSWMwJ/dskiwCXgx8HdirqtZBF0jAM1uzBcBNA5utabVh9TUz1BlyDEnSGPQeNkl2BT4FvK2qNg5rOkOttqC+OX07IcnKJCvXr1+/OZtKkjZDr2GTZEe6oPloVf1dK9/chsBo77e0+hpg4cDm+wBrZ6nvM0N92DEeparOrKolVbVk/vz5W3aSkqRZ9TkbLcDZwHVVddrAqouAqRlly4DPDtSPa7PSDgHuaENgK4BDk+zRJgYcCqxo6+5Mckg71nHT9jXTMSRJY7BDj/t+GfAbwDVJrmq1dwHvAy5IcjzwA+Dotu5i4AhgNXAP8CaAqtqQ5L3AFa3de6pqQ/v8ZuDDwM7AF9qLIceQJI1Bb2FTVV9l5vsqAK+coX0BJ25iX8uB5TPUVwIHzFC/daZjSJLGwycISJJ6Z9hIknpn2EiSemfYSJJ6Z9hIknpn2EiSemfYSJJ6N1LYJHnM77JIkjSqUa9s/jrJN5K8JcnuvfZIkjRxRgqbqvr3wBvpHoi5MsnHkryq155JkibGyPdsqup64N3AO4BfAk5P8p0kr+urc5KkyTDqPZufSfIBum/b/GXg1e3rnn8Z+ECP/ZMkTYBRH8T5QeAs4F1Vde9UsarWJnl3Lz2TJE2MUcPmCODeqnoYIMmTgCdX1T1VdV5vvZMkTYRR79n8I913xkzZpdUkSZrVqGHz5Kq6a2qhfd6lny5JkibNqGFzd5KDphaSvAS4d0h7SZL+zaj3bN4GfDLJ2ra8N/Dr/XRJkjRpRgqbqroiyU8BP0n3Vc/fqaoHe+2ZJGlijHplA/CzwKK2zYuTUFXn9tIrSdJEGSlskpwHPA+4Cni4lQswbCRJsxr1ymYJsH9VVZ+dkSRNplFno10LPKvPjkiSJteoVzZ7At9O8g3g/qliVb2ml15JkibKqGFzSp+dkCRNtlGnPv9TkucAi6vqH5PsAszrt2uSpEkx6lcM/DZwIfA3rbQA+ExfnZIkTZZRJwicCLwM2Aj/9kVqzxy2QZLlSW5Jcu1A7ZQkP0xyVXsdMbDunUlWJ/luksMG6ktbbXWSkwbq+yX5epLrk3wiyU6t/hNteXVbv2jEc5Qk9WTUsLm/qh6YWkiyA93v2QzzYWDpDPUPVNWB7XVx29/+wDHAC9s2H0oyL8k84K+Aw4H9gWNbW4D3t30tBm4Djm/144Hbqur5dF/s9v4Rz1GS1JNRw+afkrwL2DnJq4BPAn8/bIOqugzYMOL+jwTOr6r7q+p7wGrg4PZaXVU3tLA7HzgySei+JfTCtv05wFED+zqnfb4QeGVrL0kak1HD5iRgPXAN8DvAxcCWfkPnW5Nc3YbZ9mi1BcBNA23WtNqm6s8Abq+qh6bVH7Wvtv6O1l6SNCYjhU1VPVJVZ1XV0VX1+vZ5S54mcAbdY28OBNYBf97qM1151BbUh+3rMZKckGRlkpXr168f1m9J0uMw6rPRvscM/2BX1XM352BVdfPAPs8CPtcW1wALB5ruA0x9ncFM9R8BuyfZoV29DLaf2teadm9pNzYxnFdVZwJnAixZssRH8UhSTzbn2WhTngwcDTx9cw+WZO+qWtcWX0v3GByAi4CPJTkNeDawGPgG3VXK4iT7AT+km0TwhqqqJF8GXk93H2cZ8NmBfS0DLm/rv+Qz3SRpvEb9pc5bp5X+IslXgT/e1DZJPg68HNgzyRrgZODlSQ6ku0q6ke7+D1W1KskFwLeBh4ATq+rhtp+3Aivofol0eVWtaod4B3B+kj8FvgWc3epnA+clWU13RXPMKOcoSerPqMNoBw0sPonuSuepw7apqmNnKJ89Q22q/anAqTPUL6abkDC9fgPdbLXp9fvorrwkSVuJUYfR/nzg80N0VyX/4QnvjSRpIo06jPaKvjsiSZpcow6j/cGw9VV12hPTHUnSJNqc2Wg/SzfTC+DVwGU8+hcuJUma0eZ8edpBVXUndA/UBD5ZVb/VV8ckSZNj1MfV7As8MLD8ALDoCe+NJGkijXplcx7wjSSfpvsdmdcC5/bWK0nSRBl1NtqpSb4A/EIrvamqvtVftyRJk2TUYTSAXYCNVfWXdM8d26+nPkmSJsyoXwt9Mt3jYd7ZSjsCH+mrU5KkyTLqlc1rgdcAdwNU1VpmeVyNJElTRg2bB9qTkwsgyVP665IkadKMGjYXJPkbuu+Q+W3gH4Gz+uuWJGmSjDob7c+SvArYCPwk8MdVdUmvPZMkTYxZwybJPGBFVf0KYMBIkjbbrMNo7UvM7kmy2xz0R5I0gUZ9gsB9wDVJLqHNSAOoqt/rpVeSpIkyath8vr0kSdpsQ8Mmyb5V9YOqOmeuOiRJmjyz3bP5zNSHJJ/quS+SpAk1W9hk4PNz++yIJGlyzRY2tYnPkiSNbLYJAi9KspHuCmfn9pm2XFX1tF57J0maCEPDpqrmzVVHJEmTa3O+z0aSpC1i2EiSemfYSJJ6Z9hIknrXW9gkWZ7kliTXDtSenuSSJNe39z1aPUlOT7I6ydVJDhrYZllrf32SZQP1lyS5pm1zepIMO4YkaXz6vLL5MLB0Wu0k4NKqWgxc2pYBDgcWt9cJwBnQBQdwMvBS4GDg5IHwOKO1ndpu6SzHkCSNSW9hU1WXARumlY8Epp6zdg5w1ED93Op8je4bQfcGDgMuqaoNVXUb3ffpLG3rnlZVl7evqz532r5mOoYkaUzm+p7NXlW1DqC9P7PVFwA3DbRb02rD6mtmqA87hiRpTLaWCQKZoVZbUN+8gyYnJFmZZOX69es3d3NJ0ojmOmxubkNgtPdbWn0NsHCg3T7A2lnq+8xQH3aMx6iqM6tqSVUtmT9//haflCRpuLkOm4uAqRlly4DPDtSPa7PSDgHuaENgK4BDk+zRJgYcCqxo6+5MckibhXbctH3NdAxJ0piM+k2dmy3Jx4GXA3smWUM3q+x9wAVJjgd+ABzdml8MHAGsBu4B3gRQVRuSvBe4orV7T1VNTTp4M92Mt52BL7QXQ44hSRqT3sKmqo7dxKpXztC2gBM3sZ/lwPIZ6iuBA2ao3zrTMSRJ47O1TBCQJE0ww0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUO8NGktQ7w0aS1DvDRpLUu7GETZIbk1yT5KokK1vt6UkuSXJ9e9+j1ZPk9CSrk1yd5KCB/Sxr7a9Psmyg/pK2/9Vt28z9WUqSpozzyuYVVXVgVS1pyycBl1bVYuDStgxwOLC4vU4AzoAunICTgZcCBwMnTwVUa3PCwHZL+z8dSdKmbE3DaEcC57TP5wBHDdTPrc7XgN2T7A0cBlxSVRuq6jbgEmBpW/e0qrq8qgo4d2BfkqQxGFfYFPDFJFcmOaHV9qqqdQDt/ZmtvgC4aWDbNa02rL5mhrokaUx2GNNxX1ZVa5M8E7gkyXeGtJ3pfkttQf2xO+6C7gSAfffdd3iPJUlbbCxXNlW1tr3fAnya7p7LzW0IjPZ+S2u+Blg4sPk+wNpZ6vvMUJ+pH2dW1ZKqWjJ//vzHe1qSpE2Y87BJ8pQkT536DBwKXAtcBEzNKFsGfLZ9vgg4rs1KOwS4ow2zrQAOTbJHmxhwKLCirbszySFtFtpxA/uSJI3BOIbR9gI+3WYj7wB8rKr+IckVwAVJjgd+ABzd2l8MHAGsBu4B3gRQVRuSvBe4orV7T1VtaJ/fDHwY2Bn4QntJksZkzsOmqm4AXjRD/VbglTPUCzhxE/taDiyfob4SOOBxd1aS9ITYmqY+S5ImlGEjSeqdYSNJ6p1hI0nqnWEjSeqdYSNJ6p1hI0nqnWEjSeqdYSNJ6p1hI0nqnWEjSeqdYSNJ6p1hI0nqnWEjSeqdYSNJ6p1hI0nqnWEjSeqdYSNJ6p1hI0nqnWEjSeqdYSNJ6p1hI0nqnWEjSeqdYSNJ6p1hI0nqnWEjSeqdYSNJ6p1hI0nq3cSGTZKlSb6bZHWSk8bdH0nank1k2CSZB/wVcDiwP3Bskv3H2ytJ2n5NZNgABwOrq+qGqnoAOB84csx9kqTt1g7j7kBPFgA3DSyvAV46vVGSE4AT2uJdSb47B33bXuwJ/GjcnZhN3j/uHmgMtom/m9uQ54zSaFLDJjPU6jGFqjOBM/vvzvYnycqqWjLufkjT+XdzPCZ1GG0NsHBgeR9g7Zj6IknbvUkNmyuAxUn2S7ITcAxw0Zj7JEnbrYkcRquqh5K8FVgBzAOWV9WqMXdre+PwpLZW/t0cg1Q95laGJElPqEkdRpMkbUUMG0lS7wwbSVLvJnKCgOZWkp+ie0LDArrfZ1oLXFRV1421Y5K2Gl7Z6HFJ8g66xwEF+AbdtPMAH/cBqNqaJXnTuPuwPXE2mh6XJP8PeGFVPTitvhOwqqoWj6dn0nBJflBV+467H9sLh9H0eD0CPBv4/rT63m2dNDZJrt7UKmCvuezL9s6w0eP1NuDSJNfz44ef7gs8H3jr2HoldfYCDgNum1YP8H/mvjvbL8NGj0tV/UOSF9B9rcMCuv+J1wBXVNXDY+2cBJ8Ddq2qq6avSPKVue/O9st7NpKk3jkbTZLUO8NGktQ7w0YagyTPSnJ+kn9J8u0kFyd5QZJrx903qQ9OEJDmWJIAnwbOqapjWu1AnIqrCeaVjTT3XgE8WFV/PVVos6Wmpo6TZFGS/53km+31862+d5LLklyV5Nokv5BkXpIPt+Vrkrx97k9JGs4rG2nuHQBcOUubW4BXVdV9SRYDHweWAG8AVlTVqUnmAbsABwILquoAgCS799d1acsYNtLWaUfgg2147WHgBa1+BbA8yY7AZ6rqqiQ3AM9N8j+BzwNfHEuPpSEcRpPm3irgJbO0eTtwM/AiuiuanQCq6jLgF4EfAuclOa6qbmvtvgKcCPxtP92WtpxhI829LwE/keS3pwpJfhZ4zkCb3YB1VfUI8BvAvNbuOcAtVXUWcDZwUJI9gSdV1aeAPwIOmpvTkEbnMJo0x6qqkrwW+Iv2NQz3ATfSPWduyoeATyU5GvgycHervxz4r0keBO4CjqN7TND/SjL1w+M7ez8JaTP5uBpJUu8cRpMk9c6wkST1zrCRJPXOsJEk9c6wkST1zrCRJPXOsJEk9c6wkST17v8DF//MsJh+lHEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
    "classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class')['Class'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Data is hihgly imbalance. 284315 Normal transaction vs 492 Fraud transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run with Normalising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 30)\n",
      "xtest shape\n",
      "(85443, 30)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the training data and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit classifier to a model\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85298,    11],\n",
       "       [   29,   105]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85309\n",
      "          1       0.91      0.78      0.84       134\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999532\n",
      "Area under the curve : 0.891727\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run with Over Sampling data using SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.338916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.344234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.233327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.317487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   -0.338916  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.349231  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   -0.344234  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   -0.233327  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.317487  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data2['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data2 = data2.drop(['Time','Amount'],axis=1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284807, 30)\n",
      "Shape of y: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data.ix[:, data.columns != 'Class'])\n",
    "y = np.array(data.ix[:, data.columns == 'Class'])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 30)\n",
      "xtest shape\n",
      "(85443, 30)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over Sampling data using SMOTE\n",
    "smote = SMOTE(random_state=2)\n",
    "X_train_resample, y_train_resample = smote.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_resample, y_train_resample.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85288,    21],\n",
       "       [   22,   112]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confision Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85309\n",
      "          1       0.84      0.84      0.84       134\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999497\n",
      "Area under the curve : 0.917787\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run with Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data.drop(['Time'], axis = 1, inplace = True)\n",
    "data.drop(['Class'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.35980713e+00,  -7.27811733e-02,   2.53634674e+00, ...,\n",
       "          1.33558377e-01,  -2.10530535e-02,   1.49620000e+02],\n",
       "       [  1.19185711e+00,   2.66150712e-01,   1.66480113e-01, ...,\n",
       "         -8.98309914e-03,   1.47241692e-02,   2.69000000e+00],\n",
       "       [ -1.35835406e+00,  -1.34016307e+00,   1.77320934e+00, ...,\n",
       "         -5.53527940e-02,  -5.97518406e-02,   3.78660000e+02],\n",
       "       ..., \n",
       "       [  1.91956501e+00,  -3.01253846e-01,  -3.24963981e+00, ...,\n",
       "          4.45477214e-03,  -2.65608286e-02,   6.78800000e+01],\n",
       "       [ -2.40440050e-01,   5.30482513e-01,   7.02510230e-01, ...,\n",
       "          1.08820735e-01,   1.04532821e-01,   1.00000000e+01],\n",
       "       [ -5.33412522e-01,  -1.89733337e-01,   7.03337367e-01, ...,\n",
       "         -2.41530880e-03,   1.36489143e-02,   2.17000000e+02]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data frame to a numpy array\n",
    "data = np.array(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([284807, 29])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert array to PyTorch tensor\n",
    "data = torch.FloatTensor(data)\n",
    "data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator's paragrams\n",
    "g_input_size = 1     # Random noise dimension\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1   \n",
    "g_learning_rate = 2e-4\n",
    "g_steps = 1\n",
    "\n",
    "#Discriminator's paragrams\n",
    "d_input_size = 29   # Minibatch size\n",
    "d_hidden_size = 50  # Discriminator complexity\n",
    "d_output_size = 1   # Single dimension for 'real' vs. 'fake'\n",
    "d_learning_rate = 2e-4\n",
    "d_steps = 1 \n",
    "\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 10000\n",
    "print_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Raw data]\n"
     ]
    }
   ],
   "source": [
    "(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_fake_data():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    return torch.cat([data, diffs], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sampler = data[0]\n",
    "gi_sampler = inject_fake_data()\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Discriminator: Real Error 3.833092212677002 / Fake Error 0.7207157015800476 Generator: 0.6704715490341187 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.77009229618927533, 0.010418597518074552]) \n",
      "100: Discriminator: Real Error 0.012722495943307877 / Fake Error 0.6362389922142029 Generator: 0.7652853727340698 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.1233433076533778, 0.043317953254956791]) \n",
      "200: Discriminator: Real Error 0.0029825896490365267 / Fake Error 0.33752819895744324 Generator: 1.2314261198043823 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.5389342133341164, 0.052230644849638644]) \n",
      "300: Discriminator: Real Error 0.0016122934175655246 / Fake Error 0.37734341621398926 Generator: 1.1741148233413696 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.78959056221205615, 0.0088001136506832729]) \n",
      "400: Discriminator: Real Error 0.0007715817191638052 / Fake Error 0.49469202756881714 Generator: 0.9234975576400757 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.49470297427013005, 0.059798688058344346]) \n",
      "500: Discriminator: Real Error 0.000509272504132241 / Fake Error 0.21145562827587128 Generator: 1.6696704626083374 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.057916164655109931, 0.047285050601796517]) \n",
      "600: Discriminator: Real Error 0.0002485226432327181 / Fake Error 0.0956861674785614 Generator: 2.3932783603668213 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.43371676062715464, 0.025896850093169509]) \n",
      "700: Discriminator: Real Error 0.00016118395433295518 / Fake Error 0.07826413214206696 Generator: 2.678528070449829 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.61853577761814516, 0.062366688006580184]) \n",
      "800: Discriminator: Real Error 0.00010347901843488216 / Fake Error 0.10513044148683548 Generator: 2.297027826309204 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.55496742602052362, 0.042179779554873738]) \n",
      "900: Discriminator: Real Error 6.306370050879195e-05 / Fake Error 0.06073332577943802 Generator: 2.870178699493408 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.1301693071065278, 0.070044543094311185]) \n",
      "1000: Discriminator: Real Error 4.983072358299978e-05 / Fake Error 0.029771875590085983 Generator: 3.7076914310455322 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.32272568601986457, 0.069310694165082315]) \n",
      "1100: Discriminator: Real Error 3.647870835266076e-05 / Fake Error 0.02533533237874508 Generator: 3.5935540199279785 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.49019319435645792, 0.040169615432875734]) \n",
      "1200: Discriminator: Real Error 2.7656937163555995e-05 / Fake Error 0.022866029292345047 Generator: 3.9115869998931885 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.16114329726531587, 0.06731266877936147]) \n",
      "1300: Discriminator: Real Error 2.360371763643343e-05 / Fake Error 0.014970699325203896 Generator: 4.3381452560424805 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.21991992279373365, 0.080640651913372122]) \n",
      "1400: Discriminator: Real Error 1.9550514480215497e-05 / Fake Error 0.012538091279566288 Generator: 4.426350116729736 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.34513690451095846, 0.053238684842196855]) \n",
      "1500: Discriminator: Real Error 1.609338323760312e-05 / Fake Error 0.007726456969976425 Generator: 4.7244648933410645 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.020011156797409058, 0.073483037158762352]) \n",
      "1600: Discriminator: Real Error 1.4186005500960164e-05 / Fake Error 0.00834609568119049 Generator: 4.8420586585998535 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.28097240215745467, 0.067304178482324423]) \n",
      "1700: Discriminator: Real Error 1.2636263818421867e-05 / Fake Error 0.0063866362906992435 Generator: 5.048077583312988 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.089466242954648778, 0.061715892457753045]) \n",
      "1800: Discriminator: Real Error 1.096731375582749e-05 / Fake Error 0.0048677497543394566 Generator: 5.38075065612793 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.22031892938860531, 0.052093740992491651]) \n",
      "1900: Discriminator: Real Error 9.775208127393853e-06 / Fake Error 0.004329117946326733 Generator: 5.258835792541504 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.25834722405877608, 0.095984005249295096]) \n",
      "2000: Discriminator: Real Error 8.94073582458077e-06 / Fake Error 0.0033072447404265404 Generator: 5.54245138168335 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.10864807639656396, 0.08699411259641246]) \n",
      "2100: Discriminator: Real Error 8.106263521767687e-06 / Fake Error 0.0035230873618274927 Generator: 5.612692356109619 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.25738556426146936, 0.078916935434331981]) \n",
      "2200: Discriminator: Real Error 7.271792128449306e-06 / Fake Error 0.0029692817479372025 Generator: 5.8495965003967285 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.013919836231346789, 0.094319398666533494]) \n",
      "2300: Discriminator: Real Error 6.794951787014725e-06 / Fake Error 0.002140382304787636 Generator: 5.548232555389404 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.21207354834367489, 0.10203985417719379]) \n",
      "2400: Discriminator: Real Error 6.3181114455801435e-06 / Fake Error 0.002082712249830365 Generator: 5.790543079376221 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.040228121753396656, 0.12248834438022721]) \n",
      "2500: Discriminator: Real Error 5.72206135984743e-06 / Fake Error 0.0019905080553144217 Generator: 6.361231803894043 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.2107495747763535, 0.099067443993541171]) \n",
      "2600: Discriminator: Real Error 5.2452214731602e-06 / Fake Error 0.001559858093969524 Generator: 6.378058433532715 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.19704707814701672, 0.13395671808269421]) \n",
      "2700: Discriminator: Real Error 5.006801529816585e-06 / Fake Error 0.0014003023970872164 Generator: 6.500797748565674 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.12652802518729506, 0.096385694262365373]) \n",
      "2800: Discriminator: Real Error 4.649172296922188e-06 / Fake Error 0.0018708659335970879 Generator: 6.452194690704346 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.24206573824430333, 0.12830051651665852]) \n",
      "2900: Discriminator: Real Error 4.291542609280441e-06 / Fake Error 0.0011135147651657462 Generator: 6.553232669830322 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.018306096052301341, 0.17144618257453029]) \n",
      "3000: Discriminator: Real Error 4.053123120684177e-06 / Fake Error 0.001295034890063107 Generator: 6.6168293952941895 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.15292817482660556, 0.16172297843405758]) \n",
      "3100: Discriminator: Real Error 3.814703632087912e-06 / Fake Error 0.0013000661274418235 Generator: 6.8070454597473145 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.10370129372539191, 0.15832198879333209]) \n",
      "3200: Discriminator: Real Error 3.576284143491648e-06 / Fake Error 0.0009539757738821208 Generator: 7.127572059631348 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.16107763761076435, 0.17895426573890913]) \n",
      "3300: Discriminator: Real Error 3.337864654895384e-06 / Fake Error 0.0005299507756717503 Generator: 6.9797844886779785 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.20851344538146052, 0.27613959759272533]) \n",
      "3400: Discriminator: Real Error 3.099445393672795e-06 / Fake Error 0.0009895417606458068 Generator: 6.131527423858643 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.061579655470519232, 0.3159056705983278]) \n",
      "3500: Discriminator: Real Error 2.980235649374663e-06 / Fake Error 0.00020118853717576712 Generator: 5.213964462280273 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.10488223515707872, 0.43458788570953671]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600: Discriminator: Real Error 2.741816388152074e-06 / Fake Error 0.0017946885200217366 Generator: 7.316278457641602 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.017344580642108261, 0.45345038103824986]) \n",
      "3700: Discriminator: Real Error 2.6226068712276174e-06 / Fake Error 0.0007078509661369026 Generator: 5.4080810546875 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.074466776488156153, 0.61751957942973201]) \n",
      "3800: Discriminator: Real Error 2.5033971269294852e-06 / Fake Error 0.00216255453415215 Generator: 6.848730564117432 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.10724848174843295, 0.60871543193435029]) \n",
      "3900: Discriminator: Real Error 2.3841876100050285e-06 / Fake Error 0.0003922205651178956 Generator: 7.937126159667969 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.040512378873496221, 0.71882939571231375]) \n",
      "4000: Discriminator: Real Error 2.3841876100050285e-06 / Fake Error 0.0010375555139034986 Generator: 7.738458633422852 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.0098522408255215348, 0.71237802301146258]) \n",
      "4100: Discriminator: Real Error 2.264978093080572e-06 / Fake Error 0.0001683033915469423 Generator: 8.160438537597656 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.032085695143403675, 1.051957033662372]) \n",
      "4200: Discriminator: Real Error 2.264978093080572e-06 / Fake Error 0.0016539207426831126 Generator: 9.235071182250977 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.48805971289503164, 0.97417742697835441]) \n",
      "4300: Discriminator: Real Error 2.145768576156115e-06 / Fake Error 0.0005619637086056173 Generator: 9.473731994628906 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.017383981367637372, 1.1195634143100808]) \n",
      "4400: Discriminator: Real Error 2.145768576156115e-06 / Fake Error 0.0005814745090901852 Generator: 11.128583908081055 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.19193778058578229, 0.96781808190082219]) \n",
      "4500: Discriminator: Real Error 2.145768576156115e-06 / Fake Error 4.841445115744136e-05 Generator: 9.282564163208008 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.05629957441625924, 1.3556551717940064]) \n",
      "4600: Discriminator: Real Error 2.145768576156115e-06 / Fake Error 0.00027585256611928344 Generator: 8.47665023803711 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.13685603491191206, 1.1801406451311904]) \n",
      "4700: Discriminator: Real Error 2.145768576156115e-06 / Fake Error 3.2824969821376726e-05 Generator: 8.294747352600098 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.018197816250653101, 1.2376741303186196]) \n",
      "4800: Discriminator: Real Error 2.145768576156115e-06 / Fake Error 0.0003822390572167933 Generator: 7.947206974029541 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.26736627750355624, 1.3807840080024838]) \n",
      "4900: Discriminator: Real Error 2.264978093080572e-06 / Fake Error 1.5938934666337445e-05 Generator: 8.296799659729004 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.055382510711406839, 1.4762897993571211]) \n",
      "5000: Discriminator: Real Error 2.264978093080572e-06 / Fake Error 0.000401579454774037 Generator: 8.456260681152344 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.11209304682139692, 1.3994240653334118]) \n",
      "5100: Discriminator: Real Error 2.145768576156115e-06 / Fake Error 4.408830136526376e-05 Generator: 7.610121250152588 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.37250146578098164, 1.2405533833712579]) \n",
      "5200: Discriminator: Real Error 2.145768576156115e-06 / Fake Error 6.539415335282683e-05 Generator: 8.608266830444336 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.20146375894546509, 1.2583458068035198]) \n",
      "5300: Discriminator: Real Error 2.145768576156115e-06 / Fake Error 0.0006367265596054494 Generator: 8.011857032775879 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.054090584917315124, 1.3665394652632226]) \n",
      "5400: Discriminator: Real Error 2.145768576156115e-06 / Fake Error 3.02544140140526e-05 Generator: 10.644850730895996 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.30220722972319042, 1.4755350446289388]) \n",
      "5500: Discriminator: Real Error 2.0265590592316585e-06 / Fake Error 8.584357419749722e-05 Generator: 9.643439292907715 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.099108400015995426, 1.5197556753465162]) \n",
      "5600: Discriminator: Real Error 1.9073495423072018e-06 / Fake Error 0.0001738839055178687 Generator: 8.93270492553711 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.23213266144538747, 1.4078456215064485]) \n",
      "5700: Discriminator: Real Error 1.7881399116959074e-06 / Fake Error 4.4590680772671476e-05 Generator: 9.640862464904785 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.28639292408680095, 1.4984191135796925]) \n",
      "5800: Discriminator: Real Error 1.6689303947714507e-06 / Fake Error 5.056347436038777e-05 Generator: 8.999239921569824 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.035968489944934845, 1.4368877826157578]) \n",
      "5900: Discriminator: Real Error 1.6689303947714507e-06 / Fake Error 3.897548231179826e-05 Generator: 9.588403701782227 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.0707064610103081, 1.4625402890219896]) \n",
      "6000: Discriminator: Real Error 1.5497209915338317e-06 / Fake Error 0.00011266473302384838 Generator: 8.14475154876709 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.30865912601865569, 1.3410773983986946]) \n",
      "6100: Discriminator: Real Error 1.430511474609375e-06 / Fake Error 6.531162944156677e-05 Generator: 9.037860870361328 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.15561859155523367, 1.2418399329750833]) \n",
      "6200: Discriminator: Real Error 1.311302071371756e-06 / Fake Error 8.879871893441305e-05 Generator: 9.859136581420898 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.0045032902010555924, 1.2397294070891247]) \n",
      "6300: Discriminator: Real Error 1.311302071371756e-06 / Fake Error 4.348342554294504e-05 Generator: 9.155978202819824 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.010318249464035034, 1.2933119468747181]) \n",
      "6400: Discriminator: Real Error 1.1920925544472993e-06 / Fake Error 3.0282186344265938e-05 Generator: 9.383464813232422 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.11652629128817854, 1.2960608510929328]) \n",
      "6500: Discriminator: Real Error 1.1920925544472993e-06 / Fake Error 0.00012235298345331103 Generator: 10.57857894897461 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.086033351976295996, 1.3956102233859342]) \n",
      "6600: Discriminator: Real Error 1.0728831512096804e-06 / Fake Error 3.8639369449811056e-05 Generator: 10.048809051513672 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.35192359033329734, 1.2947653279899105]) \n",
      "6700: Discriminator: Real Error 9.536737479720614e-07 / Fake Error 1.512568360340083e-05 Generator: 10.760974884033203 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.086780930387562724, 1.4580768917718558]) \n",
      "6800: Discriminator: Real Error 9.536737479720614e-07 / Fake Error 4.109319343115203e-05 Generator: 10.422067642211914 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.12983994237307844, 1.3891345565816386]) \n",
      "6900: Discriminator: Real Error 8.344644015778613e-07 / Fake Error 7.642880518687889e-05 Generator: 9.082109451293945 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.18180762385499888, 1.3512709938198106]) \n",
      "7000: Discriminator: Real Error 8.344644015778613e-07 / Fake Error 2.7909451091545634e-05 Generator: 8.824013710021973 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.052168738996160438, 1.4420878447802141]) \n",
      "7100: Discriminator: Real Error 8.344644015778613e-07 / Fake Error 3.992482379544526e-05 Generator: 9.278779029846191 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.093303354906624766, 1.4915359321812245]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200: Discriminator: Real Error 7.152549983402423e-07 / Fake Error 1.302605596720241e-05 Generator: 9.858447074890137 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.16196210271325603, 1.3244442547465887]) \n",
      "7300: Discriminator: Real Error 7.152549983402423e-07 / Fake Error 3.458567152847536e-05 Generator: 9.339343070983887 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.027534751542683304, 1.1766731212974155]) \n",
      "7400: Discriminator: Real Error 5.960456519460422e-07 / Fake Error 3.055011620745063e-05 Generator: 11.283622741699219 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.33958548564335395, 1.2708019178914651]) \n",
      "7500: Discriminator: Real Error 5.960456519460422e-07 / Fake Error 4.815722786588594e-05 Generator: 10.184962272644043 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.049700605972059844, 1.4440520266404164]) \n",
      "7600: Discriminator: Real Error 5.960456519460422e-07 / Fake Error 3.075650238315575e-05 Generator: 10.286332130432129 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.048444463775075712, 1.3983326421441615]) \n",
      "7700: Discriminator: Real Error 5.960456519460422e-07 / Fake Error 2.1222398572717793e-05 Generator: 10.429718971252441 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.27902048261001194, 1.2846769252344443]) \n",
      "7800: Discriminator: Real Error 4.7683627713013266e-07 / Fake Error 5.08180855831597e-05 Generator: 10.409821510314941 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.18510719748406573, 1.3015954247647625]) \n",
      "7900: Discriminator: Real Error 4.7683627713013266e-07 / Fake Error 2.1219766495050862e-05 Generator: 10.130341529846191 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.028172254305461358, 1.1797222961439993]) \n",
      "8000: Discriminator: Real Error 4.7683627713013266e-07 / Fake Error 1.5371233530458994e-05 Generator: 10.322189331054688 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.22377540813437824, 1.0689540836222646]) \n",
      "8100: Discriminator: Real Error 4.7683627713013266e-07 / Fake Error 8.56024053064175e-06 Generator: 10.767709732055664 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.17468416485293159, 1.2273824753733609]) \n",
      "8200: Discriminator: Real Error 3.5762693073593255e-07 / Fake Error 1.3884101463190746e-05 Generator: 10.496980667114258 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.28142054738669559, 1.2807070271766268]) \n",
      "8300: Discriminator: Real Error 3.5762693073593255e-07 / Fake Error 2.1251584257697687e-05 Generator: 11.625693321228027 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.18299476494049205, 1.4163835428660039]) \n",
      "8400: Discriminator: Real Error 3.5762693073593255e-07 / Fake Error 3.85395651392173e-05 Generator: 11.661487579345703 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.19860991013461146, 1.3822698611790494]) \n",
      "8500: Discriminator: Real Error 3.5762693073593255e-07 / Fake Error 6.338467755995225e-06 Generator: 11.112537384033203 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.40842330712696601, 1.1174113206004741]) \n",
      "8600: Discriminator: Real Error 3.5762693073593255e-07 / Fake Error 8.775299647822976e-06 Generator: 11.104508399963379 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.11066698000348847, 1.3324711642996205]) \n",
      "8700: Discriminator: Real Error 3.5762693073593255e-07 / Fake Error 9.930292435456067e-06 Generator: 11.724445343017578 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.18326556374286784, 1.1866407282372409]) \n",
      "8800: Discriminator: Real Error 2.3841761276344187e-07 / Fake Error 1.5017769328551367e-05 Generator: 11.465422630310059 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.077158586218439296, 1.3436302113388296]) \n",
      "8900: Discriminator: Real Error 2.3841761276344187e-07 / Fake Error 6.921769454493187e-06 Generator: 11.654236793518066 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.25214185334485151, 1.3958793425809837]) \n",
      "9000: Discriminator: Real Error 2.3841761276344187e-07 / Fake Error 1.731621341605205e-05 Generator: 11.750489234924316 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.16594783191023202, 1.2354405075203387]) \n",
      "9100: Discriminator: Real Error 2.3841761276344187e-07 / Fake Error 9.929591215041e-06 Generator: 11.407041549682617 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.049953692945940743, 1.2676557808308666]) \n",
      "9200: Discriminator: Real Error 2.3841761276344187e-07 / Fake Error 1.2649573363887612e-05 Generator: 11.527848243713379 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.38909531384706497, 1.0757776560243024]) \n",
      "9300: Discriminator: Real Error 2.3841761276344187e-07 / Fake Error 1.4126877431408502e-05 Generator: 10.91184139251709 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.042649149894714355, 1.3909885815676541]) \n",
      "9400: Discriminator: Real Error 2.3841761276344187e-07 / Fake Error 1.1623647878877819e-05 Generator: 10.976799011230469 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.20221603430550675, 1.1300288817285846]) \n",
      "9500: Discriminator: Real Error 2.3841761276344187e-07 / Fake Error 1.6863819837453775e-05 Generator: 12.080460548400879 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.16318458164560384, 1.2190954858005587]) \n",
      "9600: Discriminator: Real Error 1.1920829479095119e-07 / Fake Error 6.062658030714374e-06 Generator: 11.301591873168945 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.32834788334780723, 1.1348362084408843]) \n",
      "9700: Discriminator: Real Error 1.1920829479095119e-07 / Fake Error 7.642242962901946e-06 Generator: 11.468368530273438 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.12436288646582899, 1.2358559965126796]) \n",
      "9800: Discriminator: Real Error 1.1920829479095119e-07 / Fake Error 9.213911653205287e-06 Generator: 12.058981895446777 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.13579903286078882, 1.2324606213739056]) \n",
      "9900: Discriminator: Real Error 1.1920829479095119e-07 / Fake Error 8.845474440022372e-06 Generator: 12.344690322875977 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.06656234994016845, 1.0916866496218109]) \n"
     ]
    }
   ],
   "source": [
    "# Training loop alternates between two modes\n",
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        \n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train Discriminator on real data\n",
    "        d_real_data = Variable(d_sampler)\n",
    "        d_real_decision = D(preprocess(d_real_data))\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train Discriminator on fake data\n",
    "        #d_gen_input = Variable(gi_sampler(minibatch_size, 29))\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "        \n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train Generator on Discriminator's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "        \n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: Discriminator: Real Error %s / Fake Error %s Generator: %s (Real Data: %s, Fake Data: %s) \" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
