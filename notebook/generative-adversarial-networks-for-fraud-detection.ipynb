{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Cuda is running\n",
    "#torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's randomize the data, just to be sure not to get any pathological ordering effects that might harm the performane of Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124011</th>\n",
       "      <td>77147.0</td>\n",
       "      <td>-1.437314</td>\n",
       "      <td>-0.672735</td>\n",
       "      <td>0.925002</td>\n",
       "      <td>-0.728117</td>\n",
       "      <td>-0.498919</td>\n",
       "      <td>-1.088232</td>\n",
       "      <td>0.098312</td>\n",
       "      <td>0.294362</td>\n",
       "      <td>-1.763211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>-0.254662</td>\n",
       "      <td>0.569343</td>\n",
       "      <td>0.599137</td>\n",
       "      <td>-0.909906</td>\n",
       "      <td>0.070153</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>149.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182926</th>\n",
       "      <td>125586.0</td>\n",
       "      <td>-1.188026</td>\n",
       "      <td>0.648003</td>\n",
       "      <td>0.195708</td>\n",
       "      <td>-2.300317</td>\n",
       "      <td>-1.876858</td>\n",
       "      <td>0.483442</td>\n",
       "      <td>-0.257970</td>\n",
       "      <td>-4.314653</td>\n",
       "      <td>1.394378</td>\n",
       "      <td>...</td>\n",
       "      <td>3.773234</td>\n",
       "      <td>-1.129681</td>\n",
       "      <td>-1.190132</td>\n",
       "      <td>0.066215</td>\n",
       "      <td>0.806729</td>\n",
       "      <td>0.669240</td>\n",
       "      <td>0.580496</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>392.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>2364.0</td>\n",
       "      <td>1.571567</td>\n",
       "      <td>-0.852696</td>\n",
       "      <td>-0.411170</td>\n",
       "      <td>-1.735533</td>\n",
       "      <td>-0.574247</td>\n",
       "      <td>-0.298426</td>\n",
       "      <td>-0.606201</td>\n",
       "      <td>-0.165091</td>\n",
       "      <td>-2.384797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546954</td>\n",
       "      <td>-1.269700</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>-0.896239</td>\n",
       "      <td>0.433003</td>\n",
       "      <td>-0.425964</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10848</th>\n",
       "      <td>18552.0</td>\n",
       "      <td>-0.265284</td>\n",
       "      <td>0.081207</td>\n",
       "      <td>1.595559</td>\n",
       "      <td>-1.671107</td>\n",
       "      <td>-0.359368</td>\n",
       "      <td>-0.158713</td>\n",
       "      <td>-0.188054</td>\n",
       "      <td>0.271057</td>\n",
       "      <td>2.710338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102560</td>\n",
       "      <td>0.673973</td>\n",
       "      <td>0.126516</td>\n",
       "      <td>-0.065758</td>\n",
       "      <td>-1.159539</td>\n",
       "      <td>-1.066871</td>\n",
       "      <td>0.283226</td>\n",
       "      <td>0.230268</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250966</th>\n",
       "      <td>155148.0</td>\n",
       "      <td>-1.071928</td>\n",
       "      <td>0.594211</td>\n",
       "      <td>-0.352817</td>\n",
       "      <td>-0.819417</td>\n",
       "      <td>1.439513</td>\n",
       "      <td>0.755137</td>\n",
       "      <td>0.594540</td>\n",
       "      <td>0.448423</td>\n",
       "      <td>0.063034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085680</td>\n",
       "      <td>0.088365</td>\n",
       "      <td>0.361190</td>\n",
       "      <td>-0.336159</td>\n",
       "      <td>-1.006584</td>\n",
       "      <td>0.176926</td>\n",
       "      <td>-0.098098</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "124011   77147.0 -1.437314 -0.672735  0.925002 -0.728117 -0.498919 -1.088232   \n",
       "182926  125586.0 -1.188026  0.648003  0.195708 -2.300317 -1.876858  0.483442   \n",
       "2807      2364.0  1.571567 -0.852696 -0.411170 -1.735533 -0.574247 -0.298426   \n",
       "10848    18552.0 -0.265284  0.081207  1.595559 -1.671107 -0.359368 -0.158713   \n",
       "250966  155148.0 -1.071928  0.594211 -0.352817 -0.819417  1.439513  0.755137   \n",
       "\n",
       "              V7        V8        V9  ...         V21       V22       V23  \\\n",
       "124011  0.098312  0.294362 -1.763211  ...   -0.032172 -0.254662  0.569343   \n",
       "182926 -0.257970 -4.314653  1.394378  ...    3.773234 -1.129681 -1.190132   \n",
       "2807   -0.606201 -0.165091 -2.384797  ...   -0.546954 -1.269700  0.009546   \n",
       "10848  -0.188054  0.271057  2.710338  ...    0.102560  0.673973  0.126516   \n",
       "250966  0.594540  0.448423  0.063034  ...   -0.085680  0.088365  0.361190   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "124011  0.599137 -0.909906  0.070153  0.017838  0.001861  149.20      0  \n",
       "182926  0.066215  0.806729  0.669240  0.580496  0.090244  392.00      0  \n",
       "2807   -0.896239  0.433003 -0.425964  0.000977 -0.003500   19.75      0  \n",
       "10848  -0.065758 -1.159539 -1.066871  0.283226  0.230268   11.85      0  \n",
       "250966 -0.336159 -1.006584  0.176926 -0.098098  0.001136   14.75      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reindex(np.random.permutation(data.index))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.174225e-15</td>\n",
       "      <td>3.429687e-16</td>\n",
       "      <td>-1.386421e-15</td>\n",
       "      <td>2.073779e-15</td>\n",
       "      <td>9.939598e-16</td>\n",
       "      <td>1.493625e-15</td>\n",
       "      <td>-5.931037e-16</td>\n",
       "      <td>1.318317e-16</td>\n",
       "      <td>-2.414318e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.416845e-16</td>\n",
       "      <td>-3.515296e-16</td>\n",
       "      <td>2.727492e-16</td>\n",
       "      <td>4.482012e-15</td>\n",
       "      <td>5.203181e-16</td>\n",
       "      <td>1.689590e-15</td>\n",
       "      <td>-3.712632e-16</td>\n",
       "      <td>-1.159267e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.174225e-15  3.429687e-16 -1.386421e-15  2.073779e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.939598e-16  1.493625e-15 -5.931037e-16  1.318317e-16 -2.414318e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.416845e-16 -3.515296e-16  2.727492e-16  4.482012e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.203181e-16  1.689590e-15 -3.712632e-16 -1.159267e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
    "classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class')['Class'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Data is hihgly imbalance. 284315 Normal transaction vs 492 Fraud transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run with Normalising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 30)\n",
      "xtest shape\n",
      "(85443, 30)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the training data and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit classifier to a model\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85287,     4],\n",
       "       [   45,   107]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85291\n",
      "          1       0.96      0.70      0.81       152\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999427\n",
      "Area under the curve : 0.851950\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run with Over Sampling data using SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.127897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.221892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   -0.349671  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.349231  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   -0.127897  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   -0.053373  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.221892  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data2['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data2 = data2.drop(['Time','Amount'],axis=1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284807, 30)\n",
      "Shape of y: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data.ix[:, data.columns != 'Class'])\n",
    "y = np.array(data.ix[:, data.columns == 'Class'])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 30)\n",
      "xtest shape\n",
      "(85443, 30)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over Sampling data using SMOTE\n",
    "smote = SMOTE(random_state=2)\n",
    "X_train_resample, y_train_resample = smote.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_resample, y_train_resample.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85274,    17],\n",
       "       [   26,   126]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confision Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85291\n",
      "          1       0.88      0.83      0.85       152\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999497\n",
      "Area under the curve : 0.914374\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run with Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"creditcard.csv\")\n",
    "#data.drop(['Time'], axis = 1, inplace = True)\n",
    "#data.drop(['Class'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data3['normAmount'] = StandardScaler().fit_transform(data3['Amount'].values.reshape(-1, 1))\n",
    "data3 = data3.drop(['Time','Amount'],axis=1)\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284807, 29)\n",
      "Shape of y: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data3.ix[:, data3.columns != 'Class'])\n",
    "y = np.array(data3.ix[:, data3.columns == 'Class'])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "X = Variable(torch.FloatTensor(X))\n",
    "y = Variable(torch.FloatTensor(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator's paragrams\n",
    "g_input_size = 29     # Random noise dimension\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1   \n",
    "g_learning_rate = 0.0002\n",
    "g_steps = 1\n",
    "\n",
    "#Discriminator's paragrams\n",
    "d_input_size = 29   # Minibatch size\n",
    "d_hidden_size = 50  # Discriminator complexity\n",
    "d_output_size = 1   # Single dimension for 'real' vs. 'fake'\n",
    "d_learning_rate = 0.0002\n",
    "d_steps = 1 \n",
    "\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "num_epochs = 2000\n",
    "print_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ELU (Exponential Linear Unit) function tends to converge cost to zero faster and produce more accurate results\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.map2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.map3(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "discriminator = Discriminator(input_size=d_input_size, hidden_size=d_hidden_size, output_size=d_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(disc):\n",
    "    h=0.1\n",
    "    x_min, x_max = data[:, 0].min() - .5, data[:, 0].max() + .5\n",
    "    y_min, y_max = data[:, 1].min() - .5, data[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    x_test = np.c_[xx.ravel(), yy.ravel()]\n",
    "    y_hat_test = disc.forward_with_sigmoid(Variable(torch.from_numpy(x_test).float()))\n",
    "\n",
    "    plt.pcolormesh(xx, yy, y_hat_test.data.numpy().reshape(xx.shape), cmap=plt.cm.Paired)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=y*20, alpha=0.1, cmap=plt.cm.flag, s=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Binary Cross Entropy loss\n",
    "BCE_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizers\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=d_learning_rate/2, betas=(beta_1, beta_2))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=g_learning_rate, betas=(beta_1, beta_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Discriminator: Real Loss 0.7146553993225098 / Fake Loss 0.7263058423995972 Generator: 0.6550813317298889 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.12243700669757251, 0.040750250465088109]) \n",
      "10: Discriminator: Real Loss 0.6888497471809387 / Fake Loss 0.7304084897041321 Generator: 0.6586706042289734 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.18390269166436687, 0.030512922292892389]) \n",
      "20: Discriminator: Real Loss 0.6655375957489014 / Fake Loss 0.7197965979576111 Generator: 0.6639719009399414 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.23001699714825072, 0.026241669274155541]) \n",
      "30: Discriminator: Real Loss 0.6435287594795227 / Fake Loss 0.7123153805732727 Generator: 0.6772176027297974 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.23986404106534762, 0.037057275082252858]) \n",
      "40: Discriminator: Real Loss 0.6217685341835022 / Fake Loss 0.7084786891937256 Generator: 0.6822635531425476 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.21521675946383639, 0.030584292913189762]) \n",
      "50: Discriminator: Real Loss 0.5989669561386108 / Fake Loss 0.6996573805809021 Generator: 0.694412350654602 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.16269288648819102, 0.030636476433036318]) \n",
      "60: Discriminator: Real Loss 0.5741133689880371 / Fake Loss 0.692550003528595 Generator: 0.695014476776123 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.10051128871995828, 0.034037408670505559]) \n",
      "70: Discriminator: Real Loss 0.547860324382782 / Fake Loss 0.6948951482772827 Generator: 0.701422929763794 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.041830240524020686, 0.030321721711316113]) \n",
      "80: Discriminator: Real Loss 0.52142733335495 / Fake Loss 0.6770505309104919 Generator: 0.703337550163269 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.0014750384565057426, 0.040716672240060182]) \n",
      "90: Discriminator: Real Loss 0.4955257773399353 / Fake Loss 0.6731557250022888 Generator: 0.7086358666419983 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.021804507436423468, 0.029283845929337766]) \n",
      "100: Discriminator: Real Loss 0.47112396359443665 / Fake Loss 0.6737558841705322 Generator: 0.7197964787483215 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.076268263675015546, 0.040604332773636155]) \n",
      "110: Discriminator: Real Loss 0.4481198787689209 / Fake Loss 0.6639531254768372 Generator: 0.7305680513381958 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.12254570527323361, 0.032909797661335526]) \n",
      "120: Discriminator: Real Loss 0.4258970618247986 / Fake Loss 0.6507490277290344 Generator: 0.7456991672515869 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.13105278950313043, 0.030530739224377094]) \n",
      "130: Discriminator: Real Loss 0.40335479378700256 / Fake Loss 0.6291705965995789 Generator: 0.7516589164733887 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.088427081961056281, 0.026631933283575458]) \n",
      "140: Discriminator: Real Loss 0.3792044222354889 / Fake Loss 0.6251091361045837 Generator: 0.7657902240753174 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.016999217456784742, 0.035349076207014204]) \n",
      "150: Discriminator: Real Loss 0.3535851538181305 / Fake Loss 0.6235344409942627 Generator: 0.7806599140167236 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.031798079866787482, 0.039938056577687141]) \n",
      "160: Discriminator: Real Loss 0.3284440040588379 / Fake Loss 0.6069234609603882 Generator: 0.7751858830451965 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.036878276230960058, 0.030981659319664276]) \n",
      "170: Discriminator: Real Loss 0.30506598949432373 / Fake Loss 0.5876773595809937 Generator: 0.806402325630188 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.039188169199844886, 0.036086629592385414]) \n",
      "180: Discriminator: Real Loss 0.28472015261650085 / Fake Loss 0.5648084282875061 Generator: 0.8117074966430664 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.13311890930194278, 0.045777531612158313]) \n",
      "190: Discriminator: Real Loss 0.26644477248191833 / Fake Loss 0.5637032389640808 Generator: 0.8267963528633118 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.14541636047692136, 0.039631570950934301]) \n",
      "200: Discriminator: Real Loss 0.2478594183921814 / Fake Loss 0.5583885312080383 Generator: 0.8669290542602539 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.078793135054152585, 0.025573112999378853]) \n",
      "210: Discriminator: Real Loss 0.22912190854549408 / Fake Loss 0.5470197796821594 Generator: 0.8777605891227722 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.035969768361798646, 0.037791579770686104]) \n",
      "220: Discriminator: Real Loss 0.20946070551872253 / Fake Loss 0.5098769068717957 Generator: 0.8761888742446899 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.13035264225869342, 0.039788602238040108]) \n",
      "230: Discriminator: Real Loss 0.19108952581882477 / Fake Loss 0.4858318567276001 Generator: 0.9129267930984497 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.089717513528363463, 0.045741622453375368]) \n",
      "240: Discriminator: Real Loss 0.1749611496925354 / Fake Loss 0.48972171545028687 Generator: 0.9425039887428284 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.035706947846659301, 0.041497518204689984]) \n",
      "250: Discriminator: Real Loss 0.16209754347801208 / Fake Loss 0.5150216221809387 Generator: 0.9643080830574036 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.17558948335976438, 0.033940543007667981]) \n",
      "260: Discriminator: Real Loss 0.15187864005565643 / Fake Loss 0.48693639039993286 Generator: 0.9854220151901245 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.2559379606411375, 0.03713290307565268]) \n",
      "270: Discriminator: Real Loss 0.1419118046760559 / Fake Loss 0.42526742815971375 Generator: 1.062864065170288 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.19174321509640793, 0.0416842351875523]) \n",
      "280: Discriminator: Real Loss 0.131429523229599 / Fake Loss 0.4442078173160553 Generator: 1.0450382232666016 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.04986285829338534, 0.041912318203370234]) \n",
      "290: Discriminator: Real Loss 0.12058267742395401 / Fake Loss 0.42370134592056274 Generator: 1.0232958793640137 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.13015968917772688, 0.053017823791490427]) \n",
      "300: Discriminator: Real Loss 0.10927867144346237 / Fake Loss 0.4670620262622833 Generator: 1.0470054149627686 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.2457712827057674, 0.041059345858706173]) \n",
      "310: Discriminator: Real Loss 0.09902080148458481 / Fake Loss 0.398328572511673 Generator: 1.1271460056304932 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.25755799381897365, 0.050920107691923081]) \n",
      "320: Discriminator: Real Loss 0.08991768956184387 / Fake Loss 0.36839425563812256 Generator: 1.245713233947754 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.17894340332212119, 0.059354569111378729]) \n",
      "330: Discriminator: Real Loss 0.0822351798415184 / Fake Loss 0.3834886848926544 Generator: 1.1910851001739502 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.033513387472465121, 0.059371490459815504]) \n",
      "340: Discriminator: Real Loss 0.07634995877742767 / Fake Loss 0.39569562673568726 Generator: 1.0769020318984985 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.11288506088071856, 0.052585237986520483]) \n",
      "350: Discriminator: Real Loss 0.07224816828966141 / Fake Loss 0.3995959460735321 Generator: 1.0736284255981445 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.27789657896962661, 0.06036579772964934]) \n",
      "360: Discriminator: Real Loss 0.06881668418645859 / Fake Loss 0.37441378831863403 Generator: 1.16444993019104 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.34110950601511986, 0.068217130704156567]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370: Discriminator: Real Loss 0.06519893556833267 / Fake Loss 0.2733074128627777 Generator: 1.3107383251190186 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.31445636882864197, 0.057748057041549922]) \n",
      "380: Discriminator: Real Loss 0.061326052993535995 / Fake Loss 0.2544025778770447 Generator: 1.3364758491516113 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.26283326847799893, 0.057419521438375032]) \n",
      "390: Discriminator: Real Loss 0.05728227272629738 / Fake Loss 0.27676087617874146 Generator: 1.5549992322921753 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.090360234266725084, 0.044396219337699744]) \n",
      "400: Discriminator: Real Loss 0.053298093378543854 / Fake Loss 0.29470133781433105 Generator: 1.2872024774551392 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.053964807427135005, 0.057760846595318271]) \n",
      "410: Discriminator: Real Loss 0.04939259588718414 / Fake Loss 0.31965601444244385 Generator: 1.2582811117172241 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.21543237220110564, 0.070275978628534658]) \n",
      "420: Discriminator: Real Loss 0.04533138871192932 / Fake Loss 0.3333859443664551 Generator: 1.3391139507293701 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.28126110393425513, 0.055150101412354303]) \n",
      "430: Discriminator: Real Loss 0.04148894175887108 / Fake Loss 0.2805107533931732 Generator: 1.3318814039230347 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.33549095690250397, 0.05991370028267691]) \n",
      "440: Discriminator: Real Loss 0.037901993840932846 / Fake Loss 0.22876623272895813 Generator: 1.625525951385498 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.33677425980567932, 0.054835794521259099]) \n",
      "450: Discriminator: Real Loss 0.0348786897957325 / Fake Loss 0.19104965031147003 Generator: 1.6852045059204102 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.27574927539661015, 0.060809595773255926]) \n",
      "460: Discriminator: Real Loss 0.032276496291160583 / Fake Loss 0.20998628437519073 Generator: 1.6734545230865479 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.17660596607060269, 0.056936501993488049]) \n",
      "470: Discriminator: Real Loss 0.030088961124420166 / Fake Loss 0.20512981712818146 Generator: 1.5738146305084229 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.05075865328825753, 0.074092709205484372]) \n",
      "480: Discriminator: Real Loss 0.028267454355955124 / Fake Loss 0.2511948049068451 Generator: 1.572590947151184 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.11537378178588276, 0.061312441774862565]) \n",
      "490: Discriminator: Real Loss 0.02698553539812565 / Fake Loss 0.23327064514160156 Generator: 1.5659503936767578 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.23632512678360118, 0.0732764768071415]) \n",
      "500: Discriminator: Real Loss 0.025986986234784126 / Fake Loss 0.24752628803253174 Generator: 1.5590242147445679 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.31353783401949653, 0.04289114056351824]) \n",
      "510: Discriminator: Real Loss 0.024960769340395927 / Fake Loss 0.23173761367797852 Generator: 1.7565608024597168 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.3857387211816064, 0.064187527425514715]) \n",
      "520: Discriminator: Real Loss 0.024082744494080544 / Fake Loss 0.18475854396820068 Generator: 1.8908096551895142 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.40710466483543661, 0.059571001232358381]) \n",
      "530: Discriminator: Real Loss 0.023019686341285706 / Fake Loss 0.1693851798772812 Generator: 1.9187982082366943 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.3323702036306776, 0.057094611766965217]) \n",
      "540: Discriminator: Real Loss 0.02205451764166355 / Fake Loss 0.13131257891654968 Generator: 2.0541727542877197 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.24463723856827307, 0.057467166284860212]) \n",
      "550: Discriminator: Real Loss 0.020935971289873123 / Fake Loss 0.1306193321943283 Generator: 1.9987819194793701 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.13243206121541304, 0.043776257340749664]) \n",
      "560: Discriminator: Real Loss 0.01981521025300026 / Fake Loss 0.14249283075332642 Generator: 1.8048200607299805 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.023202055230222899, 0.051373422600215234]) \n",
      "570: Discriminator: Real Loss 0.018647244200110435 / Fake Loss 0.1828536093235016 Generator: 1.828446865081787 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.10596435465689363, 0.047010458964428348]) \n",
      "580: Discriminator: Real Loss 0.017467841506004333 / Fake Loss 0.2069730907678604 Generator: 1.692625641822815 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.2473601822195382, 0.053128742370460759]) \n",
      "590: Discriminator: Real Loss 0.016294976696372032 / Fake Loss 0.17836789786815643 Generator: 1.7444980144500732 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.31418034023252028, 0.077474927397719745]) \n",
      "600: Discriminator: Real Loss 0.01513238251209259 / Fake Loss 0.15926159918308258 Generator: 1.8511558771133423 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.38555799938481428, 0.083639472331096337]) \n",
      "610: Discriminator: Real Loss 0.014076677151024342 / Fake Loss 0.12612779438495636 Generator: 1.9807857275009155 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.38274198616373128, 0.081159612323238747]) \n",
      "620: Discriminator: Real Loss 0.013157479465007782 / Fake Loss 0.10511085391044617 Generator: 2.173964023590088 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.34845481453270749, 0.067122288931458884]) \n",
      "630: Discriminator: Real Loss 0.012344724498689175 / Fake Loss 0.09802509099245071 Generator: 2.3954577445983887 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.30143599674619476, 0.069869219215372577]) \n",
      "640: Discriminator: Real Loss 0.011633992195129395 / Fake Loss 0.08987937122583389 Generator: 2.206068754196167 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.25429840591447106, 0.081954946702285494]) \n",
      "650: Discriminator: Real Loss 0.01100963819772005 / Fake Loss 0.09609457850456238 Generator: 2.2146477699279785 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.11673436416634198, 0.074044571638210516]) \n",
      "660: Discriminator: Real Loss 0.010471982881426811 / Fake Loss 0.11812392622232437 Generator: 2.183098793029785 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.013515058519511387, 0.058460505532555107]) \n",
      "670: Discriminator: Real Loss 0.010051951743662357 / Fake Loss 0.11563671380281448 Generator: 2.2418415546417236 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.10310480242659306, 0.080177427777771176]) \n",
      "680: Discriminator: Real Loss 0.009671878069639206 / Fake Loss 0.1769726723432541 Generator: 2.0670526027679443 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.23937366440378385, 0.064267426716670004]) \n",
      "690: Discriminator: Real Loss 0.009447959251701832 / Fake Loss 0.12218426913022995 Generator: 1.9476064443588257 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.2975982892616042, 0.065346678658419491]) \n",
      "700: Discriminator: Real Loss 0.009218735620379448 / Fake Loss 0.10213020443916321 Generator: 2.63265323638916 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.36259487476842156, 0.061337054962309762]) \n",
      "710: Discriminator: Real Loss 0.009007547982037067 / Fake Loss 0.08040282130241394 Generator: 2.015336751937866 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.37553809069353961, 0.081985753372922382]) \n",
      "720: Discriminator: Real Loss 0.008781732991337776 / Fake Loss 0.10968127101659775 Generator: 2.562758684158325 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.35620302321582004, 0.091366465696051571]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730: Discriminator: Real Loss 0.008537814021110535 / Fake Loss 0.0806964859366417 Generator: 2.6558971405029297 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.3128200985234359, 0.074114109994879745]) \n",
      "740: Discriminator: Real Loss 0.008258013986051083 / Fake Loss 0.07927320152521133 Generator: 2.6270949840545654 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.28350005941144352, 0.082445532367532104]) \n",
      "750: Discriminator: Real Loss 0.007965495809912682 / Fake Loss 0.06457023322582245 Generator: 2.6787774562835693 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.18609104735841012, 0.06948457029027022]) \n",
      "760: Discriminator: Real Loss 0.007681231014430523 / Fake Loss 0.058009132742881775 Generator: 2.511039972305298 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.097156465567391492, 0.065867805249533701]) \n",
      "770: Discriminator: Real Loss 0.007378853391855955 / Fake Loss 0.07794021815061569 Generator: 2.771585464477539 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.00052709081049623157, 0.061772769316884114]) \n",
      "780: Discriminator: Real Loss 0.007067082449793816 / Fake Loss 0.09653159976005554 Generator: 2.4133212566375732 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.10454977586351592, 0.056265737929643692]) \n",
      "790: Discriminator: Real Loss 0.006742807570844889 / Fake Loss 0.0823216661810875 Generator: 2.3700313568115234 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.20561279536321245, 0.079115844891416084]) \n",
      "800: Discriminator: Real Loss 0.006410059053450823 / Fake Loss 0.08855713158845901 Generator: 2.6185967922210693 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.26616077150764139, 0.073773444247104678]) \n",
      "810: Discriminator: Real Loss 0.006071244366466999 / Fake Loss 0.071446493268013 Generator: 2.7855849266052246 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.29736917440233557, 0.061825168927332752]) \n",
      "820: Discriminator: Real Loss 0.0057543059810996056 / Fake Loss 0.08026483654975891 Generator: 2.769646406173706 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.36837820092151907, 0.088479546415124261]) \n",
      "830: Discriminator: Real Loss 0.005466174334287643 / Fake Loss 0.07587432116270065 Generator: 2.7607531547546387 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.32666828714568041, 0.090242094317798824]) \n",
      "840: Discriminator: Real Loss 0.005218209233134985 / Fake Loss 0.05315426364541054 Generator: 2.7949347496032715 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.32705062730558987, 0.063652412226609126]) \n",
      "850: Discriminator: Real Loss 0.004978751763701439 / Fake Loss 0.049112677574157715 Generator: 2.9953629970550537 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.30562384375210466, 0.099341520390288401]) \n",
      "860: Discriminator: Real Loss 0.004770074505358934 / Fake Loss 0.05551755055785179 Generator: 3.376436948776245 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.2407893923849895, 0.068630261205010798]) \n",
      "870: Discriminator: Real Loss 0.0045770686119794846 / Fake Loss 0.05262346193194389 Generator: 2.891392946243286 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.16776641535347905, 0.086770802071385697]) \n",
      "880: Discriminator: Real Loss 0.004408047068864107 / Fake Loss 0.05422106012701988 Generator: 2.8893139362335205 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.063494579160007933, 0.093547894333257636]) \n",
      "890: Discriminator: Real Loss 0.00425731111317873 / Fake Loss 0.06210176646709442 Generator: 2.9052577018737793 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.00031765922904014587, 0.091495438014225716]) \n",
      "900: Discriminator: Real Loss 0.004124014172703028 / Fake Loss 0.05004018172621727 Generator: 2.989269971847534 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.11417066344413264, 0.096439101762447063]) \n",
      "910: Discriminator: Real Loss 0.00400695251300931 / Fake Loss 0.0756831243634224 Generator: 2.420952558517456 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.18067637612593584, 0.08749942493440728]) \n",
      "920: Discriminator: Real Loss 0.003922755364328623 / Fake Loss 0.09481299668550491 Generator: 2.2948732376098633 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.25798547447755421, 0.10574400299895187]) \n",
      "930: Discriminator: Real Loss 0.0038677649572491646 / Fake Loss 0.053869910538196564 Generator: 3.3181209564208984 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.30513297740755407, 0.0808766852708485]) \n",
      "940: Discriminator: Real Loss 0.0037987767718732357 / Fake Loss 0.02487022802233696 Generator: 3.0346579551696777 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.35918514533289547, 0.10809137993203383]) \n",
      "950: Discriminator: Real Loss 0.0037481607869267464 / Fake Loss 0.04792936518788338 Generator: 3.17124342918396 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.3439405180256942, 0.10255103621926405]) \n",
      "960: Discriminator: Real Loss 0.0036848641466349363 / Fake Loss 0.04004748538136482 Generator: 3.140850782394409 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.35745357233902503, 0.095306935666590695]) \n",
      "970: Discriminator: Real Loss 0.0036081718280911446 / Fake Loss 0.03087763860821724 Generator: 3.3615291118621826 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.3099439359944442, 0.082627881548790541]) \n",
      "980: Discriminator: Real Loss 0.003531545400619507 / Fake Loss 0.03148481994867325 Generator: 3.3767688274383545 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.26374866607887992, 0.09610407066510307]) \n",
      "990: Discriminator: Real Loss 0.0034538479521870613 / Fake Loss 0.03414774686098099 Generator: 3.240962028503418 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.2180590340546493, 0.1005737504376104]) \n",
      "1000: Discriminator: Real Loss 0.003370534861460328 / Fake Loss 0.03625793382525444 Generator: 3.6507768630981445 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.15264192281355118, 0.088980256198348331]) \n",
      "1010: Discriminator: Real Loss 0.0032981724943965673 / Fake Loss 0.03693816438317299 Generator: 2.9100894927978516 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.060534881363654959, 0.082545554571290272]) \n",
      "1020: Discriminator: Real Loss 0.0032101483084261417 / Fake Loss 0.028636975213885307 Generator: 3.3260982036590576 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.015069735975101077, 0.096738550105238769]) \n",
      "1030: Discriminator: Real Loss 0.0031199795193970203 / Fake Loss 0.03856253996491432 Generator: 2.963496446609497 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.077678686329003044, 0.067600757724669266]) \n",
      "1040: Discriminator: Real Loss 0.0030149922240525484 / Fake Loss 0.04941263422369957 Generator: 2.7393810749053955 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.14789111013042516, 0.1019067154258859]) \n",
      "1050: Discriminator: Real Loss 0.002909119240939617 / Fake Loss 0.028306080028414726 Generator: 3.054298162460327 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.22645317249256988, 0.080111746177972953]) \n",
      "1060: Discriminator: Real Loss 0.0027979977894574404 / Fake Loss 0.035785265266895294 Generator: 3.008024215698242 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.29932323612015821, 0.079154509042062851]) \n",
      "1070: Discriminator: Real Loss 0.0026923867408186197 / Fake Loss 0.032881785184144974 Generator: 2.8042430877685547 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.35123150898464794, 0.10145852103269858]) \n",
      "1080: Discriminator: Real Loss 0.002588161500170827 / Fake Loss 0.033653415739536285 Generator: 3.1953139305114746 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.36081508367226039, 0.094775951651840815]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090: Discriminator: Real Loss 0.002491953782737255 / Fake Loss 0.04254743829369545 Generator: 3.1544947624206543 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.33939043021407622, 0.10271701251204628]) \n",
      "1100: Discriminator: Real Loss 0.0024059724528342485 / Fake Loss 0.01830277219414711 Generator: 3.4808242321014404 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.3545136009824687, 0.10916457909368471]) \n",
      "1110: Discriminator: Real Loss 0.0023268689401447773 / Fake Loss 0.0318559892475605 Generator: 3.367393732070923 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.32043149604879578, 0.106934876920594]) \n",
      "1120: Discriminator: Real Loss 0.002252311911433935 / Fake Loss 0.020933208987116814 Generator: 3.813209295272827 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.33445675902325533, 0.12297978145031713]) \n",
      "1130: Discriminator: Real Loss 0.0021842713467776775 / Fake Loss 0.026848986744880676 Generator: 3.7905962467193604 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.23252130017198366, 0.087612157641364485]) \n",
      "1140: Discriminator: Real Loss 0.0021223879884928465 / Fake Loss 0.03132183849811554 Generator: 3.8488969802856445 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.15947756916284561, 0.10577920414425143]) \n",
      "1150: Discriminator: Real Loss 0.002067078137770295 / Fake Loss 0.013133588247001171 Generator: 3.7402305603027344 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.095431500467760805, 0.11570512050156527]) \n",
      "1160: Discriminator: Real Loss 0.002015594160184264 / Fake Loss 0.018813498318195343 Generator: 3.556246519088745 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.021985532394770919, 0.10516932592832394]) \n",
      "1170: Discriminator: Real Loss 0.0019678750541061163 / Fake Loss 0.03822942450642586 Generator: 3.231022834777832 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.075889404991577411, 0.1401815856733416]) \n",
      "1180: Discriminator: Real Loss 0.0019322813022881746 / Fake Loss 0.036367110908031464 Generator: 3.6325676441192627 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.15527195945895952, 0.12003906694705167]) \n",
      "1190: Discriminator: Real Loss 0.001898301183246076 / Fake Loss 0.02944597601890564 Generator: 3.627803087234497 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.25117074800976391, 0.074172271159149858]) \n",
      "1200: Discriminator: Real Loss 0.0018706521950662136 / Fake Loss 0.027911080047488213 Generator: 3.817150115966797 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.30047748109389993, 0.11322923758900746]) \n",
      "1210: Discriminator: Real Loss 0.0018470048671588302 / Fake Loss 0.027188235893845558 Generator: 3.362865447998047 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.3471392547262126, 0.10598994636894414]) \n",
      "1220: Discriminator: Real Loss 0.0018302251119166613 / Fake Loss 0.02091372199356556 Generator: 3.531761407852173 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.31899257775010736, 0.074472137085707643]) \n",
      "1230: Discriminator: Real Loss 0.0018073549726977944 / Fake Loss 0.038990769535303116 Generator: 3.4676220417022705 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.3671387855348916, 0.10704301801296744]) \n",
      "1240: Discriminator: Real Loss 0.0017877097707241774 / Fake Loss 0.04698512703180313 Generator: 3.7185895442962646 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.33740543831011344, 0.1328086065712217]) \n",
      "1250: Discriminator: Real Loss 0.0017668110085651278 / Fake Loss 0.020967774093151093 Generator: 4.169588088989258 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.25718241133566561, 0.097326674939191338]) \n",
      "1260: Discriminator: Real Loss 0.0017402403755113482 / Fake Loss 0.045890409499406815 Generator: 3.4019789695739746 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.28250892954910622, 0.12684998058676117]) \n",
      "1270: Discriminator: Real Loss 0.0017198800342157483 / Fake Loss 0.01780857890844345 Generator: 4.055047988891602 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.18889733480996099, 0.11577449989204122]) \n",
      "1280: Discriminator: Real Loss 0.0016920568887144327 / Fake Loss 0.03145957738161087 Generator: 3.8928372859954834 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.19422541141253094, 0.1218200899173676]) \n",
      "1290: Discriminator: Real Loss 0.00166029401589185 / Fake Loss 0.014855430461466312 Generator: 4.2398576736450195 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.091448021346125105, 0.13051454746213104]) \n",
      "1300: Discriminator: Real Loss 0.001625188859179616 / Fake Loss 0.039767298847436905 Generator: 3.747305154800415 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.071219519551458027, 0.13390217589715853]) \n",
      "1310: Discriminator: Real Loss 0.001594323548488319 / Fake Loss 0.018551258370280266 Generator: 3.0219533443450928 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.038139222510929764, 0.12809749702550166]) \n",
      "1320: Discriminator: Real Loss 0.0015569522511214018 / Fake Loss 0.02486695908010006 Generator: 3.5193896293640137 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.026149977640859013, 0.13107267377065812]) \n",
      "1330: Discriminator: Real Loss 0.0015186271630227566 / Fake Loss 0.021964987739920616 Generator: 3.8225417137145996 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.14881054902898855, 0.1463578595401912]) \n",
      "1340: Discriminator: Real Loss 0.0014774383744224906 / Fake Loss 0.030914783477783203 Generator: 3.189716100692749 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.23833687012565546, 0.12987274166704055]) \n",
      "1350: Discriminator: Real Loss 0.00143935508094728 / Fake Loss 0.012095438316464424 Generator: 4.058919906616211 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.25392453513782598, 0.15113614927940827]) \n",
      "1360: Discriminator: Real Loss 0.001399005064740777 / Fake Loss 0.014689337462186813 Generator: 4.377086639404297 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.23649614432762409, 0.11808643201602763]) \n",
      "1370: Discriminator: Real Loss 0.0013568662106990814 / Fake Loss 0.037763096392154694 Generator: 3.534959554672241 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.31459829853526478, 0.13958210651806527]) \n",
      "1380: Discriminator: Real Loss 0.0013208168093115091 / Fake Loss 0.017745323479175568 Generator: 3.1416401863098145 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.30265697400117741, 0.15225255581462074]) \n",
      "1390: Discriminator: Real Loss 0.0012848282931372523 / Fake Loss 0.03765815496444702 Generator: 3.647341012954712 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.30455092726082639, 0.13697650863599073]) \n",
      "1400: Discriminator: Real Loss 0.0012548686936497688 / Fake Loss 0.01846877485513687 Generator: 3.401869535446167 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.28347822998104422, 0.12984726564710908]) \n",
      "1410: Discriminator: Real Loss 0.0012281923554837704 / Fake Loss 0.020170029252767563 Generator: 4.9114203453063965 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.32228888648337334, 0.16077954737023539]) \n",
      "1420: Discriminator: Real Loss 0.0011991296196356416 / Fake Loss 0.013996879570186138 Generator: 3.8745079040527344 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.21312793048805204, 0.16248752852617207]) \n",
      "1430: Discriminator: Real Loss 0.0011744836810976267 / Fake Loss 0.019785869866609573 Generator: 4.0254340171813965 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.13662657706901946, 0.1617152819991102]) \n",
      "1440: Discriminator: Real Loss 0.0011534187942743301 / Fake Loss 0.0040004439651966095 Generator: 4.213296413421631 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.14410596315203042, 0.14804600108486093]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450: Discriminator: Real Loss 0.0011322945356369019 / Fake Loss 0.011697896756231785 Generator: 3.585561513900757 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.030251227190782284, 0.13382754665050134]) \n",
      "1460: Discriminator: Real Loss 0.0011138560948893428 / Fake Loss 0.015780555084347725 Generator: 4.37075138092041 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.023289885757298304, 0.14888761696741507]) \n",
      "1470: Discriminator: Real Loss 0.0010988786816596985 / Fake Loss 0.012399665080010891 Generator: 3.9528937339782715 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.17914857728214101, 0.17898358410469983]) \n",
      "1480: Discriminator: Real Loss 0.0010952985612675548 / Fake Loss 0.004264805931597948 Generator: 4.474221706390381 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.21093847512685018, 0.18895072278633748]) \n",
      "1490: Discriminator: Real Loss 0.0010869447141885757 / Fake Loss 0.03178231790661812 Generator: 4.089064598083496 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.21974218623905345, 0.12921998664421611]) \n",
      "1500: Discriminator: Real Loss 0.0010735192336142063 / Fake Loss 0.0061281174421310425 Generator: 3.7529404163360596 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.27642964777247658, 0.12890506252784845]) \n",
      "1510: Discriminator: Real Loss 0.0010626595467329025 / Fake Loss 0.016737332567572594 Generator: 3.7143218517303467 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.32440278345140916, 0.13012650459438582]) \n",
      "1520: Discriminator: Real Loss 0.0010539480717852712 / Fake Loss 0.005138278007507324 Generator: 4.59094762802124 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.34474291434061938, 0.14881976537420741]) \n",
      "1530: Discriminator: Real Loss 0.0010437449673190713 / Fake Loss 0.01274073775857687 Generator: 4.952510356903076 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.33219878947169618, 0.18040914515420836]) \n",
      "1540: Discriminator: Real Loss 0.0010344369802623987 / Fake Loss 0.01571902260184288 Generator: 4.288227081298828 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.33490526001771975, 0.15911890027097073]) \n",
      "1550: Discriminator: Real Loss 0.0010232197819277644 / Fake Loss 0.007215518970042467 Generator: 3.737187385559082 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.32437447542003517, 0.14425149008946653]) \n",
      "1560: Discriminator: Real Loss 0.0010108690476045012 / Fake Loss 0.01655818521976471 Generator: 4.861384391784668 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.27092965717973383, 0.15692471691047752]) \n",
      "1570: Discriminator: Real Loss 0.0010059765772894025 / Fake Loss 0.020653804764151573 Generator: 3.919212579727173 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.21630884315176258, 0.16321278573511622]) \n",
      "1580: Discriminator: Real Loss 0.0009939244482666254 / Fake Loss 0.016152070835232735 Generator: 4.323790550231934 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.20666000992059708, 0.15288505507093691]) \n",
      "1590: Discriminator: Real Loss 0.0009862277656793594 / Fake Loss 0.008305279538035393 Generator: 4.8488593101501465 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.17602277637041849, 0.15856263122194617]) \n",
      "1600: Discriminator: Real Loss 0.0009741758112795651 / Fake Loss 0.009500371292233467 Generator: 4.763444900512695 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.12192188897009554, 0.153491497342649]) \n",
      "1610: Discriminator: Real Loss 0.0009608711116015911 / Fake Loss 0.03747306764125824 Generator: 4.925217628479004 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.01710673241779722, 0.16178515326525733]) \n",
      "1620: Discriminator: Real Loss 0.0009519218583591282 / Fake Loss 0.013718841597437859 Generator: 4.514929294586182 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.00087630723057122064, 0.14148922760959198]) \n",
      "1630: Discriminator: Real Loss 0.0009358134120702744 / Fake Loss 0.03882918506860733 Generator: 3.767759084701538 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.027082980449857384, 0.15658564635744407]) \n",
      "1640: Discriminator: Real Loss 0.0009215546888299286 / Fake Loss 0.007788822986185551 Generator: 4.1604905128479 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.11187935427858911, 0.16580064566057459]) \n",
      "1650: Discriminator: Real Loss 0.0009075944544747472 / Fake Loss 0.013369078747928143 Generator: 3.9136626720428467 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.15666048074590749, 0.16980243202025694]) \n",
      "1660: Discriminator: Real Loss 0.0008861771784722805 / Fake Loss 0.013284919783473015 Generator: 4.924890518188477 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.22614555626079955, 0.14577271438513087]) \n",
      "1670: Discriminator: Real Loss 0.0008685187203809619 / Fake Loss 0.011234085075557232 Generator: 4.561441898345947 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.28404326608468744, 0.16667663710636879]) \n",
      "1680: Discriminator: Real Loss 0.0008492498891428113 / Fake Loss 0.024748116731643677 Generator: 5.05330753326416 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.31387860674796431, 0.1534319835366994]) \n",
      "1690: Discriminator: Real Loss 0.0008289672550745308 / Fake Loss 0.009646298363804817 Generator: 4.928276062011719 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.28355846733882512, 0.18375273494260944]) \n",
      "1700: Discriminator: Real Loss 0.0008101764251478016 / Fake Loss 0.005180304870009422 Generator: 4.457651615142822 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.32252583961034642, 0.15802575426014459]) \n",
      "1710: Discriminator: Real Loss 0.0007927578990347683 / Fake Loss 0.011178163811564445 Generator: 4.624029159545898 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.32934151846787024, 0.18341565792537101]) \n",
      "1720: Discriminator: Real Loss 0.000776353757828474 / Fake Loss 0.008994040079414845 Generator: 5.450334072113037 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.27022275829623488, 0.16289503391046803]) \n",
      "1730: Discriminator: Real Loss 0.0007610832108184695 / Fake Loss 0.003269211621955037 Generator: 5.371905326843262 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.23570261356131783, 0.16818241466401776]) \n",
      "1740: Discriminator: Real Loss 0.0007477813633158803 / Fake Loss 0.005351936910301447 Generator: 4.667104721069336 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.27723504204688398, 0.14071842163452944]) \n",
      "1750: Discriminator: Real Loss 0.0007346586207859218 / Fake Loss 0.014212912879884243 Generator: 4.6290059089660645 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.17175189020304843, 0.14820693204848295]) \n",
      "1760: Discriminator: Real Loss 0.0007215360528789461 / Fake Loss 0.007175233215093613 Generator: 5.636028289794922 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.14560730845249933, 0.18789395315492555]) \n",
      "1770: Discriminator: Real Loss 0.0007103820098564029 / Fake Loss 0.022908411920070648 Generator: 4.37338924407959 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.07544220739911342, 0.14668320814616734]) \n",
      "1780: Discriminator: Real Loss 0.0006997648742981255 / Fake Loss 0.02125297486782074 Generator: 5.644268035888672 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.066457325785324498, 0.18307455616608323]) \n",
      "1790: Discriminator: Real Loss 0.0006910565425641835 / Fake Loss 0.005312087945640087 Generator: 5.987237453460693 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.018452184724396671, 0.16963887872766831]) \n",
      "1800: Discriminator: Real Loss 0.0006840183632448316 / Fake Loss 0.007641944102942944 Generator: 4.687957763671875 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.025815846334243643, 0.15452298880465259]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1810: Discriminator: Real Loss 0.0006785310106351972 / Fake Loss 0.007482318673282862 Generator: 4.5476250648498535 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.090327410348530479, 0.17063767746509845]) \n",
      "1820: Discriminator: Real Loss 0.0006708964356221259 / Fake Loss 0.019936785101890564 Generator: 4.245009422302246 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.16468341365970415, 0.184225388978903]) \n",
      "1830: Discriminator: Real Loss 0.0006658266647718847 / Fake Loss 0.012896995060145855 Generator: 4.572345733642578 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.20950404060041083, 0.13888944554201338]) \n",
      "1840: Discriminator: Real Loss 0.0006647530826739967 / Fake Loss 0.008260934613645077 Generator: 5.349987983703613 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.23056189715862274, 0.14274773957232181]) \n",
      "1850: Discriminator: Real Loss 0.0006627251859754324 / Fake Loss 0.007595316972583532 Generator: 5.493620872497559 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.28197542218298749, 0.2378118845491094]) \n",
      "1860: Discriminator: Real Loss 0.0006581922061741352 / Fake Loss 0.00393911637365818 Generator: 5.343451023101807 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.2651735320687294, 0.12169126652448407]) \n",
      "1870: Discriminator: Real Loss 0.0006552100530825555 / Fake Loss 0.007293623872101307 Generator: 4.734403610229492 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.26586450302395326, 0.1541737489920823]) \n",
      "1880: Discriminator: Real Loss 0.0006510349921882153 / Fake Loss 0.013382472097873688 Generator: 5.2873077392578125 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.23697056184554921, 0.15444078377741205]) \n",
      "1890: Discriminator: Real Loss 0.000650438538286835 / Fake Loss 0.011043941602110863 Generator: 4.656779766082764 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.22389727291362038, 0.17042115343601333]) \n",
      "1900: Discriminator: Real Loss 0.0006438777782022953 / Fake Loss 0.02359204739332199 Generator: 5.007011413574219 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.21191113763328256, 0.17534100808978412]) \n",
      "1910: Discriminator: Real Loss 0.0006385099259205163 / Fake Loss 0.015021927654743195 Generator: 5.264379978179932 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.16287767810040507, 0.16027277802620132]) \n",
      "1920: Discriminator: Real Loss 0.0006315914215520024 / Fake Loss 0.005935927387326956 Generator: 4.9188055992126465 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.13178433471455656, 0.18383011074206565]) \n",
      "1930: Discriminator: Real Loss 0.0006247921846807003 / Fake Loss 0.01326882466673851 Generator: 4.865853786468506 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.056879763459337165, 0.17276879194756015]) \n",
      "1940: Discriminator: Real Loss 0.0006192455184645951 / Fake Loss 0.006457934156060219 Generator: 5.605350017547607 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.099645505948313354, 0.19179811408851011]) \n",
      "1950: Discriminator: Real Loss 0.0006102993502281606 / Fake Loss 0.0034185796976089478 Generator: 4.609285354614258 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [0.020482621830085229, 0.16060284906651159]) \n",
      "1960: Discriminator: Real Loss 0.000605050940066576 / Fake Loss 0.003920875024050474 Generator: 5.723480701446533 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.039205852895975113, 0.14816500036688665]) \n",
      "1970: Discriminator: Real Loss 0.0005990868667140603 / Fake Loss 0.009659687988460064 Generator: 6.024266719818115 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.061538688067732189, 0.18475722010020809]) \n",
      "1980: Discriminator: Real Loss 0.0005900216056033969 / Fake Loss 0.012254527769982815 Generator: 4.677770137786865 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.12421422220509627, 0.15407579550431275]) \n",
      "1990: Discriminator: Real Loss 0.0005814334726892412 / Fake Loss 0.001997482031583786 Generator: 5.292201995849609 (Real Data: [-3.6094789557106026e-11, 1.0460391654253318], Fake Data: [-0.18166771505413384, 0.1538483576520909]) \n"
     ]
    }
   ],
   "source": [
    "# Training GANs\n",
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Updating the weights of the Discriminator\n",
    "        discriminator.zero_grad() # Initialize gradients of the Discriminator to 0\n",
    "\n",
    "        # Training the Discriminator with real data\n",
    "        d_real_data = Variable(X[0]) # Wrap it in a variable\n",
    "        d_real_decision = discriminator(d_real_data) # Forward propagate this real data into the neural network\n",
    "        #target = Variable(torch.ones(input.size()[0]))\n",
    "        y_real = Variable(torch.ones(1)) # Get the target\n",
    "        d_real_loss = BCE_loss(d_real_decision, y_real) # Compute the loss between the prediction and actual\n",
    "        d_real_loss.backward() # Compute/store gradients\n",
    "    \n",
    "        # Train the Discriminator with a fake data generated by the Generator\n",
    "        #d_gen_input = Variable(torch.randn(minibatch_size, 29))\n",
    "        d_gen_input = Variable(torch.randn(minibatch_size, g_input_size))\n",
    "        d_fake_data = generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        \n",
    "        d_fake_decision = discriminator(d_fake_data.t())\n",
    "        y_fake = Variable(torch.zeros(1))\n",
    "        d_fake_loss = BCE_loss(d_fake_decision, y_fake)  # zeros = fake\n",
    "        d_fake_loss.backward()\n",
    "        d_optimizer.step()     # Apply SGD to update the weight\n",
    "        \n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Update the weight of the Generator \n",
    "        generator.zero_grad()\n",
    "\n",
    "        gen_input = Variable(torch.randn(minibatch_size, g_input_size))\n",
    "        g_fake_data = generator(gen_input)\n",
    "        dg_fake_decision = discriminator(g_fake_data.t())\n",
    "        target = Variable(torch.ones(1))\n",
    "        g_loss = BCE_loss(dg_fake_decision, target)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "        \n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: Discriminator: Real Loss %s / Fake Loss %s Generator: %s (Real Data: %s, Fake Data: %s) \" % (epoch,\n",
    "                                                            extract(d_real_loss)[0],\n",
    "                                                            extract(d_fake_loss)[0],\n",
    "                                                            extract(g_loss)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0005735611193813384]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract(d_real_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
