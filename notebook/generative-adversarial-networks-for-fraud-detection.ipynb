{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Reshape\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling1D, Conv1D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/kiem/Developer/data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's randomize the data, just to be sure not to get any pathological ordering effects that might harm the performane of Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188452</th>\n",
       "      <td>127982.0</td>\n",
       "      <td>-6.510015</td>\n",
       "      <td>5.959764</td>\n",
       "      <td>-5.007941</td>\n",
       "      <td>-2.492069</td>\n",
       "      <td>-0.776336</td>\n",
       "      <td>-1.358914</td>\n",
       "      <td>-0.043818</td>\n",
       "      <td>1.711290</td>\n",
       "      <td>3.191805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288667</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.120824</td>\n",
       "      <td>-1.154408</td>\n",
       "      <td>1.050129</td>\n",
       "      <td>0.251661</td>\n",
       "      <td>2.277098</td>\n",
       "      <td>1.449942</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274176</th>\n",
       "      <td>165884.0</td>\n",
       "      <td>-2.430772</td>\n",
       "      <td>2.851159</td>\n",
       "      <td>-1.765849</td>\n",
       "      <td>-0.836548</td>\n",
       "      <td>0.978243</td>\n",
       "      <td>0.262514</td>\n",
       "      <td>-0.206307</td>\n",
       "      <td>-4.171045</td>\n",
       "      <td>0.914315</td>\n",
       "      <td>...</td>\n",
       "      <td>3.881873</td>\n",
       "      <td>-0.411144</td>\n",
       "      <td>0.165745</td>\n",
       "      <td>-0.071293</td>\n",
       "      <td>0.019454</td>\n",
       "      <td>-0.094698</td>\n",
       "      <td>1.017410</td>\n",
       "      <td>0.622956</td>\n",
       "      <td>46.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83378</th>\n",
       "      <td>59817.0</td>\n",
       "      <td>1.499571</td>\n",
       "      <td>-0.907472</td>\n",
       "      <td>-0.083925</td>\n",
       "      <td>-1.389335</td>\n",
       "      <td>-1.269404</td>\n",
       "      <td>-1.177310</td>\n",
       "      <td>-0.612628</td>\n",
       "      <td>-0.230784</td>\n",
       "      <td>-2.311811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118564</td>\n",
       "      <td>-0.029584</td>\n",
       "      <td>-0.057346</td>\n",
       "      <td>0.504676</td>\n",
       "      <td>0.587337</td>\n",
       "      <td>-0.109641</td>\n",
       "      <td>-0.013767</td>\n",
       "      <td>-0.003628</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141053</th>\n",
       "      <td>84098.0</td>\n",
       "      <td>1.256235</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.301851</td>\n",
       "      <td>0.693207</td>\n",
       "      <td>-0.376918</td>\n",
       "      <td>-1.072151</td>\n",
       "      <td>0.081165</td>\n",
       "      <td>-0.198737</td>\n",
       "      <td>0.045670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288815</td>\n",
       "      <td>-0.837949</td>\n",
       "      <td>0.129536</td>\n",
       "      <td>0.337504</td>\n",
       "      <td>0.213873</td>\n",
       "      <td>0.095010</td>\n",
       "      <td>-0.023671</td>\n",
       "      <td>0.030620</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30291</th>\n",
       "      <td>35857.0</td>\n",
       "      <td>1.141288</td>\n",
       "      <td>0.125237</td>\n",
       "      <td>0.256195</td>\n",
       "      <td>1.039426</td>\n",
       "      <td>-0.354708</td>\n",
       "      <td>-0.660598</td>\n",
       "      <td>0.070440</td>\n",
       "      <td>-0.022250</td>\n",
       "      <td>-0.089143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083132</td>\n",
       "      <td>0.119035</td>\n",
       "      <td>-0.123593</td>\n",
       "      <td>0.308753</td>\n",
       "      <td>0.603763</td>\n",
       "      <td>-0.344765</td>\n",
       "      <td>-0.004149</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>35.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "188452  127982.0 -6.510015  5.959764 -5.007941 -2.492069 -0.776336 -1.358914   \n",
       "274176  165884.0 -2.430772  2.851159 -1.765849 -0.836548  0.978243  0.262514   \n",
       "83378    59817.0  1.499571 -0.907472 -0.083925 -1.389335 -1.269404 -1.177310   \n",
       "141053   84098.0  1.256235  0.347563  0.301851  0.693207 -0.376918 -1.072151   \n",
       "30291    35857.0  1.141288  0.125237  0.256195  1.039426 -0.354708 -0.660598   \n",
       "\n",
       "              V7        V8        V9  ...         V21       V22       V23  \\\n",
       "188452 -0.043818  1.711290  3.191805  ...   -0.288667  0.277775  0.120824   \n",
       "274176 -0.206307 -4.171045  0.914315  ...    3.881873 -0.411144  0.165745   \n",
       "83378  -0.612628 -0.230784 -2.311811  ...   -0.118564 -0.029584 -0.057346   \n",
       "141053  0.081165 -0.198737  0.045670  ...   -0.288815 -0.837949  0.129536   \n",
       "30291   0.070440 -0.022250 -0.089143  ...    0.083132  0.119035 -0.123593   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "188452 -1.154408  1.050129  0.251661  2.277098  1.449942    7.70      0  \n",
       "274176 -0.071293  0.019454 -0.094698  1.017410  0.622956   46.83      0  \n",
       "83378   0.504676  0.587337 -0.109641 -0.013767 -0.003628   15.00      0  \n",
       "141053  0.337504  0.213873  0.095010 -0.023671  0.030620    1.98      0  \n",
       "30291   0.308753  0.603763 -0.344765 -0.004149  0.012799   35.09      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reindex(np.random.permutation(data.index))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.190191e-15</td>\n",
       "      <td>3.443197e-16</td>\n",
       "      <td>-1.465298e-15</td>\n",
       "      <td>2.102945e-15</td>\n",
       "      <td>9.917299e-16</td>\n",
       "      <td>1.521031e-15</td>\n",
       "      <td>-5.636980e-16</td>\n",
       "      <td>1.191960e-16</td>\n",
       "      <td>-2.414171e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.327125e-16</td>\n",
       "      <td>-3.514530e-16</td>\n",
       "      <td>2.580623e-16</td>\n",
       "      <td>4.473883e-15</td>\n",
       "      <td>5.144878e-16</td>\n",
       "      <td>1.698022e-15</td>\n",
       "      <td>-3.760131e-16</td>\n",
       "      <td>-1.132615e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.190191e-15  3.443197e-16 -1.465298e-15  2.102945e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.917299e-16  1.521031e-15 -5.636980e-16  1.191960e-16 -2.414171e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.327125e-16 -3.514530e-16  2.580623e-16  4.473883e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.144878e-16  1.698022e-15 -3.760131e-16 -1.132615e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
    "classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class')['Class'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Data is hihgly imbalance. 284315 Normal transaction vs 492 Fraud transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Features and Configure Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1:30].values\n",
    "y = data.iloc[:, 30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -6.51001485e+00,   5.95976432e+00,  -5.00794065e+00, ...,\n",
       "          2.27709775e+00,   1.44994235e+00,   7.70000000e+00],\n",
       "       [ -2.43077161e+00,   2.85115892e+00,  -1.76584885e+00, ...,\n",
       "          1.01741022e+00,   6.22955537e-01,   4.68300000e+01],\n",
       "       [  1.49957057e+00,  -9.07471954e-01,  -8.39251188e-02, ...,\n",
       "         -1.37666383e-02,  -3.62779694e-03,   1.50000000e+01],\n",
       "       ..., \n",
       "       [ -4.23809192e+00,   4.15562430e+00,  -2.46927231e-01, ...,\n",
       "         -7.15270848e-01,  -7.46243731e-01,   1.00000000e+00],\n",
       "       [ -5.80684633e-01,  -2.68608440e-01,   1.38598219e+00, ...,\n",
       "         -7.06099979e-02,  -8.97158940e-02,   2.51590000e+02],\n",
       "       [  1.84563648e+00,  -7.07232644e-01,   6.39684664e-01, ...,\n",
       "          1.11341309e-01,  -3.39584941e-02,   3.75000000e+00]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227845, 29)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "227845/227845 [==============================] - 3s 14us/step - loss: 0.0587 - acc: 0.9975: 4s - loss: 0.3016 - acc: 0.9 - ETA: 3s - loss: 0.229 - ETA: 1s\n",
      "Epoch 2/5\n",
      "227845/227845 [==============================] - 3s 12us/step - loss: 0.0081 - acc: 0.9991\n",
      "Epoch 3/5\n",
      "227845/227845 [==============================] - 3s 12us/step - loss: 0.0050 - acc: 0.9993\n",
      "Epoch 4/5\n",
      "227845/227845 [==============================] - 3s 12us/step - loss: 0.0045 - acc: 0.9993\n",
      "Epoch 5/5\n",
      "227845/227845 [==============================] - 3s 12us/step - loss: 0.0045 - acc: 0.9993: 2s - l - ETA: 1s - loss: 0.0046  - ETA: 0s - loss: 0.0046 - ac\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a38b37f28>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the Input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, activation = 'relu', kernel_initializer = 'uniform', input_dim = 29))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, activation = 'relu', kernel_initializer = 'uniform'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer = 'uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the training set\n",
    "classifier.fit(X_train, y_train, batch_size = 100, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Convert to T or F boolean value\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56855,     7],\n",
       "       [   25,    75]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting XGBoost to the Training set\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56859,     3],\n",
       "       [   27,    73]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confision Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999530381052\n",
      "0.000140244166454\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X=X_train, y=y_train, cv=10)\n",
    "print(accuracies.mean())\n",
    "print(accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/kiem/Developer/data/creditcard.csv\")\n",
    "data.drop(['Time'], axis = 1, inplace = True)\n",
    "data.drop(['Class'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.35980713e+00,  -7.27811733e-02,   2.53634674e+00, ...,\n",
       "          1.33558377e-01,  -2.10530535e-02,   1.49620000e+02],\n",
       "       [  1.19185711e+00,   2.66150712e-01,   1.66480113e-01, ...,\n",
       "         -8.98309914e-03,   1.47241692e-02,   2.69000000e+00],\n",
       "       [ -1.35835406e+00,  -1.34016307e+00,   1.77320934e+00, ...,\n",
       "         -5.53527940e-02,  -5.97518406e-02,   3.78660000e+02],\n",
       "       ..., \n",
       "       [  1.91956501e+00,  -3.01253846e-01,  -3.24963981e+00, ...,\n",
       "          4.45477214e-03,  -2.65608286e-02,   6.78800000e+01],\n",
       "       [ -2.40440050e-01,   5.30482513e-01,   7.02510230e-01, ...,\n",
       "          1.08820735e-01,   1.04532821e-01,   1.00000000e+01],\n",
       "       [ -5.33412522e-01,  -1.89733337e-01,   7.03337367e-01, ...,\n",
       "         -2.41530880e-03,   1.36489143e-02,   2.17000000e+02]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data frame to a numpy array\n",
    "data = np.array(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([284807, 29])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert array to PyTorch tensor\n",
    "data = torch.FloatTensor(data)\n",
    "data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator's paragrams\n",
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1    # size of generated output vector\n",
    "g_learning_rate = 2e-4\n",
    "g_steps = 1\n",
    "\n",
    "#Discriminator's paragrams\n",
    "d_input_size = 29   # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "d_learning_rate = 2e-4\n",
    "d_steps = 1 \n",
    "\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 10000\n",
    "print_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Raw data]\n"
     ]
    }
   ],
   "source": [
    "(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_fake_data():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    return torch.cat([data, diffs], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sampler = data[0]\n",
    "gi_sampler = inject_fake_data()\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiem/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Discriminator: Real Error 2.9457552433013916 / Fake Error 0.6996848583221436 Generator: 0.6844757199287415 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.092201176131593773, 0.0074959623264945685]) \n",
      "100: Discriminator: Real Error 0.011755388230085373 / Fake Error 0.5344743728637695 Generator: 0.8903833031654358 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.42884511988738488, 0.021184567218151769]) \n",
      "200: Discriminator: Real Error 0.0028165271505713463 / Fake Error 0.34491613507270813 Generator: 1.2443408966064453 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.65354267687633116, 0.006623754946964747]) \n",
      "300: Discriminator: Real Error 0.002074842806905508 / Fake Error 0.37655624747276306 Generator: 1.194150686264038 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.826221135155908, 0.027328853219180459]) \n",
      "400: Discriminator: Real Error 0.0009996521985158324 / Fake Error 0.599277138710022 Generator: 0.8106622099876404 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.48747326896108428, 0.0074060721997993156]) \n",
      "500: Discriminator: Real Error 0.0003649662248790264 / Fake Error 0.1745392084121704 Generator: 1.8363503217697144 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.13305881311153545, 0.00084103046525086972]) \n",
      "600: Discriminator: Real Error 0.0002667663502506912 / Fake Error 0.07904713600873947 Generator: 2.6014702320098877 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.60918475841653763, 0.018388139232336131]) \n",
      "700: Discriminator: Real Error 0.00013256951933726668 / Fake Error 0.11407467722892761 Generator: 2.2586638927459717 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.67428801594109367, 0.010467557478041904]) \n",
      "800: Discriminator: Real Error 7.140891102608293e-05 / Fake Error 0.09172872453927994 Generator: 2.4348390102386475 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.18703668230566486, 0.0079292595037305045]) \n",
      "900: Discriminator: Real Error 5.519542173715308e-05 / Fake Error 0.031109673902392387 Generator: 3.5062904357910156 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.40451304871460486, 0.013474361865627959]) \n",
      "1000: Discriminator: Real Error 3.6359491787152365e-05 / Fake Error 0.03972051665186882 Generator: 3.26904559135437 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.54172566224788798, 0.017565366838857368]) \n",
      "1100: Discriminator: Real Error 2.4915050744311884e-05 / Fake Error 0.026249323040246964 Generator: 3.6535181999206543 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.031014168827698148, 0.0024187412261448158]) \n",
      "1200: Discriminator: Real Error 2.0384995877975598e-05 / Fake Error 0.016583584249019623 Generator: 4.119787216186523 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.43164836127182532, 0.001793058389698042]) \n",
      "1300: Discriminator: Real Error 1.6927860997384414e-05 / Fake Error 0.01829952746629715 Generator: 3.9916274547576904 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.2343735777098557, 0.01821990430599044]) \n",
      "1400: Discriminator: Real Error 1.2874685126007535e-05 / Fake Error 0.011289534159004688 Generator: 4.511363983154297 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.21434781160847893, 0.018384082850763574]) \n",
      "1500: Discriminator: Real Error 1.0728892448241822e-05 / Fake Error 0.010620329529047012 Generator: 4.55183744430542 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.2514273329027768, 0.0010818159372753496]) \n",
      "1600: Discriminator: Real Error 9.536787729302887e-06 / Fake Error 0.007611584849655628 Generator: 4.893206596374512 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.15079449271333628, 0.0064448490061007873]) \n",
      "1700: Discriminator: Real Error 8.106263521767687e-06 / Fake Error 0.007036029361188412 Generator: 4.956737041473389 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.25179191293387576, 0.0070963931720381263]) \n",
      "1800: Discriminator: Real Error 6.914161531312857e-06 / Fake Error 0.0055273124016821384 Generator: 5.196207523345947 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.065456031982241009, 0.012541942784610608]) \n",
      "1900: Discriminator: Real Error 6.1989012465346605e-06 / Fake Error 0.004934060387313366 Generator: 5.3168745040893555 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.22575555793170271, 0.0019013879663392595]) \n",
      "2000: Discriminator: Real Error 5.602851160801947e-06 / Fake Error 0.004053969867527485 Generator: 5.5131330490112305 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.056852532101088558, 0.0031469902470865614]) \n",
      "2100: Discriminator: Real Error 5.006801529816585e-06 / Fake Error 0.0035009821876883507 Generator: 5.659242630004883 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.21081971094526095, 0.023763666155323594]) \n",
      "2200: Discriminator: Real Error 4.410752353578573e-06 / Fake Error 0.0031018308363854885 Generator: 5.772063732147217 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.0084950253367424011, 0.015243417314102116]) \n",
      "2300: Discriminator: Real Error 4.053123120684177e-06 / Fake Error 0.002785696880891919 Generator: 5.899065971374512 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.20544406823043165, 0.0084939277863277426]) \n",
      "2400: Discriminator: Real Error 3.6954938877897803e-06 / Fake Error 0.002426919061690569 Generator: 6.026785850524902 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.0020844556134322592, 0.001235574008460982]) \n",
      "2500: Discriminator: Real Error 3.337864654895384e-06 / Fake Error 0.0021781024988740683 Generator: 6.157684326171875 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.17090317041709505, 0.0096879313575555792]) \n",
      "2600: Discriminator: Real Error 3.099445393672795e-06 / Fake Error 0.001891621737740934 Generator: 6.266425132751465 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.023909657679755111, 0.0062939037384261241]) \n",
      "2700: Discriminator: Real Error 2.861026132450206e-06 / Fake Error 0.0017162415897473693 Generator: 6.356477737426758 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.18745515623996997, 0.022229270809349035]) \n",
      "2800: Discriminator: Real Error 2.6226068712276174e-06 / Fake Error 0.0015806998126208782 Generator: 6.479836940765381 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.085101392248581195, 0.0215924802027532]) \n",
      "2900: Discriminator: Real Error 2.5033971269294852e-06 / Fake Error 0.0013243292924016714 Generator: 6.631071090698242 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.11139147754373221, 0.021863078997230303]) \n",
      "3000: Discriminator: Real Error 2.264978093080572e-06 / Fake Error 0.0012325792340561748 Generator: 6.666240215301514 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.083604047524517985, 0.031159749736615922]) \n",
      "3100: Discriminator: Real Error 2.145768576156115e-06 / Fake Error 0.0010835842695087194 Generator: 6.843628406524658 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.15049077467671756, 0.021535637888979348]) \n",
      "3200: Discriminator: Real Error 2.0265590592316585e-06 / Fake Error 0.0010253136279061437 Generator: 6.886577129364014 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.1622098509607644, 0.0070017667763635407]) \n",
      "3300: Discriminator: Real Error 1.9073495423072018e-06 / Fake Error 0.0009308342705480754 Generator: 6.986739158630371 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.075798005379479505, 0.016161017121162555]) \n",
      "3400: Discriminator: Real Error 1.7881399116959074e-06 / Fake Error 0.000853493984322995 Generator: 7.052627086639404 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.15668702022782688, 0.036663722050960815]) \n",
      "3500: Discriminator: Real Error 1.6689303947714507e-06 / Fake Error 0.00077474070712924 Generator: 7.169933795928955 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.091865430232779738, 0.04091045833804563]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600: Discriminator: Real Error 1.5497209915338317e-06 / Fake Error 0.0007035603630356491 Generator: 7.246893405914307 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.15505681880589189, 0.04722756558408564]) \n",
      "3700: Discriminator: Real Error 1.430511474609375e-06 / Fake Error 0.0005962547729723155 Generator: 7.294474124908447 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.014743048697710037, 0.037524446690575204]) \n",
      "3800: Discriminator: Real Error 1.311302071371756e-06 / Fake Error 0.000550915312487632 Generator: 7.524743556976318 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.19245330578294292, 0.046862171269108917]) \n",
      "3900: Discriminator: Real Error 1.311302071371756e-06 / Fake Error 0.0005567287444137037 Generator: 7.537470817565918 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.075369880631052211, 0.023631458681180974]) \n",
      "4000: Discriminator: Real Error 1.1920925544472993e-06 / Fake Error 0.0004979304503649473 Generator: 7.6558709144592285 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.10944976657629013, 0.025262511140023598]) \n",
      "4100: Discriminator: Real Error 1.1920925544472993e-06 / Fake Error 0.0004312406526878476 Generator: 7.714192867279053 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.082871562191124626, 0.032026615376515327]) \n",
      "4200: Discriminator: Real Error 1.0728831512096804e-06 / Fake Error 0.0004228583420626819 Generator: 7.817793369293213 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.11304733542532756, 0.038925913413489797]) \n",
      "4300: Discriminator: Real Error 1.0728831512096804e-06 / Fake Error 0.00038965692510828376 Generator: 7.825132846832275 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.1609501550937521, 0.033036400719887511]) \n",
      "4400: Discriminator: Real Error 9.536737479720614e-07 / Fake Error 0.0003678649081848562 Generator: 7.982784271240234 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.015996435207539593, 0.044474401701833886]) \n",
      "4500: Discriminator: Real Error 9.536737479720614e-07 / Fake Error 0.0002938750840257853 Generator: 8.187185287475586 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.1942334920167923, 0.051858965669211179]) \n",
      "4600: Discriminator: Real Error 8.344644015778613e-07 / Fake Error 0.00027955148834735155 Generator: 8.023914337158203 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.13604247826954413, 0.054866053199878161]) \n",
      "4700: Discriminator: Real Error 8.344644015778613e-07 / Fake Error 0.0002602781169116497 Generator: 8.100920677185059 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.089393179478316473, 0.049135685005747089]) \n",
      "4800: Discriminator: Real Error 8.344644015778613e-07 / Fake Error 0.0002913577773142606 Generator: 8.46158218383789 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.14019622422497849, 0.087234378783634978]) \n",
      "4900: Discriminator: Real Error 7.152549983402423e-07 / Fake Error 0.00021867544273845851 Generator: 8.608314514160156 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.0036903443778383322, 0.082320850479108892]) \n",
      "5000: Discriminator: Real Error 7.152549983402423e-07 / Fake Error 0.00022288825130090117 Generator: 8.433631896972656 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.097854455097995952, 0.081834922369722507]) \n",
      "5100: Discriminator: Real Error 7.152549983402423e-07 / Fake Error 0.00017897416546475142 Generator: 8.480905532836914 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.061459300589972531, 0.089628509268568121]) \n",
      "5200: Discriminator: Real Error 5.960456519460422e-07 / Fake Error 0.00023649971990380436 Generator: 8.472908973693848 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.06496211732256002, 0.095709376438383814]) \n",
      "5300: Discriminator: Real Error 5.960456519460422e-07 / Fake Error 0.00017965746519621462 Generator: 8.474547386169434 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.10616782423237274, 0.10086160372154421]) \n",
      "5400: Discriminator: Real Error 5.960456519460422e-07 / Fake Error 0.00021316291531547904 Generator: 8.789225578308105 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.041809136497563328, 0.10158600333504483]) \n",
      "5500: Discriminator: Real Error 5.960456519460422e-07 / Fake Error 0.0002718106552492827 Generator: 8.731735229492188 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.12856407360783939, 0.13499039826162068]) \n",
      "5600: Discriminator: Real Error 4.7683627713013266e-07 / Fake Error 0.0002540413988754153 Generator: 8.39266586303711 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.085037273836546926, 0.1718776524556824]) \n",
      "5700: Discriminator: Real Error 4.7683627713013266e-07 / Fake Error 0.00013384767225943506 Generator: 8.922163963317871 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.086394624977276249, 0.18465725616761888]) \n",
      "5800: Discriminator: Real Error 4.7683627713013266e-07 / Fake Error 9.868164488580078e-05 Generator: 8.705159187316895 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.032032495814150776, 0.25053126222842614]) \n",
      "5900: Discriminator: Real Error 4.7683627713013266e-07 / Fake Error 0.0001764653716236353 Generator: 8.643868446350098 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [-0.054139501575765941, 0.49786438472773492]) \n",
      "6000: Discriminator: Real Error 4.7683627713013266e-07 / Fake Error 0.0002728186664171517 Generator: 8.468513488769531 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.18362228469601993, 0.58429568705449142]) \n",
      "6100: Discriminator: Real Error 4.7683627713013266e-07 / Fake Error 0.0003895816917065531 Generator: 9.946852684020996 (Real Data: [3.0465385945408836, 49.174943056117513], Fake Data: [0.24882552053393989, 0.83173614590701384]) \n"
     ]
    }
   ],
   "source": [
    "# Training loop alternates between two modes\n",
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train Discriminator on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train Discriminator on real data\n",
    "        d_real_data = Variable(d_sampler)\n",
    "        d_real_decision = D(preprocess(d_real_data))\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train Discriminator on fake data\n",
    "        #d_gen_input = Variable(gi_sampler(minibatch_size, 29))\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "        \n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train Generator on Discriminator's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "        \n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: Discriminator: Real Error %s / Fake Error %s Generator: %s (Real Data: %s, Fake Data: %s) \" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
