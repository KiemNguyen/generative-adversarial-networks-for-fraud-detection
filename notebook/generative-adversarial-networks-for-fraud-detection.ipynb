{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import recall_score\n",
    "import torch\n",
    "#from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro P5000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if Cuda is running\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's randomize the data, just to be sure not to get any pathological ordering effects that might harm the performane of Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124011</th>\n",
       "      <td>77147.0</td>\n",
       "      <td>-1.437314</td>\n",
       "      <td>-0.672735</td>\n",
       "      <td>0.925002</td>\n",
       "      <td>-0.728117</td>\n",
       "      <td>-0.498919</td>\n",
       "      <td>-1.088232</td>\n",
       "      <td>0.098312</td>\n",
       "      <td>0.294362</td>\n",
       "      <td>-1.763211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>-0.254662</td>\n",
       "      <td>0.569343</td>\n",
       "      <td>0.599137</td>\n",
       "      <td>-0.909906</td>\n",
       "      <td>0.070153</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>149.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182926</th>\n",
       "      <td>125586.0</td>\n",
       "      <td>-1.188026</td>\n",
       "      <td>0.648003</td>\n",
       "      <td>0.195708</td>\n",
       "      <td>-2.300317</td>\n",
       "      <td>-1.876858</td>\n",
       "      <td>0.483442</td>\n",
       "      <td>-0.257970</td>\n",
       "      <td>-4.314653</td>\n",
       "      <td>1.394378</td>\n",
       "      <td>...</td>\n",
       "      <td>3.773234</td>\n",
       "      <td>-1.129681</td>\n",
       "      <td>-1.190132</td>\n",
       "      <td>0.066215</td>\n",
       "      <td>0.806729</td>\n",
       "      <td>0.669240</td>\n",
       "      <td>0.580496</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>392.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>2364.0</td>\n",
       "      <td>1.571567</td>\n",
       "      <td>-0.852696</td>\n",
       "      <td>-0.411170</td>\n",
       "      <td>-1.735533</td>\n",
       "      <td>-0.574247</td>\n",
       "      <td>-0.298426</td>\n",
       "      <td>-0.606201</td>\n",
       "      <td>-0.165091</td>\n",
       "      <td>-2.384797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546954</td>\n",
       "      <td>-1.269700</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>-0.896239</td>\n",
       "      <td>0.433003</td>\n",
       "      <td>-0.425964</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10848</th>\n",
       "      <td>18552.0</td>\n",
       "      <td>-0.265284</td>\n",
       "      <td>0.081207</td>\n",
       "      <td>1.595559</td>\n",
       "      <td>-1.671107</td>\n",
       "      <td>-0.359368</td>\n",
       "      <td>-0.158713</td>\n",
       "      <td>-0.188054</td>\n",
       "      <td>0.271057</td>\n",
       "      <td>2.710338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102560</td>\n",
       "      <td>0.673973</td>\n",
       "      <td>0.126516</td>\n",
       "      <td>-0.065758</td>\n",
       "      <td>-1.159539</td>\n",
       "      <td>-1.066871</td>\n",
       "      <td>0.283226</td>\n",
       "      <td>0.230268</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250966</th>\n",
       "      <td>155148.0</td>\n",
       "      <td>-1.071928</td>\n",
       "      <td>0.594211</td>\n",
       "      <td>-0.352817</td>\n",
       "      <td>-0.819417</td>\n",
       "      <td>1.439513</td>\n",
       "      <td>0.755137</td>\n",
       "      <td>0.594540</td>\n",
       "      <td>0.448423</td>\n",
       "      <td>0.063034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085680</td>\n",
       "      <td>0.088365</td>\n",
       "      <td>0.361190</td>\n",
       "      <td>-0.336159</td>\n",
       "      <td>-1.006584</td>\n",
       "      <td>0.176926</td>\n",
       "      <td>-0.098098</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "124011   77147.0 -1.437314 -0.672735  0.925002 -0.728117 -0.498919 -1.088232   \n",
       "182926  125586.0 -1.188026  0.648003  0.195708 -2.300317 -1.876858  0.483442   \n",
       "2807      2364.0  1.571567 -0.852696 -0.411170 -1.735533 -0.574247 -0.298426   \n",
       "10848    18552.0 -0.265284  0.081207  1.595559 -1.671107 -0.359368 -0.158713   \n",
       "250966  155148.0 -1.071928  0.594211 -0.352817 -0.819417  1.439513  0.755137   \n",
       "\n",
       "              V7        V8        V9  ...         V21       V22       V23  \\\n",
       "124011  0.098312  0.294362 -1.763211  ...   -0.032172 -0.254662  0.569343   \n",
       "182926 -0.257970 -4.314653  1.394378  ...    3.773234 -1.129681 -1.190132   \n",
       "2807   -0.606201 -0.165091 -2.384797  ...   -0.546954 -1.269700  0.009546   \n",
       "10848  -0.188054  0.271057  2.710338  ...    0.102560  0.673973  0.126516   \n",
       "250966  0.594540  0.448423  0.063034  ...   -0.085680  0.088365  0.361190   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "124011  0.599137 -0.909906  0.070153  0.017838  0.001861  149.20      0  \n",
       "182926  0.066215  0.806729  0.669240  0.580496  0.090244  392.00      0  \n",
       "2807   -0.896239  0.433003 -0.425964  0.000977 -0.003500   19.75      0  \n",
       "10848  -0.065758 -1.159539 -1.066871  0.283226  0.230268   11.85      0  \n",
       "250966 -0.336159 -1.006584  0.176926 -0.098098  0.001136   14.75      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reindex(np.random.permutation(data.index))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.174225e-15</td>\n",
       "      <td>3.429687e-16</td>\n",
       "      <td>-1.386421e-15</td>\n",
       "      <td>2.073779e-15</td>\n",
       "      <td>9.939598e-16</td>\n",
       "      <td>1.493625e-15</td>\n",
       "      <td>-5.931037e-16</td>\n",
       "      <td>1.318317e-16</td>\n",
       "      <td>-2.414318e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.416845e-16</td>\n",
       "      <td>-3.515296e-16</td>\n",
       "      <td>2.727492e-16</td>\n",
       "      <td>4.482012e-15</td>\n",
       "      <td>5.203181e-16</td>\n",
       "      <td>1.689590e-15</td>\n",
       "      <td>-3.712632e-16</td>\n",
       "      <td>-1.159267e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.174225e-15  3.429687e-16 -1.386421e-15  2.073779e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.939598e-16  1.493625e-15 -5.931037e-16  1.318317e-16 -2.414318e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.416845e-16 -3.515296e-16  2.727492e-16  4.482012e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.203181e-16  1.689590e-15 -3.712632e-16 -1.159267e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
    "classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class')['Class'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Data is hihgly imbalance. 284315 Normal transaction vs 492 Fraud transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run with Normalising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 30)\n",
      "xtest shape\n",
      "(85443, 30)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the training data and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit classifier to a model\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85287,     4],\n",
       "       [   45,   107]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85291\n",
      "          1       0.96      0.70      0.81       152\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999427\n",
      "Area under the curve : 0.851950\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run with Over Sampling data using SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.127897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.221892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   -0.349671  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.349231  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   -0.127897  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   -0.053373  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.221892  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data2['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data2 = data2.drop(['Time','Amount'],axis=1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284807, 30)\n",
      "Shape of y: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data.ix[:, data.columns != 'Class'])\n",
    "y = np.array(data.ix[:, data.columns == 'Class'])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 30)\n",
      "xtest shape\n",
      "(85443, 30)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over Sampling data using SMOTE\n",
    "smote = SMOTE(random_state=2)\n",
    "X_train_resample, y_train_resample = smote.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_resample, y_train_resample.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85274,    17],\n",
       "       [   26,   126]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confision Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85291\n",
      "          1       0.88      0.83      0.85       152\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999497\n",
      "Area under the curve : 0.914374\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run with DCGANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Custom DataLoader\n",
    "class FraudDataset(Dataset):\n",
    "    \n",
    "    # Initialize the data\n",
    "    def __init__(self):\n",
    "        data = pd.read_csv(\"creditcard.csv\")\n",
    "        data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "        data = data.drop(['Time','Amount'],axis=1)\n",
    "        \n",
    "        fraud_data = data.loc[data['Class']==1]\n",
    "        fraud_data.shape[0]\n",
    "        self.len = fraud_data.shape[0]\n",
    "        \n",
    "        self.fraud_data = torch.FloatTensor(np.array(fraud_data))\n",
    "        \n",
    "        #self.X = np.array(data.loc[:, data.columns != 'Class'])\n",
    "        #self.y = np.array(data.loc[:, data.columns == 'Class'])\n",
    "        \n",
    "        #self.X = torch.FloatTensor(self.X)\n",
    "        #self.y = torch.FloatTensor(self.y)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.fraud_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FraudDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=30,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator's paragrams\n",
    "g_input_size = 30     # Random noise dimension\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1   \n",
    "g_learning_rate = 0.0002\n",
    "g_steps = 1000\n",
    "\n",
    "#Discriminator's paragrams\n",
    "d_input_size = 30   # Minibatch size\n",
    "d_hidden_size = 50  # Discriminator complexity\n",
    "d_output_size = 1   # Single dimension for 'real' vs. 'fake'\n",
    "d_learning_rate = 0.0002\n",
    "d_steps = 1000\n",
    "\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "num_epochs = 1900\n",
    "print_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ELU (Exponential Linear Unit) function tends to converge cost to zero faster and produce more accurate results\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.map2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.map3(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "discriminator = Discriminator(input_size=d_input_size, hidden_size=d_hidden_size, output_size=d_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these 2 lines to run on GPU\n",
    "#generator.cuda()\n",
    "#discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(disc):\n",
    "    h=0.1\n",
    "    x_min, x_max = data[:, 0].min() - .5, data[:, 0].max() + .5\n",
    "    y_min, y_max = data[:, 1].min() - .5, data[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    x_test = np.c_[xx.ravel(), yy.ravel()]\n",
    "    y_hat_test = disc.forward_with_sigmoid(Variable(torch.from_numpy(x_test).float()))\n",
    "\n",
    "    plt.pcolormesh(xx, yy, y_hat_test.data.numpy().reshape(xx.shape), cmap=plt.cm.Paired)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=y*20, alpha=0.1, cmap=plt.cm.flag, s=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Binary Cross Entropy loss\n",
    "BCE_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizers\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=d_learning_rate/2, betas=(beta_1, beta_2))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=g_learning_rate, betas=(beta_1, beta_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Discriminator Loss: 0.237, Generator Loss: 6.642\n",
      "Epoch 11 - Discriminator Loss: 0.191, Generator Loss: 6.361\n",
      "Epoch 21 - Discriminator Loss: 0.048, Generator Loss: 5.809\n",
      "Epoch 31 - Discriminator Loss: 0.131, Generator Loss: 5.825\n",
      "Epoch 41 - Discriminator Loss: 0.227, Generator Loss: 5.789\n",
      "Epoch 51 - Discriminator Loss: 0.042, Generator Loss: 6.100\n",
      "Epoch 61 - Discriminator Loss: 0.173, Generator Loss: 6.071\n",
      "Epoch 71 - Discriminator Loss: 0.097, Generator Loss: 4.834\n",
      "Epoch 81 - Discriminator Loss: 0.084, Generator Loss: 6.283\n",
      "Epoch 91 - Discriminator Loss: 0.144, Generator Loss: 7.501\n",
      "Epoch 101 - Discriminator Loss: 0.222, Generator Loss: 7.579\n",
      "Epoch 111 - Discriminator Loss: 0.037, Generator Loss: 6.955\n",
      "Epoch 121 - Discriminator Loss: 0.010, Generator Loss: 6.333\n",
      "Epoch 131 - Discriminator Loss: 0.012, Generator Loss: 6.958\n",
      "Epoch 141 - Discriminator Loss: 0.047, Generator Loss: 5.864\n",
      "Epoch 151 - Discriminator Loss: 0.034, Generator Loss: 7.222\n",
      "Epoch 161 - Discriminator Loss: 0.158, Generator Loss: 7.213\n",
      "Epoch 171 - Discriminator Loss: 0.032, Generator Loss: 6.201\n",
      "Epoch 181 - Discriminator Loss: 0.056, Generator Loss: 5.958\n",
      "Epoch 191 - Discriminator Loss: 0.033, Generator Loss: 6.593\n",
      "Epoch 201 - Discriminator Loss: 0.026, Generator Loss: 6.206\n",
      "Epoch 211 - Discriminator Loss: 0.027, Generator Loss: 6.393\n",
      "Epoch 221 - Discriminator Loss: 0.055, Generator Loss: 7.229\n",
      "Epoch 231 - Discriminator Loss: 0.096, Generator Loss: 7.191\n",
      "Epoch 241 - Discriminator Loss: 0.090, Generator Loss: 7.113\n",
      "Epoch 251 - Discriminator Loss: 0.143, Generator Loss: 6.660\n",
      "Epoch 261 - Discriminator Loss: 0.044, Generator Loss: 6.363\n",
      "Epoch 271 - Discriminator Loss: 0.038, Generator Loss: 5.574\n",
      "Epoch 281 - Discriminator Loss: 0.013, Generator Loss: 7.116\n",
      "Epoch 291 - Discriminator Loss: 0.066, Generator Loss: 5.880\n",
      "Epoch 301 - Discriminator Loss: 0.024, Generator Loss: 7.820\n",
      "Epoch 311 - Discriminator Loss: 0.109, Generator Loss: 6.744\n",
      "Epoch 321 - Discriminator Loss: 0.043, Generator Loss: 6.131\n",
      "Epoch 331 - Discriminator Loss: 0.012, Generator Loss: 6.233\n",
      "Epoch 341 - Discriminator Loss: 0.056, Generator Loss: 6.711\n",
      "Epoch 351 - Discriminator Loss: 0.111, Generator Loss: 7.201\n",
      "Epoch 361 - Discriminator Loss: 0.095, Generator Loss: 5.871\n",
      "Epoch 371 - Discriminator Loss: 0.035, Generator Loss: 6.663\n",
      "Epoch 381 - Discriminator Loss: 0.020, Generator Loss: 6.988\n",
      "Epoch 391 - Discriminator Loss: 0.018, Generator Loss: 7.024\n",
      "Epoch 401 - Discriminator Loss: 0.256, Generator Loss: 6.487\n",
      "Epoch 411 - Discriminator Loss: 0.034, Generator Loss: 6.731\n",
      "Epoch 421 - Discriminator Loss: 0.106, Generator Loss: 6.439\n",
      "Epoch 431 - Discriminator Loss: 0.093, Generator Loss: 7.448\n",
      "Epoch 441 - Discriminator Loss: 0.075, Generator Loss: 8.201\n",
      "Epoch 451 - Discriminator Loss: 0.128, Generator Loss: 6.635\n",
      "Epoch 461 - Discriminator Loss: 0.095, Generator Loss: 7.017\n",
      "Epoch 471 - Discriminator Loss: 0.008, Generator Loss: 7.597\n",
      "Epoch 481 - Discriminator Loss: 0.024, Generator Loss: 6.875\n",
      "Epoch 491 - Discriminator Loss: 0.128, Generator Loss: 7.046\n",
      "Epoch 501 - Discriminator Loss: 0.028, Generator Loss: 6.812\n",
      "Epoch 511 - Discriminator Loss: 0.026, Generator Loss: 6.780\n",
      "Epoch 521 - Discriminator Loss: 0.168, Generator Loss: 8.282\n",
      "Epoch 531 - Discriminator Loss: 0.027, Generator Loss: 6.708\n",
      "Epoch 541 - Discriminator Loss: 0.031, Generator Loss: 5.838\n",
      "Epoch 551 - Discriminator Loss: 0.046, Generator Loss: 8.190\n",
      "Epoch 561 - Discriminator Loss: 0.009, Generator Loss: 6.147\n",
      "Epoch 571 - Discriminator Loss: 0.030, Generator Loss: 7.688\n",
      "Epoch 581 - Discriminator Loss: 0.064, Generator Loss: 7.522\n",
      "Epoch 591 - Discriminator Loss: 0.168, Generator Loss: 7.041\n",
      "Epoch 601 - Discriminator Loss: 0.013, Generator Loss: 5.698\n",
      "Epoch 611 - Discriminator Loss: 0.025, Generator Loss: 6.272\n",
      "Epoch 621 - Discriminator Loss: 0.025, Generator Loss: 7.464\n",
      "Epoch 631 - Discriminator Loss: 0.007, Generator Loss: 8.179\n",
      "Epoch 641 - Discriminator Loss: 0.045, Generator Loss: 8.226\n",
      "Epoch 651 - Discriminator Loss: 0.022, Generator Loss: 7.806\n",
      "Epoch 661 - Discriminator Loss: 0.072, Generator Loss: 8.366\n",
      "Epoch 671 - Discriminator Loss: 0.166, Generator Loss: 6.874\n",
      "Epoch 681 - Discriminator Loss: 0.041, Generator Loss: 7.564\n",
      "Epoch 691 - Discriminator Loss: 0.184, Generator Loss: 8.365\n",
      "Epoch 701 - Discriminator Loss: 0.023, Generator Loss: 7.686\n",
      "Epoch 711 - Discriminator Loss: 0.142, Generator Loss: 8.126\n",
      "Epoch 721 - Discriminator Loss: 0.020, Generator Loss: 9.321\n",
      "Epoch 731 - Discriminator Loss: 0.074, Generator Loss: 7.602\n",
      "Epoch 741 - Discriminator Loss: 0.027, Generator Loss: 8.136\n",
      "Epoch 751 - Discriminator Loss: 0.045, Generator Loss: 7.683\n",
      "Epoch 761 - Discriminator Loss: 0.082, Generator Loss: 7.786\n",
      "Epoch 771 - Discriminator Loss: 0.095, Generator Loss: 8.828\n",
      "Epoch 781 - Discriminator Loss: 0.043, Generator Loss: 7.705\n",
      "Epoch 791 - Discriminator Loss: 0.236, Generator Loss: 5.790\n",
      "Epoch 801 - Discriminator Loss: 0.081, Generator Loss: 9.929\n",
      "Epoch 811 - Discriminator Loss: 0.097, Generator Loss: 8.122\n",
      "Epoch 821 - Discriminator Loss: 0.298, Generator Loss: 9.265\n",
      "Epoch 831 - Discriminator Loss: 0.030, Generator Loss: 7.038\n",
      "Epoch 841 - Discriminator Loss: 0.207, Generator Loss: 7.731\n",
      "Epoch 851 - Discriminator Loss: 0.153, Generator Loss: 9.229\n",
      "Epoch 861 - Discriminator Loss: 0.072, Generator Loss: 8.436\n",
      "Epoch 871 - Discriminator Loss: 0.133, Generator Loss: 7.010\n",
      "Epoch 881 - Discriminator Loss: 0.034, Generator Loss: 8.312\n",
      "Epoch 891 - Discriminator Loss: 0.001, Generator Loss: 7.012\n",
      "Epoch 901 - Discriminator Loss: 0.065, Generator Loss: 9.401\n",
      "Epoch 911 - Discriminator Loss: 0.036, Generator Loss: 8.140\n",
      "Epoch 921 - Discriminator Loss: 0.128, Generator Loss: 9.434\n",
      "Epoch 931 - Discriminator Loss: 0.012, Generator Loss: 7.262\n",
      "Epoch 941 - Discriminator Loss: 0.073, Generator Loss: 8.211\n",
      "Epoch 951 - Discriminator Loss: 0.169, Generator Loss: 6.973\n",
      "Epoch 961 - Discriminator Loss: 0.097, Generator Loss: 6.881\n",
      "Epoch 971 - Discriminator Loss: 0.017, Generator Loss: 8.795\n",
      "Epoch 981 - Discriminator Loss: 0.254, Generator Loss: 9.189\n",
      "Epoch 991 - Discriminator Loss: 0.155, Generator Loss: 8.619\n",
      "Epoch 1001 - Discriminator Loss: 0.090, Generator Loss: 7.550\n",
      "Epoch 1011 - Discriminator Loss: 0.030, Generator Loss: 8.529\n",
      "Epoch 1021 - Discriminator Loss: 0.131, Generator Loss: 9.763\n",
      "Epoch 1031 - Discriminator Loss: 0.032, Generator Loss: 8.148\n",
      "Epoch 1041 - Discriminator Loss: 0.103, Generator Loss: 6.453\n",
      "Epoch 1051 - Discriminator Loss: 0.070, Generator Loss: 8.397\n",
      "Epoch 1061 - Discriminator Loss: 0.146, Generator Loss: 7.625\n",
      "Epoch 1071 - Discriminator Loss: 0.012, Generator Loss: 9.386\n",
      "Epoch 1081 - Discriminator Loss: 0.018, Generator Loss: 10.195\n",
      "Epoch 1091 - Discriminator Loss: 0.051, Generator Loss: 8.682\n",
      "Epoch 1101 - Discriminator Loss: 0.153, Generator Loss: 8.527\n",
      "Epoch 1111 - Discriminator Loss: 0.199, Generator Loss: 7.774\n",
      "Epoch 1121 - Discriminator Loss: 0.007, Generator Loss: 7.961\n",
      "Epoch 1131 - Discriminator Loss: 0.040, Generator Loss: 8.514\n",
      "Epoch 1141 - Discriminator Loss: 0.003, Generator Loss: 8.453\n",
      "Epoch 1151 - Discriminator Loss: 0.048, Generator Loss: 8.468\n",
      "Epoch 1161 - Discriminator Loss: 0.006, Generator Loss: 8.760\n",
      "Epoch 1171 - Discriminator Loss: 0.178, Generator Loss: 8.074\n",
      "Epoch 1181 - Discriminator Loss: 0.021, Generator Loss: 7.359\n",
      "Epoch 1191 - Discriminator Loss: 0.017, Generator Loss: 8.488\n",
      "Epoch 1201 - Discriminator Loss: 0.032, Generator Loss: 7.822\n",
      "Epoch 1211 - Discriminator Loss: 0.052, Generator Loss: 8.254\n",
      "Epoch 1221 - Discriminator Loss: 0.031, Generator Loss: 8.721\n",
      "Epoch 1231 - Discriminator Loss: 0.029, Generator Loss: 10.140\n",
      "Epoch 1241 - Discriminator Loss: 0.068, Generator Loss: 6.661\n",
      "Epoch 1251 - Discriminator Loss: 0.039, Generator Loss: 9.170\n",
      "Epoch 1261 - Discriminator Loss: 0.012, Generator Loss: 7.653\n",
      "Epoch 1271 - Discriminator Loss: 0.024, Generator Loss: 9.868\n",
      "Epoch 1281 - Discriminator Loss: 0.003, Generator Loss: 9.427\n",
      "Epoch 1291 - Discriminator Loss: 0.022, Generator Loss: 7.328\n",
      "Epoch 1301 - Discriminator Loss: 0.009, Generator Loss: 7.843\n",
      "Epoch 1311 - Discriminator Loss: 0.005, Generator Loss: 10.097\n",
      "Epoch 1321 - Discriminator Loss: 0.035, Generator Loss: 8.589\n",
      "Epoch 1331 - Discriminator Loss: 0.019, Generator Loss: 8.391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1341 - Discriminator Loss: 0.035, Generator Loss: 7.320\n",
      "Epoch 1351 - Discriminator Loss: 0.083, Generator Loss: 8.021\n",
      "Epoch 1361 - Discriminator Loss: 0.011, Generator Loss: 10.293\n",
      "Epoch 1371 - Discriminator Loss: 0.090, Generator Loss: 10.019\n",
      "Epoch 1381 - Discriminator Loss: 0.005, Generator Loss: 9.371\n",
      "Epoch 1391 - Discriminator Loss: 0.019, Generator Loss: 10.066\n",
      "Epoch 1401 - Discriminator Loss: 0.124, Generator Loss: 11.507\n",
      "Epoch 1411 - Discriminator Loss: 0.100, Generator Loss: 10.388\n",
      "Epoch 1421 - Discriminator Loss: 0.220, Generator Loss: 8.077\n",
      "Epoch 1431 - Discriminator Loss: 0.048, Generator Loss: 9.847\n",
      "Epoch 1441 - Discriminator Loss: 0.050, Generator Loss: 7.988\n",
      "Epoch 1451 - Discriminator Loss: 0.026, Generator Loss: 10.018\n",
      "Epoch 1461 - Discriminator Loss: 0.035, Generator Loss: 8.402\n",
      "Epoch 1471 - Discriminator Loss: 0.079, Generator Loss: 9.733\n",
      "Epoch 1481 - Discriminator Loss: 0.243, Generator Loss: 8.763\n",
      "Epoch 1491 - Discriminator Loss: 0.018, Generator Loss: 9.613\n",
      "Epoch 1501 - Discriminator Loss: 0.061, Generator Loss: 9.639\n",
      "Epoch 1511 - Discriminator Loss: 0.049, Generator Loss: 8.786\n",
      "Epoch 1521 - Discriminator Loss: 0.027, Generator Loss: 9.809\n",
      "Epoch 1531 - Discriminator Loss: 0.045, Generator Loss: 10.792\n",
      "Epoch 1541 - Discriminator Loss: 0.030, Generator Loss: 9.216\n",
      "Epoch 1551 - Discriminator Loss: 0.002, Generator Loss: 9.056\n",
      "Epoch 1561 - Discriminator Loss: 0.007, Generator Loss: 9.368\n",
      "Epoch 1571 - Discriminator Loss: 0.048, Generator Loss: 8.240\n",
      "Epoch 1581 - Discriminator Loss: 0.056, Generator Loss: 9.754\n",
      "Epoch 1591 - Discriminator Loss: 0.044, Generator Loss: 6.794\n",
      "Epoch 1601 - Discriminator Loss: 0.026, Generator Loss: 8.786\n",
      "Epoch 1611 - Discriminator Loss: 0.003, Generator Loss: 9.657\n",
      "Epoch 1621 - Discriminator Loss: 0.031, Generator Loss: 9.044\n",
      "Epoch 1631 - Discriminator Loss: 0.001, Generator Loss: 9.106\n",
      "Epoch 1641 - Discriminator Loss: 0.006, Generator Loss: 8.423\n",
      "Epoch 1651 - Discriminator Loss: 0.004, Generator Loss: 10.635\n",
      "Epoch 1661 - Discriminator Loss: 0.016, Generator Loss: 9.594\n",
      "Epoch 1671 - Discriminator Loss: 0.005, Generator Loss: 8.802\n",
      "Epoch 1681 - Discriminator Loss: 0.004, Generator Loss: 10.747\n",
      "Epoch 1691 - Discriminator Loss: 0.107, Generator Loss: 9.798\n",
      "Epoch 1701 - Discriminator Loss: 0.050, Generator Loss: 8.352\n",
      "Epoch 1711 - Discriminator Loss: 0.008, Generator Loss: 11.718\n",
      "Epoch 1721 - Discriminator Loss: 0.004, Generator Loss: 10.170\n",
      "Epoch 1731 - Discriminator Loss: 0.012, Generator Loss: 10.863\n",
      "Epoch 1741 - Discriminator Loss: 0.004, Generator Loss: 11.433\n",
      "Epoch 1751 - Discriminator Loss: 0.004, Generator Loss: 9.153\n",
      "Epoch 1761 - Discriminator Loss: 0.012, Generator Loss: 10.073\n",
      "Epoch 1771 - Discriminator Loss: 0.015, Generator Loss: 9.187\n",
      "Epoch 1781 - Discriminator Loss: 0.013, Generator Loss: 10.051\n",
      "Epoch 1791 - Discriminator Loss: 0.049, Generator Loss: 10.791\n",
      "Epoch 1801 - Discriminator Loss: 0.031, Generator Loss: 12.577\n",
      "Epoch 1811 - Discriminator Loss: 0.141, Generator Loss: 10.677\n",
      "Epoch 1821 - Discriminator Loss: 0.013, Generator Loss: 9.819\n",
      "Epoch 1831 - Discriminator Loss: 0.006, Generator Loss: 9.616\n",
      "Epoch 1841 - Discriminator Loss: 0.029, Generator Loss: 11.665\n",
      "Epoch 1851 - Discriminator Loss: 0.044, Generator Loss: 10.483\n",
      "Epoch 1861 - Discriminator Loss: 0.025, Generator Loss: 10.792\n",
      "Epoch 1871 - Discriminator Loss: 0.002, Generator Loss: 10.640\n",
      "Epoch 1881 - Discriminator Loss: 0.015, Generator Loss: 11.060\n",
      "Epoch 1891 - Discriminator Loss: 0.011, Generator Loss: 11.456\n"
     ]
    }
   ],
   "source": [
    "# Training DCGANs\n",
    "for epoch in range(num_epochs):\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    for i, fraud_data in enumerate(train_loader):\n",
    "        # Updating the weights of the Discriminator\n",
    "        discriminator.zero_grad() # Initialize gradients of the Discriminator to 0\n",
    "        \n",
    "        mini_batch = fraud_data.size()[0]\n",
    "        \n",
    "        # Get fraud data\n",
    "        X = fraud_data\n",
    "        \n",
    "        # Wrap data in PyTorch Variable\n",
    "        d_real_data = Variable(X[0])\n",
    "        y_real = Variable(torch.ones(1))\n",
    "        y_fake = Variable(torch.zeros(1))\n",
    "\n",
    "        # Training the Discriminator with real data\n",
    "        d_real_result = discriminator(d_real_data) # Forward propagate this real data into the neural network\n",
    "        d_real_loss = BCE_loss(d_real_result, y_real) # Compute the loss between the prediction and actual\n",
    "        #d_real_loss.backward()\n",
    "    \n",
    "        # Inject fake data to the generator\n",
    "        d_gen_input = Variable(torch.randn(minibatch_size, g_input_size))\n",
    "        d_fake_data = generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        \n",
    "        # Train the Discriminator with a fake data generated by the Generator\n",
    "        d_fake_result = discriminator(d_fake_data.t())\n",
    "        d_fake_loss = BCE_loss(d_fake_result, y_fake)  # zeros = fake\n",
    "        #d_fake_loss.backward()\n",
    "        \n",
    "        # Combine discriminator loss from real data and fake data\n",
    "        d_train_loss = d_real_loss + d_fake_loss\n",
    "        \n",
    "        d_train_loss.backward()\n",
    "        d_optimizer.step()     # Apply SGD to update the weight\n",
    "        d_losses.append(d_train_loss.data[0])\n",
    "        \n",
    "        # Update the weight of the Generator \n",
    "        generator.zero_grad()\n",
    "        gen_input = Variable(torch.randn(minibatch_size, g_input_size))  \n",
    "        g_fake_data = generator(gen_input)\n",
    "        \n",
    "        dg_fake_result = discriminator(g_fake_data.t())\n",
    "        g_loss = BCE_loss(dg_fake_result, y_real)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        g_losses.append(g_loss.data[0])\n",
    "        \n",
    "    if epoch % print_interval == 0:       \n",
    "        print('Epoch {} - Discriminator Loss: {:.3f}, Generator Loss: {:.3f}'.format((epoch + 1), \n",
    "                          torch.mean(torch.FloatTensor(d_losses)), torch.mean(torch.FloatTensor(g_losses)))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f398d8cd5f8>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(d_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f398413d278>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(g_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
