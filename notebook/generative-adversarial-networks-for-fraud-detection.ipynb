{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import recall_score\n",
    "import torch\n",
    "#from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Cuda is running\n",
    "#torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's randomize the data, just to be sure not to get any pathological ordering effects that might harm the performane of Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124011</th>\n",
       "      <td>77147.0</td>\n",
       "      <td>-1.437314</td>\n",
       "      <td>-0.672735</td>\n",
       "      <td>0.925002</td>\n",
       "      <td>-0.728117</td>\n",
       "      <td>-0.498919</td>\n",
       "      <td>-1.088232</td>\n",
       "      <td>0.098312</td>\n",
       "      <td>0.294362</td>\n",
       "      <td>-1.763211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>-0.254662</td>\n",
       "      <td>0.569343</td>\n",
       "      <td>0.599137</td>\n",
       "      <td>-0.909906</td>\n",
       "      <td>0.070153</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>149.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182926</th>\n",
       "      <td>125586.0</td>\n",
       "      <td>-1.188026</td>\n",
       "      <td>0.648003</td>\n",
       "      <td>0.195708</td>\n",
       "      <td>-2.300317</td>\n",
       "      <td>-1.876858</td>\n",
       "      <td>0.483442</td>\n",
       "      <td>-0.257970</td>\n",
       "      <td>-4.314653</td>\n",
       "      <td>1.394378</td>\n",
       "      <td>...</td>\n",
       "      <td>3.773234</td>\n",
       "      <td>-1.129681</td>\n",
       "      <td>-1.190132</td>\n",
       "      <td>0.066215</td>\n",
       "      <td>0.806729</td>\n",
       "      <td>0.669240</td>\n",
       "      <td>0.580496</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>392.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>2364.0</td>\n",
       "      <td>1.571567</td>\n",
       "      <td>-0.852696</td>\n",
       "      <td>-0.411170</td>\n",
       "      <td>-1.735533</td>\n",
       "      <td>-0.574247</td>\n",
       "      <td>-0.298426</td>\n",
       "      <td>-0.606201</td>\n",
       "      <td>-0.165091</td>\n",
       "      <td>-2.384797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546954</td>\n",
       "      <td>-1.269700</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>-0.896239</td>\n",
       "      <td>0.433003</td>\n",
       "      <td>-0.425964</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10848</th>\n",
       "      <td>18552.0</td>\n",
       "      <td>-0.265284</td>\n",
       "      <td>0.081207</td>\n",
       "      <td>1.595559</td>\n",
       "      <td>-1.671107</td>\n",
       "      <td>-0.359368</td>\n",
       "      <td>-0.158713</td>\n",
       "      <td>-0.188054</td>\n",
       "      <td>0.271057</td>\n",
       "      <td>2.710338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102560</td>\n",
       "      <td>0.673973</td>\n",
       "      <td>0.126516</td>\n",
       "      <td>-0.065758</td>\n",
       "      <td>-1.159539</td>\n",
       "      <td>-1.066871</td>\n",
       "      <td>0.283226</td>\n",
       "      <td>0.230268</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250966</th>\n",
       "      <td>155148.0</td>\n",
       "      <td>-1.071928</td>\n",
       "      <td>0.594211</td>\n",
       "      <td>-0.352817</td>\n",
       "      <td>-0.819417</td>\n",
       "      <td>1.439513</td>\n",
       "      <td>0.755137</td>\n",
       "      <td>0.594540</td>\n",
       "      <td>0.448423</td>\n",
       "      <td>0.063034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085680</td>\n",
       "      <td>0.088365</td>\n",
       "      <td>0.361190</td>\n",
       "      <td>-0.336159</td>\n",
       "      <td>-1.006584</td>\n",
       "      <td>0.176926</td>\n",
       "      <td>-0.098098</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "124011   77147.0 -1.437314 -0.672735  0.925002 -0.728117 -0.498919 -1.088232   \n",
       "182926  125586.0 -1.188026  0.648003  0.195708 -2.300317 -1.876858  0.483442   \n",
       "2807      2364.0  1.571567 -0.852696 -0.411170 -1.735533 -0.574247 -0.298426   \n",
       "10848    18552.0 -0.265284  0.081207  1.595559 -1.671107 -0.359368 -0.158713   \n",
       "250966  155148.0 -1.071928  0.594211 -0.352817 -0.819417  1.439513  0.755137   \n",
       "\n",
       "              V7        V8        V9  ...         V21       V22       V23  \\\n",
       "124011  0.098312  0.294362 -1.763211  ...   -0.032172 -0.254662  0.569343   \n",
       "182926 -0.257970 -4.314653  1.394378  ...    3.773234 -1.129681 -1.190132   \n",
       "2807   -0.606201 -0.165091 -2.384797  ...   -0.546954 -1.269700  0.009546   \n",
       "10848  -0.188054  0.271057  2.710338  ...    0.102560  0.673973  0.126516   \n",
       "250966  0.594540  0.448423  0.063034  ...   -0.085680  0.088365  0.361190   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "124011  0.599137 -0.909906  0.070153  0.017838  0.001861  149.20      0  \n",
       "182926  0.066215  0.806729  0.669240  0.580496  0.090244  392.00      0  \n",
       "2807   -0.896239  0.433003 -0.425964  0.000977 -0.003500   19.75      0  \n",
       "10848  -0.065758 -1.159539 -1.066871  0.283226  0.230268   11.85      0  \n",
       "250966 -0.336159 -1.006584  0.176926 -0.098098  0.001136   14.75      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reindex(np.random.permutation(data.index))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.174225e-15</td>\n",
       "      <td>3.429687e-16</td>\n",
       "      <td>-1.386421e-15</td>\n",
       "      <td>2.073779e-15</td>\n",
       "      <td>9.939598e-16</td>\n",
       "      <td>1.493625e-15</td>\n",
       "      <td>-5.931037e-16</td>\n",
       "      <td>1.318317e-16</td>\n",
       "      <td>-2.414318e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.416845e-16</td>\n",
       "      <td>-3.515296e-16</td>\n",
       "      <td>2.727492e-16</td>\n",
       "      <td>4.482012e-15</td>\n",
       "      <td>5.203181e-16</td>\n",
       "      <td>1.689590e-15</td>\n",
       "      <td>-3.712632e-16</td>\n",
       "      <td>-1.159267e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.174225e-15  3.429687e-16 -1.386421e-15  2.073779e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.939598e-16  1.493625e-15 -5.931037e-16  1.318317e-16 -2.414318e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.416845e-16 -3.515296e-16  2.727492e-16  4.482012e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.203181e-16  1.689590e-15 -3.712632e-16 -1.159267e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
    "classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class')['Class'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Data is hihgly imbalance. 284315 Normal transaction vs 492 Fraud transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run with Normalising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 29)\n",
      "xtest shape\n",
      "(85443, 29)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the training data and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit classifier to a model\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85291,     5],\n",
       "       [   39,   108]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.96      0.73      0.83       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999485\n",
      "Area under the curve : 0.867318\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run with Over Sampling data using SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bbd82a65bc57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"creditcard.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284807, 29)\n",
      "Shape of y: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data.ix[:, data.columns != 'Class'])\n",
    "y = np.array(data.ix[:, data.columns == 'Class'])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 29)\n",
      "xtest shape\n",
      "(85443, 29)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over Sampling data using SMOTE\n",
    "smote = SMOTE(random_state=2)\n",
    "X_train_resample, y_train_resample = smote.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_resample, y_train_resample.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85283,    13],\n",
       "       [   31,   116]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confision Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.90      0.79      0.84       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "Accuracy : 0.999485\n",
      "Area under the curve : 0.894482\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Area under the curve : %f' % (metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run with GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "OUTPUT_PATH = '/output/'\n",
    "MODE = 'wgan-gp'\n",
    "RESTORE_MODE = False # If this flag is True, it will continue to train from the saved model.\n",
    "\n",
    "# Custom DataLoader\n",
    "class FraudDataset(Dataset):\n",
    "    \n",
    "    # Initialize the data\n",
    "    def __init__(self):\n",
    "        data = pd.read_csv(\"creditcard.csv\")\n",
    "        data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "        data = data.drop(['Time','Amount'],axis=1)\n",
    "        \n",
    "        # Rearrange columns to the right order\n",
    "        cols = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
    "        'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'normAmount', 'Class']\n",
    "        data = data[cols]\n",
    "        \n",
    "        fraud_data = data.loc[data['Class']==1]\n",
    "        fraud_data = fraud_data.drop('Class', 1)\n",
    "        self.len = fraud_data.shape[0]\n",
    "        \n",
    "        self.fraud_data = torch.FloatTensor(np.array(fraud_data))\n",
    "        \n",
    "        #self.X = np.array(data.loc[:, data.columns != 'Class'])\n",
    "        #self.y = np.array(data.loc[:, data.columns == 'Class'])\n",
    "        \n",
    "        #self.X = torch.FloatTensor(self.X)\n",
    "        #self.y = torch.FloatTensor(self.y)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.fraud_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESTORE_MODE:\n",
    "    generator = torch.load(OUTPUT_PATH + \"generator.pt\" )\n",
    "    discriminator = torch.load(OUTPUT_PATH + \"discriminator.pt\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FraudDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=1,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator's paragrams\n",
    "g_input_size = 29     # Random noise dimension\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1   \n",
    "g_learning_rate = 0.0002\n",
    "\n",
    "#Discriminator's paragrams\n",
    "d_input_size = 29   # Minibatch size\n",
    "d_hidden_size = 50  # Discriminator complexity\n",
    "d_output_size = 1   # Single dimension for 'real' vs. 'fake'\n",
    "d_learning_rate = 0.0002\n",
    "\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "num_epochs = 5000\n",
    "print_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ELU (Exponential Linear Unit) function tends to converge cost to zero faster and produce more accurate results\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.map2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.map3(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "discriminator = Discriminator(input_size=d_input_size, hidden_size=d_hidden_size, output_size=d_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these 2 lines to run on GPU\n",
    "#generator.cuda()\n",
    "#discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(disc):\n",
    "    h=0.1\n",
    "    x_min, x_max = data[:, 0].min() - .5, data[:, 0].max() + .5\n",
    "    y_min, y_max = data[:, 1].min() - .5, data[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    x_test = np.c_[xx.ravel(), yy.ravel()]\n",
    "    y_hat_test = disc.forward_with_sigmoid(Variable(torch.from_numpy(x_test).float()))\n",
    "\n",
    "    plt.pcolormesh(xx, yy, y_hat_test.data.numpy().reshape(xx.shape), cmap=plt.cm.Paired)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=y*20, alpha=0.1, cmap=plt.cm.flag, s=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Binary Cross Entropy loss\n",
    "BCE_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimizers\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=d_learning_rate/2, betas=(beta_1, beta_2))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=g_learning_rate, betas=(beta_1, beta_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Discriminator Loss: 0.840, Generator Loss: 0.837\n",
      "Epoch 11 - Discriminator Loss: 0.333, Generator Loss: 3.293\n",
      "Epoch 21 - Discriminator Loss: 0.255, Generator Loss: 3.747\n",
      "Epoch 31 - Discriminator Loss: 0.202, Generator Loss: 3.853\n",
      "Epoch 41 - Discriminator Loss: 0.203, Generator Loss: 3.940\n",
      "Epoch 51 - Discriminator Loss: 0.176, Generator Loss: 4.119\n",
      "Epoch 61 - Discriminator Loss: 0.167, Generator Loss: 4.326\n",
      "Epoch 71 - Discriminator Loss: 0.130, Generator Loss: 4.786\n",
      "Epoch 81 - Discriminator Loss: 0.115, Generator Loss: 4.920\n",
      "Epoch 91 - Discriminator Loss: 0.100, Generator Loss: 5.120\n",
      "Epoch 101 - Discriminator Loss: 0.073, Generator Loss: 5.542\n",
      "Epoch 111 - Discriminator Loss: 0.068, Generator Loss: 5.881\n",
      "Epoch 121 - Discriminator Loss: 0.056, Generator Loss: 6.640\n",
      "Epoch 131 - Discriminator Loss: 0.034, Generator Loss: 6.898\n",
      "Epoch 141 - Discriminator Loss: 0.033, Generator Loss: 7.450\n",
      "Epoch 151 - Discriminator Loss: 0.014, Generator Loss: 7.669\n",
      "Epoch 161 - Discriminator Loss: 0.029, Generator Loss: 8.482\n",
      "Epoch 171 - Discriminator Loss: 0.017, Generator Loss: 8.841\n",
      "Epoch 181 - Discriminator Loss: 0.026, Generator Loss: 9.865\n",
      "Epoch 191 - Discriminator Loss: 0.016, Generator Loss: 9.686\n",
      "Epoch 201 - Discriminator Loss: 0.010, Generator Loss: 10.648\n",
      "Epoch 211 - Discriminator Loss: 0.008, Generator Loss: 11.394\n",
      "Epoch 221 - Discriminator Loss: 0.009, Generator Loss: 11.651\n",
      "Epoch 231 - Discriminator Loss: 0.017, Generator Loss: 13.079\n",
      "Epoch 241 - Discriminator Loss: 0.014, Generator Loss: 13.048\n",
      "Epoch 251 - Discriminator Loss: 0.002, Generator Loss: 13.288\n",
      "Epoch 261 - Discriminator Loss: 0.012, Generator Loss: 13.839\n",
      "Epoch 271 - Discriminator Loss: 0.007, Generator Loss: 14.322\n",
      "Epoch 281 - Discriminator Loss: 0.012, Generator Loss: 14.426\n",
      "Epoch 291 - Discriminator Loss: 0.007, Generator Loss: 14.909\n",
      "Epoch 301 - Discriminator Loss: 0.001, Generator Loss: 14.970\n",
      "Epoch 311 - Discriminator Loss: 0.021, Generator Loss: 15.990\n",
      "Epoch 321 - Discriminator Loss: 0.002, Generator Loss: 15.572\n",
      "Epoch 331 - Discriminator Loss: 0.006, Generator Loss: 16.118\n",
      "Epoch 341 - Discriminator Loss: 0.003, Generator Loss: 16.374\n",
      "Epoch 351 - Discriminator Loss: 0.001, Generator Loss: 16.875\n",
      "Epoch 361 - Discriminator Loss: 0.019, Generator Loss: 17.606\n",
      "Epoch 371 - Discriminator Loss: 0.001, Generator Loss: 16.426\n",
      "Epoch 381 - Discriminator Loss: 0.003, Generator Loss: 16.996\n",
      "Epoch 391 - Discriminator Loss: 0.027, Generator Loss: 18.825\n",
      "Epoch 401 - Discriminator Loss: 0.001, Generator Loss: 18.008\n",
      "Epoch 411 - Discriminator Loss: 0.000, Generator Loss: 16.764\n",
      "Epoch 421 - Discriminator Loss: 0.001, Generator Loss: 17.585\n",
      "Epoch 431 - Discriminator Loss: 0.003, Generator Loss: 18.446\n",
      "Epoch 441 - Discriminator Loss: 0.110, Generator Loss: 21.769\n",
      "Epoch 451 - Discriminator Loss: 0.001, Generator Loss: 19.075\n",
      "Epoch 461 - Discriminator Loss: 0.000, Generator Loss: 17.317\n",
      "Epoch 471 - Discriminator Loss: 0.000, Generator Loss: 15.693\n",
      "Epoch 481 - Discriminator Loss: 0.000, Generator Loss: 14.874\n",
      "Epoch 491 - Discriminator Loss: 0.002, Generator Loss: 19.797\n",
      "Epoch 501 - Discriminator Loss: 0.277, Generator Loss: 23.409\n",
      "Epoch 511 - Discriminator Loss: 0.019, Generator Loss: 23.150\n",
      "Epoch 521 - Discriminator Loss: 0.000, Generator Loss: 18.772\n",
      "Epoch 531 - Discriminator Loss: 0.000, Generator Loss: 17.256\n",
      "Epoch 541 - Discriminator Loss: 0.000, Generator Loss: 15.760\n",
      "Epoch 551 - Discriminator Loss: 0.000, Generator Loss: 15.565\n",
      "Epoch 561 - Discriminator Loss: 0.000, Generator Loss: 17.915\n",
      "Epoch 571 - Discriminator Loss: 0.076, Generator Loss: 22.822\n",
      "Epoch 581 - Discriminator Loss: 0.129, Generator Loss: 25.300\n",
      "Epoch 591 - Discriminator Loss: 0.111, Generator Loss: 25.578\n",
      "Epoch 601 - Discriminator Loss: 0.000, Generator Loss: 22.073\n",
      "Epoch 611 - Discriminator Loss: 0.000, Generator Loss: 20.375\n",
      "Epoch 621 - Discriminator Loss: 0.000, Generator Loss: 18.644\n",
      "Epoch 631 - Discriminator Loss: 0.000, Generator Loss: 16.938\n",
      "Epoch 641 - Discriminator Loss: 0.000, Generator Loss: 17.473\n",
      "Epoch 651 - Discriminator Loss: 0.000, Generator Loss: 19.695\n",
      "Epoch 661 - Discriminator Loss: 0.000, Generator Loss: 21.406\n",
      "Epoch 671 - Discriminator Loss: 0.174, Generator Loss: 25.328\n",
      "Epoch 681 - Discriminator Loss: 0.175, Generator Loss: 26.152\n",
      "Epoch 691 - Discriminator Loss: 0.007, Generator Loss: 25.943\n",
      "Epoch 701 - Discriminator Loss: 0.000, Generator Loss: 25.418\n",
      "Epoch 711 - Discriminator Loss: 0.000, Generator Loss: 23.445\n",
      "Epoch 721 - Discriminator Loss: 0.000, Generator Loss: 21.947\n",
      "Epoch 731 - Discriminator Loss: 0.000, Generator Loss: 20.428\n",
      "Epoch 741 - Discriminator Loss: 0.000, Generator Loss: 18.908\n",
      "Epoch 751 - Discriminator Loss: 0.000, Generator Loss: 19.603\n",
      "Epoch 761 - Discriminator Loss: 0.000, Generator Loss: 21.713\n",
      "Epoch 771 - Discriminator Loss: 0.001, Generator Loss: 25.349\n",
      "Epoch 781 - Discriminator Loss: 0.053, Generator Loss: 25.664\n",
      "Epoch 791 - Discriminator Loss: 0.052, Generator Loss: 26.439\n",
      "Epoch 801 - Discriminator Loss: 0.003, Generator Loss: 25.971\n",
      "Epoch 811 - Discriminator Loss: 0.000, Generator Loss: 25.605\n",
      "Epoch 821 - Discriminator Loss: 0.000, Generator Loss: 24.452\n",
      "Epoch 831 - Discriminator Loss: 0.000, Generator Loss: 23.190\n",
      "Epoch 841 - Discriminator Loss: 0.000, Generator Loss: 21.577\n",
      "Epoch 851 - Discriminator Loss: 0.000, Generator Loss: 20.152\n",
      "Epoch 861 - Discriminator Loss: 0.000, Generator Loss: 21.056\n",
      "Epoch 871 - Discriminator Loss: 0.000, Generator Loss: 23.187\n",
      "Epoch 881 - Discriminator Loss: 0.000, Generator Loss: 25.246\n",
      "Epoch 891 - Discriminator Loss: 0.076, Generator Loss: 26.679\n",
      "Epoch 901 - Discriminator Loss: 0.017, Generator Loss: 27.050\n",
      "Epoch 911 - Discriminator Loss: 0.073, Generator Loss: 26.860\n",
      "Epoch 921 - Discriminator Loss: 0.001, Generator Loss: 26.399\n",
      "Epoch 931 - Discriminator Loss: 0.011, Generator Loss: 26.059\n",
      "Epoch 941 - Discriminator Loss: 0.017, Generator Loss: 26.126\n",
      "Epoch 951 - Discriminator Loss: 0.080, Generator Loss: 26.124\n",
      "Epoch 961 - Discriminator Loss: 0.002, Generator Loss: 25.359\n",
      "Epoch 971 - Discriminator Loss: 0.008, Generator Loss: 24.637\n",
      "Epoch 981 - Discriminator Loss: 0.000, Generator Loss: 22.789\n",
      "Epoch 991 - Discriminator Loss: 0.000, Generator Loss: 21.665\n",
      "Epoch 1001 - Discriminator Loss: 0.000, Generator Loss: 20.313\n",
      "Epoch 1011 - Discriminator Loss: 0.000, Generator Loss: 18.705\n",
      "Epoch 1021 - Discriminator Loss: 0.000, Generator Loss: 18.484\n",
      "Epoch 1031 - Discriminator Loss: 0.000, Generator Loss: 20.309\n",
      "Epoch 1041 - Discriminator Loss: 0.000, Generator Loss: 21.899\n",
      "Epoch 1051 - Discriminator Loss: 0.000, Generator Loss: 22.933\n",
      "Epoch 1061 - Discriminator Loss: 0.000, Generator Loss: 23.585\n",
      "Epoch 1071 - Discriminator Loss: 0.171, Generator Loss: 26.052\n",
      "Epoch 1081 - Discriminator Loss: 0.289, Generator Loss: 26.296\n",
      "Epoch 1091 - Discriminator Loss: 0.070, Generator Loss: 26.401\n",
      "Epoch 1101 - Discriminator Loss: 0.054, Generator Loss: 25.509\n",
      "Epoch 1111 - Discriminator Loss: 0.075, Generator Loss: 25.552\n",
      "Epoch 1121 - Discriminator Loss: 0.005, Generator Loss: 25.036\n",
      "Epoch 1131 - Discriminator Loss: 0.053, Generator Loss: 25.271\n",
      "Epoch 1141 - Discriminator Loss: 0.070, Generator Loss: 25.093\n",
      "Epoch 1151 - Discriminator Loss: 0.001, Generator Loss: 24.444\n",
      "Epoch 1161 - Discriminator Loss: 0.000, Generator Loss: 23.522\n",
      "Epoch 1171 - Discriminator Loss: 0.000, Generator Loss: 21.650\n",
      "Epoch 1181 - Discriminator Loss: 0.000, Generator Loss: 19.837\n",
      "Epoch 1191 - Discriminator Loss: 0.000, Generator Loss: 18.009\n",
      "Epoch 1201 - Discriminator Loss: 0.000, Generator Loss: 17.809\n",
      "Epoch 1211 - Discriminator Loss: 0.000, Generator Loss: 19.701\n",
      "Epoch 1221 - Discriminator Loss: 0.000, Generator Loss: 21.491\n",
      "Epoch 1231 - Discriminator Loss: 0.000, Generator Loss: 21.957\n",
      "Epoch 1241 - Discriminator Loss: 0.000, Generator Loss: 22.580\n",
      "Epoch 1251 - Discriminator Loss: 0.000, Generator Loss: 22.951\n",
      "Epoch 1261 - Discriminator Loss: 0.000, Generator Loss: 23.398\n",
      "Epoch 1271 - Discriminator Loss: 0.000, Generator Loss: 23.659\n",
      "Epoch 1281 - Discriminator Loss: 0.000, Generator Loss: 23.331\n",
      "Epoch 1291 - Discriminator Loss: 0.000, Generator Loss: 24.920\n",
      "Epoch 1301 - Discriminator Loss: 0.000, Generator Loss: 25.660\n",
      "Epoch 1311 - Discriminator Loss: 0.000, Generator Loss: 25.234\n",
      "Epoch 1321 - Discriminator Loss: 0.000, Generator Loss: 25.779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1331 - Discriminator Loss: 0.071, Generator Loss: 26.260\n",
      "Epoch 1341 - Discriminator Loss: 0.043, Generator Loss: 26.612\n",
      "Epoch 1351 - Discriminator Loss: 0.030, Generator Loss: 26.274\n",
      "Epoch 1361 - Discriminator Loss: 0.001, Generator Loss: 26.524\n",
      "Epoch 1371 - Discriminator Loss: 0.013, Generator Loss: 26.263\n",
      "Epoch 1381 - Discriminator Loss: 0.000, Generator Loss: 26.040\n",
      "Epoch 1391 - Discriminator Loss: 0.014, Generator Loss: 26.329\n",
      "Epoch 1401 - Discriminator Loss: 0.012, Generator Loss: 26.134\n",
      "Epoch 1411 - Discriminator Loss: 0.016, Generator Loss: 26.117\n",
      "Epoch 1421 - Discriminator Loss: 0.007, Generator Loss: 25.923\n",
      "Epoch 1431 - Discriminator Loss: 0.007, Generator Loss: 26.452\n",
      "Epoch 1441 - Discriminator Loss: 0.004, Generator Loss: 26.439\n",
      "Epoch 1451 - Discriminator Loss: 0.024, Generator Loss: 26.134\n",
      "Epoch 1461 - Discriminator Loss: 0.007, Generator Loss: 26.107\n",
      "Epoch 1471 - Discriminator Loss: 0.032, Generator Loss: 26.240\n",
      "Epoch 1481 - Discriminator Loss: 0.024, Generator Loss: 25.791\n",
      "Epoch 1491 - Discriminator Loss: 0.016, Generator Loss: 25.751\n",
      "Epoch 1501 - Discriminator Loss: 0.049, Generator Loss: 25.777\n",
      "Epoch 1511 - Discriminator Loss: 0.057, Generator Loss: 26.075\n",
      "Epoch 1521 - Discriminator Loss: 0.001, Generator Loss: 25.998\n",
      "Epoch 1531 - Discriminator Loss: 0.008, Generator Loss: 25.732\n",
      "Epoch 1541 - Discriminator Loss: 0.002, Generator Loss: 25.783\n",
      "Epoch 1551 - Discriminator Loss: 0.019, Generator Loss: 26.123\n",
      "Epoch 1561 - Discriminator Loss: 0.000, Generator Loss: 25.411\n",
      "Epoch 1571 - Discriminator Loss: 0.031, Generator Loss: 25.919\n",
      "Epoch 1581 - Discriminator Loss: 0.013, Generator Loss: 25.823\n",
      "Epoch 1591 - Discriminator Loss: 0.021, Generator Loss: 26.230\n",
      "Epoch 1601 - Discriminator Loss: 0.001, Generator Loss: 25.612\n",
      "Epoch 1611 - Discriminator Loss: 0.001, Generator Loss: 26.347\n",
      "Epoch 1621 - Discriminator Loss: 0.001, Generator Loss: 25.941\n",
      "Epoch 1631 - Discriminator Loss: 0.004, Generator Loss: 25.903\n",
      "Epoch 1641 - Discriminator Loss: 0.001, Generator Loss: 26.014\n",
      "Epoch 1651 - Discriminator Loss: 0.001, Generator Loss: 25.988\n",
      "Epoch 1661 - Discriminator Loss: 0.000, Generator Loss: 26.157\n",
      "Epoch 1671 - Discriminator Loss: 0.023, Generator Loss: 25.903\n",
      "Epoch 1681 - Discriminator Loss: 0.002, Generator Loss: 26.289\n",
      "Epoch 1691 - Discriminator Loss: 0.000, Generator Loss: 25.988\n",
      "Epoch 1701 - Discriminator Loss: 0.000, Generator Loss: 26.054\n",
      "Epoch 1711 - Discriminator Loss: 0.001, Generator Loss: 26.006\n",
      "Epoch 1721 - Discriminator Loss: 0.014, Generator Loss: 26.207\n",
      "Epoch 1731 - Discriminator Loss: 0.001, Generator Loss: 26.317\n",
      "Epoch 1741 - Discriminator Loss: 0.007, Generator Loss: 26.228\n",
      "Epoch 1751 - Discriminator Loss: 0.018, Generator Loss: 26.396\n",
      "Epoch 1761 - Discriminator Loss: 0.001, Generator Loss: 26.032\n",
      "Epoch 1771 - Discriminator Loss: 0.001, Generator Loss: 26.258\n",
      "Epoch 1781 - Discriminator Loss: 0.004, Generator Loss: 26.356\n",
      "Epoch 1791 - Discriminator Loss: 0.001, Generator Loss: 26.509\n",
      "Epoch 1801 - Discriminator Loss: 0.003, Generator Loss: 26.462\n",
      "Epoch 1811 - Discriminator Loss: 0.001, Generator Loss: 26.389\n",
      "Epoch 1821 - Discriminator Loss: 0.001, Generator Loss: 26.459\n",
      "Epoch 1831 - Discriminator Loss: 0.000, Generator Loss: 26.011\n",
      "Epoch 1841 - Discriminator Loss: 0.001, Generator Loss: 26.203\n",
      "Epoch 1851 - Discriminator Loss: 0.024, Generator Loss: 26.161\n",
      "Epoch 1861 - Discriminator Loss: 0.001, Generator Loss: 26.407\n",
      "Epoch 1871 - Discriminator Loss: 0.000, Generator Loss: 26.203\n",
      "Epoch 1881 - Discriminator Loss: 0.000, Generator Loss: 26.196\n",
      "Epoch 1891 - Discriminator Loss: 0.001, Generator Loss: 26.307\n",
      "Epoch 1901 - Discriminator Loss: 0.003, Generator Loss: 26.243\n",
      "Epoch 1911 - Discriminator Loss: 0.008, Generator Loss: 26.457\n",
      "Epoch 1921 - Discriminator Loss: 0.003, Generator Loss: 26.538\n",
      "Epoch 1931 - Discriminator Loss: 0.003, Generator Loss: 26.080\n",
      "Epoch 1941 - Discriminator Loss: 0.000, Generator Loss: 26.220\n",
      "Epoch 1951 - Discriminator Loss: 0.028, Generator Loss: 25.983\n",
      "Epoch 1961 - Discriminator Loss: 0.004, Generator Loss: 26.207\n",
      "Epoch 1971 - Discriminator Loss: 0.002, Generator Loss: 26.456\n",
      "Epoch 1981 - Discriminator Loss: 0.007, Generator Loss: 26.215\n",
      "Epoch 1991 - Discriminator Loss: 0.043, Generator Loss: 26.321\n",
      "Epoch 2001 - Discriminator Loss: 0.000, Generator Loss: 26.242\n",
      "Epoch 2011 - Discriminator Loss: 0.000, Generator Loss: 26.144\n",
      "Epoch 2021 - Discriminator Loss: 0.001, Generator Loss: 26.269\n",
      "Epoch 2031 - Discriminator Loss: 0.008, Generator Loss: 26.399\n",
      "Epoch 2041 - Discriminator Loss: 0.077, Generator Loss: 26.461\n",
      "Epoch 2051 - Discriminator Loss: 0.049, Generator Loss: 26.533\n",
      "Epoch 2061 - Discriminator Loss: 0.000, Generator Loss: 26.229\n",
      "Epoch 2071 - Discriminator Loss: 0.001, Generator Loss: 26.369\n",
      "Epoch 2081 - Discriminator Loss: 0.000, Generator Loss: 26.314\n",
      "Epoch 2091 - Discriminator Loss: 0.003, Generator Loss: 26.627\n",
      "Epoch 2101 - Discriminator Loss: 0.009, Generator Loss: 26.361\n",
      "Epoch 2111 - Discriminator Loss: 0.028, Generator Loss: 26.676\n",
      "Epoch 2121 - Discriminator Loss: 0.010, Generator Loss: 26.241\n",
      "Epoch 2131 - Discriminator Loss: 0.000, Generator Loss: 26.648\n",
      "Epoch 2141 - Discriminator Loss: 0.000, Generator Loss: 26.472\n",
      "Epoch 2151 - Discriminator Loss: 0.007, Generator Loss: 26.691\n",
      "Epoch 2161 - Discriminator Loss: 0.008, Generator Loss: 26.612\n",
      "Epoch 2171 - Discriminator Loss: 0.002, Generator Loss: 26.486\n",
      "Epoch 2181 - Discriminator Loss: 0.019, Generator Loss: 26.215\n",
      "Epoch 2191 - Discriminator Loss: 0.016, Generator Loss: 26.487\n",
      "Epoch 2201 - Discriminator Loss: 0.000, Generator Loss: 26.659\n",
      "Epoch 2211 - Discriminator Loss: 0.009, Generator Loss: 26.590\n",
      "Epoch 2221 - Discriminator Loss: 0.003, Generator Loss: 26.311\n",
      "Epoch 2231 - Discriminator Loss: 0.014, Generator Loss: 26.780\n",
      "Epoch 2241 - Discriminator Loss: 0.000, Generator Loss: 26.519\n",
      "Epoch 2251 - Discriminator Loss: 0.000, Generator Loss: 26.535\n",
      "Epoch 2261 - Discriminator Loss: 0.001, Generator Loss: 26.311\n",
      "Epoch 2271 - Discriminator Loss: 0.000, Generator Loss: 26.429\n",
      "Epoch 2281 - Discriminator Loss: 0.001, Generator Loss: 26.799\n",
      "Epoch 2291 - Discriminator Loss: 0.000, Generator Loss: 26.759\n",
      "Epoch 2301 - Discriminator Loss: 0.000, Generator Loss: 26.316\n",
      "Epoch 2311 - Discriminator Loss: 0.001, Generator Loss: 26.349\n",
      "Epoch 2321 - Discriminator Loss: 0.002, Generator Loss: 26.376\n",
      "Epoch 2331 - Discriminator Loss: 0.002, Generator Loss: 26.824\n",
      "Epoch 2341 - Discriminator Loss: 0.002, Generator Loss: 26.206\n",
      "Epoch 2351 - Discriminator Loss: 0.003, Generator Loss: 26.269\n",
      "Epoch 2361 - Discriminator Loss: 0.012, Generator Loss: 26.431\n",
      "Epoch 2371 - Discriminator Loss: 0.000, Generator Loss: 26.408\n",
      "Epoch 2381 - Discriminator Loss: 0.000, Generator Loss: 25.982\n",
      "Epoch 2391 - Discriminator Loss: 0.003, Generator Loss: 26.480\n",
      "Epoch 2401 - Discriminator Loss: 0.018, Generator Loss: 26.743\n",
      "Epoch 2411 - Discriminator Loss: 0.002, Generator Loss: 26.553\n",
      "Epoch 2421 - Discriminator Loss: 0.001, Generator Loss: 26.516\n",
      "Epoch 2431 - Discriminator Loss: 0.031, Generator Loss: 26.409\n",
      "Epoch 2441 - Discriminator Loss: 0.000, Generator Loss: 26.513\n",
      "Epoch 2451 - Discriminator Loss: 0.007, Generator Loss: 26.622\n",
      "Epoch 2461 - Discriminator Loss: 0.009, Generator Loss: 26.375\n",
      "Epoch 2471 - Discriminator Loss: 0.000, Generator Loss: 26.422\n",
      "Epoch 2481 - Discriminator Loss: 0.015, Generator Loss: 26.847\n",
      "Epoch 2491 - Discriminator Loss: 0.000, Generator Loss: 26.564\n",
      "Epoch 2501 - Discriminator Loss: 0.004, Generator Loss: 26.645\n",
      "Epoch 2511 - Discriminator Loss: 0.004, Generator Loss: 26.701\n",
      "Epoch 2521 - Discriminator Loss: 0.001, Generator Loss: 26.506\n",
      "Epoch 2531 - Discriminator Loss: 0.000, Generator Loss: 26.501\n",
      "Epoch 2541 - Discriminator Loss: 0.075, Generator Loss: 26.859\n",
      "Epoch 2551 - Discriminator Loss: 0.002, Generator Loss: 26.379\n",
      "Epoch 2561 - Discriminator Loss: 0.002, Generator Loss: 26.501\n",
      "Epoch 2571 - Discriminator Loss: 0.001, Generator Loss: 26.554\n",
      "Epoch 2581 - Discriminator Loss: 0.000, Generator Loss: 26.361\n",
      "Epoch 2591 - Discriminator Loss: 0.000, Generator Loss: 26.414\n",
      "Epoch 2601 - Discriminator Loss: 0.002, Generator Loss: 26.555\n",
      "Epoch 2611 - Discriminator Loss: 0.000, Generator Loss: 26.639\n",
      "Epoch 2621 - Discriminator Loss: 0.000, Generator Loss: 26.664\n",
      "Epoch 2631 - Discriminator Loss: 0.001, Generator Loss: 26.350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2641 - Discriminator Loss: 0.008, Generator Loss: 26.449\n",
      "Epoch 2651 - Discriminator Loss: 0.000, Generator Loss: 26.504\n",
      "Epoch 2661 - Discriminator Loss: 0.001, Generator Loss: 26.628\n",
      "Epoch 2671 - Discriminator Loss: 0.001, Generator Loss: 26.455\n",
      "Epoch 2681 - Discriminator Loss: 0.003, Generator Loss: 26.339\n",
      "Epoch 2691 - Discriminator Loss: 0.006, Generator Loss: 26.523\n",
      "Epoch 2701 - Discriminator Loss: 0.020, Generator Loss: 26.563\n",
      "Epoch 2711 - Discriminator Loss: 0.000, Generator Loss: 26.439\n",
      "Epoch 2721 - Discriminator Loss: 0.008, Generator Loss: 26.560\n",
      "Epoch 2731 - Discriminator Loss: 0.000, Generator Loss: 26.675\n",
      "Epoch 2741 - Discriminator Loss: 0.001, Generator Loss: 26.736\n",
      "Epoch 2751 - Discriminator Loss: 0.001, Generator Loss: 26.457\n",
      "Epoch 2761 - Discriminator Loss: 0.006, Generator Loss: 26.823\n",
      "Epoch 2771 - Discriminator Loss: 0.000, Generator Loss: 26.620\n",
      "Epoch 2781 - Discriminator Loss: 0.007, Generator Loss: 26.861\n",
      "Epoch 2791 - Discriminator Loss: 0.007, Generator Loss: 26.746\n",
      "Epoch 2801 - Discriminator Loss: 0.001, Generator Loss: 26.330\n",
      "Epoch 2811 - Discriminator Loss: 0.001, Generator Loss: 26.629\n",
      "Epoch 2821 - Discriminator Loss: 0.004, Generator Loss: 26.873\n",
      "Epoch 2831 - Discriminator Loss: 0.024, Generator Loss: 26.639\n",
      "Epoch 2841 - Discriminator Loss: 0.013, Generator Loss: 26.901\n",
      "Epoch 2851 - Discriminator Loss: 0.002, Generator Loss: 26.506\n",
      "Epoch 2861 - Discriminator Loss: 0.000, Generator Loss: 26.639\n",
      "Epoch 2871 - Discriminator Loss: 0.001, Generator Loss: 26.708\n",
      "Epoch 2881 - Discriminator Loss: 0.004, Generator Loss: 26.712\n",
      "Epoch 2891 - Discriminator Loss: 0.003, Generator Loss: 26.718\n",
      "Epoch 2901 - Discriminator Loss: 0.001, Generator Loss: 26.954\n",
      "Epoch 2911 - Discriminator Loss: 0.008, Generator Loss: 26.860\n",
      "Epoch 2921 - Discriminator Loss: 0.002, Generator Loss: 26.860\n",
      "Epoch 2931 - Discriminator Loss: 0.000, Generator Loss: 26.714\n",
      "Epoch 2941 - Discriminator Loss: 0.000, Generator Loss: 26.489\n",
      "Epoch 2951 - Discriminator Loss: 0.003, Generator Loss: 26.828\n",
      "Epoch 2961 - Discriminator Loss: 0.000, Generator Loss: 26.744\n",
      "Epoch 2971 - Discriminator Loss: 0.003, Generator Loss: 26.567\n",
      "Epoch 2981 - Discriminator Loss: 0.001, Generator Loss: 26.894\n",
      "Epoch 2991 - Discriminator Loss: 0.000, Generator Loss: 26.769\n",
      "Epoch 3001 - Discriminator Loss: 0.001, Generator Loss: 26.617\n",
      "Epoch 3011 - Discriminator Loss: 0.005, Generator Loss: 26.505\n",
      "Epoch 3021 - Discriminator Loss: 0.000, Generator Loss: 26.673\n",
      "Epoch 3031 - Discriminator Loss: 0.000, Generator Loss: 26.628\n",
      "Epoch 3041 - Discriminator Loss: 0.002, Generator Loss: 26.466\n",
      "Epoch 3051 - Discriminator Loss: 0.003, Generator Loss: 26.625\n",
      "Epoch 3061 - Discriminator Loss: 0.009, Generator Loss: 26.816\n",
      "Epoch 3071 - Discriminator Loss: 0.003, Generator Loss: 26.728\n",
      "Epoch 3081 - Discriminator Loss: 0.006, Generator Loss: 26.794\n",
      "Epoch 3091 - Discriminator Loss: 0.013, Generator Loss: 26.580\n",
      "Epoch 3101 - Discriminator Loss: 0.000, Generator Loss: 26.934\n",
      "Epoch 3111 - Discriminator Loss: 0.001, Generator Loss: 26.518\n",
      "Epoch 3121 - Discriminator Loss: 0.000, Generator Loss: 26.345\n",
      "Epoch 3131 - Discriminator Loss: 0.000, Generator Loss: 26.523\n",
      "Epoch 3141 - Discriminator Loss: 0.000, Generator Loss: 26.626\n",
      "Epoch 3151 - Discriminator Loss: 0.000, Generator Loss: 26.615\n",
      "Epoch 3161 - Discriminator Loss: 0.001, Generator Loss: 26.595\n",
      "Epoch 3171 - Discriminator Loss: 0.001, Generator Loss: 26.623\n",
      "Epoch 3181 - Discriminator Loss: 0.000, Generator Loss: 26.810\n",
      "Epoch 3191 - Discriminator Loss: 0.001, Generator Loss: 26.401\n",
      "Epoch 3201 - Discriminator Loss: 0.001, Generator Loss: 26.587\n",
      "Epoch 3211 - Discriminator Loss: 0.000, Generator Loss: 26.842\n",
      "Epoch 3221 - Discriminator Loss: 0.001, Generator Loss: 26.734\n",
      "Epoch 3231 - Discriminator Loss: 0.012, Generator Loss: 26.666\n",
      "Epoch 3241 - Discriminator Loss: 0.000, Generator Loss: 26.689\n",
      "Epoch 3251 - Discriminator Loss: 0.004, Generator Loss: 26.494\n",
      "Epoch 3261 - Discriminator Loss: 0.000, Generator Loss: 26.827\n",
      "Epoch 3271 - Discriminator Loss: 0.000, Generator Loss: 26.826\n",
      "Epoch 3281 - Discriminator Loss: 0.000, Generator Loss: 26.566\n",
      "Epoch 3291 - Discriminator Loss: 0.001, Generator Loss: 26.702\n",
      "Epoch 3301 - Discriminator Loss: 0.008, Generator Loss: 26.792\n",
      "Epoch 3311 - Discriminator Loss: 0.002, Generator Loss: 26.943\n",
      "Epoch 3321 - Discriminator Loss: 0.000, Generator Loss: 26.788\n",
      "Epoch 3331 - Discriminator Loss: 0.005, Generator Loss: 26.899\n",
      "Epoch 3341 - Discriminator Loss: 0.001, Generator Loss: 26.915\n",
      "Epoch 3351 - Discriminator Loss: 0.001, Generator Loss: 26.840\n",
      "Epoch 3361 - Discriminator Loss: 0.000, Generator Loss: 26.872\n",
      "Epoch 3371 - Discriminator Loss: 0.006, Generator Loss: 26.583\n",
      "Epoch 3381 - Discriminator Loss: 0.000, Generator Loss: 26.626\n",
      "Epoch 3391 - Discriminator Loss: 0.001, Generator Loss: 26.769\n",
      "Epoch 3401 - Discriminator Loss: 0.000, Generator Loss: 26.709\n",
      "Epoch 3411 - Discriminator Loss: 0.005, Generator Loss: 26.518\n",
      "Epoch 3421 - Discriminator Loss: 0.000, Generator Loss: 26.728\n",
      "Epoch 3431 - Discriminator Loss: 0.003, Generator Loss: 26.592\n",
      "Epoch 3441 - Discriminator Loss: 0.001, Generator Loss: 26.857\n",
      "Epoch 3451 - Discriminator Loss: 0.001, Generator Loss: 26.272\n",
      "Epoch 3461 - Discriminator Loss: 0.001, Generator Loss: 26.731\n",
      "Epoch 3471 - Discriminator Loss: 0.000, Generator Loss: 26.702\n",
      "Epoch 3481 - Discriminator Loss: 0.057, Generator Loss: 26.860\n",
      "Epoch 3491 - Discriminator Loss: 0.000, Generator Loss: 26.784\n",
      "Epoch 3501 - Discriminator Loss: 0.000, Generator Loss: 26.722\n",
      "Epoch 3511 - Discriminator Loss: 0.000, Generator Loss: 26.708\n",
      "Epoch 3521 - Discriminator Loss: 0.032, Generator Loss: 26.697\n",
      "Epoch 3531 - Discriminator Loss: 0.008, Generator Loss: 26.589\n",
      "Epoch 3541 - Discriminator Loss: 0.008, Generator Loss: 26.593\n",
      "Epoch 3551 - Discriminator Loss: 0.000, Generator Loss: 26.745\n",
      "Epoch 3561 - Discriminator Loss: 0.011, Generator Loss: 26.710\n",
      "Epoch 3571 - Discriminator Loss: 0.001, Generator Loss: 26.769\n",
      "Epoch 3581 - Discriminator Loss: 0.000, Generator Loss: 26.921\n",
      "Epoch 3591 - Discriminator Loss: 0.007, Generator Loss: 26.749\n",
      "Epoch 3601 - Discriminator Loss: 0.004, Generator Loss: 26.686\n",
      "Epoch 3611 - Discriminator Loss: 0.005, Generator Loss: 26.651\n",
      "Epoch 3621 - Discriminator Loss: 0.018, Generator Loss: 26.945\n",
      "Epoch 3631 - Discriminator Loss: 0.000, Generator Loss: 26.476\n",
      "Epoch 3641 - Discriminator Loss: 0.002, Generator Loss: 26.427\n",
      "Epoch 3651 - Discriminator Loss: 0.000, Generator Loss: 26.380\n",
      "Epoch 3661 - Discriminator Loss: 0.007, Generator Loss: 26.853\n",
      "Epoch 3671 - Discriminator Loss: 0.000, Generator Loss: 26.271\n",
      "Epoch 3681 - Discriminator Loss: 0.001, Generator Loss: 26.469\n",
      "Epoch 3691 - Discriminator Loss: 0.000, Generator Loss: 26.738\n",
      "Epoch 3701 - Discriminator Loss: 0.001, Generator Loss: 26.558\n",
      "Epoch 3711 - Discriminator Loss: 0.001, Generator Loss: 26.711\n",
      "Epoch 3721 - Discriminator Loss: 0.000, Generator Loss: 26.681\n",
      "Epoch 3731 - Discriminator Loss: 0.000, Generator Loss: 26.494\n",
      "Epoch 3741 - Discriminator Loss: 0.015, Generator Loss: 26.587\n",
      "Epoch 3751 - Discriminator Loss: 0.000, Generator Loss: 26.288\n",
      "Epoch 3761 - Discriminator Loss: 0.000, Generator Loss: 26.370\n",
      "Epoch 3771 - Discriminator Loss: 0.001, Generator Loss: 26.519\n",
      "Epoch 3781 - Discriminator Loss: 0.000, Generator Loss: 26.503\n",
      "Epoch 3791 - Discriminator Loss: 0.001, Generator Loss: 26.586\n",
      "Epoch 3801 - Discriminator Loss: 0.004, Generator Loss: 26.708\n",
      "Epoch 3811 - Discriminator Loss: 0.009, Generator Loss: 26.199\n",
      "Epoch 3821 - Discriminator Loss: 0.001, Generator Loss: 26.514\n",
      "Epoch 3831 - Discriminator Loss: 0.000, Generator Loss: 26.467\n",
      "Epoch 3841 - Discriminator Loss: 0.001, Generator Loss: 26.159\n",
      "Epoch 3851 - Discriminator Loss: 0.001, Generator Loss: 26.544\n",
      "Epoch 3861 - Discriminator Loss: 0.007, Generator Loss: 26.428\n",
      "Epoch 3871 - Discriminator Loss: 0.027, Generator Loss: 26.718\n",
      "Epoch 3881 - Discriminator Loss: 0.000, Generator Loss: 26.485\n",
      "Epoch 3891 - Discriminator Loss: 0.003, Generator Loss: 26.735\n",
      "Epoch 3901 - Discriminator Loss: 0.057, Generator Loss: 26.666\n",
      "Epoch 3911 - Discriminator Loss: 0.009, Generator Loss: 26.792\n",
      "Epoch 3921 - Discriminator Loss: 0.002, Generator Loss: 26.550\n",
      "Epoch 3931 - Discriminator Loss: 0.003, Generator Loss: 26.619\n",
      "Epoch 3941 - Discriminator Loss: 0.000, Generator Loss: 26.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3951 - Discriminator Loss: 0.001, Generator Loss: 26.557\n",
      "Epoch 3961 - Discriminator Loss: 0.001, Generator Loss: 26.418\n",
      "Epoch 3971 - Discriminator Loss: 0.005, Generator Loss: 26.660\n",
      "Epoch 3981 - Discriminator Loss: 0.010, Generator Loss: 26.265\n",
      "Epoch 3991 - Discriminator Loss: 0.000, Generator Loss: 26.482\n",
      "Epoch 4001 - Discriminator Loss: 0.001, Generator Loss: 26.772\n",
      "Epoch 4011 - Discriminator Loss: 0.000, Generator Loss: 26.206\n",
      "Epoch 4021 - Discriminator Loss: 0.001, Generator Loss: 26.569\n",
      "Epoch 4031 - Discriminator Loss: 0.001, Generator Loss: 26.708\n",
      "Epoch 4041 - Discriminator Loss: 0.006, Generator Loss: 26.583\n",
      "Epoch 4051 - Discriminator Loss: 0.010, Generator Loss: 26.564\n",
      "Epoch 4061 - Discriminator Loss: 0.001, Generator Loss: 26.740\n",
      "Epoch 4071 - Discriminator Loss: 0.001, Generator Loss: 26.529\n",
      "Epoch 4081 - Discriminator Loss: 0.001, Generator Loss: 26.402\n",
      "Epoch 4091 - Discriminator Loss: 0.020, Generator Loss: 26.389\n",
      "Epoch 4101 - Discriminator Loss: 0.000, Generator Loss: 27.036\n",
      "Epoch 4111 - Discriminator Loss: 0.001, Generator Loss: 26.912\n",
      "Epoch 4121 - Discriminator Loss: 0.000, Generator Loss: 26.480\n",
      "Epoch 4131 - Discriminator Loss: 0.001, Generator Loss: 26.520\n",
      "Epoch 4141 - Discriminator Loss: 0.003, Generator Loss: 26.567\n",
      "Epoch 4151 - Discriminator Loss: 0.002, Generator Loss: 26.067\n",
      "Epoch 4161 - Discriminator Loss: 0.000, Generator Loss: 26.067\n",
      "Epoch 4171 - Discriminator Loss: 0.000, Generator Loss: 26.400\n",
      "Epoch 4181 - Discriminator Loss: 0.007, Generator Loss: 26.541\n",
      "Epoch 4191 - Discriminator Loss: 0.000, Generator Loss: 26.225\n",
      "Epoch 4201 - Discriminator Loss: 0.008, Generator Loss: 26.703\n",
      "Epoch 4211 - Discriminator Loss: 0.003, Generator Loss: 26.582\n",
      "Epoch 4221 - Discriminator Loss: 0.000, Generator Loss: 26.507\n",
      "Epoch 4231 - Discriminator Loss: 0.003, Generator Loss: 26.313\n",
      "Epoch 4241 - Discriminator Loss: 0.002, Generator Loss: 26.336\n",
      "Epoch 4251 - Discriminator Loss: 0.005, Generator Loss: 26.577\n",
      "Epoch 4261 - Discriminator Loss: 0.000, Generator Loss: 26.323\n",
      "Epoch 4271 - Discriminator Loss: 0.000, Generator Loss: 26.401\n",
      "Epoch 4281 - Discriminator Loss: 0.003, Generator Loss: 26.424\n",
      "Epoch 4291 - Discriminator Loss: 0.001, Generator Loss: 26.805\n",
      "Epoch 4301 - Discriminator Loss: 0.001, Generator Loss: 26.706\n",
      "Epoch 4311 - Discriminator Loss: 0.001, Generator Loss: 26.415\n",
      "Epoch 4321 - Discriminator Loss: 0.001, Generator Loss: 26.498\n",
      "Epoch 4331 - Discriminator Loss: 0.022, Generator Loss: 26.723\n",
      "Epoch 4341 - Discriminator Loss: 0.000, Generator Loss: 26.591\n",
      "Epoch 4351 - Discriminator Loss: 0.000, Generator Loss: 26.623\n",
      "Epoch 4361 - Discriminator Loss: 0.000, Generator Loss: 26.643\n",
      "Epoch 4371 - Discriminator Loss: 0.005, Generator Loss: 26.301\n",
      "Epoch 4381 - Discriminator Loss: 0.004, Generator Loss: 26.384\n",
      "Epoch 4391 - Discriminator Loss: 0.002, Generator Loss: 26.631\n",
      "Epoch 4401 - Discriminator Loss: 0.000, Generator Loss: 26.855\n",
      "Epoch 4411 - Discriminator Loss: 0.000, Generator Loss: 26.395\n",
      "Epoch 4421 - Discriminator Loss: 0.000, Generator Loss: 26.483\n",
      "Epoch 4431 - Discriminator Loss: 0.001, Generator Loss: 26.336\n",
      "Epoch 4441 - Discriminator Loss: 0.002, Generator Loss: 26.614\n",
      "Epoch 4451 - Discriminator Loss: 0.000, Generator Loss: 26.671\n",
      "Epoch 4461 - Discriminator Loss: 0.006, Generator Loss: 26.617\n",
      "Epoch 4471 - Discriminator Loss: 0.001, Generator Loss: 26.613\n",
      "Epoch 4481 - Discriminator Loss: 0.004, Generator Loss: 26.753\n",
      "Epoch 4491 - Discriminator Loss: 0.029, Generator Loss: 26.647\n",
      "Epoch 4501 - Discriminator Loss: 0.004, Generator Loss: 26.888\n",
      "Epoch 4511 - Discriminator Loss: 0.004, Generator Loss: 26.980\n",
      "Epoch 4521 - Discriminator Loss: 0.009, Generator Loss: 26.877\n",
      "Epoch 4531 - Discriminator Loss: 0.000, Generator Loss: 26.414\n",
      "Epoch 4541 - Discriminator Loss: 0.001, Generator Loss: 26.702\n",
      "Epoch 4551 - Discriminator Loss: 0.003, Generator Loss: 26.802\n",
      "Epoch 4561 - Discriminator Loss: 0.001, Generator Loss: 26.897\n",
      "Epoch 4571 - Discriminator Loss: 0.000, Generator Loss: 26.844\n",
      "Epoch 4581 - Discriminator Loss: 0.002, Generator Loss: 26.721\n",
      "Epoch 4591 - Discriminator Loss: 0.005, Generator Loss: 26.600\n",
      "Epoch 4601 - Discriminator Loss: 0.006, Generator Loss: 26.321\n",
      "Epoch 4611 - Discriminator Loss: 0.000, Generator Loss: 26.458\n",
      "Epoch 4621 - Discriminator Loss: 0.007, Generator Loss: 26.938\n",
      "Epoch 4631 - Discriminator Loss: 0.001, Generator Loss: 26.615\n",
      "Epoch 4641 - Discriminator Loss: 0.001, Generator Loss: 26.418\n",
      "Epoch 4651 - Discriminator Loss: 0.000, Generator Loss: 26.486\n",
      "Epoch 4661 - Discriminator Loss: 0.000, Generator Loss: 26.602\n",
      "Epoch 4671 - Discriminator Loss: 0.000, Generator Loss: 26.674\n",
      "Epoch 4681 - Discriminator Loss: 0.000, Generator Loss: 26.797\n",
      "Epoch 4691 - Discriminator Loss: 0.003, Generator Loss: 26.608\n",
      "Epoch 4701 - Discriminator Loss: 0.000, Generator Loss: 26.459\n",
      "Epoch 4711 - Discriminator Loss: 0.004, Generator Loss: 26.647\n",
      "Epoch 4721 - Discriminator Loss: 0.000, Generator Loss: 26.766\n",
      "Epoch 4731 - Discriminator Loss: 0.001, Generator Loss: 26.919\n",
      "Epoch 4741 - Discriminator Loss: 0.002, Generator Loss: 26.691\n",
      "Epoch 4751 - Discriminator Loss: 0.001, Generator Loss: 26.780\n",
      "Epoch 4761 - Discriminator Loss: 0.000, Generator Loss: 26.699\n",
      "Epoch 4771 - Discriminator Loss: 0.025, Generator Loss: 26.973\n",
      "Epoch 4781 - Discriminator Loss: 0.001, Generator Loss: 26.642\n",
      "Epoch 4791 - Discriminator Loss: 0.030, Generator Loss: 26.633\n",
      "Epoch 4801 - Discriminator Loss: 0.002, Generator Loss: 26.446\n",
      "Epoch 4811 - Discriminator Loss: 0.001, Generator Loss: 26.749\n",
      "Epoch 4821 - Discriminator Loss: 0.000, Generator Loss: 26.535\n",
      "Epoch 4831 - Discriminator Loss: 0.000, Generator Loss: 26.550\n",
      "Epoch 4841 - Discriminator Loss: 0.000, Generator Loss: 26.234\n",
      "Epoch 4851 - Discriminator Loss: 0.000, Generator Loss: 26.175\n",
      "Epoch 4861 - Discriminator Loss: 0.000, Generator Loss: 26.512\n",
      "Epoch 4871 - Discriminator Loss: 0.000, Generator Loss: 26.543\n",
      "Epoch 4881 - Discriminator Loss: 0.002, Generator Loss: 26.628\n",
      "Epoch 4891 - Discriminator Loss: 0.042, Generator Loss: 26.525\n",
      "Epoch 4901 - Discriminator Loss: 0.031, Generator Loss: 26.346\n",
      "Epoch 4911 - Discriminator Loss: 0.012, Generator Loss: 26.595\n",
      "Epoch 4921 - Discriminator Loss: 0.001, Generator Loss: 26.560\n",
      "Epoch 4931 - Discriminator Loss: 0.005, Generator Loss: 26.536\n",
      "Epoch 4941 - Discriminator Loss: 0.001, Generator Loss: 26.584\n",
      "Epoch 4951 - Discriminator Loss: 0.005, Generator Loss: 26.685\n",
      "Epoch 4961 - Discriminator Loss: 0.001, Generator Loss: 26.889\n",
      "Epoch 4971 - Discriminator Loss: 0.001, Generator Loss: 26.298\n",
      "Epoch 4981 - Discriminator Loss: 0.001, Generator Loss: 26.772\n",
      "Epoch 4991 - Discriminator Loss: 0.000, Generator Loss: 26.333\n"
     ]
    }
   ],
   "source": [
    "# Training DCGANs\n",
    "for epoch in range(num_epochs):\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    synthentic_data = []\n",
    "    for i, fraud_data in enumerate(train_loader):\n",
    "        # Updating the weights of the Discriminator\n",
    "        discriminator.zero_grad() # Initialize gradients of the Discriminator to 0\n",
    "        \n",
    "        mini_batch = fraud_data.size()[0]\n",
    "        \n",
    "        # Wrap data in PyTorch Variable\n",
    "        d_real_data = Variable(fraud_data[0])\n",
    "        y_real = Variable(torch.ones(1))\n",
    "        y_fake = Variable(torch.zeros(1))\n",
    "\n",
    "        # Training the Discriminator with real data\n",
    "        d_real_result = discriminator(d_real_data) # Forward propagate this real data into the neural network\n",
    "        d_real_loss = BCE_loss(d_real_result, y_real) # Compute the loss between the prediction and actual\n",
    "        d_real_loss.backward()\n",
    "    \n",
    "        # Inject fake data to the generator\n",
    "        d_gen_input = Variable(torch.randn(minibatch_size, g_input_size))\n",
    "        d_fake_data = generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        \n",
    "        # Train the Discriminator with a fake data generated by the Generator\n",
    "        d_fake_result = discriminator(d_fake_data.t())\n",
    "        d_fake_loss = BCE_loss(d_fake_result, y_fake)  # zeros = fake\n",
    "        d_fake_loss.backward()\n",
    "        \n",
    "        # Combine discriminator loss from real data and fake data\n",
    "        d_train_loss = d_real_loss + d_fake_loss\n",
    "        \n",
    "        #d_train_loss.backward()\n",
    "        d_optimizer.step()     # Apply SGD to update the weight\n",
    "        d_losses.append(d_train_loss.data[0])\n",
    "        \n",
    "        # Update the weight of the Generator \n",
    "        generator.zero_grad()\n",
    "        gen_input = Variable(torch.randn(minibatch_size, g_input_size))  \n",
    "        g_fake_data = generator(gen_input)\n",
    "        \n",
    "        dg_fake_result = discriminator(g_fake_data.t())\n",
    "        g_loss = BCE_loss(dg_fake_result, y_real)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        g_losses.append(g_loss.data[0])\n",
    "        \n",
    "        synthentic_data.append(d_fake_data.t())\n",
    "        \n",
    "    if epoch % print_interval == 0:       \n",
    "        print('Epoch {} - Discriminator Loss: {:.3f}, Generator Loss: {:.3f}'.format((epoch + 1), \n",
    "                          torch.mean(torch.FloatTensor(d_losses)), torch.mean(torch.FloatTensor(g_losses))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x108a1fd30>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(d_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x108afcc88>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(g_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.3822,  0.0317,  0.0014, -0.0450, -0.1218, -0.0108, -0.0986,\n",
       "          -0.0724, -3.0409,  0.0034, -2.2768, -0.4490, -1.7581,  0.0028,\n",
       "          -0.0362,  1.4236, -0.0833, -0.0115,  0.5943, -0.0314, -0.1327,\n",
       "          -0.1249,  0.0042, -0.2262, -0.1904,  1.7413, -0.0036,  0.4067,\n",
       "           1.1211]]),\n",
       " tensor([[ 0.7645,  0.1375,  0.0031, -0.1066, -0.0364, -3.0884,  0.7573,\n",
       "          -0.0319,  0.0049,  0.0044, -2.7916, -2.9899,  2.6977, -0.0862,\n",
       "          -0.0471,  0.0029, -0.0195, -0.0378, -3.1178,  0.7503, -0.0237,\n",
       "           2.6920, -0.1083,  0.2422,  0.0040,  2.5488, -0.0573, -0.0106,\n",
       "           0.7746]]),\n",
       " tensor([[-0.2057, -0.0811, -1.9128,  2.5443,  0.2132, -0.0095, -0.0465,\n",
       "           1.4691, -0.1399, -0.1024, -0.0902, -0.0934,  0.0045,  0.0052,\n",
       "           0.5008,  0.4118,  0.0044,  0.8030, -0.0174, -0.1112, -0.0438,\n",
       "           2.4512,  1.1232, -0.1235,  0.0051, -0.1376, -0.1071, -0.3311,\n",
       "           0.0134]]),\n",
       " tensor([[-0.1421, -0.1305, -0.0774,  2.5110, -1.6641, -0.0601,  2.6373,\n",
       "          -2.6837,  0.6165,  0.0036, -0.0020, -0.1034,  0.7766,  0.0166,\n",
       "           0.0012,  0.8192,  0.5695, -2.8445, -0.0025, -0.0593, -0.0011,\n",
       "           0.0040, -0.0538,  2.5270,  0.6608,  0.0039, -3.2777,  0.7782,\n",
       "          -0.2753]]),\n",
       " tensor([[-0.1348,  0.0008,  0.2220,  2.0922, -0.1016, -0.0281,  0.0038,\n",
       "           0.4619, -0.0915, -0.7889,  2.3912, -0.5308, -0.0016,  2.7731,\n",
       "           0.0027, -0.1285,  2.4874, -0.0649, -0.1195,  0.8312, -0.0016,\n",
       "          -0.0012, -0.0005,  0.3198, -0.3683, -0.1078, -0.1272, -0.0443,\n",
       "           2.0960]]),\n",
       " tensor([[-0.1132, -0.1157, -3.3004, -0.0071, -0.0194, -0.0466,  0.0021,\n",
       "          -3.0832, -0.1165, -0.1116, -0.0008, -0.4941,  1.7485,  0.7749,\n",
       "           1.6136, -0.0008,  0.5468,  0.7329, -0.5947,  0.4552, -0.1332,\n",
       "          -0.0505, -0.0705, -0.0120, -0.2470, -0.0194, -0.0864, -2.5574,\n",
       "          -0.0487]]),\n",
       " tensor([[-0.1200,  2.5739, -0.1307,  0.7390, -0.0792,  0.0011, -3.1044,\n",
       "          -0.1235, -2.9076,  0.0016,  0.7001, -0.4043, -0.0809, -0.1349,\n",
       "          -0.1304, -0.5683, -0.2117,  0.8022,  2.3341,  2.5421, -0.0038,\n",
       "          -0.0187, -0.0180, -0.0300, -0.0134, -0.1309, -0.0084, -0.0219,\n",
       "          -0.1145]]),\n",
       " tensor([[-0.0284, -0.1296, -0.0016, -0.1958,  0.4970, -0.0676,  0.2022,\n",
       "           0.6850, -0.0015, -0.0200, -0.3522, -0.1238, -0.5610, -0.3423,\n",
       "           0.1290, -0.0669, -0.1242, -0.0233, -0.0082, -0.0838, -0.0077,\n",
       "          -0.0071, -0.1212,  0.0013, -0.0387,  2.5502, -0.6476, -3.0882,\n",
       "          -0.0554]]),\n",
       " tensor([[ 0.0019, -0.0710,  0.0024,  1.4634, -0.0138,  0.0023, -0.1117,\n",
       "          -0.0331,  2.4260, -0.0924, -0.1306,  0.1553, -0.1131, -0.0934,\n",
       "          -0.0171, -0.0507, -0.0931,  2.5516, -0.0291, -0.1345,  0.7480,\n",
       "          -0.0161, -0.0900, -0.0735, -0.0038, -0.0149,  0.0003, -0.0007,\n",
       "          -0.1253]]),\n",
       " tensor([[-2.0943e-01, -8.4061e-03, -1.4886e-02, -5.8313e-02, -5.3390e-02,\n",
       "          -7.5513e-03,  2.5013e+00, -1.1754e-01, -4.8869e-02, -5.9617e-02,\n",
       "           6.8889e-01, -9.3345e-05,  2.7395e+00,  2.4062e-03, -1.1381e-02,\n",
       "          -1.3815e-01,  7.3375e-01, -3.5393e-02,  2.2050e-03, -2.4742e+00,\n",
       "           2.6510e-03, -1.2142e-01, -5.8300e-01, -2.3689e-03,  2.3225e-01,\n",
       "          -1.2726e-01, -9.2937e-02, -4.7190e-03, -1.4964e-04]]),\n",
       " tensor([[ 2.6703, -0.1163, -0.0331, -0.0440, -0.1242,  2.5106, -0.1388,\n",
       "          -0.1302, -0.1214, -0.0636, -0.0084,  0.5868, -0.1127, -0.0156,\n",
       "           0.2344, -2.9429, -0.1372, -0.4500, -0.0084, -0.0004,  0.0475,\n",
       "           0.6851,  2.2898,  0.2982, -0.0964,  0.2592, -0.3953, -0.0328,\n",
       "           2.8258]]),\n",
       " tensor([[-0.0792,  2.5691,  0.7347, -0.0725, -0.3496, -0.5793, -0.1233,\n",
       "           2.4676, -0.1389, -2.6390, -0.0240, -0.1387, -0.3720,  0.0007,\n",
       "          -0.0623, -0.0163, -0.1091, -0.0033, -0.1072, -0.1411, -0.0003,\n",
       "          -1.7405, -0.0063,  0.7719, -0.1393, -0.1315, -0.1087, -0.1409,\n",
       "          -0.1294]]),\n",
       " tensor([[-1.0810e-02, -2.6899e-04, -4.7409e-02, -1.0880e-02, -9.7621e-03,\n",
       "          -1.3853e-02, -4.1471e-02, -1.6387e-02, -2.8935e-03, -6.0583e-03,\n",
       "          -1.3030e-03, -4.8953e-02,  3.5083e-01, -2.4691e-02, -1.3901e-03,\n",
       "          -5.0702e-02,  7.9530e-01, -3.2683e-02, -5.3493e-02, -1.3820e-01,\n",
       "           2.3515e+00, -1.7075e-02, -2.9004e-03, -1.3732e-01,  4.7198e-05,\n",
       "           7.6924e-01, -6.2400e-02, -3.2613e-02, -4.1641e-03]]),\n",
       " tensor([[-0.0044, -0.0632,  0.4631, -0.1147,  0.8217, -0.0342, -0.0137,\n",
       "          -0.0916, -0.0675,  2.7398, -0.2217, -0.0872, -0.0472, -0.0478,\n",
       "          -0.0169,  0.7998, -0.1271, -0.0686, -0.2098, -0.0023,  0.7429,\n",
       "          -0.5624, -0.5203, -0.1418, -0.0982, -0.1444, -0.1122, -0.0028,\n",
       "          -0.0406]]),\n",
       " tensor([[-0.0198, -0.0855, -0.0052, -0.0280, -0.5874, -0.0668, -0.3750,\n",
       "           0.4807, -0.0391, -0.0832, -0.1309,  2.5370, -0.0032, -0.0587,\n",
       "           0.6420, -0.0074,  0.6468,  0.6908, -1.1990, -0.1028, -0.1333,\n",
       "          -0.0678,  2.2400, -0.0211, -0.1326,  2.5705, -0.1001, -0.0332,\n",
       "          -0.0505]]),\n",
       " tensor([[-0.0004, -0.0078,  0.7588, -3.1281,  0.7445, -0.0051, -0.0340,\n",
       "          -0.0238, -0.0303, -0.0003,  0.7169,  0.7102, -0.1407, -0.0571,\n",
       "          -0.0358,  2.5684,  0.7308, -0.1760,  0.7038, -0.0075, -0.1028,\n",
       "          -0.0233, -0.0555, -0.0089, -0.5085, -3.1533, -0.0311, -0.0890,\n",
       "           0.6316]]),\n",
       " tensor([[-0.0164, -0.3306,  0.1810, -0.1292, -0.0323, -0.0817, -0.0447,\n",
       "          -0.1300,  0.0002, -0.0494, -0.0030, -0.0230, -1.6422, -0.0243,\n",
       "           0.6251, -0.1158, -0.4679, -0.0026, -2.4847, -0.0078,  2.6436,\n",
       "          -0.0740, -0.0094,  1.9311, -0.1373, -0.0086,  2.6951,  0.7967,\n",
       "          -2.6960]]),\n",
       " tensor([[ 0.6110, -0.0001, -0.5690, -0.1247, -0.4669, -0.1223,  2.5334,\n",
       "          -0.2582,  2.6494, -0.0007, -0.0334, -0.0400, -0.0626, -0.0170,\n",
       "           0.7457,  0.6419, -0.0675, -0.0306, -0.0098, -0.0538, -0.0467,\n",
       "           0.7549, -0.2312,  0.3563,  2.6880, -0.0079, -0.5753, -0.0789,\n",
       "           0.6240]]),\n",
       " tensor([[-2.2881, -0.1056, -0.0460,  2.6269, -0.0841, -0.0021, -0.0425,\n",
       "          -0.2010, -0.1263, -0.0184, -0.0253, -0.1251, -0.0372, -0.1371,\n",
       "           2.5565, -0.1250, -0.1030, -0.0336, -0.0920, -0.3695,  2.6454,\n",
       "           1.0862,  0.7704, -0.1255,  2.6921, -0.0567, -0.0085,  2.5723,\n",
       "          -0.0867]]),\n",
       " tensor([[-0.0741, -0.0012, -0.2675, -0.0884, -0.1281, -0.0009, -0.0162,\n",
       "          -3.2795, -0.9781, -0.0056, -0.1114, -0.1206, -0.1362,  0.0016,\n",
       "          -0.0930, -0.0954,  2.6855,  0.2610, -0.0124, -0.0342,  0.7939,\n",
       "          -0.1046,  0.0977, -0.4323, -0.0244, -0.0325, -0.1235,  0.7390,\n",
       "           0.4485]]),\n",
       " tensor([[-0.1467, -0.1318,  2.3713, -0.0107, -0.0474, -0.1327, -0.1140,\n",
       "          -0.0907, -0.0414, -0.0067,  0.7318, -0.0054,  2.0865, -0.1331,\n",
       "          -0.0777, -0.0752, -0.0126, -0.0706, -0.0807, -0.0560,  0.7603,\n",
       "          -0.0500,  0.2509, -0.0107, -0.0303, -0.1174,  0.6852,  1.7998,\n",
       "          -0.1316]]),\n",
       " tensor([[ 0.2104, -0.0075, -0.5236,  2.7391,  2.6039,  0.3747,  0.7491,\n",
       "          -0.1482,  0.1618, -0.0107, -0.6410, -0.0279,  0.6971, -0.0749,\n",
       "          -0.0205, -0.0704,  2.5855, -0.1153, -0.0634, -0.0454,  0.7683,\n",
       "          -0.1161, -0.0229,  2.6252, -0.0679,  0.4794, -0.1167, -0.0068,\n",
       "          -0.0083]]),\n",
       " tensor([[-0.0072, -0.1242, -0.0104, -0.0110, -0.0106,  0.5450, -0.1771,\n",
       "          -0.0355, -0.0109, -0.1054,  0.6410, -0.0074, -0.4241, -0.0382,\n",
       "           0.7757, -0.0794, -0.0635, -0.0104,  2.5266, -0.0324, -0.0125,\n",
       "          -0.0093, -0.1407,  0.0514, -0.1113, -0.0285, -0.1412, -0.0103,\n",
       "          -0.0342]]),\n",
       " tensor([[-0.6308, -0.0158, -0.2401, -0.3483, -0.0192,  0.7746, -0.2671,\n",
       "          -0.0806, -0.0356, -0.0086,  2.5429, -0.0107,  2.3391, -0.1419,\n",
       "          -0.0079, -2.8720,  0.7392,  0.4085, -0.1055,  0.7509,  0.7435,\n",
       "          -0.5661, -0.0317,  0.7195,  2.5070, -1.9224, -0.0138, -0.0086,\n",
       "          -0.1078]]),\n",
       " tensor([[-0.0477, -0.0106, -0.0559, -0.1404, -0.0443, -0.0086, -0.0128,\n",
       "          -0.0099, -2.1446, -0.0174, -1.9553, -0.0395, -0.0197, -0.0476,\n",
       "           0.7390,  2.6084, -0.0096, -0.0409,  0.7616, -0.1465, -0.0132,\n",
       "          -0.0135, -0.0689, -0.0631, -0.5230, -0.5812, -0.1111,  0.0360,\n",
       "          -0.1257]]),\n",
       " tensor([[-0.0088,  0.6862, -0.1366, -3.1495, -0.0093,  1.8705,  0.7352,\n",
       "          -0.1400,  0.7768, -0.3395,  0.7636, -0.0193, -0.0698,  0.4580,\n",
       "          -0.0179, -0.1935, -0.1107,  0.5935,  2.7219, -0.0119, -0.0427,\n",
       "           0.7631, -0.0100, -0.0278, -0.0206, -0.1060, -0.2868, -0.5640,\n",
       "          -0.0287]]),\n",
       " tensor([[-0.0126, -0.0107, -0.0802,  1.4595, -0.1416, -0.0123, -0.0444,\n",
       "           0.4082, -0.0611, -0.0571, -3.1531, -0.0133, -0.0298, -0.1866,\n",
       "          -0.1460, -0.0434, -0.1050, -0.1138, -0.0107,  0.7599, -0.1469,\n",
       "          -0.0778,  1.7042, -0.1497, -0.0101,  2.8234, -0.2162, -0.1490,\n",
       "          -0.0104]]),\n",
       " tensor([[ 0.6889, -0.0582,  0.4896, -0.0597, -0.0790, -0.0826, -0.0142,\n",
       "          -0.1247,  0.1223,  0.7758, -0.0224, -0.0742,  0.3006, -0.0261,\n",
       "          -0.0117, -0.0591, -0.0142,  0.6378, -0.1332, -0.0200, -0.0092,\n",
       "          -0.0203,  0.7323, -0.0241,  1.6751, -0.0381, -0.0790,  0.0296,\n",
       "          -0.0359]]),\n",
       " tensor([[-0.0421, -0.1086, -0.0093, -0.1269, -0.0113, -0.0125, -0.1594,\n",
       "          -0.1086, -0.1111,  0.7741,  0.6706, -0.0342, -0.1363,  0.5583,\n",
       "          -0.0177, -0.0100,  1.9176, -0.0111,  0.7596, -0.0096, -0.1482,\n",
       "          -0.0143,  2.8173, -0.0513, -0.1233, -0.0219, -0.1157, -0.0100,\n",
       "          -2.5745]]),\n",
       " tensor([[-0.0174, -0.0642, -3.0852, -0.1140,  0.2013,  0.4340, -0.0148,\n",
       "          -0.1001, -1.3547, -0.0271, -0.1734, -0.0251, -0.0661, -0.1229,\n",
       "          -0.2210, -0.1089,  1.3875, -3.1567, -0.0118, -0.0132, -0.0285,\n",
       "           0.7599, -0.0817, -0.0967, -0.1235, -0.0095, -2.9092,  0.0086,\n",
       "          -0.3564]]),\n",
       " tensor([[ 2.1238, -0.0098,  0.3010, -0.4010, -2.6117, -0.0108,  2.4135,\n",
       "           0.8193, -2.7758,  2.5337, -2.7287,  0.7626, -0.1038, -0.0401,\n",
       "          -0.0202, -0.0130,  0.2234,  0.8006, -3.1939, -0.0420, -0.0321,\n",
       "           0.6860,  1.0837, -0.0193, -0.1422, -0.1378,  0.7605, -0.0098,\n",
       "          -0.2401]]),\n",
       " tensor([[-0.0604,  0.4509, -0.0117, -0.0098, -0.0754, -0.0150, -0.1192,\n",
       "          -0.0520, -0.0931, -0.2515, -0.1300, -0.0243, -0.0555, -0.0571,\n",
       "          -0.0167, -0.1245,  0.7500, -0.5505, -0.1164, -0.0779,  0.8031,\n",
       "          -0.3812,  0.7688,  2.3817, -0.1201, -0.0490,  0.7271,  0.6636,\n",
       "          -0.4032]]),\n",
       " tensor([[ 2.6003,  2.1796, -0.1135, -0.0623,  2.6991, -0.0171, -0.0572,\n",
       "          -0.0544,  0.7566, -0.0440,  0.7775, -0.5367, -0.0257,  0.5464,\n",
       "          -0.1061, -0.0937, -0.0120, -0.1391, -0.8270, -0.3789, -0.0142,\n",
       "          -0.0230, -0.1158, -0.0103,  0.0295, -0.1278, -0.1431, -0.1240,\n",
       "          -0.0292]]),\n",
       " tensor([[ 0.7239,  2.5378,  2.0448, -0.0470, -0.3224, -0.0144, -0.1276,\n",
       "           1.8976, -0.0342, -0.1183,  0.6513, -0.1491, -0.0105,  0.6181,\n",
       "           0.6677,  0.7495, -0.1425, -0.1431, -0.0235, -0.0623, -0.0092,\n",
       "           2.7594, -0.0087,  2.5926, -0.1879, -0.0098, -0.0097, -0.0107,\n",
       "          -0.0560]]),\n",
       " tensor([[ 0.3775, -0.3793, -0.0564,  0.7313,  0.4798, -0.0538,  0.0084,\n",
       "           0.0125,  0.7595, -0.0201, -0.0081,  0.0722, -0.0091, -0.1946,\n",
       "           0.3323, -0.0084, -0.1054,  2.5513,  0.1975, -0.1502, -0.6476,\n",
       "           0.7682, -0.0781, -0.0598, -0.1172, -0.0451, -0.0627, -0.0377,\n",
       "          -0.3304]]),\n",
       " tensor([[-0.1363, -0.1442, -0.1472, -0.1350, -0.0656, -0.4022, -0.0217,\n",
       "           0.7029, -0.0437, -0.0317, -0.0551, -0.0901,  1.1453,  0.1418,\n",
       "          -0.5555, -0.1400, -3.0998,  0.7737, -0.0104, -0.5769, -0.0491,\n",
       "          -0.0637, -0.0367, -0.1441, -0.5596, -0.0091, -0.0309, -0.0077,\n",
       "          -0.0235]]),\n",
       " tensor([[-0.0386, -2.2087, -0.6210, -2.7835,  2.6884, -0.1259, -0.0300,\n",
       "          -0.1313,  0.7369, -0.1395,  0.7487, -0.1620,  0.5262, -0.1334,\n",
       "          -0.0225, -0.0844, -0.0101, -0.0265,  0.4454, -0.0240, -0.0485,\n",
       "          -0.0245, -0.0117,  0.5578,  0.1790, -0.0224, -0.0944, -2.9150,\n",
       "          -0.1174]]),\n",
       " tensor([[-0.0105, -0.0119, -0.1001,  2.7311, -0.0085,  2.5503, -0.1386,\n",
       "          -0.0480, -0.0924, -0.1417, -0.0113,  2.9562,  2.6850, -0.1359,\n",
       "          -0.1439, -0.4149,  2.5792, -0.0126,  0.5316, -0.5494, -0.1452,\n",
       "          -0.2329, -0.0126, -0.1154, -0.0097, -0.0540, -0.1128, -0.0098,\n",
       "          -0.0341]]),\n",
       " tensor([[-0.0499,  1.2822, -0.1423, -0.1421, -0.1524, -0.0130,  0.7649,\n",
       "           0.1669,  1.2955, -0.0133, -0.0082,  2.5966,  1.3429, -1.4493,\n",
       "          -0.1076, -0.0411, -0.0122, -0.0191,  2.5369, -0.1283,  0.6463,\n",
       "          -0.0097, -0.0573, -0.0903,  0.1215, -0.0213, -0.1124, -0.1246,\n",
       "           2.7497]]),\n",
       " tensor([[ 0.7517,  2.5220, -0.0198, -0.0514, -0.1221,  0.2307, -0.1477,\n",
       "          -0.5631, -0.1128,  2.8160, -3.2218, -0.0715, -0.1087, -0.1323,\n",
       "          -0.3101,  1.8981,  0.7571, -0.0349, -0.1360, -0.0655,  2.6688,\n",
       "           0.7257, -0.1739, -0.1056, -0.0162, -0.0078,  0.0497, -1.9636,\n",
       "          -0.0153]]),\n",
       " tensor([[-0.1278, -0.0866,  0.7233,  1.3228,  0.7337, -0.0892, -0.0252,\n",
       "           2.5588, -0.0318, -0.4364, -3.2581, -0.1373, -0.0806, -0.0078,\n",
       "          -0.0225, -0.0781, -0.0169, -0.0431, -0.0834, -0.0792, -0.0233,\n",
       "          -0.0423, -0.2926, -0.1269, -0.0948,  2.5411, -0.2821, -0.0684,\n",
       "          -2.3058]]),\n",
       " tensor([[-0.0600,  0.0002, -0.2166, -0.0056, -0.0844,  0.1428, -1.6251,\n",
       "          -0.7436, -2.7065,  1.9147, -0.0031, -0.0012,  0.0198, -0.9753,\n",
       "           1.7009,  1.3823, -0.1412,  0.7604, -0.0577,  1.9451, -0.5303,\n",
       "           1.3426, -0.6078, -0.0499, -0.1215, -0.1504, -0.0009,  1.5023,\n",
       "           0.7748]]),\n",
       " tensor([[ 1.9284, -0.1177, -0.6343,  0.4744, -0.0130, -0.5543, -0.0176,\n",
       "          -0.0046,  0.7666,  0.7579,  0.7810, -0.5851, -0.0132,  0.9333,\n",
       "           0.7717,  0.7593,  2.6009, -0.0531, -0.4417,  0.3404, -0.1132,\n",
       "           0.7731, -2.5745, -2.9544, -0.1376, -0.1382, -0.0729, -0.0283,\n",
       "          -0.6210]]),\n",
       " tensor([[ 0.0049,  0.2222,  0.6919, -0.1992,  0.6917,  0.0056, -0.1350,\n",
       "          -0.0028, -0.3427,  0.7740, -3.2645, -0.0930, -0.1177, -0.0077,\n",
       "          -0.0773, -0.0708, -0.0222, -0.0495, -0.1301, -0.0046,  0.0023,\n",
       "          -0.1066, -0.0017, -0.0005,  0.0041, -0.1853,  0.4053,  2.6601,\n",
       "           2.8333]]),\n",
       " tensor([[-0.0681, -0.0096,  0.0027, -2.7218,  0.6720,  2.6811,  0.0065,\n",
       "           0.0003,  0.0053, -0.0369, -0.1082,  0.7930, -0.1190,  2.6580,\n",
       "          -0.0037, -0.1358,  0.1302, -0.1387,  0.7619, -0.0594, -0.0072,\n",
       "          -0.1296, -0.1251, -0.0921,  0.7658,  2.7478, -0.0032, -0.0079,\n",
       "          -0.0528]]),\n",
       " tensor([[ 0.0068, -0.1256, -3.0464,  0.0057,  0.0019, -0.0273, -0.0231,\n",
       "           0.0064,  0.4818, -0.0008, -0.0591, -1.1341,  0.0020, -0.1402,\n",
       "          -0.0300, -0.0856, -0.0074, -0.0604, -0.0416,  0.0008,  0.4828,\n",
       "          -0.6012,  0.7704, -0.0384,  0.4744, -0.0777, -0.0526, -0.0114,\n",
       "          -0.0743]]),\n",
       " tensor([[ 0.0042,  0.0055,  0.0797, -0.1207,  0.3078, -0.0386,  0.0015,\n",
       "          -0.0069, -0.0829,  0.0068, -0.1332, -0.5507, -0.0494,  0.0073,\n",
       "          -0.1725,  0.9837, -0.1118,  0.0067, -0.0946, -0.1600, -2.0818,\n",
       "          -0.0027, -0.0128,  0.0046, -0.1058,  2.5775, -0.2685,  0.0040,\n",
       "           0.0057]]),\n",
       " tensor([[-0.0898, -0.4302,  0.0061,  0.8081, -0.0257, -0.0426,  0.0009,\n",
       "          -0.0677, -2.6800,  0.5961, -0.0248,  2.5675, -0.0038, -0.0164,\n",
       "           0.5932, -0.1979,  0.7430,  0.0053,  1.1860, -0.0047,  0.0652,\n",
       "           0.0067,  2.5633, -0.1248,  0.4775, -0.1250, -0.2637,  0.0061,\n",
       "           2.5138]]),\n",
       " tensor([[-0.0890, -0.1036, -0.6392,  0.7115, -0.0083, -2.9390,  2.5720,\n",
       "           0.0071,  0.0031, -0.0747, -0.2976, -0.3116,  0.0050, -0.0500,\n",
       "           0.0048, -0.0265,  0.7525,  0.0537,  2.5918, -0.0420, -3.1561,\n",
       "           0.0057, -0.0042, -0.1191, -0.0802,  0.7335,  0.0074, -0.0012,\n",
       "          -0.0763]]),\n",
       " tensor([[ 0.0064,  0.0066,  0.0070, -0.0288,  0.7175,  2.2525,  0.0048,\n",
       "           0.0058, -0.0125,  2.0094, -0.0299, -3.0548, -0.0555,  0.0003,\n",
       "           0.0081,  0.0081, -1.0968, -0.0415,  1.4244,  0.0076,  0.7505,\n",
       "          -0.2495, -0.0099,  0.7707,  0.0083,  0.0021,  2.5639, -0.0304,\n",
       "          -1.0516]]),\n",
       " tensor([[ 0.0051, -0.1140,  0.0059, -0.0140, -0.0039,  0.7114, -0.0531,\n",
       "           0.0072,  0.5980, -0.0421, -3.0773,  0.6987, -2.9310, -0.0764,\n",
       "           0.0019,  0.0045, -0.6182,  0.0088, -0.3868, -0.1054, -1.4631,\n",
       "          -0.0015, -0.0082, -0.0313, -0.3787, -0.0679, -0.1254,  0.8187,\n",
       "           0.7173]]),\n",
       " tensor([[-0.0942,  2.6805, -0.1098, -0.0306, -0.0775, -0.1246, -0.0824,\n",
       "          -0.1203,  0.0074,  0.0091, -2.7312, -0.0589, -0.0183, -0.0335,\n",
       "          -0.0095, -0.4267,  0.0004, -0.0158, -0.0411,  0.0089,  0.0063,\n",
       "          -0.0165,  1.7675,  0.4902, -0.2804, -0.0030,  0.0088, -0.0327,\n",
       "          -0.1980]]),\n",
       " tensor([[-3.1554, -0.0231,  0.4914,  0.7393, -0.0043,  0.3882, -0.0360,\n",
       "          -0.0170, -0.0116,  0.7182, -0.0188, -2.6475,  0.7496, -0.2991,\n",
       "           0.3543,  0.8115, -0.0980, -0.0981, -0.0063, -0.3867, -0.0816,\n",
       "           0.0098,  0.8136, -0.4597,  0.0756, -0.0538,  0.0047, -0.0003,\n",
       "           2.6981]]),\n",
       " tensor([[ 0.0098, -0.0216, -0.0791,  0.0043,  0.6354,  0.2858, -0.0872,\n",
       "          -0.0067,  0.0062,  1.9436,  0.9141, -0.0124,  0.4730, -0.0182,\n",
       "          -0.0515, -0.0076,  1.5709, -0.1262,  0.7418, -0.0732, -0.0108,\n",
       "           2.2087, -2.6368, -0.0008,  0.0088, -0.5367,  1.9669, -0.1146,\n",
       "          -0.0383]]),\n",
       " tensor([[ 0.0104,  2.5053,  1.4613,  0.0054,  0.2685, -3.0803,  0.7588,\n",
       "           0.3087, -0.0133,  0.0088,  1.2065, -0.2701,  2.4658, -0.0296,\n",
       "          -0.1326, -0.1085, -0.1161,  0.0066,  0.7954,  0.0014, -0.0564,\n",
       "          -0.0029, -0.0006, -1.6340,  2.6980, -0.0013,  0.8063,  0.7715,\n",
       "           0.0081]]),\n",
       " tensor([[ 0.0002,  0.8034, -0.0997, -0.4947,  2.5480,  0.0096,  0.7161,\n",
       "          -0.0539, -0.0555, -0.1235,  0.3606,  1.6554,  0.0093,  0.0092,\n",
       "           0.7749, -0.1383,  1.4214, -0.1305,  0.0017, -1.5023,  0.6392,\n",
       "          -0.0492,  2.0162, -0.1255,  0.7778, -0.4672, -0.1147, -0.1296,\n",
       "          -0.1099]]),\n",
       " tensor([[ 0.0096, -0.0267,  0.6888, -0.1173,  0.7790,  0.0076,  0.0089,\n",
       "          -0.0825,  0.0040,  0.8270, -0.0710,  0.0061, -0.5452,  0.0093,\n",
       "          -0.0288, -0.0281,  0.7612, -0.1267, -0.0129, -0.1241,  1.8480,\n",
       "           0.3158,  0.0061,  0.0090,  0.0088,  2.8037, -0.1952, -0.5496,\n",
       "          -3.0574]]),\n",
       " tensor([[-0.0192, -0.0642, -0.0330, -0.0794, -0.0939, -0.0790, -0.0765,\n",
       "          -0.0096,  1.2360, -0.0178, -0.0461,  2.5701, -0.0961, -2.2933,\n",
       "          -0.1186,  2.8204, -1.0134, -0.0512,  0.0068, -0.0264,  0.0118,\n",
       "           0.7880, -0.0236,  0.0040, -0.1146, -0.5608,  2.3311, -0.0168,\n",
       "           0.2004]]),\n",
       " tensor([[ 2.6937,  0.7621,  0.0120,  2.6369, -0.0026, -0.0151,  0.0098,\n",
       "           0.0686, -0.4520, -0.0539,  0.0093, -0.0379, -0.1302,  2.3225,\n",
       "          -1.5504, -0.5483,  0.0115, -0.4711, -0.1215, -0.0361,  0.0091,\n",
       "          -0.4405, -1.1777,  0.1458, -0.1040, -0.0833,  0.0029, -0.0940,\n",
       "           0.7744]]),\n",
       " tensor([[ 0.0115, -0.1154,  0.2169, -0.1532, -0.1437,  0.1842, -0.0797,\n",
       "          -0.0528,  0.5528,  2.4856, -0.0533,  2.5888, -0.0072,  1.9902,\n",
       "           0.7995, -2.9818,  0.0128, -0.0202, -0.0177,  0.7659,  2.7380,\n",
       "          -0.0146, -0.0934,  0.6319, -0.1288,  0.0282,  0.0106,  0.0033,\n",
       "          -0.1279]]),\n",
       " tensor([[ 0.0107,  0.0088,  0.7515,  0.7084,  1.1631,  1.3878,  0.0099,\n",
       "          -0.1278, -0.3563,  2.6140,  0.0074, -0.1474, -0.0060, -0.6399,\n",
       "          -0.0132, -0.1041, -0.0223,  0.0003, -0.1263,  0.0127, -0.0024,\n",
       "           1.3200,  0.7751, -0.1761,  0.1375,  2.5774,  1.2716, -0.0003,\n",
       "          -0.1375]]),\n",
       " tensor([[-0.1215, -0.1379,  0.0093, -0.0310, -0.0573,  0.6630,  0.6962,\n",
       "          -0.0238,  2.5688,  0.0517, -0.1132, -0.1101,  2.4544,  0.6481,\n",
       "          -0.0240,  1.0822,  0.7059,  2.8537, -0.1353, -0.0737,  0.6215,\n",
       "           2.6536, -0.1220, -0.0760,  0.0124, -0.1317, -0.0105, -0.0950,\n",
       "          -0.0085]]),\n",
       " tensor([[ 0.0050,  0.7704,  0.0062, -0.4544,  0.0131, -0.0473,  0.0090,\n",
       "           0.0485, -0.3506, -0.0272,  0.5690,  0.7907, -0.1100,  0.2411,\n",
       "           2.2900, -0.0053,  0.5892,  0.0042, -0.1051, -0.3009, -0.0381,\n",
       "           0.0071,  0.0134, -2.4326,  2.3635,  0.0127,  1.8736,  0.0093,\n",
       "          -0.1213]]),\n",
       " tensor([[-0.0838,  0.5374, -0.0268,  1.7797,  0.0135, -0.0811,  0.7651,\n",
       "           2.6524,  0.4717, -0.0086,  0.0033,  1.3068,  0.0123, -2.9477,\n",
       "          -0.0562, -0.0608,  2.6371,  0.0123,  2.8922,  0.0105,  0.0129,\n",
       "          -0.0439,  0.7716, -0.1248, -0.1470,  0.7706, -0.0061,  0.0082,\n",
       "           0.1938]]),\n",
       " tensor([[-0.3664,  0.0046, -0.0102,  2.8032,  0.7910, -0.0718,  0.1622,\n",
       "           0.7083, -0.0025, -0.0925,  0.7842,  0.7807,  0.0116, -0.0121,\n",
       "          -2.9653,  0.0029, -0.2040,  2.6330,  0.0108,  0.0124,  0.0092,\n",
       "           0.7424,  0.0086, -0.0670, -0.1263, -0.0855, -0.0966, -0.0039,\n",
       "           0.6413]]),\n",
       " tensor([[ 0.6745, -0.0850,  0.7832, -0.0118,  0.0179,  0.3930, -1.0865,\n",
       "           1.0626, -0.1305,  2.6341,  0.7463,  0.7908, -0.1332,  0.6200,\n",
       "          -0.0051, -0.0795,  0.4418,  0.0115,  0.0062,  0.0068,  0.8168,\n",
       "           0.7736,  0.0154, -2.8665, -0.0473,  0.5939, -0.0842, -0.5029,\n",
       "          -3.0667]]),\n",
       " tensor([[ 0.0126, -0.0243,  0.0154, -0.1046,  0.1573, -0.0137, -0.1198,\n",
       "          -0.1220,  0.0089, -0.5290, -2.9864,  2.5952,  0.0023,  0.0143,\n",
       "           0.0081, -0.0631, -0.0769,  0.5407,  0.0152,  0.1232,  0.0040,\n",
       "           2.5887,  0.0020,  0.6477,  0.0043, -0.1827, -3.0790, -0.1230,\n",
       "          -0.1220]]),\n",
       " tensor([[ 0.1010,  0.0010,  2.6574,  0.7736, -1.8763, -0.0060, -0.5520,\n",
       "           0.7534,  0.7871, -0.1146,  0.0051, -0.2241,  2.5521,  0.0121,\n",
       "           0.5252, -0.2109, -0.0639, -0.0125,  0.0120, -0.3564, -0.0954,\n",
       "          -0.3408, -0.1277, -0.0486,  0.0106, -0.0190, -0.0678,  0.0085,\n",
       "          -0.0569]]),\n",
       " tensor([[-0.0865, -0.0094,  0.0125, -0.8862, -0.4613,  0.0126, -0.0170,\n",
       "           0.0151, -0.0100,  0.0120,  0.7809,  0.5693, -0.1246,  0.7695,\n",
       "           2.6053, -0.1275,  0.7850,  0.0039,  0.2083,  0.0001, -0.1453,\n",
       "           0.4049,  0.0052,  0.4329,  0.0144, -0.1254,  0.3538,  2.5851,\n",
       "          -0.0067]]),\n",
       " tensor([[-0.2247,  0.0144, -0.0848,  0.0102, -0.9514, -0.0590, -0.0359,\n",
       "          -0.1147, -0.0153,  0.0096, -0.0180, -0.1125, -1.5898,  0.6591,\n",
       "           0.7696,  2.6432, -0.0634, -0.1260, -0.3400, -0.0705,  0.6007,\n",
       "          -0.0902, -0.0561,  1.4961,  0.0006, -0.0569,  0.0014,  0.3290,\n",
       "           0.0145]]),\n",
       " tensor([[ 0.0039, -0.0006,  0.7012,  0.1104,  0.0149,  0.0063, -0.0048,\n",
       "           0.0379, -0.1075, -0.0871,  0.2092, -0.0173,  0.0151,  2.3791,\n",
       "          -0.3860, -0.0158, -0.1914, -0.0007, -2.8414,  0.7112, -0.0398,\n",
       "           0.7802, -0.0351, -0.1098, -0.0778,  0.0138, -0.1134, -0.0370,\n",
       "          -0.0361]]),\n",
       " tensor([[-0.0183,  0.0151, -0.1293, -0.0172, -0.0719, -2.4391,  0.7637,\n",
       "          -1.8660,  0.0862, -0.1171, -0.0128, -0.0206, -0.0059, -0.0125,\n",
       "           0.3104, -0.1057, -0.4193, -0.0013, -3.1132,  2.2138, -0.6018,\n",
       "           0.0135, -0.0206, -1.4752, -1.5190, -0.4642,  0.0141,  2.6860,\n",
       "          -3.0712]]),\n",
       " tensor([[ 0.3796, -0.0332, -3.0927,  1.0910, -0.5493, -0.3602,  0.0138,\n",
       "          -0.0366, -0.4672,  0.7489,  2.6649, -0.3324,  0.0065,  0.5230,\n",
       "           0.8247, -0.1204,  0.6034,  0.7808, -0.5838, -0.3942,  0.0084,\n",
       "           0.0143, -0.0756,  0.0060, -0.1171, -0.3186,  0.0096,  0.0100,\n",
       "          -0.1146]]),\n",
       " tensor([[-0.1102,  0.7511, -0.0929, -0.0819, -0.0980,  2.6594,  0.0285,\n",
       "           0.4459, -0.1164,  1.2096, -0.1221, -0.1007,  0.4380, -0.0082,\n",
       "          -0.0541,  2.6367,  0.1172,  0.8683, -0.1217, -1.6051, -0.2364,\n",
       "           0.0159,  0.0139,  0.0153, -0.1059,  0.0084, -0.0547,  2.5850,\n",
       "           0.0153]]),\n",
       " tensor([[ 2.6921, -0.0389, -0.0943, -0.3287, -0.0065, -0.0271,  0.3145,\n",
       "           0.0142,  0.7736,  0.0116, -0.0643,  0.7865,  2.5770,  0.0091,\n",
       "           2.5709, -0.0779, -0.0476, -0.0155,  0.0117, -0.0713, -0.4524,\n",
       "          -0.0439,  0.0100, -0.0685, -0.0003, -0.0017, -0.0124, -2.9395,\n",
       "           0.0142]]),\n",
       " tensor([[-2.7824, -0.0807,  0.0036,  0.3538,  0.0046, -0.0417,  0.0030,\n",
       "           0.0102,  2.9495, -0.0043,  0.0113,  0.0133, -0.5264, -0.0800,\n",
       "           0.0125, -0.2350,  0.7836, -0.0411,  2.8356,  1.7015, -0.0354,\n",
       "          -0.0946,  0.0051,  0.0050,  0.3687,  0.0075,  0.5268, -1.0284,\n",
       "          -0.1155]]),\n",
       " tensor([[-0.1116,  0.3195,  0.1678, -0.0861, -0.0898, -0.4209, -1.9348,\n",
       "           2.3994, -0.1284,  2.8340, -1.8085,  0.0109,  0.7987, -0.5362,\n",
       "          -0.0775, -0.0567,  0.7964, -0.0958,  1.0312,  0.0091, -1.6695,\n",
       "          -2.7929,  1.1896,  0.0102, -0.1194,  0.0419,  0.0106, -0.1025,\n",
       "           0.7763]]),\n",
       " tensor([[ 0.0076, -0.0017, -0.1194,  0.0144, -0.5041,  0.8002,  0.0118,\n",
       "           2.7434, -0.3192, -0.0608, -0.0386,  0.6199,  2.5721, -0.2387,\n",
       "          -0.0993, -0.0106, -1.0931,  0.7836,  2.7840, -0.0718,  0.0114,\n",
       "          -0.1241, -0.1306, -0.0965,  0.0042,  0.0057,  0.0133, -0.0145,\n",
       "          -0.4062]]),\n",
       " tensor([[ 1.9496, -0.0041,  2.4649,  0.6041, -0.0508,  2.9585, -0.0050,\n",
       "           0.7466,  1.7086,  0.0098, -0.2722,  0.0093, -0.0569, -2.9422,\n",
       "           2.5246,  0.0026, -2.4514,  0.0060,  0.7767, -0.0154,  0.6380,\n",
       "           0.0032,  0.2491,  1.6184,  0.7791,  0.7802,  0.0079, -0.1017,\n",
       "          -0.0047]]),\n",
       " tensor([[ 0.0123,  0.0168, -0.0106, -0.0814, -0.1189, -2.8958, -0.1093,\n",
       "          -3.1820,  0.0197, -0.3436,  0.0172,  0.0194,  0.0168, -0.2090,\n",
       "           0.7880, -2.3195,  2.8681, -0.5799, -0.2905,  0.0176,  0.8020,\n",
       "          -0.1145, -0.0839,  0.8378,  0.0052,  0.8154, -0.0347, -0.0482,\n",
       "          -0.0863]]),\n",
       " tensor([[-0.0347,  0.6698, -0.0321, -0.1287,  2.7295, -0.0214, -2.9597,\n",
       "          -0.0823, -0.1053,  0.0202, -0.1089, -0.0226,  0.0189,  0.6886,\n",
       "           0.7868,  0.0199,  0.0158,  0.0180, -0.0999,  0.5455,  2.1560,\n",
       "           0.7324, -0.1143, -2.0450,  1.9344,  2.7449, -0.1158,  0.7143,\n",
       "          -3.0933]]),\n",
       " tensor([[-0.5548,  0.0208, -0.0646,  0.0012, -0.1043, -0.0179,  0.0073,\n",
       "           0.0162,  0.0209,  2.6816, -0.0416, -0.0731,  0.0206,  0.7908,\n",
       "           0.4546,  0.6199,  0.0163,  0.0098,  2.5953,  0.1903,  0.2498,\n",
       "           0.7864,  2.7163, -0.0403,  0.7859,  0.7920,  0.0085, -0.0166,\n",
       "          -0.0165]]),\n",
       " tensor([[ 0.0039,  0.0122, -0.0946, -0.1030, -0.0799,  2.1888, -0.0296,\n",
       "          -0.4119,  2.6428, -0.0021, -0.1192, -0.0153,  1.8925, -0.0243,\n",
       "           0.0189, -0.0045, -0.0830, -0.0578,  2.4972,  1.3246, -0.3075,\n",
       "          -0.0189, -0.0654, -0.0662, -0.0659, -2.9028, -0.3909,  0.0035,\n",
       "          -0.1189]]),\n",
       " tensor([[-0.1369, -0.2169, -0.0205, -0.0457, -0.0180,  0.0219, -0.0948,\n",
       "          -0.0535,  0.3251, -0.0069, -0.0741,  0.0212, -0.2832,  0.2145,\n",
       "           0.3429, -0.0319,  0.0210,  0.0184, -0.1193, -0.0043,  0.7878,\n",
       "          -0.5892, -0.1079, -0.0122,  0.0074,  0.4724, -0.5423, -0.1140,\n",
       "           2.5919]]),\n",
       " tensor([[ 0.8006,  0.0199, -2.0589,  0.6683,  0.7634, -0.2073,  0.0157,\n",
       "          -0.0175, -0.3797, -0.0158, -0.2237, -3.0104,  0.0220,  0.0204,\n",
       "           0.7859, -0.6118, -0.0818,  0.0202,  0.0190,  0.0221,  0.0206,\n",
       "           0.0225,  0.8056, -0.0777,  2.7254,  0.0185, -0.0342, -0.3207,\n",
       "           0.0167]]),\n",
       " tensor([[ 2.3017e-02, -1.3157e-01,  1.6930e-02, -9.6797e-03, -4.3114e-03,\n",
       "           7.8032e-01,  1.2593e+00, -1.0129e-01, -1.1228e-01, -3.9114e-02,\n",
       "           2.5207e-03, -1.3132e-02, -4.4527e-02,  1.0143e-02,  2.5833e+00,\n",
       "          -3.5619e-01, -6.5828e-02,  9.2034e-03, -2.3517e-01,  7.7546e-05,\n",
       "           1.2076e-02, -2.5418e-01, -5.8036e-02,  7.9690e-03, -3.6272e-01,\n",
       "           2.5265e+00, -5.6518e-02, -3.1891e-01,  2.1910e-02]]),\n",
       " tensor([[ 0.0002, -0.2789, -0.0485, -0.5044, -2.8790, -0.1088, -2.6852,\n",
       "           0.0068, -0.1093,  1.2257, -0.4715, -0.0163,  2.8713,  0.0056,\n",
       "          -0.0272, -0.1196, -0.0380,  0.0229,  0.0220,  2.6976,  0.0195,\n",
       "          -0.1146,  0.0192, -0.0420,  0.0224, -0.1085, -0.1089,  0.2861,\n",
       "          -0.1156]]),\n",
       " tensor([[ 0.0181,  0.0002,  0.0225, -0.0698, -0.2577,  0.0212, -0.6022,\n",
       "           2.5932, -0.4550, -0.1047, -0.0758,  0.0197,  2.4012,  0.1984,\n",
       "           0.0152,  0.0170,  0.0093, -0.1022, -0.0178,  0.0041,  1.6536,\n",
       "           0.7720, -0.0039,  0.0071, -0.0355,  2.7381, -0.1916, -0.0392,\n",
       "          -2.4650]]),\n",
       " tensor([[ 0.0079, -0.1201,  1.4267,  2.1196, -0.1781,  0.0204,  0.7601,\n",
       "           0.8134, -0.0895, -0.0440, -0.0820, -0.6269,  0.7963,  0.0064,\n",
       "          -0.1284,  0.0204,  0.0203, -0.2636,  0.0021, -0.0528,  1.8275,\n",
       "          -0.1275, -0.0131,  0.3525,  0.0185,  0.0224, -2.8221,  0.4302,\n",
       "           0.7603]]),\n",
       " tensor([[-0.0640,  2.6329,  0.7827, -0.0009,  0.7838, -0.0976, -0.7349,\n",
       "           0.6352,  0.0180, -0.0064,  0.6085,  0.0229, -0.0622, -0.0776,\n",
       "          -0.1100, -0.1026,  1.0810,  0.0221, -0.1890,  0.0138,  2.4254,\n",
       "          -3.1136, -1.1506,  0.0146, -0.0251, -0.0907,  2.5893,  0.0181,\n",
       "           0.0170]]),\n",
       " tensor([[-0.0215, -0.0038,  0.0170, -2.7453, -0.9368,  0.8027, -0.0322,\n",
       "          -0.3803,  0.7824,  1.5463, -2.2617, -0.0035, -0.0458, -0.5655,\n",
       "           0.0031,  2.5512,  0.7740,  0.0130,  0.8206, -0.0947,  0.7246,\n",
       "          -0.0993,  2.6210,  0.7157,  0.1119,  0.0093, -0.1025,  0.0342,\n",
       "          -0.5558]]),\n",
       " tensor([[-0.1459, -0.0535,  0.8205,  0.7653,  0.6408,  0.6532,  1.2583,\n",
       "          -0.0193, -0.1532,  0.0195, -0.4477,  0.0181, -0.0038, -0.3139,\n",
       "           0.0172, -0.0076,  0.7731,  0.0218, -0.4646,  0.5743, -0.0213,\n",
       "          -0.2773,  0.0226, -0.0999, -0.1123,  2.4105,  0.0147,  2.4870,\n",
       "          -0.0273]]),\n",
       " tensor([[ 0.0154, -0.0178, -0.0423, -0.2189, -0.0998, -0.0956, -0.0166,\n",
       "          -0.1098,  0.7604,  0.3176,  0.0187,  0.8192, -0.1180,  0.7767,\n",
       "           0.0184,  1.2252, -0.5300,  2.7210,  2.6409, -0.0130, -0.0602,\n",
       "          -0.0327, -0.4628, -0.0217,  0.7624, -0.0482,  0.4136, -0.2444,\n",
       "          -0.1195]]),\n",
       " tensor([[ 0.0150,  0.0161,  0.0173,  0.7993,  0.0189, -0.0028,  0.0169,\n",
       "          -0.0791,  0.8158,  0.0024,  0.0195,  2.1884,  0.0598,  0.0188,\n",
       "           0.0136,  0.0013,  0.0923, -2.8484, -0.0435,  0.7912, -0.0059,\n",
       "          -0.0940, -0.1111, -0.1044,  0.0201,  0.0065, -0.0463,  0.0130,\n",
       "          -0.4772]]),\n",
       " tensor([[ 0.2823, -0.0034,  0.7875, -0.0784, -0.0039, -0.1019, -1.5164,\n",
       "           0.0140,  2.5873, -0.0873,  0.0183,  0.7914, -0.0348, -0.0942,\n",
       "           0.7910, -0.0712,  0.7412,  0.0125, -0.0339,  0.0069, -0.1064,\n",
       "           0.3329,  0.0053,  0.0154, -0.0589, -0.7167, -0.0259,  0.8143,\n",
       "           0.0196]]),\n",
       " tensor([[ 0.8278,  2.7952,  0.0188,  0.7889,  0.0160,  0.0897,  0.0043,\n",
       "          -0.0590,  0.0108,  0.0140, -0.5821, -2.4608,  0.7454,  0.3210,\n",
       "           0.0164,  0.0151, -0.0374, -3.1555,  0.7885, -0.1220, -2.8467,\n",
       "           0.0069,  2.7533,  0.1637, -0.2909, -0.5531, -0.0124, -0.1145,\n",
       "           0.5091]]),\n",
       " tensor([[-0.0388,  1.7251,  0.0038, -0.4302,  0.7861,  0.1002, -0.0532,\n",
       "           0.0809, -0.1085,  0.0168, -0.0196, -0.4033,  1.8619, -0.0547,\n",
       "           0.0073, -0.0103,  0.4658,  2.6480,  2.7224,  0.7204, -0.1379,\n",
       "           0.0165, -0.0145, -0.3747, -0.0065, -0.2434, -0.1212,  0.0043,\n",
       "          -0.4296]]),\n",
       " tensor([[ 0.0060,  0.7683,  0.4219, -0.0007, -2.7137,  0.6454, -0.0945,\n",
       "          -0.1237, -0.0682, -0.1177, -0.1152, -0.5603,  0.0012, -0.1030,\n",
       "           0.0143, -0.0928,  0.7814,  0.0041,  0.7401,  0.0147,  0.0163,\n",
       "           0.5684,  2.4418,  0.3540,  0.0069, -0.2273,  0.7448,  2.3023,\n",
       "          -0.0036]]),\n",
       " tensor([[-0.0342,  0.7423, -0.0516,  0.0141,  0.0145, -0.9763,  0.0137,\n",
       "           0.7418, -0.0079, -0.6094, -0.0995, -0.0295,  0.0058, -0.2330,\n",
       "          -0.0060, -0.0102, -0.1145,  0.0081,  2.5829,  1.3367, -0.0809,\n",
       "           0.7349, -0.1046,  0.0154,  0.6890,  2.6354, -0.0412,  0.7754,\n",
       "          -0.1195]]),\n",
       " tensor([[-0.2411,  0.0107, -0.1673,  0.8158, -0.1255, -0.0310, -0.0308,\n",
       "          -0.0997, -0.0330, -0.0112,  0.0094,  0.0115,  2.6712, -0.0966,\n",
       "          -3.4275,  0.0022, -0.0646,  2.5873, -0.0527, -0.1167, -0.1430,\n",
       "           0.0020,  0.4019, -2.6891,  2.0976,  0.0741, -2.4550,  2.5614,\n",
       "          -0.1026]]),\n",
       " tensor([[ 0.0023, -0.1032,  0.7877,  0.1610, -2.0843, -0.0576,  1.5572,\n",
       "          -0.1097, -0.0799,  2.6031,  0.0096, -0.0183, -0.0640,  0.0149,\n",
       "           0.7677, -0.1013,  2.6687, -0.0754,  0.2235, -0.0702, -0.0446,\n",
       "          -0.0343, -0.2267,  0.0057, -0.0062,  2.6926,  2.6331,  0.5523,\n",
       "          -0.0004]]),\n",
       " tensor([[ 0.0245, -0.1252, -0.0279, -0.0503,  0.0137, -0.1238, -3.1978,\n",
       "          -0.0285,  0.0109,  0.7992, -0.0090,  0.0079, -0.1176, -0.1111,\n",
       "          -2.4420, -0.0450, -0.4619, -0.0038, -0.0256, -0.0760,  2.5661,\n",
       "          -0.0807, -0.0104,  0.0128, -2.9233,  0.5811,  0.0142, -0.5501,\n",
       "          -0.1222]]),\n",
       " tensor([[-0.1981, -0.0001, -0.0153,  0.7357, -0.6028,  0.2669, -0.0219,\n",
       "           2.5775, -1.5257, -0.1199,  0.7324, -0.0750, -0.5855,  0.6417,\n",
       "           0.0140,  0.7717, -0.1238, -0.0149,  0.6427,  0.0096, -0.0473,\n",
       "           0.0121, -2.7012, -0.1020,  0.7797, -0.1246,  0.4187,  0.6022,\n",
       "          -0.1105]]),\n",
       " tensor([[ 0.0014,  2.5767,  0.0125, -0.0540,  0.0149,  0.0156, -0.0966,\n",
       "           0.0136,  0.0075, -0.1105,  0.7691,  2.3072, -2.9027, -0.0075,\n",
       "           0.7610, -0.0964, -0.0102, -0.1260, -1.4745, -0.0224,  2.6430,\n",
       "           0.0105, -0.0492, -0.0071, -0.8041,  0.0047,  0.7766,  2.6502,\n",
       "           0.6570]]),\n",
       " tensor([[-0.2895,  2.4982, -0.1124, -0.0010, -0.0974, -0.0186, -2.2043,\n",
       "           0.0089, -0.2092,  0.0055, -0.2338,  0.0890,  2.4207, -2.8733,\n",
       "          -0.1238, -0.0817, -0.0009,  0.0068,  0.0019,  0.0026, -0.0043,\n",
       "          -3.1544, -0.0898,  2.6354,  2.5978,  0.4608, -0.0357,  0.1818,\n",
       "          -0.0026]]),\n",
       " tensor([[ 0.0042, -0.0103, -0.0187, -0.0049, -0.0016,  0.1807,  0.0013,\n",
       "           0.0059,  2.6063, -0.0621, -0.0207,  0.0052,  0.4433,  0.0063,\n",
       "          -0.1147, -0.0495, -0.1281,  0.4989, -0.0023,  2.6813,  0.0070,\n",
       "           0.0060, -0.1227, -2.8166,  0.0050,  2.5622,  0.0047, -1.9688,\n",
       "          -0.0316]]),\n",
       " tensor([[ 0.0002,  0.0360, -0.0091,  0.7320, -0.0253, -0.0806, -0.0057,\n",
       "           0.0062, -0.1005, -1.8998,  0.0014,  0.0025,  2.8187, -0.6000,\n",
       "          -0.0754, -0.0037, -0.3202,  0.7789, -0.0983,  0.0038, -2.7723,\n",
       "          -0.1149,  0.0016, -0.0043, -0.1982, -0.1327, -0.0204, -0.0220,\n",
       "          -0.0306]]),\n",
       " tensor([[-0.0269, -0.1070,  0.0054, -0.1005, -0.1829, -0.0130,  0.7723,\n",
       "          -0.0070, -0.8435, -0.1158, -0.0935, -0.0647, -0.1295, -0.0105,\n",
       "           0.5483, -0.0241,  0.0003, -0.1030, -0.0912, -0.0162, -1.8627,\n",
       "          -0.1138,  0.0057, -0.1272, -0.1013,  2.9756, -0.5369, -0.3718,\n",
       "          -0.0169]]),\n",
       " tensor([[-3.0414,  0.1194, -0.1167, -0.0047, -3.1556, -0.0044,  0.0048,\n",
       "          -0.0977, -0.0506,  0.0052, -0.1231,  0.2743, -0.1215,  0.0028,\n",
       "          -0.1028, -0.0534, -0.1100, -0.0120, -0.0146,  0.7123,  0.0054,\n",
       "          -3.0899,  2.8401,  2.7486, -0.0095, -0.2001, -0.0399,  0.7967,\n",
       "          -0.7862]]),\n",
       " tensor([[-1.1541, -0.0615, -0.1292,  0.7110,  0.0025, -0.0637, -0.0602,\n",
       "          -2.6660,  0.1272,  2.5860,  0.7535,  2.5834, -0.1023, -0.0237,\n",
       "           0.7108,  0.0004, -0.4360,  0.7353, -1.3814, -0.0063, -0.1036,\n",
       "          -2.7262, -2.9716,  0.7733, -0.0132,  0.7616,  0.0070, -0.0280,\n",
       "          -0.0936]]),\n",
       " tensor([[-0.1362, -0.1396,  0.7748, -0.0007, -0.0503, -0.0027, -2.7877,\n",
       "          -0.6636, -0.0519, -0.0030, -0.0082,  0.4334,  0.1296, -0.0376,\n",
       "          -0.2039, -0.1400, -0.1097,  0.0002, -0.0004, -0.0146, -0.0045,\n",
       "          -0.1836, -2.6216,  0.0005, -0.0849,  2.6097, -1.8737, -0.1303,\n",
       "           0.7500]]),\n",
       " tensor([[-0.0661, -0.5180,  0.1263,  2.9012, -2.5963, -0.0883,  0.7550,\n",
       "          -0.0498, -0.0232, -0.1035, -0.5181, -0.1029, -0.1061, -0.0655,\n",
       "          -1.0327, -0.0073, -0.0017,  0.7579,  0.2761, -0.0910,  2.4675,\n",
       "          -0.0010, -0.0237, -0.0048, -0.0062,  2.5696,  2.1745, -0.0294,\n",
       "           2.6785]]),\n",
       " tensor([[-1.3702e-01, -1.0935e-01, -1.3144e-01, -6.0943e-03, -1.1709e-01,\n",
       "           2.7911e+00,  4.9513e-05, -6.3336e-03, -5.2459e-03, -4.0871e-02,\n",
       "           2.3849e+00, -7.6645e-02, -8.4201e-02, -8.2530e-02, -7.1057e-02,\n",
       "          -8.9094e-03, -9.9434e-02,  7.9270e-01,  7.7212e-01, -7.9753e-03,\n",
       "           2.6949e+00, -2.2390e-02,  2.1179e-01, -2.5334e-01,  2.6861e+00,\n",
       "           1.9224e-01, -1.2008e-01,  2.5709e+00,  7.7057e-01]]),\n",
       " tensor([[ 0.5168, -1.8601, -0.0758, -0.0186, -0.0035, -0.0040, -0.0049,\n",
       "           1.6741, -0.0101, -0.1804, -0.0145, -0.5404, -2.8640, -0.0065,\n",
       "           2.5692,  0.7406,  0.2812, -3.0848,  2.5845, -0.1045, -0.0154,\n",
       "          -0.0074, -0.1265, -0.1326,  1.5719, -0.0019, -0.0169, -0.0096,\n",
       "           2.5585]]),\n",
       " tensor([[-0.0009,  0.4308, -0.1402,  0.3394, -0.0028, -0.0157, -0.2563,\n",
       "          -0.0017, -0.0009,  1.8615,  0.3580,  0.7692, -0.1144,  2.6019,\n",
       "          -0.0956, -0.0332,  0.4826,  0.7303, -0.0521, -0.0879,  2.6174,\n",
       "          -2.4388, -0.0645,  0.7909, -0.6305, -0.1285, -2.9696, -0.1055,\n",
       "          -2.6983]]),\n",
       " tensor([[ 0.6017, -2.9400, -0.0778, -0.0032, -2.7940, -0.0016, -0.2687,\n",
       "           3.6199, -0.0044,  3.1718,  1.7858, -0.0468,  0.7423,  2.6782,\n",
       "          -0.0003,  0.2625,  0.0741, -0.0186, -0.0872, -0.4267, -0.0493,\n",
       "          -0.1206,  0.5747, -0.0264, -0.1042, -0.1418,  2.5113, -0.1409,\n",
       "           0.0127]]),\n",
       " tensor([[ 0.3840, -0.1277,  0.4680,  0.0656, -0.0518, -0.0579, -0.0044,\n",
       "          -0.0096, -0.0011,  0.1083,  0.7580, -0.5032, -2.8217, -0.0630,\n",
       "           0.2523, -0.1951,  0.3280,  0.6492, -0.0530, -0.0949,  1.9875,\n",
       "          -0.1255, -0.1168, -0.0795, -0.6231,  0.4938, -0.0950, -0.0001,\n",
       "          -0.0652]]),\n",
       " tensor([[-0.0907,  0.0001, -0.1355,  0.7353, -0.0682,  0.7656, -0.1354,\n",
       "           0.4108, -0.0493, -0.0070,  0.7687, -0.0099,  0.6633,  2.5919,\n",
       "           0.7674,  0.7879, -0.0015,  2.6846, -0.1196, -0.0612, -0.4422,\n",
       "          -0.0118,  0.8213,  1.4116, -0.0011,  0.0568, -0.0247,  0.1743,\n",
       "           0.7486]]),\n",
       " tensor([[-0.0737, -0.0773, -0.1329, -0.3555, -0.0632, -0.1357, -0.0234,\n",
       "          -1.1593, -0.0709,  0.3647, -0.0004, -0.2718, -0.6031, -0.0478,\n",
       "           0.6636, -0.0963,  0.7481, -0.0233,  2.4373,  0.6956, -0.1333,\n",
       "          -0.1331, -0.1190, -0.0019, -1.6150,  2.5960,  0.4537, -0.0129,\n",
       "           2.8569]]),\n",
       " tensor([[ 0.7481, -0.0046, -0.0193, -0.0764,  0.4351, -0.4727, -0.0389,\n",
       "           0.6607, -0.0997, -0.1325, -0.0103, -0.0186,  2.5246,  2.9654,\n",
       "          -0.1116,  0.0524, -0.6259,  2.0099,  0.7639, -0.0026, -3.2114,\n",
       "          -0.0758, -0.0596, -0.0008, -0.0121, -2.5110, -0.4788, -0.0823,\n",
       "           0.6084]]),\n",
       " tensor([[ 7.8737e-01, -7.2488e-03,  2.0289e-01, -3.4169e-03, -8.7382e-02,\n",
       "          -1.0956e-02, -2.0749e-01, -3.4517e-01, -6.1636e-01, -1.1542e-01,\n",
       "           7.5561e-01, -4.6631e-03, -1.0717e-01, -3.2153e-02, -1.0002e+00,\n",
       "          -6.3415e-02, -9.1870e-02, -4.6505e-03, -4.5910e-01,  1.8923e+00,\n",
       "           2.5613e+00,  2.3102e-05, -2.8394e-03,  2.5277e+00,  2.7016e+00,\n",
       "           4.8012e-01, -2.4584e-02,  2.7149e+00, -1.2578e-01]]),\n",
       " tensor([[ 2.5236, -0.0111, -0.0282,  2.5013, -0.1270, -0.0266, -1.3859,\n",
       "          -0.0071,  0.7633,  0.6414, -0.0851, -0.1376, -0.0155, -0.1048,\n",
       "          -0.0492, -0.0345, -0.0132, -0.1348, -0.1329, -0.1138, -0.0582,\n",
       "          -0.2366,  0.1686, -0.0087, -0.0309, -2.0908, -0.0219,  0.2496,\n",
       "          -0.0136]]),\n",
       " tensor([[-3.0821, -0.0134, -0.0075, -0.1126, -0.0709,  0.3306, -0.0588,\n",
       "          -0.0095, -0.1045, -0.0311,  0.1689, -0.0318,  1.4954, -0.0911,\n",
       "           2.5928,  0.8030, -0.0548,  1.3598,  0.0988,  2.4024,  0.1434,\n",
       "           0.6128, -0.0067, -0.0270, -0.0129,  0.7626, -0.5952,  0.7019,\n",
       "          -0.0124]]),\n",
       " tensor([[-0.0196,  0.7557,  0.7490, -0.1195, -0.1339, -0.0063, -0.1251,\n",
       "          -0.0174, -0.0993,  0.5077, -0.0082, -0.1136, -0.0517, -0.1245,\n",
       "          -0.1236, -0.1150, -0.0724, -0.3518, -0.0238, -0.3130,  1.6001,\n",
       "          -0.0095, -0.0132, -1.6617, -0.0372, -0.0699, -0.0433, -0.0648,\n",
       "          -0.0430]]),\n",
       " tensor([[-0.0503,  0.1162,  0.5080, -0.1167, -0.0141, -0.1212,  1.1039,\n",
       "           0.3034, -0.3834,  2.6610, -0.0632, -0.1309, -0.3126, -0.0294,\n",
       "          -0.0520, -0.1153,  2.2817, -0.0749, -0.0860, -0.0440, -0.1122,\n",
       "          -0.3969, -0.6669, -1.2801, -0.0235, -0.0620, -0.1191,  0.5990,\n",
       "          -0.3345]]),\n",
       " tensor([[ 0.2647, -0.0771,  0.7670,  0.5848, -0.3865, -0.0354, -0.1006,\n",
       "          -0.0716, -3.0253, -0.0126, -0.0764, -0.1323, -0.0164, -0.2768,\n",
       "          -0.2332, -2.7257, -1.7443, -0.0155,  2.4013,  0.7186,  1.2376,\n",
       "          -0.0624,  0.7617, -0.0488, -0.0557, -0.0107, -0.1305, -0.1288,\n",
       "          -0.0245]]),\n",
       " tensor([[ 0.0209,  0.4484, -0.0084, -0.0103, -2.4883, -0.0538, -2.7333,\n",
       "           0.7612, -0.0495, -0.1254, -1.3503, -0.0188, -0.1438, -2.5632,\n",
       "          -0.0834, -0.0095, -0.0759, -0.0751, -0.1328,  0.6528, -0.1461,\n",
       "          -0.0196,  0.3270, -0.0324,  0.7550, -0.1002,  0.7418, -3.0040,\n",
       "           0.7520]]),\n",
       " tensor([[-0.3250,  0.6393, -2.9546, -0.0155, -2.8822, -0.0170, -0.0633,\n",
       "          -0.2483, -0.1230, -0.0898, -0.0160, -0.1445, -0.0946,  0.7835,\n",
       "          -0.0390, -1.8420,  1.9348, -0.0755, -0.2593,  1.0357, -0.1409,\n",
       "          -0.0206, -0.1348,  0.0663, -0.0714, -0.0686, -0.0691, -0.1323,\n",
       "          -0.0107]]),\n",
       " tensor([[ 0.7064, -0.1431, -0.0085,  1.6101, -2.9708, -2.8426, -0.0127,\n",
       "          -0.0225, -0.0108, -0.1415,  0.7755, -0.0646, -0.1227, -0.0185,\n",
       "          -0.0084,  2.3414, -0.0334, -2.6013,  0.0069,  2.5924, -0.1003,\n",
       "          -0.1000, -0.0467, -0.0217,  0.7624,  2.5972, -0.0159, -0.0573,\n",
       "           0.5456]]),\n",
       " tensor([[ 2.5428, -0.1363,  0.6548, -0.0095, -0.0089, -0.0243, -0.0083,\n",
       "          -2.5014, -0.1269, -0.0088, -0.0092, -0.0108,  2.6810, -0.1132,\n",
       "          -0.0092, -0.0694, -0.0092, -0.0998,  0.7444, -0.0110, -0.1078,\n",
       "          -0.0086, -0.0924,  0.7097, -0.2387, -3.3016, -0.0465, -0.0258,\n",
       "           0.8173]]),\n",
       " tensor([[ 1.3554,  1.4955,  0.2440, -0.0100,  2.5578,  0.7529, -0.0086,\n",
       "          -1.4355,  0.1301, -0.6079,  0.2323, -0.0105, -0.0132,  0.0781,\n",
       "          -0.0173,  0.2549, -0.0919, -0.0178, -2.9704, -0.0573, -0.0558,\n",
       "          -0.1446, -0.0107, -0.0127, -0.0730, -0.0113, -0.1449, -0.0640,\n",
       "           0.7613]]),\n",
       " tensor([[-0.1871, -0.0114, -0.0138, -0.0168,  0.7908, -0.0236,  2.5517,\n",
       "           0.7790,  0.7342,  0.1568,  0.3003, -0.0146,  0.1434, -0.0148,\n",
       "          -0.0491,  2.3522, -0.0110,  0.4996, -0.0137, -0.0960, -0.0124,\n",
       "          -0.1441,  2.5497, -0.0560,  0.0828, -0.0168, -0.4058,  0.7789,\n",
       "          -2.4434]]),\n",
       " tensor([[ 0.2609, -0.0384,  0.7888, -0.0124, -3.3126,  0.1253,  2.4795,\n",
       "          -0.0149, -0.0237, -0.0336, -0.0173, -0.0802, -0.5417, -2.8383,\n",
       "          -0.0157, -0.0180,  2.5482, -0.1266, -0.0142, -0.0343, -0.0161,\n",
       "          -0.0545, -0.0122,  0.6013, -0.1332, -2.3390,  0.6021, -0.4875,\n",
       "           2.7468]]),\n",
       " tensor([[ 0.7969, -2.7556, -0.1091, -0.0988, -0.0453, -0.0174, -0.0163,\n",
       "          -0.0451,  0.7251, -0.0713, -0.0136, -0.1346, -0.0155, -0.0284,\n",
       "          -0.0955, -0.5386, -0.0340, -0.1575, -0.0536, -0.0246, -0.0253,\n",
       "          -0.0190, -0.0287, -0.4572, -0.9260, -0.0156,  0.6988, -0.0556,\n",
       "          -0.1499]]),\n",
       " tensor([[ 1.2780, -0.6067, -0.0906,  0.7416, -2.8935, -0.0369,  0.7497,\n",
       "          -0.0323, -0.0142,  0.7676, -0.5201, -0.1204, -0.0971, -0.0937,\n",
       "          -0.4918, -0.0587, -0.5977, -0.0143, -0.1403, -0.0215, -0.1098,\n",
       "           2.5969, -2.8290, -0.2029,  2.4732, -0.0169, -0.1230, -0.0160,\n",
       "          -0.0238]]),\n",
       " tensor([[-3.0457, -1.7232,  2.5694, -0.5853, -0.1379, -0.1304, -0.0228,\n",
       "          -0.0997,  0.7515, -0.0286, -0.4005, -0.1833, -0.0244, -0.1347,\n",
       "          -0.0222, -0.1428, -0.0310, -0.0425,  0.7445, -0.2408, -0.1173,\n",
       "           0.0103,  2.5590, -0.0368, -0.1490, -0.0444,  0.6091, -0.0406,\n",
       "          -0.0923]]),\n",
       " tensor([[-0.0133, -0.0135, -0.1153, -0.1088, -0.0831, -0.1521,  2.0719,\n",
       "          -0.1485, -0.0298, -0.2673, -0.0134, -0.0168, -0.0495, -2.7447,\n",
       "          -0.0143,  2.6198, -0.1110, -0.2791,  2.6303,  0.7495,  0.0415,\n",
       "          -0.1120,  2.5667, -0.0712, -0.6562,  2.3608, -0.0155, -2.3689,\n",
       "          -0.0171]]),\n",
       " tensor([[-0.0499, -0.1496,  0.7042, -0.0155, -0.2987,  0.6933, -0.1488,\n",
       "          -0.1527, -0.5298, -0.0204, -0.0344, -2.8326, -0.0877, -0.0158,\n",
       "          -0.2565, -0.0992,  0.4216,  0.7250, -0.0357, -0.0432,  0.5103,\n",
       "           1.6476, -2.3825, -0.4549, -0.0646, -0.0138,  1.0307,  2.5890,\n",
       "          -0.1194]]),\n",
       " tensor([[-0.0182,  0.7476,  0.7718, -0.6502, -0.3166, -0.0766, -0.0964,\n",
       "           0.7507,  0.7355,  2.3051, -0.3246, -0.0765, -0.1486,  0.6140,\n",
       "          -0.1412,  1.7655, -0.1497, -0.0178, -0.0648,  2.3256, -0.1019,\n",
       "          -0.0381, -0.0159, -0.6575, -0.1724, -0.0283, -0.0141, -0.0153,\n",
       "           2.0973]]),\n",
       " tensor([[-2.9775, -3.2988, -0.0177, -0.0146, -0.1236, -2.7091, -0.1351,\n",
       "          -0.1473, -0.0352, -0.0794, -0.3108, -0.1455, -0.1223, -0.0707,\n",
       "          -0.4467, -0.0484, -0.0290, -0.0082, -0.0173, -0.0334,  0.5402,\n",
       "           0.6443, -0.7232, -0.1383,  0.0861, -0.1035, -0.0132, -0.1494,\n",
       "          -2.2628]]),\n",
       " tensor([[-0.0715, -0.2575, -0.0169, -0.0209, -0.0887, -0.0955,  0.6218,\n",
       "          -0.0651, -2.2182, -0.1518,  0.6828,  2.5657,  0.5962, -2.8469,\n",
       "          -0.1435, -0.0211, -0.1383, -0.0358, -0.0168, -2.0019,  0.7289,\n",
       "           0.6657,  2.5076, -0.1686, -0.0199,  0.7619, -0.1121, -0.1686,\n",
       "          -0.0136]]),\n",
       " tensor([[ 0.8035,  2.5513,  2.7961,  2.6521, -0.1212, -0.5364, -0.0138,\n",
       "           0.0321, -0.0177, -0.1401, -0.0538, -0.1418, -0.0145, -0.0170,\n",
       "          -0.1036, -3.0867, -0.1351,  1.1511, -0.0144, -0.0228, -0.0148,\n",
       "          -0.1133, -0.0312,  2.4302,  0.1289,  2.0922,  1.9038, -0.0502,\n",
       "           0.3781]]),\n",
       " tensor([[ 3.0481,  0.1920, -0.1425, -0.5165, -0.1474, -0.0983, -0.4040,\n",
       "          -0.0147, -0.0260, -0.1515, -0.2215,  2.5510, -3.0432,  0.7710,\n",
       "          -0.0362,  1.0595, -0.0839, -0.4671,  0.7473, -0.0321, -3.0982,\n",
       "          -0.0317, -0.0434, -0.5731, -0.0153,  2.7906, -0.1322, -0.1085,\n",
       "          -0.0542]]),\n",
       " tensor([[-0.1533,  1.0269, -0.1294, -0.2196, -0.3786, -0.1375,  0.6862,\n",
       "          -0.0232,  0.2350, -0.0370, -0.0287,  1.2859, -0.0182, -0.0190,\n",
       "          -0.0314, -0.0149, -0.1437, -0.1457, -0.2126,  0.7236, -0.0163,\n",
       "          -0.1448, -0.5224, -0.0395, -0.1944,  0.6836, -0.0372, -0.1293,\n",
       "          -0.0155]]),\n",
       " tensor([[-0.0793,  2.4454, -0.1097,  0.4120, -0.0178, -0.0196, -0.0139,\n",
       "          -0.4224,  0.0571, -0.0362,  0.7539, -0.0277, -0.0219,  2.7437,\n",
       "          -0.0280, -0.0199, -0.1537, -0.0300,  2.5883, -0.1233,  2.2601,\n",
       "          -0.1344, -0.3021, -0.1432, -0.0171, -0.0213, -0.0904, -0.8485,\n",
       "           2.5172]]),\n",
       " tensor([[ 0.5317, -0.0222,  0.5879, -0.1536, -0.1438, -0.0145, -0.0994,\n",
       "          -0.1183,  0.3693, -0.0300, -0.1178, -0.0869, -0.1132, -0.1331,\n",
       "           0.7470,  0.1427, -0.2762, -1.7162, -0.1234, -0.0135, -0.4560,\n",
       "           0.7216, -0.1651, -0.0153, -2.5806, -0.1453,  1.5994, -0.2409,\n",
       "          -0.1314]]),\n",
       " tensor([[-0.0576, -0.0526, -0.0248, -2.9910, -0.0925, -0.0982,  0.1660,\n",
       "          -0.0227,  0.7511,  0.5018,  0.7605, -0.1287,  2.3648,  2.4263,\n",
       "          -0.0766, -0.0996, -0.0227, -0.1456, -0.0941, -0.1457,  0.7384,\n",
       "          -0.0431,  0.7269, -0.0174, -0.0743, -0.1208, -0.1282, -1.5635,\n",
       "          -0.0969]]),\n",
       " tensor([[-0.1266, -0.0162, -0.0348, -0.2158, -0.0164, -0.0198,  1.4346,\n",
       "          -0.1480, -3.1242, -0.1131, -0.0141, -0.0153,  0.4381, -1.7430,\n",
       "          -0.0813, -0.0458, -0.0951, -0.0549, -0.1260,  0.7635,  0.7665,\n",
       "          -0.1110,  0.8154, -0.1410,  2.7570, -0.0245, -0.0471, -0.0291,\n",
       "          -0.0140]]),\n",
       " tensor([[-0.0637, -0.0222, -0.2140, -0.1263, -0.5499,  0.7765,  0.4416,\n",
       "          -0.1420, -0.1289, -0.1473, -0.0296, -2.4244, -0.5420, -0.1018,\n",
       "          -0.1200,  2.5514,  0.4243, -1.8590,  0.2428, -0.0320,  2.6477,\n",
       "          -0.1140, -0.2675,  2.6327,  0.4343, -0.0131,  1.8304,  0.6665,\n",
       "          -1.3452]]),\n",
       " tensor([[-0.0209, -0.0870,  3.0041, -0.0854,  0.7736, -0.0973, -0.0927,\n",
       "           2.6284, -0.0309,  2.8266, -0.0140, -0.1201, -3.0344,  2.5556,\n",
       "          -0.0618, -0.0455, -0.0170, -2.9627,  0.4730, -0.1150, -0.0335,\n",
       "          -0.0438,  2.4729, -0.0465,  0.7396, -0.2115, -3.0337,  0.7266,\n",
       "          -0.6674]]),\n",
       " tensor([[-0.0638, -0.0162, -0.1119, -0.1458, -0.1041, -0.0386, -0.0336,\n",
       "           2.5729, -0.0199, -0.0524, -0.0168, -0.0127,  2.9708, -0.0139,\n",
       "          -0.0030, -0.0143,  2.8062,  2.6338, -0.0997,  0.8581, -2.3861,\n",
       "           0.7615, -2.3986, -0.1397, -0.0620, -2.8793, -0.1440,  0.5849,\n",
       "          -0.0247]]),\n",
       " tensor([[-3.1968, -0.0131, -0.0800, -0.0592,  0.7463, -1.8142, -0.1041,\n",
       "          -0.0339, -0.0525, -0.0205, -0.1223,  0.7865, -0.1446, -0.1283,\n",
       "          -0.1346, -0.0317, -0.0196,  0.7811, -0.1401, -0.0141, -0.0126,\n",
       "          -0.6394, -0.1487,  0.4171,  0.4427,  2.5277, -0.0547, -0.0788,\n",
       "          -0.0220]]),\n",
       " tensor([[-0.1261,  0.5218,  0.7724, -0.0723, -0.0868, -0.0131,  0.7559,\n",
       "          -0.1388, -0.0180,  0.7779, -0.0163, -0.0831,  2.5289, -0.1451,\n",
       "          -3.1129,  0.7182, -0.0462,  2.7128,  0.7005, -0.0294, -0.1357,\n",
       "          -0.3818, -0.1420,  1.9434, -0.0120,  2.5503, -0.0126, -0.0418,\n",
       "          -0.0206]]),\n",
       " tensor([[-0.0209, -0.1530,  0.5008, -0.0189, -0.0313, -0.0690, -0.0432,\n",
       "          -0.0191,  1.7394, -3.0964,  2.5405, -0.1347, -0.3264, -0.0406,\n",
       "           0.7497,  0.4001, -0.0448, -0.1391, -2.3381, -0.6309, -0.0236,\n",
       "          -0.5022, -0.0193, -0.0421, -0.0632, -0.0409, -0.1386, -2.3745,\n",
       "          -0.0336]]),\n",
       " tensor([[-0.0726,  0.2797, -0.1509,  0.9504, -0.0230,  2.5437,  0.7552,\n",
       "          -0.0589, -0.0228, -0.0499, -0.0243, -0.0497, -0.0389, -0.0847,\n",
       "          -0.0855, -0.1552, -0.4199, -0.1034, -0.0356, -0.1301,  0.7385,\n",
       "          -3.3517,  0.1913, -0.3676,  0.3573,  2.6009,  0.6278, -0.1016,\n",
       "           1.2961]]),\n",
       " tensor([[-0.0673,  0.2156,  0.7340,  2.5282,  0.4975, -0.4959, -0.0420,\n",
       "           2.5287, -0.0398, -0.0333, -0.0240, -0.0235,  0.5964, -2.2623,\n",
       "          -0.0980, -0.0312, -0.0396,  0.7850, -0.0279,  0.6765, -0.0519,\n",
       "           0.0424, -0.0253, -0.1423, -0.0626, -0.0251, -1.7491,  0.7408,\n",
       "          -0.0467]]),\n",
       " tensor([[-0.6120, -0.0997,  2.8641, -0.2667,  0.7154,  0.7023, -0.0950,\n",
       "          -0.1584, -0.0056, -0.1322,  2.1964,  0.7063, -0.0264, -0.1044,\n",
       "           0.0397,  0.2681, -3.2346,  2.5420, -0.3500, -0.0505, -0.1838,\n",
       "          -0.1548, -0.0375, -0.0324,  0.3113,  0.1607, -0.0580, -0.0269,\n",
       "          -0.0956]]),\n",
       " tensor([[-0.0315, -0.0653, -0.0479, -0.1243, -2.9694, -0.0319,  2.8537,\n",
       "           0.6915,  2.5398, -0.1951,  0.4215, -0.1574, -0.1833, -0.5818,\n",
       "          -0.3385, -0.1588, -0.0258, -0.1308,  0.4083, -0.0796, -3.1678,\n",
       "          -0.0690, -0.0289,  0.7451, -2.9417, -0.1469, -0.0365, -0.0933,\n",
       "          -0.0386]]),\n",
       " tensor([[-0.6306, -2.7221,  0.6919,  2.8618,  0.0213, -0.0259, -0.4781,\n",
       "           0.6285, -0.0273, -0.0399,  2.6678, -0.1275,  2.4000, -0.0267,\n",
       "          -0.0265, -0.0280, -0.0265, -0.0406, -0.6639, -0.4115,  0.1785,\n",
       "          -0.1469,  0.5465,  0.3500, -0.0930,  0.3429, -0.1573,  0.7562,\n",
       "           1.0489]]),\n",
       " tensor([[-0.0395, -0.0758, -0.0334, -0.0344, -0.1289, -0.0238,  0.5104,\n",
       "          -0.1125, -0.0274, -0.0338, -0.0613, -0.0462, -0.2309, -0.1335,\n",
       "          -0.0816, -0.1874, -0.0487, -0.0923, -0.0525, -0.5337, -0.1875,\n",
       "          -0.0565,  0.7539, -0.0562, -0.0258, -0.0310, -0.0256, -0.0252,\n",
       "          -0.2621]]),\n",
       " tensor([[-0.0261, -0.1897, -0.0425, -0.1398,  0.7566, -0.1653, -0.1078,\n",
       "          -0.0486, -0.5870, -0.0261, -0.0286, -0.1453, -0.0260,  0.7599,\n",
       "          -0.0279,  2.6976,  0.4256,  2.5924,  0.6650,  1.5911, -0.1544,\n",
       "          -0.0338, -0.3313, -0.0338, -0.5560, -0.0596, -0.1175, -0.1573,\n",
       "          -0.0274]]),\n",
       " tensor([[-0.0250, -0.0483, -0.1026, -0.1617, -0.0299, -0.1537,  0.2114,\n",
       "          -0.4310, -0.6883, -0.0264, -2.9715, -2.2302,  0.0118, -0.1427,\n",
       "           0.7947, -0.0275,  0.7291, -0.0389, -0.0252,  0.4496,  1.2905,\n",
       "          -0.1457,  1.0965, -0.3619, -0.1478,  0.6620, -0.0270, -0.0879,\n",
       "          -0.0282]]),\n",
       " tensor([[-0.1423, -0.1145, -0.1374, -0.4102, -0.0479, -0.1347, -0.1166,\n",
       "          -0.0379, -0.2473,  0.1737, -0.0460,  1.9124, -0.1269, -0.1139,\n",
       "          -0.0973, -0.0608, -0.4826, -0.0339, -0.0371, -2.9091, -0.0398,\n",
       "          -0.1028, -0.0656, -0.0433, -0.1412, -0.1344, -3.0342, -0.0677,\n",
       "           0.0135]]),\n",
       " tensor([[-0.0352, -0.0329,  2.5579, -0.1427,  2.4242,  0.8905,  0.7195,\n",
       "           0.7448, -0.0869, -0.1578,  0.7368,  0.9721, -0.1137, -0.1605,\n",
       "          -0.5603, -0.0592, -0.0970, -0.3967, -0.1444,  1.3454,  0.5463,\n",
       "          -0.0384,  0.7210, -0.6070, -0.3702, -0.1633, -0.0356, -0.0462,\n",
       "           0.5120]]),\n",
       " tensor([[-0.1158, -0.1726, -3.0635, -0.0374, -2.8975,  0.2621, -2.6131,\n",
       "          -0.0576, -0.0350, -0.1386, -0.1664,  0.7293, -0.1712, -0.0643,\n",
       "          -0.0450, -0.0355,  0.7656, -0.0341, -0.6824, -2.8368, -0.0354,\n",
       "          -0.0430, -0.0434, -0.0544, -2.9889, -0.1754, -0.0366, -0.0353,\n",
       "          -0.0696]]),\n",
       " tensor([[ 2.5501, -0.8079, -0.0376, -0.1639, -0.1197, -0.1425, -0.5203,\n",
       "           0.1049, -0.3158, -0.1289,  0.2522, -0.0282, -0.6638,  0.7096,\n",
       "          -0.0524, -0.1804,  0.7352, -0.2829, -2.6255, -0.0367, -0.1470,\n",
       "          -0.1704, -0.2343, -0.0649, -1.8099, -0.0351,  2.5694, -2.9998,\n",
       "          -0.1450]]),\n",
       " tensor([[ 2.5884, -0.0487, -0.0417, -0.0378, -0.0867, -2.2930, -0.1320,\n",
       "           0.1505, -0.1242, -0.0455,  0.6608,  0.7540, -0.0367, -0.1430,\n",
       "           2.5295, -0.0400, -0.0693,  0.4664, -0.0374, -0.0610, -0.0800,\n",
       "           2.3997, -0.0861,  0.7743,  2.5795, -0.1694, -0.1514, -0.2510,\n",
       "          -0.2923]]),\n",
       " tensor([[-3.3431, -0.0562, -0.1656, -0.1578, -0.0969, -0.1676,  0.7065,\n",
       "          -0.0933, -0.0489, -0.1842, -0.1555, -0.0539,  2.6626, -0.6787,\n",
       "          -0.0402, -0.0372, -0.1534, -0.1414,  2.5660, -0.0404, -0.0437,\n",
       "          -0.0433,  0.5206,  0.1940,  0.5713, -0.0384,  0.7477, -0.0771,\n",
       "          -0.0364]]),\n",
       " tensor([[ 2.6239, -0.0605, -0.1446, -0.1701, -0.3269, -0.1460, -0.0937,\n",
       "           0.4575, -0.5606,  0.2408, -0.0437, -0.0448, -2.7946, -0.2322,\n",
       "          -0.0402, -0.4879, -0.5789, -0.1501, -0.0581,  0.4999, -0.5696,\n",
       "          -0.6780, -0.0716, -0.0527,  0.4141,  0.7261, -0.2991, -0.0378,\n",
       "          -0.0394]]),\n",
       " tensor([[-0.1659, -0.0492,  0.2845, -0.0511, -0.0940, -0.1163, -0.3478,\n",
       "           0.0749, -0.1255,  1.7565,  2.6385, -0.4975, -0.0775, -0.0370,\n",
       "          -1.0112, -0.0395, -0.6080, -0.0577,  0.6742,  1.8343, -0.0717,\n",
       "          -0.0423, -0.0396, -2.3459, -0.0886, -0.0394,  0.7306, -0.2177,\n",
       "           2.4059]]),\n",
       " tensor([[-0.1738,  2.6806,  0.3927,  2.3958,  0.2000, -0.4310, -0.0449,\n",
       "           1.6271, -0.1516, -0.1203,  1.4018, -0.1751,  0.8975, -0.0494,\n",
       "          -0.0828, -0.3962, -0.0430, -0.4490, -0.0728, -0.6146, -0.0441,\n",
       "          -0.1425, -0.0428, -0.1009, -0.5606, -0.1325, -0.4227, -0.0408,\n",
       "           2.5191]]),\n",
       " tensor([[-0.1766,  0.2748, -0.1019,  1.4470, -0.1649, -0.0622,  2.5673,\n",
       "           0.5715, -0.0702, -0.0563, -0.1037,  2.5220, -0.1482, -0.6755,\n",
       "           0.7251, -0.0442, -0.1363, -1.8913, -0.0964, -0.1783, -0.0432,\n",
       "           2.6093, -0.1112, -0.4573,  0.5288,  0.7210, -0.1594, -2.2416,\n",
       "          -0.0448]]),\n",
       " tensor([[ 0.3403, -0.0431,  0.7547, -0.4077, -0.1013,  1.9469, -0.1734,\n",
       "          -2.1467, -0.0430, -0.0158, -0.1270,  2.6538, -0.4529, -0.0898,\n",
       "          -0.0441, -0.1336, -0.0495,  0.5294, -0.4132, -0.1072, -0.0801,\n",
       "          -0.0530,  0.6632, -0.1557, -1.1951,  0.6780, -0.6315, -0.0484,\n",
       "          -0.0461]]),\n",
       " tensor([[-0.0561,  0.6625, -0.0794,  0.3827, -0.0446, -0.1300, -2.9538,\n",
       "          -0.0635,  0.2206,  0.3618,  0.2138, -0.0976, -0.1140, -0.1026,\n",
       "          -0.0440, -0.3587,  1.1268, -0.3210, -0.0431, -0.0498, -2.4501,\n",
       "          -0.1284, -0.1245, -1.9740, -0.1563, -0.0636,  0.7413, -0.6714,\n",
       "          -3.1588]]),\n",
       " tensor([[-0.0700, -0.0558, -0.0489, -0.0449, -0.1450, -0.0497, -0.1586,\n",
       "          -0.1378, -0.1565,  1.2431, -0.0645, -3.0613, -0.0471, -0.0437,\n",
       "          -0.0636, -0.0528,  0.1324, -0.1092, -0.1913, -0.0501, -0.0438,\n",
       "          -0.0606, -0.0556, -0.1747, -0.1571,  2.5507,  0.6756, -0.0484,\n",
       "          -0.0867]]),\n",
       " tensor([[-0.1836, -0.0747, -0.1506, -0.2572,  0.5611, -0.0574, -0.1319,\n",
       "          -0.0462, -0.0582, -0.1744, -0.1646, -0.1514,  0.6505, -0.1387,\n",
       "          -0.0436, -0.0538, -0.0713, -0.1608, -0.1203, -0.1921,  0.6894,\n",
       "          -0.0476, -0.0592, -0.0962, -0.0527,  0.7089, -0.6629,  0.7640,\n",
       "          -0.0556]]),\n",
       " tensor([[-0.0731, -0.0508, -0.5540, -0.0472, -0.1372, -0.4159, -0.8419,\n",
       "          -0.1677,  2.5621, -0.1732, -0.4312, -1.5164, -0.1267, -0.0437,\n",
       "          -0.0448,  0.7513, -0.1244, -0.0976, -0.0352, -0.0611,  0.3372,\n",
       "          -0.1430,  0.5786,  2.5273, -0.0512, -0.0907,  0.1875, -0.0431,\n",
       "          -0.1090]]),\n",
       " tensor([[-0.1019, -0.1589, -0.0587, -0.0629, -3.0216, -0.1282,  0.7384,\n",
       "           2.6485,  0.7297, -0.1771, -0.0922, -0.2492, -0.0467, -0.0455,\n",
       "          -0.0734,  0.7624, -0.0864, -0.0438, -0.0487, -0.1608,  0.1586,\n",
       "          -0.0939, -2.9852, -0.0537, -0.1462, -0.1766,  2.5129, -3.2746,\n",
       "           0.2344]]),\n",
       " tensor([[ 2.5781,  1.1918, -0.0432, -0.0687,  2.4617, -0.0497, -0.0945,\n",
       "          -0.3487, -0.4766,  0.7133, -0.1737, -0.0929, -0.1068,  0.7019,\n",
       "           0.4036, -0.0910,  1.7229, -0.0433, -0.1726, -0.1395, -0.0445,\n",
       "          -2.8457, -0.0522, -0.0557, -0.0835, -0.0471,  2.0635, -0.0431,\n",
       "          -0.6965]]),\n",
       " tensor([[-0.1001, -0.0472,  0.7465, -0.0453, -0.1269,  2.6490, -0.1649,\n",
       "          -0.0606, -0.5619,  2.5136,  0.4255,  2.4536, -0.2895, -0.1709,\n",
       "          -0.0933, -0.0509,  0.2106, -0.0762,  0.5939, -1.1351, -0.1087,\n",
       "           2.4343, -0.0429, -0.0442, -0.1595, -0.0439,  0.7667, -0.0446,\n",
       "          -0.1679]]),\n",
       " tensor([[-0.0469, -2.6199,  0.6744, -0.1242,  0.7328, -0.1387, -0.0926,\n",
       "           0.7440,  0.2860, -0.0440, -0.0483, -0.0286, -0.3904, -0.5509,\n",
       "           0.6771, -0.1001, -0.0429, -0.0888, -2.7557, -0.0539, -3.0976,\n",
       "          -0.0713, -0.1426,  0.2666,  0.0078, -0.1033, -0.0612, -0.0466,\n",
       "          -0.6416]]),\n",
       " tensor([[-0.4382,  2.1136, -0.0447, -0.4249, -0.1016,  2.6563, -0.2617,\n",
       "           0.3989,  0.2956, -0.1586, -0.0504, -0.1135,  2.0047,  0.6832,\n",
       "          -0.0489, -0.1099, -0.0548, -0.5751, -0.0433, -0.0601, -0.0445,\n",
       "          -0.0435, -0.0445,  0.6477,  2.1309, -0.0781,  2.6711, -0.1599,\n",
       "          -0.0477]]),\n",
       " tensor([[-0.0489, -0.0703, -0.1173,  2.5989, -0.0496,  0.7705, -0.0485,\n",
       "           2.5209, -0.1234,  0.3026, -0.0431, -0.1196, -0.1811, -0.6863,\n",
       "           0.0536,  0.7261, -0.0928, -0.0904, -0.1231, -0.6230, -0.0577,\n",
       "          -0.1267, -0.1286, -0.1261,  0.7411, -0.0597, -0.1062, -0.1754,\n",
       "           0.7085]]),\n",
       " tensor([[-0.0489,  0.7794, -0.0765, -0.0610,  2.0935, -0.0604, -0.0760,\n",
       "           2.3160, -0.1058,  0.7714, -0.1859, -0.0513, -0.0500, -0.1055,\n",
       "          -2.7764, -0.0965, -0.0623, -0.1157, -0.0572, -0.0812, -0.0702,\n",
       "          -0.0910,  0.5077, -0.1115, -0.0865, -0.1098,  0.5718,  0.6515,\n",
       "          -0.1391]]),\n",
       " tensor([[ 1.6200, -0.6475, -0.0511, -0.0490, -0.0509,  2.5332, -0.2867,\n",
       "          -0.0591, -0.0904, -0.1170,  2.7885, -0.5218, -0.0494, -0.1051,\n",
       "          -0.1815, -0.0579, -0.1749,  2.5702, -0.1634, -0.0620, -0.0509,\n",
       "          -0.1236, -0.1706, -0.1747,  0.6938, -0.4056, -0.1814, -0.1713,\n",
       "          -0.0853]]),\n",
       " tensor([[-0.1505, -0.1624, -0.1564,  1.4536, -0.0576, -0.1310, -0.3717,\n",
       "          -0.8174, -0.1179, -0.3010, -0.0511,  0.7198, -0.1636, -0.1283,\n",
       "           0.7029, -0.1640, -0.1806, -0.0517,  0.0858, -0.0542, -0.1793,\n",
       "          -0.0513, -0.0502,  0.3416,  0.6292,  1.8937, -0.1647, -0.0530,\n",
       "           1.7943]]),\n",
       " tensor([[-0.1866, -0.1130, -0.1646, -0.4793, -0.6690, -0.0583, -0.0794,\n",
       "          -0.0850, -0.0913, -0.0522, -0.0537, -0.0604, -0.0544, -0.1555,\n",
       "          -0.1846, -0.1562, -0.1304, -0.0566,  2.6314, -2.2433,  0.6683,\n",
       "          -0.1104,  0.7185,  0.0440, -0.0632, -0.1855, -0.0653,  0.6765,\n",
       "          -0.1488]]),\n",
       " tensor([[-0.0803,  0.7183, -0.0542, -0.0772, -0.0584,  0.6983,  0.1117,\n",
       "          -0.1190,  1.4845,  0.5098,  0.3055, -0.0831,  1.3534, -0.1908,\n",
       "           0.5413, -0.1363, -2.7634, -0.6099, -0.0598, -0.1267, -0.1094,\n",
       "           0.7169, -0.0714, -0.0822, -0.1120,  0.7219, -0.1718, -0.1522,\n",
       "          -0.0605]]),\n",
       " tensor([[-0.1935, -2.8719, -0.1659,  0.7008, -0.1021, -0.0619, -0.2176,\n",
       "          -0.0717, -0.0576, -0.1581, -0.0730, -0.1847,  0.7025, -0.1839,\n",
       "           2.5975, -0.1471, -0.4119, -0.0035,  0.6723, -0.0545, -0.1005,\n",
       "          -0.0591, -0.1274, -0.0634, -0.3271, -0.1181,  2.2432, -0.1881,\n",
       "          -0.0538]]),\n",
       " tensor([[-0.0546, -0.0535, -0.0580, -0.1677, -0.5043,  1.1146, -0.0638,\n",
       "          -3.0438, -0.0743, -2.3351,  2.4502, -0.1074, -0.1833, -0.1120,\n",
       "          -0.1207,  2.4910, -0.0529, -0.0599, -0.0797, -0.2206,  0.1774,\n",
       "          -0.1490, -0.4199,  0.7115, -0.0580, -0.6318,  2.4801, -0.1681,\n",
       "          -0.0585]]),\n",
       " tensor([[-0.1428, -0.3943, -0.0747, -0.1130, -0.0593, -0.1173, -0.0784,\n",
       "          -0.0552, -0.1963, -0.1753,  2.4914,  0.7257,  2.8603, -0.0761,\n",
       "           0.7300, -0.0863, -0.1569, -0.1011, -0.1870,  0.7000, -0.1227,\n",
       "           0.7024, -0.0575, -0.1899, -0.2950,  2.5382, -0.1048,  0.5847,\n",
       "           1.0275]]),\n",
       " tensor([[ 0.4368, -1.1719, -0.7119, -0.1574, -0.0648, -0.1072, -0.1114,\n",
       "          -0.0630,  0.4994, -0.6859, -0.1529, -0.0695,  0.7052, -0.1354,\n",
       "           2.5629, -0.2624,  0.6807, -0.1221, -0.0713, -0.1112, -0.0247,\n",
       "          -0.0590, -0.1884, -0.1808, -0.0561, -0.1026,  0.1891, -0.1521,\n",
       "           0.3060]]),\n",
       " tensor([[ 0.6804,  0.5401, -0.0633, -0.0548,  2.7494,  2.5180, -0.1215,\n",
       "          -0.1818,  0.3745,  0.0751, -0.1889, -0.0605, -0.0626, -0.1707,\n",
       "          -0.0548, -0.0026, -0.1419, -0.0877,  2.5103, -0.1460, -0.0569,\n",
       "          -0.1811, -0.1708, -0.0550, -0.0690, -0.1813, -0.0550,  2.5179,\n",
       "           0.5805]]),\n",
       " tensor([[-0.0700, -0.0879, -0.0977,  0.6081,  2.5570,  0.1862,  0.4501,\n",
       "          -0.0573, -0.1093, -2.8730,  0.5181, -0.1882,  0.3427, -0.1542,\n",
       "          -0.1328,  2.3804, -0.1271, -0.1469, -0.1651, -0.2665, -0.1034,\n",
       "          -0.0573, -0.0781, -0.0985, -0.0652, -0.1800,  0.5764, -0.0642,\n",
       "          -2.7774]]),\n",
       " tensor([[-0.1037, -0.1447, -0.1047, -0.1728, -0.0479,  2.9505, -1.3412,\n",
       "           1.5279, -3.0647, -0.0581, -1.2345, -0.0597, -1.9729,  2.4493,\n",
       "          -0.1050,  0.0632, -0.6763, -0.1921, -0.0584, -0.1181, -0.1896,\n",
       "           0.6609, -0.1791, -0.3347, -0.4369, -0.1794, -0.1397,  0.3610,\n",
       "          -0.3943]]),\n",
       " tensor([[-0.0732, -0.1432, -0.1823, -0.1780, -0.5601, -0.1798, -0.0565,\n",
       "          -0.1817,  0.6805, -0.1550, -0.1028, -0.1467,  2.6132, -0.1514,\n",
       "           2.5903, -0.0542, -0.1865, -0.0594,  1.1022, -0.0675,  0.7384,\n",
       "           0.7132,  2.5962,  2.5448, -0.2888, -0.2567, -0.1316, -0.0633,\n",
       "          -0.2633]]),\n",
       " tensor([[ 0.7824, -0.1881, -0.1149, -0.1203,  0.4573, -0.0719, -0.0579,\n",
       "          -0.1615, -0.1681, -0.1255, -0.0544, -0.1419, -0.3154,  0.7088,\n",
       "          -0.1334, -0.0676, -0.1055, -0.0616, -0.0597, -0.0579, -0.0540,\n",
       "          -0.7019, -0.0563, -0.1730, -0.1791, -0.0571, -0.1051,  2.5314,\n",
       "          -0.1355]]),\n",
       " tensor([[ 0.9175, -0.6113,  0.6870,  0.1410, -0.1785, -0.4903, -0.2194,\n",
       "          -0.0584,  2.7517,  2.3873, -0.4160,  0.6119,  0.6680,  2.0693,\n",
       "          -0.0788, -0.0722,  0.7225, -0.6497, -0.0543, -0.1679, -0.1772,\n",
       "          -0.2276, -2.8300, -0.0570,  2.7784, -0.0581,  0.7192, -0.1680,\n",
       "          -0.0564]]),\n",
       " tensor([[-0.1877, -2.9899, -0.1586,  1.3239, -0.0566, -0.1379, -0.0997,\n",
       "          -0.1221, -0.0880, -0.0615, -0.0581, -2.6888, -0.1069,  0.1658,\n",
       "           0.2234, -0.3564, -0.0909, -0.0761,  2.7465, -0.1617, -0.0591,\n",
       "          -0.6740, -0.1699,  0.7272, -0.1084, -0.0652, -0.0560, -0.1812,\n",
       "           0.3759]]),\n",
       " tensor([[-0.1936, -0.1897, -2.8050, -0.1865, -0.1718,  0.7202, -1.4154,\n",
       "          -0.1501,  1.8091,  2.5189, -0.1252, -0.4010, -0.0920, -2.8204,\n",
       "          -0.0558, -0.0521, -0.0790, -0.0563,  0.4518, -0.0520, -0.0526,\n",
       "          -0.2389,  0.1302, -0.2025, -0.1935,  1.1796,  0.1085,  0.1179,\n",
       "           2.7543]]),\n",
       " tensor([[ 0.6884, -2.6771, -0.2456, -0.0512, -0.0774, -0.1863, -0.1909,\n",
       "          -0.1116,  2.6752, -0.5506, -0.0502, -0.1201,  0.7541, -0.3166,\n",
       "          -0.0745,  0.6199, -0.1310, -0.0552, -0.1357, -0.5913, -0.0515,\n",
       "          -0.0679, -0.0506, -0.1478, -0.0817, -0.1353, -0.0540,  1.8378,\n",
       "          -0.1286]]),\n",
       " tensor([[-0.0695, -0.1561,  0.7252, -0.0525,  0.7241, -0.1646, -0.1423,\n",
       "          -1.3710, -0.1820, -0.0633, -0.1597, -0.7028, -0.0521,  2.5421,\n",
       "          -0.1363, -0.0984,  0.0412, -0.0655, -0.1814,  0.7412,  0.7571,\n",
       "          -0.0579, -0.1860, -0.4341, -0.3086,  0.7519, -0.0685, -0.0542,\n",
       "          -0.0864]]),\n",
       " tensor([[ 1.3487, -0.0582, -0.0597,  0.7299, -0.1660, -0.1286, -0.0618,\n",
       "           0.1420, -0.0493, -0.0672, -0.0740, -0.5532,  0.7218, -0.0578,\n",
       "          -0.0565, -0.3099,  0.7347, -2.3544, -0.0825, -0.0799, -0.0858,\n",
       "          -0.1493, -0.0620, -0.1665, -0.0546, -0.1779, -0.0565, -0.3964,\n",
       "           2.7452]]),\n",
       " tensor([[-0.0721, -0.0861,  0.4413, -0.0516,  0.6321, -0.0567,  2.5972,\n",
       "           1.5328, -0.1352, -0.0631, -0.1015, -0.0575, -3.0330,  0.0635,\n",
       "          -0.0519, -0.1789,  0.7600, -2.7620,  0.7674, -0.2174, -0.3870,\n",
       "           0.4126, -0.1731, -0.1593, -0.1302,  0.6630, -0.0895, -0.0656,\n",
       "           0.2117]]),\n",
       " tensor([[-0.1820, -0.1844, -0.1014, -0.0550,  0.7284, -0.1121, -0.0675,\n",
       "          -0.0932, -0.0550, -0.0547,  0.5963, -0.0535, -0.1755,  0.7332,\n",
       "          -0.1153, -0.2209, -0.0540,  0.4016, -3.1338,  0.6123,  0.2513,\n",
       "          -0.1656, -0.1821,  0.7334, -0.0537,  0.5223, -0.0677, -0.0543,\n",
       "          -0.0543]]),\n",
       " tensor([[ 0.6620, -0.0798, -0.0761, -0.0572,  0.6628, -0.0695, -0.0552,\n",
       "          -0.0552,  0.2334,  2.1964, -0.1245, -0.0541, -0.0109, -0.1073,\n",
       "          -0.1759, -0.1224, -0.0552, -0.0538, -0.1896, -0.1498, -0.1757,\n",
       "           0.7266, -0.4504, -0.1509, -0.1901, -0.7637, -0.0966, -0.7102,\n",
       "          -0.1777]]),\n",
       " tensor([[-0.0664, -0.0744, -0.0951, -0.1633, -0.1676, -0.1456, -0.5776,\n",
       "          -0.0932,  0.7269, -0.1789, -0.1816, -0.0620, -0.0739,  2.6101,\n",
       "          -0.0869, -0.1078,  0.3002,  2.0274, -0.1875,  0.3446,  0.5629,\n",
       "          -0.0568, -0.7171,  2.5780, -0.1920, -0.1774, -0.1662, -0.2747,\n",
       "          -0.1779]]),\n",
       " tensor([[ 2.6200, -0.1834, -0.6023,  2.3876, -0.1246,  0.6438, -2.9933,\n",
       "           0.0547, -0.0566, -0.0571, -0.0583, -0.0609,  1.7278, -0.7809,\n",
       "          -1.3646,  0.6559, -0.5590, -0.0550, -0.1833, -0.1527, -0.1835,\n",
       "          -0.0551, -0.0627,  0.5652, -0.1816, -0.1405,  2.4838, -0.1363,\n",
       "          -2.9342]]),\n",
       " tensor([[-0.1552,  0.4725, -0.0774, -0.1666, -0.1451, -0.1544, -0.0590,\n",
       "          -0.0670,  2.6024, -0.2876,  0.6423,  2.4212, -0.1432, -0.1694,\n",
       "           0.2920, -0.0662, -1.0249, -0.6152, -0.0556, -0.2797,  0.0718,\n",
       "          -0.0712, -0.4786, -3.1526, -0.0753, -2.9927, -0.1888, -3.3143,\n",
       "          -0.1509]]),\n",
       " tensor([[ 0.1055,  2.4655, -3.3353, -0.7175,  0.1882, -0.0724, -0.5652,\n",
       "          -0.0710, -0.1526,  2.6987,  0.6996, -0.0581, -0.1668,  1.2629,\n",
       "           2.5605, -0.1592, -0.0687, -0.1583, -0.1861,  2.1073, -0.1870,\n",
       "           2.1544, -0.1913,  0.3974, -2.9630, -0.0843,  2.5269, -0.0803,\n",
       "          -0.0601]]),\n",
       " tensor([[ 0.7179, -0.0654,  2.0721,  2.7302, -0.1871, -0.0587, -0.0945,\n",
       "          -0.0562, -0.0775,  0.0528,  2.4997,  0.7103, -2.9630, -0.0579,\n",
       "          -0.1894, -0.1566, -0.0879,  2.3537, -0.0638, -0.0615, -0.0558,\n",
       "          -0.3421,  1.4185, -0.4914, -0.0626,  2.0566, -0.0612, -0.2584,\n",
       "          -0.0559]]),\n",
       " tensor([[-0.0555,  0.7409, -0.6721,  2.6540, -0.1199, -0.0645,  0.0549,\n",
       "          -0.0551,  1.6830, -0.1781, -0.0927, -0.1046,  2.5298,  0.7137,\n",
       "          -0.1524, -0.0668,  0.0874, -0.0560, -0.1280,  0.6351, -0.1531,\n",
       "           0.3198, -0.0808, -0.1522, -0.1677, -0.0917, -0.0733,  0.1539,\n",
       "          -0.6470]]),\n",
       " tensor([[-0.1832,  0.4279, -2.7741, -0.0697,  2.4603,  0.7179, -0.1621,\n",
       "          -0.0823, -0.0577,  2.4400, -0.1029, -0.1327,  0.0440, -0.0560,\n",
       "          -0.0554, -0.0613, -0.1422, -0.0545,  2.2416,  0.2867, -0.1612,\n",
       "          -0.6025, -3.2861,  1.9955, -0.0550, -0.0547,  0.6881, -0.1556,\n",
       "          -0.0617]]),\n",
       " tensor([[-0.0635, -0.7066, -2.3498, -0.3593, -0.0703,  2.5848, -2.2198,\n",
       "          -0.1697, -0.1582, -0.0540, -0.0558, -0.1123, -0.0544, -0.1601,\n",
       "          -0.0633,  0.6002, -0.0714, -0.0600, -0.0568,  0.0063,  0.4227,\n",
       "          -0.1673, -2.3554, -0.1252, -0.0548, -0.0438, -0.2089, -0.1734,\n",
       "          -0.1373]]),\n",
       " tensor([[-0.0522,  0.7270,  0.7136,  0.0645,  0.5428, -0.0860, -0.1907,\n",
       "          -0.0649, -0.1536, -0.0668, -0.0636, -0.0929, -0.5059, -0.0991,\n",
       "           0.0646,  2.1361,  2.7171, -0.0047,  0.6987, -0.5232, -0.3392,\n",
       "           0.3820,  2.7022, -2.7229, -0.1810, -0.2351,  0.7557, -0.0551,\n",
       "          -2.8848]]),\n",
       " tensor([[-0.0643,  1.2481, -0.1596, -0.0788, -0.0705,  2.4883,  2.9053,\n",
       "          -0.0675,  0.6131,  2.4801, -0.1767,  0.3011, -0.0846, -0.3665,\n",
       "          -0.0658, -0.8663,  2.5310, -0.1785, -0.2006, -0.0545, -0.0509,\n",
       "          -0.0523, -0.1657, -0.0562,  2.5172, -0.0852, -1.6121, -0.0530,\n",
       "           2.5342]]),\n",
       " tensor([[ 0.3694, -0.6168, -0.1627, -0.0609, -0.1338, -0.1290, -0.0586,\n",
       "          -0.0572, -0.1114, -0.0852, -0.0836, -0.0520, -0.1664, -0.0521,\n",
       "          -0.0536, -0.0679, -0.6528, -2.0563, -0.0930, -0.0618,  0.7240,\n",
       "          -0.1661, -0.6649, -0.1291, -0.1821, -0.0766,  0.5216, -0.6091,\n",
       "          -0.0722]]),\n",
       " tensor([[-0.0557, -0.0546,  0.1967, -0.0660, -0.0564, -0.0629,  1.9758,\n",
       "           0.6940, -0.1841,  2.4896, -0.0526, -0.0544,  2.5679, -0.0515,\n",
       "          -3.0746, -0.0518,  0.7198,  2.6341, -3.1339, -0.1856, -0.0854,\n",
       "           0.4427, -0.0524, -0.1268, -0.0660, -0.1776, -0.1138,  2.6281,\n",
       "          -0.0534]]),\n",
       " tensor([[-0.5105, -0.0791, -0.1220, -0.0584, -0.0638, -0.1911, -0.0777,\n",
       "          -0.0681,  0.6054, -0.1027, -0.1790, -0.1039,  2.7583, -0.1194,\n",
       "          -0.5016, -0.1814, -0.0637,  0.5110, -0.4521, -0.6696, -0.0578,\n",
       "          -0.0565, -0.0761,  0.2266, -0.1475, -0.0938,  2.6269, -0.0876,\n",
       "          -0.2126]]),\n",
       " tensor([[-0.1783, -0.0949, -0.1618, -0.0691,  2.7695, -0.1201, -0.0537,\n",
       "          -0.3014, -0.0500, -0.0585,  0.3418, -0.2506, -0.5249, -0.1282,\n",
       "          -0.0735,  0.7438, -0.1458, -0.1357, -0.0501,  2.4313, -0.1721,\n",
       "          -0.1159, -0.0733, -0.1127,  2.5866, -0.0594, -0.1209,  0.7011,\n",
       "          -0.2873]]),\n",
       " tensor([[-0.0792, -0.1387, -0.0522,  0.6324, -0.1004,  0.7233, -0.1112,\n",
       "          -0.1372,  0.3851, -0.5973, -0.0540, -0.1440, -0.0555, -0.1735,\n",
       "          -0.6369,  0.0430, -0.1593,  0.6903, -0.1177, -0.0507, -0.1303,\n",
       "          -0.1155, -0.1084, -0.0609, -2.9758,  0.7418, -2.1382, -0.1693,\n",
       "          -0.2509]]),\n",
       " tensor([[-0.3299, -2.2318, -0.1845,  0.1968, -0.0522, -0.1552,  0.7381,\n",
       "          -0.0513, -0.0901, -0.2337, -0.0501, -0.5649, -0.1180, -0.1825,\n",
       "          -2.5796, -0.3458, -0.0828, -0.0513, -0.1647, -0.5362, -0.1490,\n",
       "          -0.0744, -0.0762, -0.0569,  0.7227, -0.2779, -0.1315, -0.0550,\n",
       "          -0.1762]]),\n",
       " tensor([[ 2.5269, -0.5939,  0.3162, -0.0496, -0.1868, -0.1699, -0.0683,\n",
       "          -2.8996, -0.1531, -0.1237, -2.9959, -0.0516, -0.1385, -0.3309,\n",
       "          -0.1763, -0.1855,  2.6235,  2.8396, -0.0538, -0.1363, -0.1675,\n",
       "          -0.0743, -0.1538,  0.7024, -3.1344,  1.9147,  0.5510,  0.6780,\n",
       "           0.0263]]),\n",
       " tensor([[-0.4375, -0.1228,  2.9079, -0.1558, -0.0559, -0.0897, -2.7129,\n",
       "          -0.0673,  0.8470, -0.0735,  0.7333,  2.5371, -0.0491, -0.0783,\n",
       "          -0.1502,  0.4447, -0.0504, -0.0581, -0.1132, -0.0893, -0.2933,\n",
       "          -0.1231, -0.0638, -0.0674, -3.1297, -0.0520, -0.1584, -0.1862,\n",
       "          -0.4046]]),\n",
       " tensor([[ 0.0514, -0.0502,  1.2847, -2.4293, -0.0680, -0.1864, -0.0963,\n",
       "          -3.2381, -0.0845, -0.1816,  0.7084,  0.7468, -0.0503, -0.1612,\n",
       "          -0.0558, -0.1711, -1.2817, -0.1643,  0.7549,  0.0108, -0.0502,\n",
       "          -0.0819, -0.0722, -0.0506,  2.5931, -3.0385, -0.4321, -0.0582,\n",
       "          -0.5339]]),\n",
       " tensor([[-0.2152, -0.0581, -0.0499, -0.1313, -0.1044, -0.4580,  0.2722,\n",
       "          -0.1095,  2.6406, -0.2749, -0.0821, -0.0560,  1.7277, -0.2198,\n",
       "          -0.0501, -0.1327, -0.1969,  1.6895, -0.0751, -0.1803, -0.1153,\n",
       "          -0.2271, -0.6630, -0.0615, -0.5991,  0.3973,  0.3579, -1.6019,\n",
       "          -0.1837]]),\n",
       " tensor([[-0.0621, -0.1487, -0.2815, -0.1248, -0.0959, -0.0508, -0.0585,\n",
       "           0.7340, -0.0467,  1.8208, -0.5025, -0.0530, -0.1502,  2.7528,\n",
       "          -0.1858, -0.1135, -0.0607,  1.6872,  2.7892, -0.1763, -0.0519,\n",
       "          -2.3682, -0.1054,  2.7012, -0.1138, -0.0912,  0.4823, -0.0555,\n",
       "           2.4620]]),\n",
       " tensor([[-0.0682, -0.1211,  2.9007, -0.1856, -0.0524, -1.7389,  2.5655,\n",
       "          -0.6654, -0.0544, -0.1073, -0.1124, -0.1778, -0.1577, -0.1845,\n",
       "          -0.0497, -0.1810,  0.6966, -0.0831, -2.8388, -0.0495,  0.7357,\n",
       "           0.5811,  0.7207,  0.7271, -0.1724, -0.0539, -3.2930, -0.1730,\n",
       "           2.5488]]),\n",
       " tensor([[-0.2988, -0.1070, -0.3591,  0.1573, -0.0859, -0.1827, -0.0693,\n",
       "           1.6921, -0.1029, -0.1733, -0.0528, -0.0527, -0.1705, -0.0591,\n",
       "           0.5591, -0.0534, -0.6500, -2.5698,  0.6474,  1.2162,  0.3004,\n",
       "           0.7323, -0.1530,  0.7133, -0.1109, -0.0545, -3.2140,  0.6932,\n",
       "          -0.1075]]),\n",
       " tensor([[-0.6578, -0.1880, -0.1673, -0.0879, -0.0617, -0.1619, -2.4555,\n",
       "          -0.6788, -0.0683, -0.0565, -0.3652, -0.0852,  0.6521,  2.3826,\n",
       "          -0.1400, -0.0872, -0.1618,  0.1489, -2.1704,  0.2572,  0.6959,\n",
       "           0.2178, -0.2051, -0.0649, -0.0630, -0.1521, -0.2039, -0.0530,\n",
       "          -0.0469]]),\n",
       " tensor([[-0.1490, -3.0283,  0.7453, -0.3094, -0.0613, -0.0718, -0.1098,\n",
       "          -0.1071, -0.2175,  2.3960, -0.0928, -0.0565, -0.0610, -0.0534,\n",
       "          -0.3162, -0.0857, -0.6849, -0.6427, -0.1749, -0.0531, -0.5928,\n",
       "           0.7377,  0.6199,  0.6570, -0.5973, -0.1587, -0.0532, -0.1423,\n",
       "          -0.0548]]),\n",
       " tensor([[ 1.7754, -0.0591, -0.0838,  0.6794, -0.0546, -3.0549, -0.0537,\n",
       "           2.5582,  2.5248,  2.6133, -0.1882, -0.0881,  0.3772, -2.9502,\n",
       "          -0.0644, -0.0203, -0.0711, -0.0554, -0.1340,  2.5611, -0.0570,\n",
       "          -0.1485, -0.1346, -0.0564, -0.0813, -0.0534,  1.3908, -0.0546,\n",
       "          -0.6199]]),\n",
       " tensor([[-0.1774, -0.0773, -0.0747, -0.0747, -0.1515, -0.1487, -0.0822,\n",
       "          -0.1381, -2.8988,  0.7081, -0.6218, -2.2637, -0.1630, -0.1832,\n",
       "           2.4969,  2.5441, -0.1904, -0.0540, -0.1838, -0.0663, -0.0531,\n",
       "          -0.0613, -0.0623, -0.0869, -0.1729,  2.7363, -0.1752, -0.1645,\n",
       "           0.6806]]),\n",
       " tensor([[-0.4623, -0.0927, -0.1659, -0.5614, -1.9598,  0.6499, -0.0906,\n",
       "          -0.6031, -0.0930,  0.1975,  2.7344, -0.1347, -0.0573,  0.7667,\n",
       "          -0.0896, -0.5735, -0.0531,  0.3518, -0.1765, -0.1066, -0.0549,\n",
       "          -0.0545, -0.2619, -0.0532,  0.0147, -0.1044, -0.1794, -0.3555,\n",
       "          -0.0532]]),\n",
       " tensor([[-0.0607,  0.7514, -0.0535, -0.1824, -0.1793, -0.0543, -0.0553,\n",
       "           0.5058,  2.3133,  0.0634, -0.0540, -2.7995, -0.0962, -0.0996,\n",
       "          -0.0849,  0.4299, -0.1548, -3.2645, -0.1264,  1.2879, -0.1782,\n",
       "          -2.2390, -0.1691, -0.1082,  2.4536, -0.0671,  0.6780, -0.0551,\n",
       "          -2.7112]]),\n",
       " tensor([[-0.0622,  0.9819,  0.7190, -0.1380,  0.5807,  2.5858, -0.1633,\n",
       "          -0.1372,  0.0492, -0.0533, -0.0798, -0.1218, -0.0635,  2.5332,\n",
       "          -0.2378, -0.1633, -0.1207,  2.5417, -0.3538, -0.0639,  0.6575,\n",
       "          -0.1006,  0.4119, -2.6022, -3.1375, -0.1655, -0.0526,  0.6967,\n",
       "          -0.2581]]),\n",
       " tensor([[-0.0770,  0.4551, -0.1459,  0.5777, -0.0557, -0.1563, -0.0612,\n",
       "           0.4921, -0.0509, -0.0785, -0.0924, -0.0488, -0.0540, -0.1392,\n",
       "           0.1764,  0.5919, -0.1464, -0.0593,  0.0992, -0.5559, -0.0627,\n",
       "           2.5132,  0.1522,  0.7287,  0.7346, -0.1100, -0.0508, -0.0795,\n",
       "          -0.1379]]),\n",
       " tensor([[ 0.7261, -0.1047, -0.0467, -0.1061,  0.7080, -0.0591, -0.1286,\n",
       "          -0.0832, -0.1690, -0.1614, -0.5192, -0.1173, -0.1037,  2.2415,\n",
       "           0.1921,  0.6509,  0.1531, -0.0812,  0.7196, -0.0449, -0.4360,\n",
       "           0.7376, -0.0475, -0.7033, -0.0610,  2.6475, -0.6665,  2.5957,\n",
       "           0.7104]]),\n",
       " tensor([[ 0.7469,  2.4995, -0.4031, -0.1043, -0.1517, -0.0446,  0.7408,\n",
       "          -0.1564, -0.0805,  0.1250, -0.1088,  2.5672,  2.5836, -0.0452,\n",
       "          -0.1297, -0.0421, -0.0892,  0.3766, -0.1609, -0.1641, -0.1592,\n",
       "          -0.0562, -0.0435, -0.1367, -0.0660, -0.0571, -0.1087, -0.1147,\n",
       "          -0.0573]]),\n",
       " tensor([[ 0.4174, -0.0612, -0.1719, -0.7005, -0.1411,  2.1002, -0.1114,\n",
       "          -0.1408, -0.1142, -0.0582, -0.0526, -0.0302, -0.0407, -0.0528,\n",
       "          -0.0590, -0.0535, -0.0510,  0.7485,  2.5042,  2.5001,  0.7042,\n",
       "          -3.1214,  0.7223, -0.1705, -0.0576, -0.0487, -2.9136, -0.1693,\n",
       "          -0.0459]]),\n",
       " tensor([[-0.1709, -0.0752, -0.1699, -0.0534, -0.3423, -0.0541, -0.0650,\n",
       "          -0.0536,  1.1833, -0.0129, -0.0939, -0.1533, -0.1526, -0.0409,\n",
       "          -0.0836, -0.0628, -0.0448, -0.0412,  0.5998,  0.5307, -0.0831,\n",
       "          -0.1615, -0.5658, -0.0457,  0.6542,  0.7594, -0.0533,  2.6209,\n",
       "           0.7283]]),\n",
       " tensor([[-0.1440,  0.1063, -0.0652,  0.3161,  0.5045, -0.0905, -0.0445,\n",
       "          -0.0421,  0.7141, -0.0420, -0.0422, -0.1788, -0.1009,  2.8225,\n",
       "          -0.3941,  0.6618, -0.1712,  2.6291,  2.7408, -0.0988, -0.0424,\n",
       "          -0.1283, -0.1304,  0.2630, -0.1384, -0.0463,  0.1142, -0.0588,\n",
       "          -0.0463]]),\n",
       " tensor([[-0.0457,  0.6621, -0.0632, -0.1465,  0.7553,  0.4554, -0.1728,\n",
       "          -0.0788, -2.6710, -0.1712, -0.0568, -0.0424, -0.0484,  2.5190,\n",
       "           0.0531, -0.0409,  0.5603,  0.5438, -1.6051,  0.6620, -0.0786,\n",
       "          -0.3358, -0.1217, -0.0403, -0.2449,  0.7303,  0.5243, -0.0458,\n",
       "           0.7218]]),\n",
       " tensor([[-0.0415, -0.1615, -3.0743,  0.0066, -0.1229, -0.0579, -0.4303,\n",
       "           2.5336, -0.0464, -0.0438, -0.1289,  0.7213, -0.1714, -0.0458,\n",
       "          -0.0461,  0.2465,  0.0873, -0.1350,  0.2611,  2.9646,  2.6119,\n",
       "           0.7130, -0.0449, -0.0988,  1.1304, -0.1375, -0.1472, -0.0431,\n",
       "          -0.1745]]),\n",
       " tensor([[-2.7655, -0.1334,  0.7919, -0.0393, -0.0461,  0.0455, -0.5844,\n",
       "           0.0070, -1.4126,  0.7273,  0.7541, -0.1500, -0.5236,  0.2852,\n",
       "          -0.2157,  0.5330, -0.1531, -0.0791, -0.0423, -0.1593, -0.2312,\n",
       "          -0.1446, -0.0418, -0.0435,  0.0064,  0.0521, -0.1547,  0.1452,\n",
       "           1.4945]]),\n",
       " tensor([[-0.1041,  0.3556, -0.1266, -0.0446,  0.3122, -0.0877, -0.0392,\n",
       "           0.7780, -0.0410, -0.1183,  0.5481, -0.0938, -0.4407, -0.0407,\n",
       "           0.5165, -0.0454,  1.7282,  1.9156, -0.1792, -0.0874,  2.8605,\n",
       "          -0.0495, -0.0713,  2.5234,  0.6525, -0.0448, -0.0682, -0.6852,\n",
       "           0.7466]]),\n",
       " tensor([[-0.1099, -0.0812, -0.0399, -0.0441,  0.2904,  0.5555, -0.0960,\n",
       "          -0.0590, -0.1039, -0.0413, -0.1037, -0.0470,  0.8926, -0.0476,\n",
       "          -0.0949, -0.0407, -0.0406, -0.0884,  1.5709, -0.6154,  0.7182,\n",
       "           2.7631,  0.7195, -0.3023,  0.6183, -0.0474, -0.0441,  0.0182,\n",
       "          -0.6332]]),\n",
       " tensor([[ 0.7449, -0.1773, -0.0414, -0.1708, -0.0419, -0.6938, -0.0446,\n",
       "          -2.7845,  0.7413,  0.7388, -0.0468, -1.4329,  2.5543, -0.0464,\n",
       "           0.1429, -0.5879, -0.1603, -0.0491,  0.2023, -0.0991,  2.5727,\n",
       "          -0.1370, -0.0427, -0.4428,  2.6094, -0.0432, -0.4212, -0.1859,\n",
       "          -0.0441]]),\n",
       " tensor([[-0.1555, -0.0419, -0.1311, -0.1081, -2.6730,  0.6360, -0.0773,\n",
       "          -0.0606, -0.1458,  0.7287,  0.6659, -0.0543,  0.4607,  0.7251,\n",
       "          -3.0396,  0.7345, -0.0443, -0.0520, -0.5775,  2.4674, -0.0458,\n",
       "          -2.4324, -3.0810, -0.0490, -0.1694, -0.1345, -0.0437, -0.2610,\n",
       "           0.7170]]),\n",
       " tensor([[-0.1366, -0.3206,  0.4629, -0.0842, -0.0414,  0.7292,  0.6139,\n",
       "          -0.0423, -0.0429, -0.0460,  2.5239,  0.1194, -0.0788, -0.0477,\n",
       "          -0.0527,  0.7831, -0.0447, -0.0401, -0.0505, -0.0621, -0.1602,\n",
       "          -0.1527,  0.6835, -0.0304, -0.0420,  2.5536, -0.0495, -0.0591,\n",
       "          -0.3445]]),\n",
       " tensor([[ 2.5827,  2.7570, -0.1687, -0.0428, -0.8951, -0.0941,  2.6335,\n",
       "          -2.9809,  1.6589, -0.1447,  2.2122, -0.3211,  0.7320, -0.1087,\n",
       "           0.6253, -0.1901, -0.0441,  0.6809,  0.3552, -0.0412,  0.7277,\n",
       "          -0.1673, -0.0884,  1.0553, -0.1457,  2.6247, -0.0426, -0.1076,\n",
       "          -3.1556]]),\n",
       " tensor([[ 0.7360,  0.7352,  0.4722, -2.8704, -0.2064, -0.0512, -0.0464,\n",
       "          -0.0458, -0.0532, -0.0698, -0.0943,  0.7462, -0.0639,  0.7052,\n",
       "          -0.0515,  0.7259, -0.3416, -3.0877, -0.1669, -0.0437, -0.1765,\n",
       "           2.1417,  0.7318, -0.6485, -0.0707,  0.5704,  0.6458, -0.0486,\n",
       "           0.6921]]),\n",
       " tensor([[ 0.3063, -0.1698, -0.0967, -0.0429, -3.1291, -0.0539,  0.2772,\n",
       "           2.6004,  0.5127, -0.1609,  0.1431, -0.2307,  0.5751, -0.0551,\n",
       "          -0.1178, -0.0860, -0.0770, -0.1138, -0.0851, -0.1860, -0.0551,\n",
       "          -0.6868, -0.3829, -0.0708, -0.1726, -0.0780, -0.0585, -1.8616,\n",
       "           0.7717]]),\n",
       " tensor([[-0.0428,  0.7144, -0.0865, -0.0758, -0.0431, -0.1667, -0.1825,\n",
       "          -0.4720,  0.3010, -0.0955, -0.0825, -0.1308, -0.0838, -0.0490,\n",
       "           0.3401, -0.0722,  2.5438, -0.0428, -0.1599, -0.0505, -2.4257,\n",
       "          -0.0969, -0.0428, -0.0649, -0.1953, -0.0569,  2.5610, -0.0979,\n",
       "          -0.1347]]),\n",
       " tensor([[-0.1189, -3.0382, -0.1154, -0.2135, -0.0457,  2.3194,  2.5291,\n",
       "          -0.1770, -0.1830,  0.7339, -2.9447, -0.0788, -0.0683, -0.1781,\n",
       "          -0.3734, -0.0455,  0.3868,  0.7285, -0.0548, -0.0429, -2.9544,\n",
       "          -0.1284,  2.5198, -0.0490, -0.0716, -0.0496, -0.4367, -0.0716,\n",
       "          -0.0937]]),\n",
       " tensor([[ 2.5924, -0.0328, -0.1108, -0.0922, -0.0704, -0.0434, -0.1781,\n",
       "           2.5444, -0.0569, -0.0445,  0.3916, -0.2572,  0.6085,  2.6759,\n",
       "          -0.0479,  0.3288,  0.6836, -0.0493, -0.0501, -1.4512,  2.4706,\n",
       "           0.0114, -0.0475, -0.0687, -0.0823, -0.0434, -0.0448,  0.7414,\n",
       "          -0.0491]]),\n",
       " tensor([[-0.0447, -0.0442, -0.2685, -0.6082, -0.1287, -0.1729, -0.3290,\n",
       "          -0.0438, -0.0466, -0.0598,  0.1491, -0.0897,  1.5983,  1.6841,\n",
       "          -0.1678, -0.1809, -0.0497, -0.0461, -0.1185, -0.3043, -0.0482,\n",
       "           1.0820,  2.0627, -0.1327, -0.0821, -0.0678, -0.1224,  0.5439,\n",
       "          -0.0437]]),\n",
       " tensor([[-0.0471,  0.1382, -0.1472,  2.5151, -0.0498, -0.1847, -0.0467,\n",
       "          -0.0521, -2.6964,  2.5563, -0.0542, -0.2054, -0.0077, -0.0674,\n",
       "          -0.1011, -0.0656, -0.0739, -0.1629, -0.0560, -0.9898, -0.1311,\n",
       "          -0.0510, -0.0468, -0.0479, -0.5534, -0.4877, -0.0485, -0.0970,\n",
       "           2.5690]]),\n",
       " tensor([[ 3.0825,  0.7248, -1.3879, -0.0920, -0.3299, -0.1183, -0.0581,\n",
       "          -0.1014, -0.0476, -0.3402, -0.0745,  0.7198,  0.6167, -0.1756,\n",
       "           2.6597, -0.0501, -0.0503,  0.7285,  0.7232, -0.1823, -0.0553,\n",
       "          -0.1795,  1.8794, -0.1638, -0.0726,  0.7333, -2.6157, -0.0771,\n",
       "          -0.1786]]),\n",
       " tensor([[ 2.5476, -2.9385, -0.1670, -0.0491,  2.0610,  2.5487,  0.6875,\n",
       "          -0.1741, -0.1319, -0.1798, -0.0668,  0.7381, -0.1814, -3.0612,\n",
       "          -0.1662, -0.1308, -0.0497, -0.0492, -0.2009, -0.1684, -0.0522,\n",
       "          -0.0758,  0.7362,  0.7673, -0.0487,  2.3580, -0.0499, -0.1506,\n",
       "          -0.1272]]),\n",
       " tensor([[-0.0509,  0.7548,  2.3339,  0.7148,  1.0106, -0.0558, -0.0662,\n",
       "           2.1984,  2.5809, -0.0508, -0.1142,  0.5535, -0.1720, -0.0495,\n",
       "          -0.1526, -0.1147, -0.0686, -2.8576, -0.2756,  2.5386,  0.7274,\n",
       "          -0.1766,  2.4227, -0.1038,  2.4361, -0.1815, -0.0535,  0.7215,\n",
       "          -0.0648]]),\n",
       " tensor([[-2.6654, -0.0590,  2.7936, -0.1126, -0.1015, -0.1186, -2.9335,\n",
       "          -0.3385, -2.6764,  0.2179,  0.7379,  2.5107, -0.1591, -0.0510,\n",
       "           0.4704, -0.6014, -0.2596, -0.1535, -0.1351, -0.0531, -0.0548,\n",
       "          -0.1720, -0.2530, -0.1116, -0.3319, -0.0633, -0.0552, -0.0528,\n",
       "           0.7371]]),\n",
       " tensor([[-0.0530,  0.4430,  0.7898,  1.4066, -0.0969,  2.5576, -0.0526,\n",
       "           0.7375, -0.0488, -0.0612,  0.6815, -0.1405,  0.2126, -0.0867,\n",
       "          -3.2054, -0.0872, -0.0519, -0.1899, -0.1174, -0.1777,  0.7201,\n",
       "          -0.0634, -0.4870, -0.1345, -0.0504, -0.1149, -0.3786, -0.0670,\n",
       "          -0.0467]]),\n",
       " tensor([[ 1.8538, -0.1784, -0.3236, -2.9020, -0.5542,  0.7728, -0.0645,\n",
       "           0.6433, -0.0923,  0.7210, -0.0537, -2.7592,  2.5420, -0.0668,\n",
       "          -0.1354, -0.0573, -0.0516, -0.0611,  0.7543, -0.0598, -0.0484,\n",
       "          -0.1662,  0.2515, -0.0995,  0.7807, -0.1254, -0.8755, -0.2675,\n",
       "          -0.0665]]),\n",
       " tensor([[ 1.7220, -0.0478,  1.4627,  0.6659,  0.3673, -0.0492,  2.5848,\n",
       "          -0.2116, -0.0538, -0.6476, -0.0548,  2.7069, -0.1775, -0.0753,\n",
       "          -2.8722, -0.0905, -2.0284,  0.0639, -0.0683, -0.0527, -0.0932,\n",
       "          -0.1276, -0.0533, -2.7309, -2.8568,  0.0064, -0.0780, -0.0693,\n",
       "          -0.1274]]),\n",
       " tensor([[-0.0980, -2.4134, -0.1286, -0.1870, -0.1013, -0.0729, -0.1825,\n",
       "          -0.0597, -0.0802,  2.6023, -0.1591, -0.0479, -0.0611, -0.1309,\n",
       "          -0.4565, -0.1413, -3.1298, -0.1570, -0.1278, -0.1643,  0.7561,\n",
       "           0.6134, -0.1474,  2.5959, -0.0887, -0.0491, -0.0697, -0.0922,\n",
       "          -0.0500]]),\n",
       " tensor([[-0.0509,  0.0189, -0.0741,  0.7060, -0.0797,  1.7884, -0.0587,\n",
       "          -0.1355, -0.0770, -0.1738, -0.0664, -2.5519, -3.2862, -0.0555,\n",
       "          -0.1475, -0.1343, -0.4563, -0.2819,  2.1448, -0.6072,  0.7472,\n",
       "           2.5226, -0.0505, -1.3257, -0.0560, -0.1168, -0.6055, -0.1571,\n",
       "          -0.1020]]),\n",
       " tensor([[-0.0619, -0.0763, -0.0860, -0.0604, -0.0612,  0.7786,  2.3878,\n",
       "          -0.6919, -0.1798, -0.0659, -0.3041, -0.0482,  1.4443,  0.6461,\n",
       "          -0.0517, -0.1782, -0.1043, -0.1588, -0.2668, -0.0476, -0.1487,\n",
       "          -3.1243, -0.0869,  2.5382, -0.0611, -0.0675,  0.7309, -0.0697,\n",
       "          -0.1742]]),\n",
       " tensor([[-0.0488,  0.6834, -0.0826, -0.0478, -3.0007, -2.8861,  0.5202,\n",
       "          -0.1749, -0.0518, -0.0486,  0.6979,  0.7263, -0.0734, -0.1688,\n",
       "          -0.1736, -0.4816, -0.0477, -0.1857, -0.3254,  0.1768,  1.8175,\n",
       "          -0.1013, -0.0799, -0.0993, -0.0539, -0.0475, -0.1686, -0.6414,\n",
       "           0.6507]]),\n",
       " tensor([[-0.0485, -0.2361, -0.0577,  2.6058, -2.7627,  0.7500, -0.1369,\n",
       "          -0.1562,  0.0965, -0.0510, -0.0835, -0.0570, -0.0507, -0.0858,\n",
       "          -2.8803,  0.4830, -0.1462, -0.1580, -0.0766, -0.1178, -0.0485,\n",
       "          -0.0504, -0.0475,  0.7136, -0.1314, -0.0481, -0.0601, -0.1526,\n",
       "          -0.1080]]),\n",
       " tensor([[-0.1359, -0.6188,  2.4127, -0.0512, -0.4689, -0.1005,  0.7559,\n",
       "          -0.0642,  0.0039, -0.1572, -0.1840,  0.7222, -2.1177, -0.3077,\n",
       "          -0.0556, -2.9231, -0.0783, -0.0676, -0.1799, -2.3535, -0.0962,\n",
       "           2.5585, -2.8093, -0.6040, -0.0931, -2.8821, -0.4558, -0.1685,\n",
       "          -0.3109]]),\n",
       " tensor([[-0.0661, -0.1238,  0.0977, -3.0472,  1.9498, -0.0332, -0.3285,\n",
       "           2.5343, -0.0475, -0.0664, -0.1730, -0.0712, -0.0838, -3.0098,\n",
       "          -0.1523,  1.5342, -3.1244,  0.7449,  0.6939,  0.4906, -0.1782,\n",
       "          -0.0506, -0.1544,  0.2807, -0.0696, -1.6463,  0.3504,  0.1523,\n",
       "           2.8031]]),\n",
       " tensor([[-0.1422, -0.0502, -0.4024,  2.5121, -0.0544, -0.1834, -0.1323,\n",
       "          -0.4035, -0.0848,  0.4934, -0.0785,  0.4682, -0.4415,  2.3130,\n",
       "          -0.0823, -0.1050, -0.0565, -0.0048, -0.5853, -0.7478, -0.0477,\n",
       "          -0.0612, -0.0810, -0.1384, -0.1492, -0.0688,  0.7379, -0.0532,\n",
       "          -0.0853]]),\n",
       " tensor([[ 0.4617, -0.1078, -0.0591, -0.0480, -0.0932, -0.0525, -0.0599,\n",
       "          -0.0690, -0.0500, -0.1492, -0.4709, -0.0570, -0.1830,  0.6020,\n",
       "           2.5490, -0.0862, -0.1234,  0.7342, -0.4137, -0.1169, -0.0475,\n",
       "           0.7355, -0.1293, -0.2475, -0.1786, -0.0490, -0.1173, -0.0855,\n",
       "          -0.0477]]),\n",
       " tensor([[-0.0470, -0.9881, -0.1536, -1.7692,  0.7351, -0.1154, -0.0945,\n",
       "           0.1998,  0.7143, -3.1740, -0.0811, -0.0644, -0.0670, -0.1669,\n",
       "           0.6359, -0.1124, -0.6104,  0.7266, -0.3492,  2.6067,  0.2903,\n",
       "          -0.0478,  0.5981, -2.5654, -0.0477,  0.6402, -0.0484, -0.4480,\n",
       "           0.6825]]),\n",
       " tensor([[-0.1834, -0.0504, -0.1319, -0.0506, -0.0964, -0.5951, -0.1787,\n",
       "           2.5620, -0.0509, -0.1791, -0.0649, -0.0467, -0.6706, -0.1225,\n",
       "          -0.0520,  0.7270,  0.7222,  0.7258,  2.8561, -0.0528, -0.1069,\n",
       "          -0.0475,  0.5286, -0.0723, -0.0467,  0.1028, -0.0785, -0.1721,\n",
       "           0.6219]]),\n",
       " tensor([[-0.0349, -0.1396,  0.3455,  0.2368, -0.0486,  0.0951, -0.0464,\n",
       "          -0.0653, -0.1509, -0.1743, -0.0649,  1.5566, -0.0654,  2.4995,\n",
       "          -0.0462, -0.0894,  0.1171, -0.0518, -0.1027, -0.1823,  0.7077,\n",
       "          -0.0492, -0.0632, -0.1441, -0.0604, -0.0545, -0.0890,  2.1575,\n",
       "          -0.5276]]),\n",
       " tensor([[-0.0467,  2.6329, -0.0599,  2.6046, -0.1086, -0.1488,  2.5838,\n",
       "          -0.0478,  0.3441, -2.3141, -0.0466, -0.2938,  0.6063, -0.0510,\n",
       "          -0.0933, -0.0458, -0.6485, -0.1030, -0.1665, -2.7914, -0.0490,\n",
       "          -0.5499, -0.0472, -0.1201, -0.0729, -0.0833,  0.7270, -0.5162,\n",
       "          -0.0462]]),\n",
       " tensor([[-0.0472, -0.0870, -0.1762, -0.0510, -0.1800, -0.1714,  0.2751,\n",
       "          -0.0618, -0.0992, -0.0530,  0.7357, -0.3933, -0.8727,  0.1305,\n",
       "           0.6737, -0.0798, -0.0529, -0.2283, -0.0584, -0.0712, -0.0844,\n",
       "          -0.4374,  0.7389,  1.0249, -0.0597,  0.7249, -0.1780, -0.1170,\n",
       "          -0.0958]]),\n",
       " tensor([[-0.1000, -0.2991, -0.3318,  2.5838,  0.7463, -0.6642, -0.0529,\n",
       "          -0.0933, -0.0849, -1.7311, -0.0709, -0.1395, -3.2293, -0.1426,\n",
       "           0.6970, -2.9308, -0.2729, -1.0451,  0.0421, -0.0463,  2.5710,\n",
       "          -0.0637, -0.0560, -0.0904, -0.0565,  1.8119, -0.3361, -0.0464,\n",
       "          -0.1723]]),\n",
       " tensor([[ 0.7213, -0.0664,  2.6473, -0.0926, -0.1277, -2.3672, -0.0475,\n",
       "          -0.0972,  0.4405, -0.0477,  0.5406, -0.1754, -0.1437,  2.8524,\n",
       "           2.5814,  0.1334, -0.0980, -3.0157, -0.1512, -0.2228, -0.1472,\n",
       "          -0.0770, -0.0575, -0.0490,  2.5616,  2.6927, -0.5493,  2.5807,\n",
       "           2.7609]]),\n",
       " tensor([[-0.1137, -1.7609, -0.0497, -3.0122, -0.0895, -0.1239, -0.0390,\n",
       "          -2.8220, -1.1414, -0.0878,  0.6143, -0.1310,  2.2945,  0.6993,\n",
       "          -0.0517, -0.1792, -2.7545,  2.3059, -0.0505,  0.6958, -0.0545,\n",
       "          -0.1711, -0.0504,  0.6427, -0.1228, -2.8304, -0.4803, -0.0420,\n",
       "          -0.1086]]),\n",
       " tensor([[-0.0477, -0.0666, -0.0999, -0.1051, -0.1608, -0.0492, -0.0544,\n",
       "          -0.0641, -0.1833, -0.0538,  0.7410, -0.1410, -0.7087, -0.0528,\n",
       "          -0.0126, -0.0362, -2.6268, -0.1758, -0.0846, -0.0608, -0.0660,\n",
       "           0.1296, -2.9994, -0.0492, -0.1663, -0.1767, -0.0543,  2.6041,\n",
       "          -0.6688]]),\n",
       " tensor([[-0.0639, -0.0691, -0.1886, -0.4987, -0.0543, -0.6095, -0.0511,\n",
       "          -0.0913, -0.0514, -0.0529, -0.5581, -0.0587, -0.0553, -0.2451,\n",
       "          -0.5561,  0.7181, -0.1689, -0.0518, -0.0893, -0.1299, -0.1989,\n",
       "          -0.0622, -0.1128, -0.1482, -0.1708, -0.0524, -0.0550,  0.7324,\n",
       "          -0.1642]]),\n",
       " tensor([[-2.5098, -0.1647, -0.0896, -0.1249, -0.0485, -0.1122, -0.0505,\n",
       "          -0.0733, -0.0491, -0.3161,  0.0067,  0.7133, -0.1306,  0.7116,\n",
       "          -0.1807,  0.2336,  2.8048, -2.8264,  0.0330, -0.3319, -0.1725,\n",
       "           0.7051, -0.0547, -0.0499, -0.0461, -0.1724, -0.0827, -0.0681,\n",
       "           2.5245]]),\n",
       " tensor([[-0.0536, -2.8536, -0.2817,  2.6088,  2.6408,  2.6414, -0.0467,\n",
       "           2.6781, -2.8849, -0.6403, -0.5573,  2.5979, -0.1622, -0.0514,\n",
       "          -0.0437, -0.1683, -0.0433, -1.0910,  0.6782,  3.0452, -0.0457,\n",
       "          -0.1087,  0.7090, -0.0473, -0.0872, -0.1729, -0.1398, -0.1386,\n",
       "          -0.0194]]),\n",
       " tensor([[ 0.7090, -0.0453, -0.0459, -0.0605, -0.1364, -0.1329, -0.0504,\n",
       "          -0.0624, -0.0418,  0.7780, -0.1790, -0.1740, -0.1788,  2.6385,\n",
       "          -0.1537, -0.0940, -0.1522, -0.0445,  0.1931, -0.0463, -0.0610,\n",
       "          -0.1682,  2.5098,  0.4684, -0.1738, -0.4050, -0.0428,  2.6527,\n",
       "          -0.1795]]),\n",
       " tensor([[-0.1633, -0.0813,  0.7048,  1.3381, -0.0721,  1.7475, -0.0415,\n",
       "           0.6144, -0.0493,  2.6520, -0.1736, -0.0481, -0.1327, -0.0410,\n",
       "          -0.3368,  0.1278,  0.7011, -0.0573, -0.2242, -0.0420, -0.1539,\n",
       "          -0.1468, -0.0590, -0.0478, -0.0603,  2.6970, -0.3813, -0.0428,\n",
       "           2.6062]]),\n",
       " tensor([[-1.5822, -0.5828, -0.1816, -0.1513, -0.2663,  0.3587, -0.0412,\n",
       "          -0.0678, -0.0466, -0.0793,  0.2031,  2.7854, -0.1049, -0.1479,\n",
       "          -0.0429,  2.4490,  3.0605, -0.0578, -0.1559, -0.0657, -0.1441,\n",
       "          -0.0490,  0.2079, -0.0417,  0.2743,  2.5888, -0.0472, -0.1777,\n",
       "          -0.0589]]),\n",
       " tensor([[-0.1709, -0.0613, -0.0446, -0.0420, -0.0941, -0.1413, -0.5032,\n",
       "          -0.1306, -0.0612,  0.7259, -0.0553,  0.3163,  0.6669, -0.1470,\n",
       "          -0.4459,  0.0427,  0.7922, -0.0431,  2.7821, -0.1556, -0.0412,\n",
       "           2.6508,  0.3515, -0.1793, -0.4648, -0.1305,  0.7671,  0.6198,\n",
       "          -0.0502]]),\n",
       " tensor([[-0.1714, -1.1091, -0.0404, -0.1761, -0.0479, -0.4854, -0.0820,\n",
       "          -0.0495, -0.1698, -0.0413, -0.0654, -0.0684, -0.0472,  2.5388,\n",
       "          -0.1720, -2.7633, -0.3617, -0.1431, -1.4924, -0.0762, -0.0534,\n",
       "          -0.6704,  2.1762, -0.0450, -0.2423, -0.0699, -0.0461, -0.0857,\n",
       "          -0.0499]]),\n",
       " tensor([[ 0.7154, -0.0454,  1.0881, -0.1454, -0.0418, -0.1148,  0.7217,\n",
       "          -0.1520,  0.0201,  2.6763, -0.1725, -0.0525, -0.1748, -0.2138,\n",
       "           2.3191, -0.1385,  0.7605, -0.1613, -0.1623, -0.0525, -1.2698,\n",
       "          -0.0440, -0.0801, -0.1780, -0.1366, -0.0407, -0.0536, -0.0892,\n",
       "          -0.1710]]),\n",
       " tensor([[-0.0410, -0.1333, -0.0427, -0.1071, -0.3574, -0.1737, -0.0426,\n",
       "          -0.1791, -0.0610, -0.1003, -0.1205, -0.5019,  2.6497, -0.0456,\n",
       "          -0.5021,  0.2884, -0.1508, -0.0502, -0.0558,  0.7339, -0.1465,\n",
       "           2.5995, -0.5480,  2.6069, -0.1706, -0.0417, -0.0425,  2.4086,\n",
       "          -0.0915]]),\n",
       " tensor([[-0.1557, -0.0774, -2.6750, -0.0666, -0.1656, -1.2898, -0.0404,\n",
       "          -2.8492, -0.0878, -0.0555, -0.0495,  0.7284, -0.0763,  0.4206,\n",
       "          -0.0470, -0.1655,  0.7074, -0.1655,  0.6984, -0.1094, -0.0464,\n",
       "           1.0244,  0.7394, -3.0390, -0.1388, -0.6438, -0.0513, -0.5328,\n",
       "          -0.4910]]),\n",
       " tensor([[-0.1307, -0.0604, -0.0502,  0.6320,  2.2963, -0.0665,  0.4941,\n",
       "           0.3821, -0.1367, -0.1444, -0.1622, -0.0475, -0.0697, -0.0589,\n",
       "          -0.0469,  0.4126,  1.7841,  0.7293, -0.0808,  0.0432,  2.8487,\n",
       "          -0.6433, -0.1757,  1.6711, -0.1731, -0.1213, -0.3807, -0.4590,\n",
       "          -0.0668]]),\n",
       " tensor([[-0.0543,  1.5134, -0.0720, -0.0387,  2.4697,  2.3958, -0.7020,\n",
       "          -0.1430, -2.1322, -0.1502,  2.6571, -0.2899, -0.1137, -0.0652,\n",
       "          -0.1515,  0.4793, -0.1801,  0.0479,  0.1749,  2.5976, -0.1601,\n",
       "          -0.0484, -0.0567,  0.4673, -0.1219, -0.0385, -0.0488, -0.1614,\n",
       "           2.6653]]),\n",
       " tensor([[-0.1870,  2.6354, -0.1395, -2.7894, -0.0629, -0.0382, -0.0406,\n",
       "          -0.1780, -0.0773, -0.0712, -0.0954, -0.0425, -0.0421, -0.1097,\n",
       "          -0.0489, -0.0433,  0.2328, -0.1505, -2.2107, -0.1187, -0.0678,\n",
       "          -0.0411, -0.1334, -0.1694, -2.6112, -2.1966, -0.1324,  0.0858,\n",
       "          -0.1413]]),\n",
       " tensor([[-0.3482,  0.7559, -0.1536, -0.0399, -0.1382, -0.0618, -0.1252,\n",
       "           0.7253, -0.0461, -0.0376, -0.0388, -2.1600, -0.1750, -0.0575,\n",
       "          -0.0427, -0.1777, -0.0936, -0.2421, -0.0785, -2.7629, -0.0933,\n",
       "          -0.0486, -0.1553, -0.0375, -0.1736, -0.0455, -0.0547,  0.6616,\n",
       "          -1.0776]]),\n",
       " tensor([[-0.1293, -0.0409,  2.5868, -0.0445,  2.5065, -0.1469,  0.1352,\n",
       "          -0.1738, -0.1385, -0.0492, -0.0460, -0.1433, -0.9071, -0.0955,\n",
       "          -0.0378,  1.3846, -0.1311, -0.0374, -0.0549, -0.0462, -0.0649,\n",
       "           0.7315, -0.0414, -0.1955, -0.1603, -0.1632, -0.1766, -2.2613,\n",
       "          -0.0677]]),\n",
       " tensor([[-0.5002,  2.6467, -0.0436, -0.0469, -2.9374, -0.1014, -3.2891,\n",
       "           0.2906,  0.7386, -0.2345, -0.1741, -0.0409, -0.0977, -0.0378,\n",
       "           0.1040, -0.0745, -0.1380, -0.0395, -0.0523, -0.0683, -0.0617,\n",
       "          -0.1791, -0.1788, -0.1566,  2.7395, -0.0480, -0.1645, -0.1600,\n",
       "          -2.6293]]),\n",
       " tensor([[-0.0577, -0.0595, -0.0406, -0.0990, -0.1601, -2.7239,  2.7608,\n",
       "          -0.1432, -0.0675, -0.6356,  0.7192, -0.0410,  1.3155, -0.1723,\n",
       "          -0.1633, -0.0430, -0.0392, -0.2420,  0.2952, -0.2588,  0.7341,\n",
       "          -0.0431, -0.1289, -0.0589, -0.0535,  0.8057, -0.0466, -0.0447,\n",
       "           0.4152]]),\n",
       " tensor([[-0.1713, -0.0518, -0.1661, -0.4382, -2.8366, -0.0427,  0.7259,\n",
       "           0.5601, -0.5948, -0.0512, -0.1699, -0.0421, -0.1447, -0.0552,\n",
       "           0.6252, -0.0387, -0.0404, -0.0880,  2.2120, -0.0605, -0.1511,\n",
       "          -0.0846, -0.0571, -0.1126, -0.1535, -0.0465, -0.1671, -0.1461,\n",
       "          -0.0449]]),\n",
       " tensor([[-0.1530,  0.5759, -0.1600,  0.4879,  2.5702, -0.0402, -0.1609,\n",
       "          -0.2902,  2.7628, -0.0448, -0.0439,  0.3217, -2.9236, -0.1670,\n",
       "          -0.3188, -0.1370, -0.0778,  0.6803, -0.0498, -0.1605, -0.2216,\n",
       "           0.7005, -0.0466, -2.9643, -0.1603, -0.1014, -0.1635, -0.0454,\n",
       "          -0.0564]]),\n",
       " tensor([[-0.6698,  2.7136, -0.1553, -0.0427,  0.1490, -0.0440,  0.3036,\n",
       "          -0.1519, -0.1353, -0.0902, -0.0427,  0.6956,  0.0343, -1.8762,\n",
       "          -0.1274, -0.1483, -0.1182,  0.2282, -0.0427, -0.1753, -0.4666,\n",
       "          -0.1781, -0.2762,  0.7184, -0.0422,  0.7131, -0.0482, -0.1761,\n",
       "          -0.1603]]),\n",
       " tensor([[-0.0570,  2.6398,  0.6405,  0.2616, -0.0430, -0.5577, -1.4831,\n",
       "          -0.1374, -0.1278, -0.0479, -0.1387, -0.0553, -0.0659, -0.0759,\n",
       "          -0.1838,  0.3315, -0.0515,  2.3648, -0.1570,  0.0975, -0.0495,\n",
       "          -0.1525, -0.0639, -0.0744, -0.0709,  0.6432, -2.7584, -0.1229,\n",
       "           0.7314]]),\n",
       " tensor([[-0.0452, -0.0503, -3.2590,  0.3674, -0.1017, -0.0471,  2.7064,\n",
       "          -2.2372, -0.1273, -0.0200, -0.1624,  0.6970, -2.9046, -0.6216,\n",
       "          -0.2768, -0.1972, -0.1450, -0.1426,  2.5784, -0.1022,  2.5585,\n",
       "          -0.0530, -0.1512, -0.0469,  2.7413, -2.8759, -3.0377, -0.1205,\n",
       "           2.7175]]),\n",
       " tensor([[-0.1304, -0.6391, -0.0759, -0.0756,  2.5922,  2.5319, -0.0861,\n",
       "          -0.0740, -0.1224, -0.0507,  2.6066, -0.1096, -0.4157,  3.4107,\n",
       "           0.7240, -0.0482, -0.0538, -0.4644, -0.4787,  0.7252,  0.7035,\n",
       "          -0.0479, -0.0450, -0.0619,  0.0128, -0.0498,  0.0662, -0.1565,\n",
       "           0.5672]]),\n",
       " tensor([[-0.0585, -0.6181, -0.1034, -0.0434, -0.0800, -0.0567, -0.0740,\n",
       "          -0.0529, -0.1649, -0.1612, -0.0943, -0.0734, -1.5522, -0.0454,\n",
       "           0.3864, -0.0509, -3.1081, -0.0971, -0.1135, -0.0568, -0.1590,\n",
       "          -0.0481, -0.1168, -0.1641,  0.6488,  0.7268, -0.0913,  0.1827,\n",
       "          -0.1826]]),\n",
       " tensor([[ 0.7144, -0.1140, -0.1030,  0.7297, -0.0498, -0.0522, -0.0741,\n",
       "           0.7247, -0.1146, -0.1257, -0.1036, -0.4805, -0.0486, -0.0472,\n",
       "           0.7146,  0.6938,  2.8272, -1.9022,  0.1752, -0.1806, -0.0446,\n",
       "          -0.1778, -0.4787, -0.0900, -0.1698, -0.0604,  0.7165, -0.5393,\n",
       "          -0.0670]]),\n",
       " tensor([[-0.0765,  0.7202, -0.1451, -0.0469,  0.0853, -0.4178, -0.0822,\n",
       "           2.7203, -0.1790, -0.1847, -0.1768, -0.0523,  0.6855, -0.1820,\n",
       "          -3.1206, -0.0495,  2.7225, -0.0770, -0.1292, -0.0510,  0.0952,\n",
       "          -2.6809,  0.6757, -0.1547, -0.0494, -0.0643, -0.0607, -3.0505,\n",
       "          -0.0526]]),\n",
       " tensor([[-0.0896,  2.5825,  0.6580, -0.2901, -0.1788, -0.0978, -0.0456,\n",
       "           0.7344, -3.0542, -0.0904, -0.0496, -0.3510, -0.4553, -0.1752,\n",
       "           0.0859, -0.6005, -0.1673, -0.0503, -0.3460, -0.0446, -0.0548,\n",
       "          -0.1612, -0.1348, -0.0699, -0.5179,  0.2843, -0.1207, -0.1480,\n",
       "           0.6727]]),\n",
       " tensor([[-0.1811, -3.2142, -0.1782, -0.0802, -0.0745, -0.4476, -0.1239,\n",
       "          -0.0486,  1.8253, -0.5873, -0.0451, -0.1041, -0.0993, -0.1279,\n",
       "          -0.0470,  0.0710,  0.6270, -0.0465, -0.0524, -0.1225, -0.1809,\n",
       "          -0.1243, -0.0235, -0.0442, -0.6069, -0.3485,  0.0392, -0.0442,\n",
       "          -0.0475]]),\n",
       " tensor([[ 0.0326, -2.2013, -0.0686, -0.0647, -0.0446, -0.0613,  0.5520,\n",
       "          -0.0432, -0.0534, -0.0462, -0.3179,  0.5735, -0.0437, -0.3967,\n",
       "          -0.0467,  0.7120, -0.0876, -0.0572, -0.0738, -0.0433,  0.6893,\n",
       "          -0.0769, -0.0510, -0.1424, -0.4196, -0.1583,  0.1562, -0.0463,\n",
       "          -0.0444]]),\n",
       " tensor([[-2.5177, -0.1310, -0.1407, -0.0461, -1.4440,  1.0894, -0.0560,\n",
       "          -0.1587, -1.6211, -0.6253, -0.0811, -0.1722,  0.2825, -0.1650,\n",
       "          -0.0528, -0.0479, -0.1629,  2.6115,  0.2073, -0.0525, -0.1021,\n",
       "          -2.8060, -0.1652, -0.0562, -1.6560, -0.1845, -0.0477, -0.1548,\n",
       "          -0.1584]]),\n",
       " tensor([[ 1.4751, -0.0435, -0.1785,  0.1104,  0.0266, -0.0448, -0.5810,\n",
       "           0.7232, -3.0726, -2.2770, -0.1741, -0.1719, -0.1835, -0.1662,\n",
       "           2.7442,  0.4565,  0.7165, -0.0593, -0.0431, -0.0438, -0.1137,\n",
       "          -0.0582, -0.1108, -0.1265,  0.7436, -0.1158,  0.5583, -0.1181,\n",
       "          -0.0429]]),\n",
       " tensor([[ 0.1035,  0.7248, -0.1295,  0.6001,  2.6223, -0.0941,  1.9891,\n",
       "           0.7232,  0.7344, -0.4788, -0.0458, -0.0460, -0.0667, -0.1090,\n",
       "          -0.3330, -0.4611,  0.5549, -0.0653, -0.2448,  2.5835, -3.1174,\n",
       "           0.2092, -0.0469, -0.0759, -0.0769, -1.1125, -0.0499, -0.0447,\n",
       "           0.6417]]),\n",
       " tensor([[ 2.4147, -0.1637, -0.0632, -0.5673,  0.7072, -0.0482, -0.0534,\n",
       "          -0.1687, -0.9467, -0.0439, -0.1506,  0.3368, -0.0602, -0.1130,\n",
       "          -3.0873, -2.5996, -0.0534,  0.7237, -0.1101, -0.1644, -0.1459,\n",
       "          -0.1592,  0.7283, -0.1665,  2.5739, -0.6412, -2.1614, -0.1508,\n",
       "           0.3125]]),\n",
       " tensor([[-0.1779,  0.1259,  0.5659, -0.0486,  0.1571, -0.1661, -0.0718,\n",
       "          -0.1385,  1.7699, -0.1325, -0.4994,  0.3630, -0.0504, -0.0916,\n",
       "           0.4675, -0.1074, -0.1462,  2.8198, -0.2790,  2.5520,  0.4609,\n",
       "          -0.1549, -1.6221, -0.0443, -0.0407, -0.1191,  0.7519, -0.1654,\n",
       "          -0.1838]]),\n",
       " tensor([[-0.1880, -0.1273, -0.0676,  0.7434,  1.1173, -0.0465, -3.2243,\n",
       "          -0.0636, -0.1633, -0.0521,  2.7321,  0.8336, -0.0504, -0.0463,\n",
       "          -0.0555, -0.1337, -0.1840, -0.0510,  0.4874,  0.0442, -0.1804,\n",
       "          -0.4711, -0.1077, -2.9615, -0.0591, -0.0564, -0.1136, -0.1275,\n",
       "          -0.0470]]),\n",
       " tensor([[-0.0480, -0.0962, -0.1863, -0.0912,  0.7089, -0.0915, -0.0592,\n",
       "          -0.1273,  0.7498, -0.0724, -0.1878,  0.4425,  0.6653, -0.1002,\n",
       "          -0.0273, -0.0539, -0.1280,  2.3629, -0.4020, -0.3032, -0.1193,\n",
       "           0.6799, -0.0491, -2.1713, -0.1026, -0.1872, -0.0629, -0.1873,\n",
       "           2.7246]]),\n",
       " tensor([[-0.1139, -0.1271, -0.0831, -0.1666, -0.0911, -0.0522, -0.0489,\n",
       "          -0.0489, -0.0833,  0.4502, -3.2192, -0.0628, -0.1881, -0.0725,\n",
       "          -0.1589, -0.0064,  0.7675, -0.1817,  0.6394, -0.1066, -0.1339,\n",
       "          -0.0812, -0.1656,  0.2859, -0.2076, -0.3439, -0.1533, -0.1746,\n",
       "          -3.0699]]),\n",
       " tensor([[-0.1136,  0.6858, -0.0523, -0.0592, -0.4220, -0.0532, -0.1466,\n",
       "           0.6289, -0.0507, -0.1202, -0.1594,  0.0804, -0.0845,  0.5448,\n",
       "          -0.6245, -0.1866, -0.4973, -0.1660, -0.0597, -0.0650, -0.1644,\n",
       "          -0.0497, -0.2436, -0.1305, -0.1305, -0.0951, -0.5133, -0.1809,\n",
       "          -0.6652]]),\n",
       " tensor([[-0.1591,  0.0524,  1.9941, -0.0498,  0.6047, -0.0509,  2.6026,\n",
       "          -0.1781, -0.1699, -0.1883, -0.1536, -0.0544, -0.1210,  0.7104,\n",
       "          -0.1169, -0.1126, -0.1085,  0.7166, -0.0541,  0.4107, -0.1557,\n",
       "          -0.1675, -0.0677, -0.4362, -0.1726, -0.0494, -0.1117, -0.0502,\n",
       "          -0.0627]]),\n",
       " tensor([[-2.6982, -0.1254, -0.1377, -0.1876, -0.1020, -0.0729,  0.3079,\n",
       "           0.6803, -0.0670, -0.2386, -0.6808,  0.6821,  0.4907, -0.0539,\n",
       "           0.3829, -0.0606,  0.1223, -0.1569, -0.0824,  0.2508, -0.1671,\n",
       "          -0.0551, -0.6739,  0.1604, -0.0548, -0.0875, -0.1558, -0.0832,\n",
       "          -0.0940]]),\n",
       " tensor([[-0.0975, -0.1179, -0.1862, -0.0564, -0.0772, -0.1688, -1.1474,\n",
       "           1.5249,  0.7108, -0.0655, -0.1843, -0.0773,  0.7177, -0.5647,\n",
       "          -0.1084,  0.9870, -0.0517, -0.0647, -0.1137, -2.4894, -0.7014,\n",
       "           0.7283, -0.1633, -0.0529, -0.0048,  0.7334,  0.1416, -0.0493,\n",
       "          -0.0639]]),\n",
       " tensor([[-0.1277,  0.5053, -0.0673, -0.1163, -0.1664, -0.0914, -0.1693,\n",
       "          -0.1868,  0.6787, -0.0619, -0.0696,  0.6498,  0.4943, -0.0493,\n",
       "          -0.1819, -0.1178,  0.7550, -0.1795, -0.5955,  2.5974,  0.6684,\n",
       "           0.5473, -0.0937, -0.0471, -0.0494, -0.0183, -0.6327,  0.7586,\n",
       "          -2.7538]]),\n",
       " tensor([[-0.0466, -0.0893, -0.1775, -0.1750, -0.0962, -0.1854,  0.2311,\n",
       "          -0.0630, -3.0170,  0.0454, -0.0818, -0.1681, -0.0524, -0.0492,\n",
       "          -1.2027, -0.1600,  0.6996, -0.1830, -2.0795, -0.1826, -0.0914,\n",
       "          -0.5242,  0.7638, -0.0526,  0.7139,  2.2874, -0.1311, -0.0478,\n",
       "          -0.1614]]),\n",
       " tensor([[-0.0926,  0.3966,  0.4414, -0.1821,  0.4828, -0.1008, -0.0642,\n",
       "          -0.1560, -0.2752, -0.0585, -0.0473, -3.0241, -1.4524, -0.1174,\n",
       "          -0.1888, -0.0762,  2.5095, -0.0838, -0.2245,  2.4737, -0.1000,\n",
       "           0.1048,  0.9482, -3.0632, -0.1707, -0.0624, -0.0457,  1.2619,\n",
       "          -0.0473]]),\n",
       " tensor([[-0.1086,  0.4740, -0.2817, -0.0743,  0.1706, -0.0674, -0.0600,\n",
       "          -0.1797, -0.0430, -2.8242, -0.1603,  2.2122,  0.4742, -0.0703,\n",
       "           0.4615, -0.1828,  0.4732,  0.7093, -2.8232, -0.1799, -0.0484,\n",
       "           2.1628, -0.0671, -0.1772, -0.0557, -0.1774, -0.0436, -0.0458,\n",
       "           0.1635]]),\n",
       " tensor([[ 0.9063,  2.6245,  0.7225, -0.0442, -0.0449,  0.0296, -0.1625,\n",
       "           0.1296, -0.0436,  0.1621,  0.3373, -0.0779, -0.1044, -0.0449,\n",
       "          -0.1810, -1.8754, -0.1757,  0.6338, -0.1875,  2.5933,  0.0141,\n",
       "          -0.0572,  0.1068, -0.1786, -0.0441, -0.0443, -0.7254, -0.1312,\n",
       "          -0.5353]]),\n",
       " tensor([[-0.0718,  0.7227, -0.0661,  0.7652, -0.0459, -0.1790, -0.0592,\n",
       "          -0.0859,  2.4641, -0.1475,  0.7208, -0.0673,  0.7296,  0.7525,\n",
       "          -0.0754,  0.6008, -0.0442,  0.0771, -0.1802,  0.5538,  2.6053,\n",
       "          -0.1716, -0.0791, -0.0765, -0.0467, -0.1740, -0.0423, -0.0580,\n",
       "          -0.1835]]),\n",
       " tensor([[ 0.3255, -0.1028, -0.0612, -0.0711, -0.0437, -2.7348, -0.1507,\n",
       "          -0.1242, -0.1800,  0.7379, -0.0706, -0.0525,  0.6832, -0.3831,\n",
       "          -0.1495,  0.6491, -0.1195,  0.7533, -0.0511, -0.0908,  0.8497,\n",
       "          -0.0431, -0.1268,  0.3056,  0.5252, -0.0504,  0.0306, -0.0466,\n",
       "           1.5965]]),\n",
       " tensor([[ 2.3649,  0.3047, -0.1646, -0.0474, -0.1737, -0.0741, -0.0514,\n",
       "          -0.0450,  2.6071, -0.0458, -0.2476,  0.7156,  0.4307, -0.6430,\n",
       "          -0.0580,  2.9366, -0.0492,  2.7145, -0.1992,  2.3276, -0.0555,\n",
       "          -0.3530, -0.0477, -0.1486, -0.1344, -0.3989, -0.3381,  0.5839,\n",
       "          -0.0504]]),\n",
       " tensor([[-0.0543,  0.6437, -0.1750, -0.1046, -0.3803, -0.0428, -0.0782,\n",
       "           0.7524, -0.0936, -0.2100, -0.1797,  0.3803, -0.0619, -0.1169,\n",
       "          -0.2516, -0.1839, -0.4050, -0.0702, -1.3433, -0.0476, -0.1366,\n",
       "           0.7295, -0.2280, -0.1624, -0.1081, -0.0498, -0.1501, -0.0896,\n",
       "           0.7765]]),\n",
       " tensor([[ 0.6121, -0.0949,  1.9200,  0.3905, -0.0433,  0.6003, -0.1522,\n",
       "          -0.1793, -0.6230, -0.1450,  2.7435,  2.5710, -0.0562,  0.7413,\n",
       "          -0.6274, -0.0455, -0.1190, -0.1010, -0.0718,  0.6408, -0.2680,\n",
       "           0.6406, -2.6866, -0.0448, -0.0427, -0.2749, -0.1801, -0.0653,\n",
       "          -0.1301]]),\n",
       " tensor([[-0.2053, -0.1556, -0.0423,  0.6629, -0.0588,  0.7174, -0.1542,\n",
       "           0.6922, -0.1432, -0.1661,  0.5431,  2.4936, -0.0418,  0.6565,\n",
       "           2.6439, -0.0480, -0.1614, -2.9813,  0.0771, -1.9278, -0.0717,\n",
       "          -0.1139, -0.0647, -0.0516, -0.7717, -0.1332,  0.5626, -0.0523,\n",
       "           0.5742]]),\n",
       " tensor([[ 1.7198, -0.1384, -0.0586, -0.0880, -3.0773, -0.1680, -0.0689,\n",
       "          -0.0423, -1.3150, -0.1693, -3.0114, -0.1173, -0.0709, -0.0712,\n",
       "          -2.1927, -0.0432, -0.1507, -0.0493, -0.1923, -0.0565, -0.0479,\n",
       "          -0.0418, -0.0441, -0.1143, -2.8899,  0.1439,  0.6546, -0.1280,\n",
       "           0.7069]]),\n",
       " tensor([[-0.1853, -0.0481,  0.3815, -0.1250,  2.8154, -0.0443, -0.0443,\n",
       "          -0.0934, -0.0777, -0.6620,  0.7199,  1.8393, -0.1434, -0.0568,\n",
       "          -0.1087,  2.6010,  0.2089, -0.0691,  0.7260, -0.5275, -0.0472,\n",
       "          -0.1799,  2.5950,  0.5678,  2.4897, -0.0578, -0.0696, -0.0623,\n",
       "          -0.0419]]),\n",
       " tensor([[-0.1641, -0.6660,  0.6432, -0.0810, -0.0453,  0.7085, -0.1039,\n",
       "          -0.1155, -0.1830, -0.0756, -0.2219, -0.0800, -0.0897, -0.0619,\n",
       "          -0.3022, -0.0845, -0.1154,  0.7292,  2.7509, -0.0493,  2.5682,\n",
       "          -0.0762, -0.0501, -1.5262, -3.1524, -0.3545, -0.1118, -0.1394,\n",
       "          -0.1549]]),\n",
       " tensor([[-0.0750, -0.0542,  0.0899,  0.7822, -0.0839, -0.0526, -1.8570,\n",
       "          -0.0458, -0.0747, -0.1372, -0.1202,  1.1960, -0.0734,  2.8244,\n",
       "          -2.2765, -0.1477, -0.1728, -0.1916, -0.0503, -0.0547, -0.0874,\n",
       "          -0.1044, -0.0599,  0.2127,  0.7088,  0.7101, -0.1025, -0.1498,\n",
       "           0.1845]]),\n",
       " tensor([[ 0.6333, -0.1180, -0.0716, -0.1039, -0.0611, -0.1573,  2.6495,\n",
       "           2.6748, -0.1765, -0.6273,  0.1069, -0.1476, -1.5896, -0.4690,\n",
       "           2.6206,  3.5950,  1.0222, -0.0801, -0.0930,  1.0399, -0.0131,\n",
       "          -0.1903,  1.4295, -0.1578, -0.0470,  0.5636,  2.0684, -0.1562,\n",
       "           0.1215]]),\n",
       " tensor([[-0.0549, -0.1525, -0.1501,  0.2408, -0.0696, -0.1267, -0.0716,\n",
       "          -0.0581, -0.0471, -2.7737,  0.4087, -0.0477,  0.3693, -0.0460,\n",
       "          -0.1696, -0.0618, -0.1543, -0.0789, -0.0429,  0.7211, -0.1844,\n",
       "          -0.0609,  0.0743, -0.0673, -0.0430, -0.0525, -0.0875, -0.0613,\n",
       "          -0.5034]]),\n",
       " tensor([[ 0.1570, -0.5052,  0.6647, -2.9743,  0.7304, -0.1790, -0.1601,\n",
       "           1.4339, -0.1502, -0.1406, -0.0503,  2.4488, -0.1600, -0.0596,\n",
       "          -0.0499, -3.1132, -0.1089, -0.1283, -0.0429, -0.0541,  1.3963,\n",
       "           0.7357, -0.0462, -0.0454,  0.3059, -0.1038, -0.1842,  2.6927,\n",
       "          -0.1082]]),\n",
       " tensor([[-0.1611,  0.1322,  2.8552,  0.3702, -0.1085, -0.1792,  2.6064,\n",
       "          -0.0422, -0.0861, -0.1048, -0.0441, -0.0514, -0.5935, -0.1199,\n",
       "          -0.0613, -0.1783, -0.0590, -0.0478, -0.1376, -0.1387, -0.0983,\n",
       "          -0.0712, -0.0550, -0.0427, -0.0984, -0.0749, -0.1566, -0.1724,\n",
       "          -0.1220]]),\n",
       " tensor([[-0.7390,  2.5285, -0.1581, -3.1266, -0.0633, -0.0453, -0.0668,\n",
       "           2.0926,  0.6216, -0.1714,  0.7648, -0.1233, -2.0882, -0.6083,\n",
       "           2.6509, -0.7824, -1.3539, -0.0570,  1.4005,  0.7510, -0.0465,\n",
       "          -0.1446, -0.2093, -0.0700,  0.7729, -0.0418,  0.4125, -0.1385,\n",
       "          -0.5900]]),\n",
       " tensor([[-0.0987, -0.0404,  0.7362,  2.7983, -0.1622, -0.0413, -0.0681,\n",
       "          -0.0878, -0.5645, -0.1774,  0.0008, -0.1144, -0.0403, -0.0555,\n",
       "          -0.0407,  0.7293,  2.6153, -0.0457,  1.1308, -0.0790, -2.1582,\n",
       "          -0.0646, -0.0474, -0.1650, -0.1620,  0.5728,  0.6438, -0.8878,\n",
       "           0.7120]]),\n",
       " tensor([[-0.0383, -0.0588,  0.1425, -0.1710,  2.6918, -0.0358,  0.5525,\n",
       "           2.6025, -0.0799, -0.0374, -0.0350, -0.0754, -0.0411, -3.0062,\n",
       "           2.1989,  0.3790, -0.0434, -0.1298, -0.0370, -0.0411,  2.6675,\n",
       "           0.6334, -0.1359, -0.1944,  0.7412, -0.0645,  0.4680,  0.7281,\n",
       "           0.3927]]),\n",
       " tensor([[-0.0370, -0.4041, -0.0823,  0.7315, -0.6127,  0.7280, -0.0808,\n",
       "           0.2980, -0.0363, -0.1450, -0.0427, -0.1332, -0.0404, -0.5223,\n",
       "           0.9272, -0.2329, -0.0300,  0.5171, -0.1297,  0.7916, -0.0888,\n",
       "          -0.2600,  2.2379, -0.0375, -0.3086, -0.0371, -0.0435, -0.5787,\n",
       "           1.7074]]),\n",
       " tensor([[ 0.0283, -0.1750, -0.1191,  0.2452,  0.0285, -0.0676, -0.1629,\n",
       "          -0.0605, -0.1652,  1.6115, -0.3413, -0.0945, -0.0339, -0.1233,\n",
       "           0.7572, -0.3868, -2.3350,  0.3864, -0.5290, -0.2446,  1.9586,\n",
       "          -0.1123, -0.6649, -0.1630, -0.0787,  0.8232, -0.1089, -0.1132,\n",
       "          -0.0315]]),\n",
       " tensor([[ 0.2121,  0.6346,  1.1748, -0.1040, -0.1217, -0.2169, -2.3320,\n",
       "          -0.0494, -0.1005, -2.9708, -1.7431, -0.0840,  2.6941,  2.6355,\n",
       "          -0.0260,  0.7375, -0.0268, -0.1547, -0.0656, -0.1129, -0.5053,\n",
       "          -0.3282, -0.1076, -0.1510, -0.4307,  0.0746, -0.0409, -0.1053,\n",
       "           2.3905]]),\n",
       " tensor([[ 0.2628, -0.1211, -0.3490,  0.3813, -0.0985,  1.0980, -0.0276,\n",
       "          -0.0388, -0.4429, -0.1645, -0.1662,  0.3891, -0.1113, -0.1920,\n",
       "           0.4895, -0.0914, -0.1567, -0.0292, -0.4065, -0.0356, -0.1588,\n",
       "           2.4179,  0.0307,  1.3374,  2.7335,  0.7362,  2.4353, -0.0475,\n",
       "          -0.0293]]),\n",
       " tensor([[ 0.5148, -0.1284, -0.0346, -0.0477,  0.4958,  0.5010, -0.1601,\n",
       "           0.6820, -2.9372, -0.1114, -0.1482, -0.0385, -0.0283, -0.0245,\n",
       "          -0.1281, -0.0415,  0.6602,  0.6228, -1.7414, -0.0616, -0.0584,\n",
       "          -0.0646, -0.0325,  2.1746, -0.1401, -3.2595, -0.1574, -3.0972,\n",
       "           1.7752]]),\n",
       " tensor([[-0.0685, -0.1370,  0.7082, -0.1571, -0.0404,  0.6602, -0.0467,\n",
       "          -0.0793, -0.1453, -0.0646,  0.6906, -0.5096, -0.6540,  2.4139,\n",
       "          -0.0456,  2.4452,  1.7852,  2.6284, -0.0835, -0.1446, -0.0636,\n",
       "          -0.0776,  0.7286, -0.0368, -0.0677, -0.1110, -0.0289,  2.7793,\n",
       "          -1.2547]]),\n",
       " tensor([[-0.0201, -0.0213,  0.7660, -0.5818,  0.7379,  1.7628, -0.1170,\n",
       "          -0.0211, -0.0401,  0.5337, -0.0212, -0.0434,  0.5741,  0.7597,\n",
       "          -0.4629, -0.0502, -0.1623, -0.4644, -0.1012, -0.1597,  0.5463,\n",
       "          -0.3751,  2.6088,  2.6398, -0.1511, -0.0235, -2.4105,  1.1343,\n",
       "          -0.0205]]),\n",
       " tensor([[-0.1449,  0.6896,  2.6286, -0.0531, -0.0698, -0.1103, -2.7214,\n",
       "           0.7125,  0.6926, -0.6306,  2.4737,  0.7562, -0.0224, -0.1091,\n",
       "          -0.0753, -0.0372, -0.0274, -0.1521, -0.1347, -0.1576,  0.0294,\n",
       "          -0.4347, -0.1016, -0.1379, -2.2820,  0.8008,  0.7005, -0.0810,\n",
       "           0.6095]]),\n",
       " tensor([[-0.5353,  2.6738, -0.0883, -0.1610,  1.1125, -3.0046, -0.3226,\n",
       "          -0.0481,  0.7296, -0.0239, -0.0273, -0.0468, -0.0473,  1.0201,\n",
       "          -0.0236, -0.0966, -0.0205, -0.1472, -0.0671,  2.7413,  0.6951,\n",
       "          -0.5432,  1.6540, -0.0543, -0.3329, -0.0964, -0.1105, -0.1523,\n",
       "          -0.0209]]),\n",
       " tensor([[-1.2921,  0.5225, -0.0276,  0.7363, -0.0216, -0.0349, -0.0893,\n",
       "          -0.4706,  0.4037, -0.1540, -0.0304,  0.8922, -1.0008,  0.7472,\n",
       "          -0.0334, -0.0676, -0.0219, -0.2588,  1.7046, -0.0226, -0.5358,\n",
       "          -0.1495, -0.0355,  0.4469, -0.0442, -0.1341, -0.0435, -0.0682,\n",
       "          -0.0627]]),\n",
       " tensor([[-0.1413,  1.4031, -0.0557,  0.6934, -0.0285, -0.0634, -0.1190,\n",
       "          -0.0230, -0.0436, -0.4353,  0.4465, -0.0787, -0.3072, -0.2361,\n",
       "          -0.0685, -0.1625, -0.0537,  0.2803, -0.0251,  0.7051, -0.1565,\n",
       "          -0.0257,  0.7318,  0.0629, -0.0224, -0.3957, -0.1736,  2.2016,\n",
       "          -0.2101]]),\n",
       " tensor([[ 0.7216, -0.3669, -0.0402,  0.4045, -0.3516, -0.0186, -0.0236,\n",
       "          -0.1539, -0.0324, -0.1433, -0.0582, -0.0846, -0.0605, -0.1910,\n",
       "           0.7163, -0.1425, -2.8253, -0.0203, -0.0912, -0.0343,  0.6786,\n",
       "          -0.0287,  2.7838, -0.1499, -0.1060,  3.3954, -0.0362,  2.7037,\n",
       "          -0.2992]]),\n",
       " tensor([[-0.0188, -0.0231,  0.0943,  2.7628, -0.1544,  0.4759, -0.0626,\n",
       "          -0.0512, -0.1537, -0.1027, -0.0598, -0.0174, -0.0204,  0.7732,\n",
       "          -0.0751,  2.6836,  2.6995,  0.0257, -0.2244,  0.7553,  2.7413,\n",
       "          -0.0205,  0.7289, -0.0253,  2.6797, -0.2922, -0.0176, -0.1389,\n",
       "          -0.0152]]),\n",
       " tensor([[-0.1461,  0.5273,  0.5999, -0.0857, -0.1547,  0.7488, -0.0132,\n",
       "           0.3343, -0.0310, -0.0628, -0.1270,  0.6639, -0.0357, -2.9994,\n",
       "          -0.1141, -0.0154, -0.0543, -0.0322, -2.8464, -1.2864, -0.1490,\n",
       "          -0.1490, -0.0336, -2.7996, -2.3030, -0.0870, -0.1554, -0.2541,\n",
       "          -0.0110]]),\n",
       " tensor([[-0.0316, -0.0568, -1.7941, -0.3187, -0.1122,  0.7844, -0.0124,\n",
       "          -0.0630, -0.0432, -0.1412, -0.0255, -0.1056, -1.7655, -0.1410,\n",
       "          -0.0120, -0.0862, -0.2405, -0.0925,  2.5774, -0.0609,  0.0895,\n",
       "          -0.0111, -0.1371, -2.3704,  0.4455, -2.7372, -0.0110,  0.0805,\n",
       "           0.3715]]),\n",
       " tensor([[-2.2697,  0.4161, -0.4350, -0.0380, -0.0495, -0.1298, -0.0086,\n",
       "           2.7465, -0.1524, -0.0428, -0.0152, -0.0128, -0.3687, -0.1264,\n",
       "          -0.0071, -0.0540, -0.2060, -0.0262, -0.0142,  0.4777, -0.0146,\n",
       "          -0.0101, -0.0097,  0.7518,  0.5100, -0.2670,  2.9168, -0.0874,\n",
       "          -0.0087]]),\n",
       " tensor([[-0.1059, -0.1512, -0.0473, -0.0690, -0.1014, -0.0262, -0.0165,\n",
       "          -0.0166,  0.3749, -0.1516, -0.1368, -0.1514, -0.0267, -0.0072,\n",
       "          -0.1043,  0.1696, -0.0157, -0.1131, -0.0096, -0.0087, -0.0676,\n",
       "          -0.1122, -0.6933, -0.1659,  0.6027, -0.1279, -0.1233, -0.0121,\n",
       "          -0.0891]]),\n",
       " tensor([[-3.0626, -0.0742, -0.0154, -0.7408,  0.6210, -0.0987, -0.1037,\n",
       "          -0.3524, -0.0196,  0.7494,  2.8905,  1.2189, -0.1323,  0.7542,\n",
       "          -0.0258, -0.0213,  0.6724, -0.0785, -0.0158, -1.0595, -0.0062,\n",
       "          -0.0296, -2.4822, -0.0465, -0.0130, -0.1177, -0.0966,  0.7387,\n",
       "          -0.0076]]),\n",
       " tensor([[ 0.5363, -0.1411, -0.1212, -0.0092,  2.4129, -0.1254,  2.7224,\n",
       "          -0.0279,  0.7412, -0.0110, -0.0137, -2.0419,  1.7470, -0.0143,\n",
       "          -0.0094, -0.1020, -0.0074,  2.8157,  0.0517, -0.5698, -0.0398,\n",
       "           2.7263, -0.0727,  0.7393, -0.0581, -0.6354, -0.0158,  0.7379,\n",
       "           0.7553]]),\n",
       " tensor([[-0.0038, -0.0173, -0.0203, -0.2066,  0.7551, -0.0114,  2.0997,\n",
       "          -0.0884, -0.0019, -0.0071, -0.0550, -0.0320, -0.1287, -0.3933,\n",
       "          -0.0018,  0.7607, -0.3373, -0.1272, -0.1340,  2.7119, -0.4020,\n",
       "          -0.0104, -0.1292, -0.1030, -0.1394, -0.0055, -0.1444, -0.0082,\n",
       "          -0.1040]]),\n",
       " tensor([[-0.0205, -0.0245, -0.0372, -0.0781,  0.2158,  0.6820, -0.0246,\n",
       "           0.4337, -0.1255, -0.0232, -0.1400,  0.7814, -0.2174,  0.8477,\n",
       "          -0.0084,  0.7534, -0.1656, -0.1126,  0.6011, -2.8268, -0.0532,\n",
       "           0.1339,  0.5386, -0.0567,  2.4665, -0.0745, -0.0114, -2.2097,\n",
       "          -0.1050]]),\n",
       " tensor([[-0.0938, -0.0502, -0.1321, -0.1232, -0.3518,  0.8151,  0.3978,\n",
       "           0.4071, -1.7255, -0.1382, -0.0063, -0.1097, -0.1456, -0.2418,\n",
       "           0.0600, -0.2041, -0.0027, -0.0476, -0.0733, -0.1212, -3.0501,\n",
       "          -0.1059, -0.1216, -0.0170, -0.0022, -0.0809,  0.7621,  2.0450,\n",
       "          -0.0079]]),\n",
       " tensor([[-0.1405, -0.0162, -0.1448, -0.0072, -0.2090, -0.0181, -0.0353,\n",
       "           0.5420, -0.0439, -0.5846,  0.0083, -0.0035, -0.1432, -0.0555,\n",
       "          -0.0205, -2.4660, -1.3484,  2.8128,  0.3078, -0.1312,  0.0047,\n",
       "           0.7690,  0.7466, -0.0035,  1.0028, -0.0476,  0.1920,  0.5118,\n",
       "          -0.1277]]),\n",
       " tensor([[-0.3819, -0.1436,  0.3157,  0.7443,  2.7139, -0.0243,  0.7312,\n",
       "          -0.3169,  0.7022, -0.0067, -0.0998, -0.0617, -0.0550, -0.1341,\n",
       "          -0.1652, -0.4877, -0.0068, -0.2514,  1.2683,  0.7598, -0.1090,\n",
       "          -0.0277, -0.1324, -0.0056, -0.0359,  0.7883, -0.5324, -0.0141,\n",
       "           1.1667]]),\n",
       " tensor([[-0.1005,  0.9404, -0.3414, -0.1460,  0.7798, -0.0031, -2.8899,\n",
       "          -0.0915, -0.0193, -0.0532, -0.0070, -0.0224, -0.1080,  0.2299,\n",
       "          -0.0438, -0.3154, -0.6462,  1.7910, -0.1422, -0.0057, -0.4563,\n",
       "           0.4497, -0.5423, -0.0024, -0.1411, -0.0079,  0.6375, -0.1397,\n",
       "          -0.0036]]),\n",
       " tensor([[-0.1223, -0.1455,  2.6616, -0.0619,  0.7741, -0.0127, -0.0143,\n",
       "          -0.0289, -0.1437, -0.0273, -0.0576,  0.0248, -0.0294, -0.5029,\n",
       "          -0.1437, -0.0338, -0.0264, -0.3722, -0.0791,  0.3329, -0.1753,\n",
       "           0.0856, -0.0321,  0.5824,  0.6093, -0.1089,  2.7138,  0.5768,\n",
       "          -0.5378]]),\n",
       " tensor([[-0.0135,  2.7627,  0.4482,  0.8216, -0.0074, -0.0564, -2.9654,\n",
       "           0.3290, -0.0186,  2.7498, -2.8949,  0.3588,  3.0325, -0.0147,\n",
       "          -0.1575, -0.1471, -0.1449,  0.6431,  0.7294,  0.6145,  2.8174,\n",
       "          -0.0060, -0.0121, -0.0938, -0.0431,  0.7110, -0.0722,  0.3526,\n",
       "          -0.0497]]),\n",
       " tensor([[-0.0535, -0.0159,  0.7691, -0.0285,  0.1813, -0.0314,  2.4568,\n",
       "          -0.0746, -0.1296, -0.4659, -0.0086, -0.0065,  0.3370,  2.7806,\n",
       "           1.1063, -0.0205, -0.0298, -0.0857, -0.0897,  2.8145,  1.1631,\n",
       "          -0.1089, -0.1456, -0.0293, -0.0785,  0.1786, -0.0227,  0.0175,\n",
       "          -0.0906]]),\n",
       " tensor([[-0.5989,  2.7149, -0.0085,  0.1194,  0.1377, -0.0715, -0.0117,\n",
       "          -0.2828, -0.0073, -0.1589,  0.7884, -0.0457, -0.0672, -0.0155,\n",
       "          -0.0106, -0.0571, -0.7173,  0.5896, -2.6310, -0.0419, -0.0253,\n",
       "          -0.1264, -0.1246,  2.7343, -0.1523, -0.0117,  0.5538, -0.1498,\n",
       "          -0.0183]]),\n",
       " tensor([[-0.0118, -0.0062, -0.1692, -0.4054,  2.7234, -0.0385, -0.0076,\n",
       "          -0.0712, -0.1100,  0.7549,  0.1441, -0.0364, -0.0078, -2.8383,\n",
       "          -0.0126,  0.7997, -0.4482, -0.0097,  0.5961, -0.0161, -0.1188,\n",
       "           0.0460, -0.1402,  2.8692, -0.1230,  0.7720,  2.0851, -0.0258,\n",
       "          -0.1027]]),\n",
       " tensor([[-2.1889,  0.6784, -0.1291, -0.6501, -2.7439,  0.2423,  0.6681,\n",
       "          -0.1352, -0.0622, -0.1154,  2.2126, -0.1289, -0.0052, -0.0600,\n",
       "           2.8250,  2.9249, -0.0028,  2.7258,  2.8101, -0.1021, -0.0065,\n",
       "          -0.0042, -0.0035, -0.0039, -0.0206, -0.0120, -0.0913, -0.2414,\n",
       "           0.7952]]),\n",
       " tensor([[-0.1427, -0.0317, -0.0052, -0.1292, -0.2761, -0.1362, -0.1257,\n",
       "           0.7118, -0.0154, -0.0055, -0.0059, -0.0808, -0.1295, -0.0172,\n",
       "          -0.0134, -0.0197, -0.3600,  1.6393, -0.1290, -0.0202, -0.0502,\n",
       "          -0.0159,  2.6903, -0.0026,  0.3289,  3.0937,  0.6767, -0.1139,\n",
       "           0.5100]]),\n",
       " tensor([[-0.2258, -0.0403, -0.0015, -0.0064, -0.0270,  1.9458, -0.0201,\n",
       "           2.9907, -0.6185, -0.0560, -0.4456,  0.4023,  0.5134, -0.0487,\n",
       "          -0.0357, -2.8384, -0.1207, -2.7776, -0.1059, -0.0049, -0.0560,\n",
       "          -0.1275, -0.1047, -0.0650, -0.0160, -0.1266, -0.2069, -0.0061,\n",
       "           2.6915]]),\n",
       " tensor([[-0.0225,  2.9586, -0.0998, -0.0778,  2.2448,  0.7112, -0.1126,\n",
       "           2.6781, -0.1565,  0.2502,  2.6920, -0.1355, -0.0099, -0.0015,\n",
       "          -0.1451, -0.1333, -0.0974, -0.0134,  0.0703, -0.0037, -0.1431,\n",
       "          -0.0485, -0.0021, -0.1242, -0.0022, -0.0071, -0.0048,  0.7682,\n",
       "           0.6603]]),\n",
       " tensor([[-0.0186, -0.2291,  0.4555, -0.0036, -0.7524,  2.6952, -0.0028,\n",
       "           0.7734, -0.1266,  2.1191, -0.1335,  2.6179, -0.1281, -0.1523,\n",
       "          -0.0039,  2.7017, -0.4190, -0.1043, -0.0084, -0.5151, -0.1082,\n",
       "          -0.3582, -0.4542, -0.0985, -0.0418,  0.1745, -0.0101,  0.6608,\n",
       "          -0.0016]]),\n",
       " tensor([[-0.0440, -0.0032,  0.2165,  0.4223, -0.0256, -0.0013, -0.0361,\n",
       "          -0.0109, -0.0547, -0.0071, -0.0887, -0.0330, -0.0940, -0.1169,\n",
       "          -0.3828, -0.1432, -0.0184, -0.2500, -0.0048,  0.0961,  2.6240,\n",
       "           0.0146, -2.7391,  1.8030, -3.0122,  0.7391, -0.1378, -0.4638,\n",
       "           0.4048]]),\n",
       " tensor([[-1.8438, -0.0172, -0.1462, -0.0067, -1.1134, -0.0228, -0.1205,\n",
       "           2.7045, -0.0860, -0.2366, -0.0237,  0.0080,  0.1208, -0.1275,\n",
       "          -0.0467, -0.1059, -0.0097, -0.0234, -0.3594,  2.6796, -0.1355,\n",
       "           0.7806, -0.0158,  0.7803, -0.0930, -0.0282,  2.9697, -0.0494,\n",
       "           0.7077]]),\n",
       " tensor([[-0.0044,  0.2581, -0.0555, -0.1442,  2.7511,  0.0871,  2.7846,\n",
       "          -0.0113, -0.0142,  0.9324, -0.0029, -0.0040, -0.0324, -0.0015,\n",
       "           0.5705, -0.2816, -0.1286, -0.0060,  0.6453, -0.0086,  1.8663,\n",
       "          -0.1396,  0.7763, -0.1395, -0.1360,  0.7856, -0.4724, -0.1012,\n",
       "          -0.1414]]),\n",
       " tensor([[-0.0333, -0.0074, -0.2649, -3.2519, -0.0111, -0.1443,  0.8062,\n",
       "           0.3504,  1.8771,  0.8470, -0.0081,  0.7771, -0.0163,  0.3372,\n",
       "           0.7975, -0.1288,  0.0223, -3.0829,  0.7400, -0.0120, -0.0052,\n",
       "          -0.0327, -0.0284, -0.2163, -0.0439, -0.0112, -0.5887,  1.7986,\n",
       "          -0.0146]]),\n",
       " tensor([[-0.0759,  0.6867, -0.1155, -0.0824, -0.2336, -0.0228, -0.0074,\n",
       "           2.6769, -2.4519, -0.0063,  0.5620, -0.5230, -0.0572,  0.7401,\n",
       "          -0.0085, -0.1927, -0.0133,  0.5537, -0.0281,  0.9138, -0.1410,\n",
       "          -0.0903, -0.5694,  0.6048, -0.4987,  0.7532, -0.0059, -0.1474,\n",
       "          -0.1493]]),\n",
       " tensor([[-0.0449, -0.0191, -0.0718,  1.1482, -0.0109, -0.0363, -0.5834,\n",
       "          -0.1508,  0.7654, -0.2970, -0.1049,  0.7353,  0.1655, -0.5649,\n",
       "           0.2616, -0.1453, -0.0428, -0.1274, -0.1268, -0.0904,  3.1237,\n",
       "          -0.6157,  2.3621, -0.1163,  0.7559, -0.0836, -0.0370, -0.0090,\n",
       "           2.6845]]),\n",
       " tensor([[ 0.2070, -0.0153,  2.2508, -0.0883, -0.0292, -0.3708,  0.0127,\n",
       "          -3.0579,  0.1270, -0.1445,  2.7631, -0.3208, -0.1032, -0.5339,\n",
       "          -0.0949, -2.9369, -0.1294, -0.0533, -2.5791, -0.0130, -1.4991,\n",
       "          -0.1515,  0.7446,  0.3996,  2.6785, -0.0221, -0.0163, -0.1524,\n",
       "          -0.0183]]),\n",
       " tensor([[-0.1233,  0.4120, -0.0100, -0.0415, -2.9959, -0.0173, -0.0134,\n",
       "           2.2978, -0.0439, -0.0005, -0.1023,  2.8229, -0.1089, -0.1113,\n",
       "          -0.0642, -0.1528,  0.1364, -0.1440,  2.6632,  0.6304,  0.7437,\n",
       "           0.7380,  0.7559,  0.1750,  0.7176, -0.0440, -0.0118, -0.1092,\n",
       "          -0.0783]]),\n",
       " tensor([[-0.4651, -0.1103, -0.2630,  0.7660, -0.0684, -0.0923,  0.2380,\n",
       "           0.6377, -0.0095,  0.5303,  0.8147, -0.0493, -0.1226, -0.0140,\n",
       "          -0.4619,  2.6112, -0.0369, -0.0541, -0.6139,  0.2502, -0.0262,\n",
       "          -0.0269, -0.3235, -0.6583, -0.0930,  0.6988,  0.7448, -0.1486,\n",
       "          -0.1557]]),\n",
       " tensor([[-0.0995, -0.0264, -0.1412,  0.7439,  2.0390,  0.7318,  2.7185,\n",
       "          -0.0132, -0.1457, -0.1522, -0.0218, -0.0134, -0.0169, -0.0330,\n",
       "          -0.0328, -0.2824, -0.0109, -0.1498, -0.0355,  0.7230,  0.5321,\n",
       "          -0.1547,  0.6969,  2.5332, -0.0221, -2.7496, -0.0964, -3.1405,\n",
       "           0.7602]]),\n",
       " tensor([[ 0.7909,  2.9554, -0.0146, -0.0181,  2.5375, -0.1530, -0.0168,\n",
       "           2.3421, -0.0617, -0.0347, -0.0486, -0.0110, -0.3667, -0.0538,\n",
       "           2.6776, -0.0147, -1.8606, -0.1042, -2.5876,  2.7536, -0.1446,\n",
       "          -0.0925, -0.1015,  1.9436, -0.2294,  0.0180, -0.0199, -0.0915,\n",
       "           0.7735]]),\n",
       " tensor([[-0.0108, -0.1775,  0.1814,  0.1707,  0.6763,  2.6764,  0.7742,\n",
       "          -0.2586, -0.0229,  0.4201, -0.1058, -0.0135, -0.1395, -0.0248,\n",
       "          -0.0404, -0.1822, -0.1392,  0.0530, -0.2144, -0.0280, -0.0105,\n",
       "          -0.1082, -0.1388, -0.1269,  2.6822, -2.5545, -0.1226, -0.0446,\n",
       "           2.3244]]),\n",
       " tensor([[-0.0723,  0.6472, -0.1493, -0.0670, -0.0282, -0.0498, -0.1133,\n",
       "           3.6419, -0.1529,  0.7662, -0.0132, -0.0136, -0.0959, -2.5244,\n",
       "           0.7606, -0.0121,  1.9236, -0.0249, -0.3875, -0.0557, -0.1523,\n",
       "           0.6647, -0.0566,  2.9105, -0.0392, -0.0291, -0.1446,  0.7780,\n",
       "          -0.1220]]),\n",
       " tensor([[ 2.7685, -0.1118, -0.0123,  2.7375,  0.7626, -2.0399, -0.0373,\n",
       "          -1.5855, -0.0819, -0.0181,  0.3809, -0.1380,  0.6726, -0.1293,\n",
       "          -2.9558, -0.0183, -0.0306, -0.0267,  0.7570, -0.2260, -0.0201,\n",
       "           0.3305, -0.0561, -0.0977, -0.0231, -0.1128, -0.0270,  0.7497,\n",
       "          -0.0248]]),\n",
       " tensor([[-0.0681,  2.6966, -0.0337, -0.5966, -0.0858, -0.0163,  2.8195,\n",
       "          -0.0418,  2.5022, -0.0150, -0.1057,  2.6686, -0.5572,  0.1403,\n",
       "          -0.1058, -0.0110, -0.1511,  0.6931,  2.1447, -0.0106,  2.6769,\n",
       "          -0.1194, -0.1384, -0.4182, -0.0180, -0.4198,  0.3149, -0.5971,\n",
       "           0.6960]]),\n",
       " tensor([[ 0.4745, -0.0940, -0.0117, -0.5238, -0.4254, -0.0143, -0.0178,\n",
       "           0.6987, -0.0511, -0.0159, -0.1110, -0.0166, -2.6059, -0.1033,\n",
       "           0.7275, -0.0243, -0.1049, -1.1401,  0.4259, -0.0963,  1.9027,\n",
       "          -0.1476, -0.0125, -0.1480, -0.2133,  1.1437, -0.0237, -0.0119,\n",
       "          -0.0163]]),\n",
       " tensor([[ 2.0048, -0.0700, -0.1046, -0.0959, -0.0614, -0.5586, -0.0615,\n",
       "           0.7864, -0.4933, -0.0230, -0.1457, -0.0145, -0.1120, -0.1085,\n",
       "          -0.0162, -0.1499, -0.0235, -0.0165,  1.2363,  2.6629, -0.2325,\n",
       "          -2.6090,  0.7442, -0.1451, -3.0330,  2.5852, -0.1003, -0.3148,\n",
       "           1.3208]]),\n",
       " tensor([[-0.0180, -0.1535, -0.0190, -0.0135, -0.0137, -0.2867,  0.7846,\n",
       "           2.2646, -0.0555, -0.0547,  2.7022, -0.1221, -0.0891,  1.2584,\n",
       "           0.7636, -0.0957, -0.1268, -0.2380,  1.4718, -0.0176,  2.6526,\n",
       "          -0.1501, -0.0427, -0.0545,  0.0744,  0.6388,  0.3215, -0.0133,\n",
       "          -0.0413]]),\n",
       " tensor([[-0.1442, -0.0160, -0.0140, -0.0978, -0.1708, -0.1042, -0.0710,\n",
       "          -0.1159,  0.6892,  2.6403,  2.0464, -0.0122, -2.9411,  0.7887,\n",
       "          -0.1519,  0.7833,  2.6416,  0.7573,  0.4011,  0.7429, -0.0769,\n",
       "          -0.0122, -0.1363, -0.1476, -0.1248, -0.0268,  0.6968,  0.7521,\n",
       "          -0.1547]]),\n",
       " tensor([[ 0.2817,  2.8013,  0.7674, -0.1539, -0.4540, -0.0162,  0.2828,\n",
       "          -0.0124, -0.0656, -0.1414, -0.0751, -0.1447, -0.1362, -0.0319,\n",
       "          -0.0219, -0.1201, -0.0363, -0.4241, -0.1109,  2.9236, -0.1487,\n",
       "           2.8863, -0.0216, -0.0984, -0.0147,  2.6456, -0.2885,  1.5102,\n",
       "          -3.0818]]),\n",
       " tensor([[ 2.5678, -0.1415, -0.0137, -0.0713, -0.0161,  0.7104, -0.0314,\n",
       "          -0.1077, -0.1418, -0.1283, -0.0352, -0.4523, -0.0181, -0.0457,\n",
       "           0.6956,  1.9864,  1.2058, -0.0555, -0.0336, -3.0012,  0.7758,\n",
       "          -0.0190, -0.0156, -0.1507,  2.3127, -0.0525, -0.0517, -0.1925,\n",
       "          -0.0618]]),\n",
       " tensor([[ 2.6772, -0.5311,  0.0480, -0.0140, -0.0126, -2.8874, -0.0871,\n",
       "           2.2314,  0.2972, -0.0237,  0.7604, -0.0165, -0.1224, -0.2492,\n",
       "          -0.0447, -0.0132, -0.0812, -0.1390, -0.1533, -0.0163, -0.0718,\n",
       "          -0.1439,  1.0992, -0.0215,  0.5819, -0.1415, -0.3406, -0.0277,\n",
       "          -0.1145]]),\n",
       " tensor([[-0.3033, -0.0218,  2.2844, -0.0406,  0.2516, -0.0180, -0.0211,\n",
       "           2.6437,  0.7245, -0.0746,  1.4558,  0.0714,  2.9825,  2.3160,\n",
       "          -0.2550, -0.0219, -0.0194,  0.7484,  0.5902, -0.1520, -0.0294,\n",
       "          -0.1211, -0.0226, -0.0281, -0.0137,  0.0791, -0.0489, -0.0208,\n",
       "          -0.0241]]),\n",
       " tensor([[-0.0251, -0.1417,  0.7549, -0.6415,  0.7525,  0.6577, -0.0991,\n",
       "           0.7400, -0.1778,  2.6260, -0.0156, -0.0206, -2.4599, -0.0392,\n",
       "           0.1471,  0.1209,  2.6066, -0.1239, -0.0136, -0.1410, -0.3450,\n",
       "           2.7445, -0.1008, -0.0165, -0.0491, -0.1323, -0.0127, -0.0295,\n",
       "          -0.0718]]),\n",
       " tensor([[-0.0169,  0.5366, -0.0868, -0.0134, -0.0232, -0.0871,  0.0728,\n",
       "          -0.1385,  0.6666,  0.5163, -0.0122, -0.0194, -0.0311, -3.1326,\n",
       "          -0.1096, -0.0813, -0.5204, -0.1137, -0.1469, -0.0144, -0.0180,\n",
       "          -0.6327,  0.6583, -0.1320, -0.0673,  2.6399, -2.4481,  0.2030,\n",
       "          -0.0508]]),\n",
       " tensor([[-0.0144,  0.7382, -0.1356, -0.0402,  0.0421,  0.7408,  0.5874,\n",
       "          -0.0225, -0.0132, -0.0247,  0.3590, -0.1191, -0.0184, -0.3157,\n",
       "          -0.1336, -0.1215, -0.0285, -0.2036,  0.7827,  0.7594, -0.0924,\n",
       "          -0.1403,  0.7366,  0.5223, -0.0140, -0.0193, -0.0128,  2.7285,\n",
       "           2.6496]]),\n",
       " tensor([[-0.0674, -0.0186, -0.0133, -0.1490, -0.0425, -0.0653, -0.1224,\n",
       "           0.7841, -0.0030,  2.6780, -0.0521, -0.0753, -0.1359,  0.4948,\n",
       "          -0.0213, -0.3714, -2.8495, -0.1784, -0.0959, -0.1237, -0.0376,\n",
       "          -0.3976, -0.0158, -0.0142,  0.5723, -0.1556, -0.0848, -0.0166,\n",
       "           2.7201]]),\n",
       " tensor([[-0.0233, -0.0544, -3.0820, -0.0541, -0.1506, -3.0292,  2.6789,\n",
       "          -1.0013,  0.3879,  0.2668,  0.7344, -0.0130,  0.7176, -0.2179,\n",
       "           0.0384, -0.3260,  2.7776, -2.7830, -0.0284, -0.0732, -0.1302,\n",
       "          -0.0252,  2.6789, -0.0136, -0.0984, -1.3770, -0.1520, -0.0288,\n",
       "          -0.4267]]),\n",
       " tensor([[-0.0321, -0.1562, -0.0126, -0.4678, -0.0125, -0.3251,  2.6969,\n",
       "          -2.9252, -0.1533, -0.0328, -0.0156, -0.1425, -0.1347, -0.0371,\n",
       "           0.7608, -2.9075,  0.7773,  0.1189, -0.0733, -0.1005, -0.0879,\n",
       "          -0.0287, -0.6636,  2.2320, -0.0998, -0.0774, -0.0161, -0.0499,\n",
       "          -0.0371]]),\n",
       " tensor([[-0.0851, -0.3397, -0.0168, -0.1514, -0.0204, -0.0929, -0.1482,\n",
       "          -0.0104, -0.5709, -0.0967, -0.0335, -0.0191, -1.8973,  2.6202,\n",
       "          -0.0523, -0.1101, -0.0089, -0.0383, -0.0181, -0.2328, -0.1352,\n",
       "          -0.1473,  2.6524, -0.1449, -0.0086,  2.4357, -0.1528,  0.2522,\n",
       "          -0.0856]]),\n",
       " tensor([[-0.0239, -0.0332, -0.0218, -3.0734, -0.0457, -0.5403,  0.3704,\n",
       "          -0.0225,  0.4570, -2.6141,  0.4210, -0.0175, -0.4503,  1.9599,\n",
       "          -0.0153, -0.0541,  2.6801, -0.0091, -0.2705, -0.0702, -0.0139,\n",
       "           2.6727, -0.0581, -0.1129, -0.2190, -0.0231, -3.0517, -0.3124,\n",
       "           0.3454]]),\n",
       " tensor([[-0.5651, -0.1105, -0.1078, -0.2221, -0.1524, -0.1310, -0.0172,\n",
       "          -0.0957,  2.9297, -0.0534,  2.9734, -0.0249, -0.0102,  0.7422,\n",
       "          -0.1348,  2.6750, -0.1497,  1.6351,  0.7596, -0.1533, -0.1406,\n",
       "          -0.1509, -0.0890, -0.0106, -0.0114, -0.1406,  0.5890, -0.0555,\n",
       "          -0.1526]]),\n",
       " tensor([[-0.0248,  0.4907, -0.0960, -0.0176, -0.1164, -0.0509, -0.0532,\n",
       "          -0.5918,  0.1902, -0.1365, -0.0105, -0.0374, -0.5154, -0.0114,\n",
       "           0.0772, -0.0570, -0.0886,  0.6210,  2.6854,  2.5227, -0.0525,\n",
       "           2.5279, -0.5574, -0.5819, -0.1714, -0.0192,  2.6430, -0.0460,\n",
       "           3.0065]]),\n",
       " tensor([[-0.0617, -0.1536, -0.1273, -0.6130, -0.0581,  1.8049, -0.1455,\n",
       "          -2.0242, -2.2967,  1.4357, -1.1164,  2.4313, -0.1062, -0.0166,\n",
       "          -0.1476, -0.1877, -2.7810,  2.7068, -0.0897, -0.1158, -0.3348,\n",
       "           2.7723, -0.0817,  0.6644, -2.5908, -0.0752,  0.6745,  0.6212,\n",
       "          -0.0893]]),\n",
       " tensor([[ 1.7538,  2.6632, -0.0296, -0.0328,  0.6286, -0.0910, -0.1446,\n",
       "           2.6865, -0.0123, -0.0156, -2.1728, -0.1962, -0.1453, -0.0106,\n",
       "          -0.0157,  0.4050, -0.1494, -0.1312, -0.4146,  0.1474, -0.0228,\n",
       "          -0.0096,  2.6628, -0.0169, -0.0215,  0.6539, -0.4217,  1.0134,\n",
       "          -0.0821]]),\n",
       " tensor([[-1.6032, -0.0228, -0.0111,  2.6695,  0.1127, -0.0123, -0.1423,\n",
       "          -0.0105,  2.6195, -0.0192, -0.0400, -0.0117, -0.0226, -0.3250,\n",
       "          -0.0247,  0.7455, -0.0074,  2.7735,  1.4132, -0.0546, -0.0211,\n",
       "          -0.0116,  2.7645,  0.0894, -0.0765, -0.1550,  0.4270,  0.0445,\n",
       "          -0.4392]]),\n",
       " tensor([[-0.0344, -0.0700, -0.1222, -0.1363, -0.1433, -0.0317, -2.9474,\n",
       "          -0.5255, -0.0155, -0.0696, -0.0277, -2.7885, -0.1429,  0.7749,\n",
       "          -2.9554, -0.0694,  0.6626, -0.0951, -0.0155,  2.7192, -0.1224,\n",
       "          -0.1502, -0.1376, -0.1075, -0.1196, -0.1324,  2.6472, -0.1431,\n",
       "          -0.1405]]),\n",
       " tensor([[-0.0234,  0.7830, -0.0157, -0.0377, -0.0168, -0.3404, -0.3107,\n",
       "          -0.0161, -0.0277, -2.6921,  1.7892,  0.4243, -0.1523, -2.3899,\n",
       "          -2.5987, -0.0753, -0.0828,  0.7145, -0.0150, -0.0097, -0.0211,\n",
       "           0.7417,  0.7371,  0.1075,  0.0640, -2.0687,  2.3228, -0.1420,\n",
       "          -0.0124]]),\n",
       " tensor([[-3.0293, -0.0091, -2.7194,  0.1067,  1.3397, -0.1244, -0.0580,\n",
       "          -0.2652,  0.6653, -0.0940, -0.4635,  0.2696, -0.0589, -0.0096,\n",
       "          -0.1115, -0.0095, -0.0978, -0.0113, -0.0614, -0.1548,  0.6220,\n",
       "           2.7258, -3.0899, -0.1512, -0.0176, -0.0617, -0.2685, -3.0079,\n",
       "           0.7604]]),\n",
       " tensor([[-0.1402,  1.2176, -0.0507, -0.3351, -0.0255, -0.0093, -0.0136,\n",
       "          -0.0147,  2.3851, -0.1354, -0.0247, -0.2638, -0.0332, -0.0372,\n",
       "           2.6163, -0.5693, -0.0140, -0.6199,  0.2277, -0.0098,  0.6913,\n",
       "          -0.0184, -0.1516, -0.0561, -0.0771, -0.0119,  1.8110,  2.8295,\n",
       "          -0.0424]]),\n",
       " tensor([[-0.1476,  0.6724, -0.0832,  0.7753,  0.3077, -0.0051,  2.6721,\n",
       "          -0.4466, -0.1291, -0.0068, -0.0176, -0.0195, -0.0546, -0.0090,\n",
       "           0.7564, -1.1289, -0.0825, -0.0071, -0.0267, -0.0063, -0.0058,\n",
       "          -0.0228, -0.1212,  2.6547,  0.7631, -0.1479, -0.0041, -0.1460,\n",
       "          -0.0515]]),\n",
       " tensor([[-0.2976, -0.0115, -0.4394, -2.3899, -3.0720, -0.0506,  0.5811,\n",
       "          -0.3901,  0.5953, -0.0234, -0.0095,  0.7737,  0.7537,  0.7341,\n",
       "           2.8428, -0.1066,  0.6325, -0.0030, -0.4404, -0.0201, -0.0047,\n",
       "          -0.0521,  0.5514,  2.8676, -0.0515, -0.1041, -0.0054, -0.0827,\n",
       "          -0.4973]]),\n",
       " tensor([[-2.4134,  0.6208,  0.7644,  0.7125, -0.0272, -0.0231, -0.0715,\n",
       "          -0.0013,  2.9444, -0.0131, -0.1387,  2.6822, -0.0044, -0.0054,\n",
       "          -0.0387, -0.0002, -0.0146, -0.0044, -0.0162,  0.8490,  0.6777,\n",
       "           0.8184,  0.2191, -0.1414, -0.0117, -0.0139, -0.0218,  0.1767,\n",
       "           0.7797]]),\n",
       " tensor([[-0.1187, -2.6120, -2.8157, -0.0050, -0.0645, -0.0332, -0.1278,\n",
       "          -0.1292,  0.0044, -0.0194, -0.1220,  3.1606,  0.0504, -0.0103,\n",
       "           1.2257, -0.0817,  2.3487,  2.2557, -0.0976, -0.0137,  0.5011,\n",
       "           0.3397, -0.0010,  0.7572, -0.1433, -0.0227, -0.0006, -0.0016,\n",
       "          -0.0430]]),\n",
       " tensor([[-0.0682, -0.0042, -0.6302, -0.0864,  0.0521, -0.0271, -0.0029,\n",
       "          -0.0082, -0.0831,  0.5959, -0.1406,  0.7491, -0.0909, -0.0137,\n",
       "          -0.0270, -0.1624, -0.0609,  0.2428, -0.0281, -0.0222,  0.2447,\n",
       "           0.4027, -0.6404,  1.9704,  0.7169, -0.0205, -0.0009, -0.0182,\n",
       "          -0.0089]]),\n",
       " tensor([[-1.8370e-01, -2.6163e-03, -3.5217e-03,  5.1513e-02, -1.3594e-01,\n",
       "          -7.7331e-02, -1.3492e-03, -9.7358e-03,  6.1778e-01,  1.1010e-01,\n",
       "           7.6112e-01,  2.1983e-01,  7.0652e-02,  7.9614e-01, -2.1543e-02,\n",
       "          -1.3654e-01, -1.0919e-01, -9.7069e-03,  3.5860e-01,  6.5804e-01,\n",
       "          -1.1747e-03, -4.6082e-06, -2.8908e+00, -1.4550e+00, -5.2567e-01,\n",
       "           7.7020e-01, -2.4377e-02, -2.5715e-02,  1.7970e-04]]),\n",
       " tensor([[ 2.6846, -0.1318, -0.0393,  0.7419, -0.0231, -0.4077, -0.1286,\n",
       "          -0.0199, -0.0050, -0.0859, -0.0934, -0.1154, -0.1181, -0.0492,\n",
       "           0.0007, -0.0430, -0.0110,  0.0009, -0.0230, -0.0922, -0.0366,\n",
       "          -0.0081, -0.1414,  1.8491, -0.0106,  2.8305, -0.0116,  1.4085,\n",
       "           0.8149]]),\n",
       " tensor([[ 0.4719,  0.8314, -0.0005,  2.7080, -0.0593,  0.6961, -0.1064,\n",
       "          -0.0179, -0.1434,  0.0384, -0.0037, -0.0321, -0.0121, -0.5862,\n",
       "          -0.0148,  0.6782, -0.0124, -0.0017, -0.0087,  0.7123, -0.0132,\n",
       "           0.0023, -2.8261, -0.1121, -0.1890,  0.7295,  0.0005,  0.0237,\n",
       "          -0.1040]]),\n",
       " tensor([[ 0.7370,  0.0013,  0.0019,  0.0021, -2.3880,  1.3713,  0.4987,\n",
       "          -0.4211, -0.0637, -0.1080,  0.0008, -0.0250,  0.4523, -0.0200,\n",
       "          -0.5906,  0.5063, -0.1205,  2.1564, -2.4013, -0.0073, -0.0219,\n",
       "          -0.0020, -0.0162, -0.0013,  0.0027, -0.4560,  0.0005,  0.6840,\n",
       "          -0.0659]]),\n",
       " tensor([[-0.0026, -0.0031, -0.1781, -0.0067, -0.0036,  0.6394, -0.1409,\n",
       "          -0.0135, -0.0441, -0.0082, -0.0021, -0.0867,  0.2727, -0.0394,\n",
       "          -0.0111,  0.0035, -0.0553, -0.1164, -0.0001, -0.0299, -0.0449,\n",
       "          -0.6034, -0.1400,  0.0138, -0.1329,  2.6531, -0.1253, -1.1702,\n",
       "          -2.9698]]),\n",
       " tensor([[ 0.7435,  0.0013, -0.0012,  0.8732, -0.0875, -0.0807, -0.1412,\n",
       "           0.7496, -0.0189, -0.0307, -0.0104,  0.0428, -0.4136, -0.0002,\n",
       "          -0.0521, -0.0121, -0.0447,  0.6432, -0.0078, -0.0435,  3.2113,\n",
       "          -2.6175,  1.3412, -0.2141, -0.1371, -0.0898, -0.0315, -0.0228,\n",
       "          -0.0681]]),\n",
       " tensor([[-0.0173,  2.8389, -0.5354,  0.8041,  0.0019, -0.0015,  0.0035,\n",
       "          -0.0852, -2.0717, -0.0029,  2.0376, -0.0460, -0.0742, -0.0999,\n",
       "          -0.0121, -0.1359, -0.1376, -0.0106, -0.0457, -0.1107, -0.3614,\n",
       "           0.0594, -0.0085, -0.1098,  2.5660, -0.1242, -0.0021,  0.0014,\n",
       "          -0.0200]]),\n",
       " tensor([[ 0.2209, -0.0003, -0.0392, -0.1642, -0.1208, -2.8119, -0.3941,\n",
       "          -0.1359, -0.0020, -0.0725, -0.1042, -0.0373,  0.0033,  0.0011,\n",
       "           0.7719, -0.0004, -0.1383, -0.3283,  2.6507, -0.1272, -0.1325,\n",
       "           0.7250,  0.8040,  0.3397, -2.5251,  2.6730, -0.0173,  0.7558,\n",
       "           0.7646]]),\n",
       " tensor([[ 0.2931,  0.0027,  0.0604, -0.1296,  2.7340, -0.2712, -2.8051,\n",
       "           0.0016, -0.0045, -0.0030,  0.3392, -0.1080, -0.1350, -0.0293,\n",
       "           0.0019,  2.7917,  0.0862,  0.2255, -0.1327, -0.0022,  0.0029,\n",
       "           2.3255,  0.5814, -0.3621, -0.0447, -0.3353,  0.6924, -0.0780,\n",
       "           0.2321]]),\n",
       " tensor([[-3.1482e-02, -2.2845e-03, -1.0652e-01, -2.0696e-01,  8.0150e-01,\n",
       "          -2.3124e-03, -5.4733e-02,  2.0575e-01, -1.1215e-03, -9.6324e-02,\n",
       "          -1.4689e-02, -1.4984e-01, -3.4533e-01, -1.1193e-01, -1.7822e-02,\n",
       "          -6.1540e-02, -3.2337e-02, -1.8403e-01,  2.7705e-05, -3.2063e-02,\n",
       "          -1.2473e-01, -4.3247e-01,  2.7386e+00, -3.4841e-02,  7.6166e-01,\n",
       "           2.7992e+00, -1.3138e+00, -6.5982e-02, -1.5884e-02]]),\n",
       " tensor([[-0.0093, -0.1333, -0.0734, -0.0057, -0.2296,  2.8131, -0.0189,\n",
       "          -0.4110, -0.0042,  0.7893, -0.0033, -0.0450, -0.0082, -0.0592,\n",
       "          -0.1103,  1.5215, -0.0039,  0.2234, -0.1930, -0.0972, -0.0153,\n",
       "          -0.1028, -0.0082, -0.1209,  0.8034, -0.1116, -0.0092, -0.0170,\n",
       "          -0.0113]]),\n",
       " tensor([[ 0.1715,  0.2457,  2.3235, -0.0259, -0.0797, -0.1422, -0.0344,\n",
       "           2.8599, -0.0970, -0.0829, -0.4450, -0.5015, -0.0893, -0.0920,\n",
       "          -3.0567, -0.0037, -0.0174, -0.0946, -0.0109, -0.6382, -0.0041,\n",
       "          -0.0966, -0.1101, -0.1861,  0.7559, -0.4340, -0.0042, -0.1330,\n",
       "           0.3094]]),\n",
       " tensor([[-0.0514,  0.6885, -0.1177,  0.7449,  0.7386, -0.0051, -0.0072,\n",
       "          -0.0143,  2.6758, -0.0056,  0.0616, -0.0612, -0.0616, -0.0058,\n",
       "          -0.0117, -0.0242, -0.0416, -0.0677, -0.0299, -0.0613,  0.7606,\n",
       "          -0.0138, -0.0724, -0.0573, -0.0261, -0.1056, -0.0065, -0.0288,\n",
       "          -0.0493]]),\n",
       " tensor([[-0.0051,  0.7917, -0.1360, -0.0851,  0.6770, -0.0382, -0.0333,\n",
       "          -0.1443, -0.0609,  0.6133, -0.0668, -0.0202, -0.0266,  0.0852,\n",
       "          -0.5396, -0.0053, -0.0068, -0.1215, -0.0550, -0.0056, -0.0158,\n",
       "          -0.0851,  0.7863,  0.0082, -0.1310,  2.4893, -0.0059, -0.0451,\n",
       "          -0.0043]]),\n",
       " tensor([[-0.1079, -0.4787,  0.2011, -0.1437, -0.0296, -0.1292,  2.2984,\n",
       "          -0.0271,  0.6763, -0.0799, -2.7879, -0.0353,  2.7255,  0.0875,\n",
       "           0.5808,  0.5630, -0.2117, -0.0668, -0.0382,  0.8140, -0.1093,\n",
       "          -0.5675, -0.0141, -0.0194, -0.1239,  2.5601, -0.0444, -0.1178,\n",
       "          -0.0047]]),\n",
       " tensor([[-0.0209,  2.0121, -0.1301,  0.7555, -0.0852,  1.5495, -2.7010,\n",
       "          -0.0059, -0.0370, -2.8407,  0.0055, -0.0067, -0.0953, -0.0767,\n",
       "          -0.1782, -0.0257, -0.1221,  3.1355,  2.1538, -0.0103,  0.3006,\n",
       "           0.7570, -0.0060, -0.2455, -0.1099, -0.1336,  0.1045, -0.0058,\n",
       "           0.7066]]),\n",
       " tensor([[-0.0352, -0.0171, -0.0502, -0.0064,  0.8654, -0.0241,  0.4990,\n",
       "           0.8000, -0.0392, -0.0160, -0.0944, -0.0125, -0.0427,  0.7283,\n",
       "          -2.9132, -0.0120, -0.1469,  0.4890, -0.5726,  2.8544, -0.0053,\n",
       "           0.7608, -0.0923,  1.4496, -0.0466, -0.0930, -3.0441,  0.8216,\n",
       "           0.7998]]),\n",
       " tensor([[-0.0170, -0.2598, -0.0056, -0.1179, -0.1842, -0.0069,  2.9010,\n",
       "          -0.1307, -0.0103, -0.0077, -0.0109, -0.1107,  0.0004, -0.0403,\n",
       "          -0.5057, -0.0130, -0.0931,  0.0485, -0.0631,  1.5530, -0.0225,\n",
       "          -0.1015, -0.0401,  0.6729, -0.1371, -0.0987, -0.0740, -0.1419,\n",
       "          -2.1174]]),\n",
       " tensor([[ 0.7713, -0.1367,  0.7646, -0.0066, -0.0281,  0.1098, -0.0418,\n",
       "          -0.0071, -0.0089, -0.0959, -0.3127, -0.1448, -0.1033, -0.0556,\n",
       "           2.5932, -0.0764, -0.0307, -0.2667, -0.0974, -0.0099, -2.9534,\n",
       "          -0.2885, -0.1382, -0.4534, -0.0764, -0.0064, -0.0322, -0.2070,\n",
       "          -0.1046]]),\n",
       " tensor([[-0.0543, -0.0048, -0.4259, -0.0240, -0.4645,  2.5408, -0.0055,\n",
       "          -0.0474,  0.7600, -0.0055, -0.0465, -0.1195, -0.1403,  0.3648,\n",
       "           2.6631, -0.0161, -0.0048, -0.1081, -0.0080, -0.0468, -0.0097,\n",
       "          -0.0065, -0.4286, -0.0073, -0.0335, -0.0115, -0.0119, -0.5286,\n",
       "          -0.0824]]),\n",
       " tensor([[ 0.0188, -0.0147,  0.2777, -0.0050, -0.1309,  0.3768,  2.1682,\n",
       "          -0.0892, -0.0614, -0.0178, -0.1187,  0.3299,  2.6313, -0.0627,\n",
       "          -0.0070, -0.0170, -0.0116, -0.1351, -0.0221, -0.0059, -0.1215,\n",
       "          -0.0168, -0.2325, -2.1911, -2.8540,  0.2011,  0.2679,  2.6495,\n",
       "           0.1745]]),\n",
       " tensor([[-0.0256, -0.0307, -0.0071, -0.0574, -0.1135, -0.1130, -2.7843,\n",
       "          -0.0231, -2.8189, -0.0177,  0.7389, -0.0402,  0.7917, -0.5170,\n",
       "           2.6840,  0.4582, -0.0906, -0.0756, -0.0110, -0.1426,  2.2642,\n",
       "           2.5411, -0.2162, -0.0176, -0.0620, -0.0367, -0.0080,  1.9537,\n",
       "          -0.1471]]),\n",
       " tensor([[ 0.4360, -0.0060,  0.3576,  0.2186, -0.1173, -0.0242, -0.5311,\n",
       "          -0.0118, -0.0060, -0.0180, -0.0221, -0.1195, -0.1428,  1.8741,\n",
       "          -0.0887, -0.0435, -0.0054,  0.6284, -0.0152, -2.5822, -0.0739,\n",
       "           2.3543, -0.1070, -0.4606,  0.7141, -0.1439, -0.1103, -0.1967,\n",
       "          -0.0104]]),\n",
       " tensor([[-0.0218, -0.1339,  0.7571,  2.3322,  0.2443, -0.0190,  0.2833,\n",
       "          -0.1297, -0.0856, -0.1508, -3.1404,  0.7628, -0.0138, -0.0519,\n",
       "          -0.1457, -0.0532,  0.1442, -1.4280,  0.5950,  1.4412,  0.5458,\n",
       "          -0.0069,  0.7597,  2.6525,  2.7102,  0.0722, -0.0788, -0.3968,\n",
       "          -0.1269]]),\n",
       " tensor([[-2.6091, -0.0584, -0.1444,  0.5557, -0.0264, -0.1407, -0.0083,\n",
       "          -0.0089, -0.0224, -0.0895,  0.7844,  0.3933, -0.0749, -0.0251,\n",
       "          -0.1435,  0.8758, -0.0170, -0.0068, -0.4712, -0.0077, -0.1499,\n",
       "          -0.0909, -0.0447, -0.0451, -0.0091, -0.1209,  0.3544,  0.6026,\n",
       "          -0.2689]]),\n",
       " tensor([[-0.0378, -0.0823,  0.2354,  2.1078, -0.0581,  0.7670, -0.0092,\n",
       "           0.5841, -2.7268, -0.0381,  0.4636, -0.2540, -0.5788, -0.5604,\n",
       "          -0.0550, -0.4800, -0.1391, -0.3725, -0.0112,  2.5511, -0.0079,\n",
       "           0.7548, -0.0182, -0.0243,  0.0531, -2.8810, -0.9125,  0.2930,\n",
       "           2.7448]]),\n",
       " tensor([[-0.0100, -0.0099, -0.0448, -0.0150, -0.1247, -0.1457,  0.7690,\n",
       "           2.6397,  0.7233,  0.7339, -0.1499,  0.5136, -0.0256, -0.0447,\n",
       "           0.7759, -0.4575, -0.0097, -0.4818, -0.0521, -0.0304, -2.9012,\n",
       "          -0.1277, -0.0968, -0.0277, -0.1612,  0.4393, -0.0299, -3.0394,\n",
       "          -0.0149]]),\n",
       " tensor([[-0.3471, -0.0077, -0.5346, -0.0281, -0.0812, -0.0342, -0.0749,\n",
       "          -0.1292, -0.0137, -0.0073, -0.1136,  0.5386, -0.0564, -0.0087,\n",
       "          -0.1252, -0.0721,  2.9708, -0.0223, -0.1326,  2.6596, -0.0708,\n",
       "          -0.0559,  3.0601,  0.6710,  2.7762, -0.1203, -0.2408, -0.1393,\n",
       "          -0.0493]]),\n",
       " tensor([[-0.0888, -0.0195,  0.0498, -0.0178,  0.5837, -0.4912, -0.0284,\n",
       "          -0.0702, -0.0708,  0.0923,  1.7522, -0.0571, -0.0174, -0.1622,\n",
       "          -0.1491,  1.4223,  0.6513, -0.0105, -0.1924, -0.0209, -2.6414,\n",
       "          -0.0855, -0.0294,  0.7622, -0.0226, -0.0334, -0.2077, -0.0372,\n",
       "          -0.5800]]),\n",
       " tensor([[-0.1387, -0.0566,  0.7605,  2.9854, -0.1439, -0.1329, -0.1144,\n",
       "          -0.1345,  0.7510, -0.0324,  0.3468,  0.7623,  2.6153, -0.1064,\n",
       "          -0.3985, -0.0250, -0.6196, -0.0794, -0.0223, -0.0068,  2.5083,\n",
       "           0.7701, -0.1140, -0.1442,  0.0721, -0.0383,  0.6908, -0.5014,\n",
       "          -2.8592]]),\n",
       " tensor([[ 1.9543, -0.0094, -0.0495, -2.6350, -0.0070,  0.1330,  0.6326,\n",
       "          -0.0068, -0.1021, -0.1100, -1.1739,  1.2648, -2.8639, -3.0625,\n",
       "           2.6899,  3.0436,  0.8068,  2.9967, -0.0416,  2.6147, -0.0169,\n",
       "           2.7101, -0.1703, -0.1355, -0.0803, -0.0527, -0.0071,  0.3278,\n",
       "          -0.0394]]),\n",
       " tensor([[-0.0086,  2.0677,  0.7869,  2.5876, -0.1453, -0.0551, -0.0227,\n",
       "          -0.1327, -0.0150, -0.0197, -0.0105, -0.0132,  0.7957, -0.1218,\n",
       "           1.1939,  0.1153, -0.1409, -0.0221, -0.1213, -0.4428, -0.0101,\n",
       "           0.7522, -1.7929, -0.0579, -0.1346, -0.0279,  1.9704, -0.0377,\n",
       "          -0.1219]]),\n",
       " tensor([[-0.1270,  0.7942,  1.5385,  1.3716, -0.1463,  0.7575, -0.0101,\n",
       "           2.3526, -0.1223,  2.6707, -0.0100, -0.1326, -0.1110,  2.7743,\n",
       "          -0.1161, -0.0752, -0.0468, -0.0254,  2.5174, -0.0100,  2.6605,\n",
       "           0.1041, -0.0530, -2.0196,  2.6443,  0.0623, -0.0690, -0.0077,\n",
       "          -0.1201]]),\n",
       " tensor([[-1.6230, -0.2547, -0.0186,  0.7633, -0.0099,  0.2677, -0.0104,\n",
       "          -0.0626, -0.0093, -0.4111, -0.0077, -0.0102, -0.0078, -0.0157,\n",
       "          -0.0913,  0.7833,  2.7107,  2.4834,  0.3190, -2.7235, -0.0945,\n",
       "          -0.0706, -1.9436,  2.4741,  0.3623, -0.0368, -0.0730, -0.3959,\n",
       "          -0.0073]]),\n",
       " tensor([[-0.0521,  1.6618,  0.8087, -0.0091, -0.0324, -0.1203, -0.0382,\n",
       "           0.2793,  2.7564,  0.7397, -0.1327, -0.2038,  2.0122, -0.0119,\n",
       "          -0.0845, -0.0172,  0.1126,  0.1229,  0.5728, -0.0491,  0.5644,\n",
       "          -0.0435, -0.5164, -2.6429, -0.1003, -0.0101,  0.7599,  0.7753,\n",
       "          -0.1041]]),\n",
       " tensor([[-2.4100,  0.7520, -0.6376, -0.0112, -0.0832, -0.1440, -0.0888,\n",
       "          -0.3808, -0.0128, -0.3544, -1.8328, -0.2884,  0.0192, -0.0120,\n",
       "          -0.4799, -0.0841, -0.0115,  0.4867, -3.0422, -0.0981, -0.0081,\n",
       "          -0.1122, -2.7609, -0.1158, -0.1087, -0.1451, -0.0878, -0.1044,\n",
       "           2.1664]]),\n",
       " tensor([[-0.0716, -0.1254, -0.1268, -0.1220, -0.0144, -0.1102, -0.0323,\n",
       "          -0.1355,  0.5788, -0.1190, -0.0317, -0.1438,  0.7733, -2.5664,\n",
       "          -0.0436,  0.7679, -0.0090, -0.0313,  0.0461, -0.1092, -0.0081,\n",
       "          -0.0803, -0.1172, -0.1260, -1.8131, -0.0120, -0.0108, -0.0692,\n",
       "          -0.0134]]),\n",
       " tensor([[-0.0109,  0.7456,  0.5009, -2.8425,  1.5162, -0.0171, -0.0095,\n",
       "           1.6262, -0.0075, -0.0713,  0.7962, -0.1294, -0.0312, -0.0858,\n",
       "          -0.0177,  0.7627, -0.1477,  1.2308,  2.4885, -3.0102, -0.0386,\n",
       "          -0.0106,  0.7360, -0.0150, -0.0382, -0.0087,  2.6613, -0.0947,\n",
       "          -0.0207]]),\n",
       " tensor([[-0.4859, -0.0158,  1.8543, -0.0302, -0.1185,  0.3986,  0.7793,\n",
       "          -2.4091, -0.0175, -0.0207,  0.1515, -0.0357, -0.1419, -0.0100,\n",
       "          -0.0086, -0.0193,  0.7800,  0.6258, -0.1159, -0.1192, -0.0403,\n",
       "           2.8551, -0.0970, -0.0189,  2.7385, -0.5383, -2.4998, -0.0551,\n",
       "          -0.0911]]),\n",
       " tensor([[-0.0138,  0.7483,  2.4494,  0.9594, -0.0098,  0.5280, -0.0546,\n",
       "          -0.0543, -1.7508, -0.1325,  0.5643, -0.0078,  2.7492, -0.3499,\n",
       "          -0.1298, -0.0493,  2.7990, -0.0812, -0.0781, -0.0082, -0.5703,\n",
       "           0.7468,  1.6057,  0.7746, -0.0268, -0.0621, -0.1184,  2.5382,\n",
       "          -0.0541]]),\n",
       " tensor([[-0.1337, -0.0118, -0.0103, -0.0221, -0.0311, -0.0489, -0.0751,\n",
       "          -0.0400,  0.7518, -0.1185,  0.6213, -0.0128, -0.1314, -0.0671,\n",
       "           0.6738, -2.7714, -0.1261, -0.0138,  0.7088, -0.1266, -3.1014,\n",
       "           0.5774, -0.0088, -0.0558,  0.7890, -0.0551, -0.0566, -2.5279,\n",
       "          -0.0574]]),\n",
       " tensor([[-0.0174, -0.6440, -0.0127, -2.6869, -0.1404, -2.2120, -0.0094,\n",
       "          -0.1003,  0.7566, -0.0174, -0.0501, -0.0156, -0.0598,  0.3304,\n",
       "          -0.0090, -0.5871, -0.0926, -0.0558,  0.0079,  0.7769, -0.0557,\n",
       "          -0.0139, -3.2289,  0.7895, -0.0168,  0.1384, -0.0210, -0.2816,\n",
       "          -0.0097]]),\n",
       " tensor([[-0.0081, -0.0087,  2.7458, -0.0133,  0.8002,  0.7617, -0.0100,\n",
       "          -0.1242, -3.0480, -0.7070, -0.1410, -0.0365, -3.0527, -0.1388,\n",
       "          -0.1385, -0.0289, -0.1503, -0.0486, -0.1325, -1.1868,  2.5903,\n",
       "          -2.7226, -0.0152, -0.0113,  0.0713, -0.0107, -0.1222, -0.0664,\n",
       "          -2.7196]]),\n",
       " tensor([[-0.4590, -0.0993, -0.7484, -0.1378, -0.0099,  0.7928,  2.6297,\n",
       "          -0.0551, -0.5404, -0.0766, -0.0387, -0.0105, -0.0776,  0.7632,\n",
       "          -0.0410, -0.0565, -0.0083, -0.0642, -0.0059, -0.3817, -0.1234,\n",
       "          -0.1459, -0.1595, -3.2286, -0.0188, -0.3718, -0.0057,  0.7564,\n",
       "           2.9919]]),\n",
       " tensor([[-0.0106, -0.0044, -0.1420, -0.0322, -1.0715,  2.6254, -0.0652,\n",
       "          -0.0051, -0.0105, -0.0215, -0.0822,  0.5567, -0.0265, -0.1024,\n",
       "          -0.0083, -0.0111, -0.0092, -0.1366,  0.4364,  2.5129, -0.3136,\n",
       "          -0.1411,  2.7020, -0.1292,  0.7275, -0.0067, -0.0816, -0.3474,\n",
       "          -0.0057]]),\n",
       " tensor([[-3.1204, -1.3047, -0.1468, -3.0506, -0.0697,  0.0080, -0.5063,\n",
       "           2.8736, -0.1228, -0.3902,  0.7325, -0.1524, -0.0522,  0.2600,\n",
       "          -0.2827,  0.6352, -0.0700, -0.0508, -0.0788,  2.3218, -0.0243,\n",
       "          -0.0369, -0.0582,  2.6747,  0.7507, -0.0542,  0.3749, -0.0578,\n",
       "          -0.0373]]),\n",
       " tensor([[ 2.7699, -0.1328, -0.0037, -0.0042, -0.0474, -0.1592, -0.0062,\n",
       "          -0.0036, -0.0156,  0.1049, -0.0119, -0.1109, -1.6717, -0.3042,\n",
       "          -0.0168, -0.0095, -0.1266,  0.5803,  0.1194,  2.6637, -0.0133,\n",
       "          -0.0203, -0.3666, -0.0220,  1.6283,  0.2500, -0.0161,  0.5503,\n",
       "          -0.0155]]),\n",
       " tensor([[-0.0424, -0.0239, -0.0176, -0.0282, -0.7098, -0.1311, -0.1459,\n",
       "           1.2115,  0.7243, -0.0555,  3.0151, -0.0143, -0.0457, -0.2456,\n",
       "          -0.2766, -0.0363, -0.1408, -0.0871,  0.0752, -0.0158,  2.7206,\n",
       "          -0.4621, -0.0230,  0.4929, -0.0112, -0.0208, -1.4912, -1.4906,\n",
       "           0.7550]]),\n",
       " tensor([[-0.0373, -0.1139,  2.7221, -0.0865, -0.0049,  0.7632, -0.0132,\n",
       "          -0.1247, -0.0044, -1.5577, -0.0108,  0.7618, -0.1238, -0.0040,\n",
       "          -0.0867, -0.1583,  0.6101,  2.6590,  0.2525,  0.4919, -0.0026,\n",
       "          -0.1410,  0.7152, -0.0116, -0.0656, -0.5302, -0.1030,  2.2010,\n",
       "           2.0780]]),\n",
       " tensor([[-0.0106, -0.0282, -3.0489, -0.0032, -0.3988, -1.6766, -0.9077,\n",
       "          -0.0120, -0.0097, -0.0530,  0.7931,  2.6439, -0.0808, -0.0224,\n",
       "          -0.1349, -0.1290, -0.7441, -0.0716, -0.0071, -0.0068, -2.6609,\n",
       "          -0.0045, -0.1087, -0.0106, -0.0328, -0.0840, -2.7733, -0.1321,\n",
       "          -1.1935]]),\n",
       " tensor([[-0.0070, -2.2128, -0.0153,  0.7981, -0.1238, -0.0616, -0.1409,\n",
       "           0.7634, -0.0822, -0.0911, -0.0057, -2.9519, -0.0128, -0.0178,\n",
       "           2.6340,  0.9325, -0.0167,  0.7312, -0.0343, -0.0036, -0.5830,\n",
       "          -0.0046,  1.5864, -0.0015, -0.0028,  1.2490, -2.2947,  2.9208,\n",
       "          -0.0033]]),\n",
       " tensor([[-0.5485, -0.1345, -0.0620, -0.0061,  0.2413, -0.0037, -0.0036,\n",
       "           0.7515, -2.6577,  0.8341, -0.1334, -0.0866, -0.5846, -0.1214,\n",
       "          -0.0033,  0.2348, -0.0368,  2.2468, -0.1194,  0.7643,  0.7572,\n",
       "           0.2443, -0.4921, -0.0321,  2.5839,  0.1372, -0.0539, -0.1359,\n",
       "          -0.0836]]),\n",
       " tensor([[-0.0081, -0.0282, -0.0044,  2.7125, -2.9859,  0.5032, -0.0507,\n",
       "          -0.1037, -0.1890, -0.0083, -0.0055, -0.0271, -0.0444,  0.7713,\n",
       "          -2.8723,  1.2911, -0.0167,  0.0062, -0.1267, -0.0724, -0.1141,\n",
       "           2.6603, -2.7505, -0.0079, -0.0767, -0.2989, -0.0099,  2.8683,\n",
       "           2.6516]]),\n",
       " tensor([[ 0.7575, -0.0163, -0.1131, -0.0473, -0.5091,  0.3929, -0.2292,\n",
       "          -0.0751, -0.0059,  2.8375, -0.1331, -0.6575,  0.5797, -0.0471,\n",
       "          -3.0485,  0.7329, -0.0191, -0.3027, -0.0649, -0.0093, -0.0117,\n",
       "          -0.0165, -1.9170, -0.0853,  0.5835, -0.0081, -0.2342, -0.0514,\n",
       "           0.1763]]),\n",
       " tensor([[ 2.4158, -0.0530, -0.0181, -0.6368, -0.0349, -0.1376, -0.3378,\n",
       "          -3.0243,  0.7031, -0.0222, -0.1358, -0.1239, -0.0174,  0.4457,\n",
       "          -0.0129, -3.0481,  0.7089,  0.3785, -0.0148, -0.0113,  2.6791,\n",
       "           1.2061, -0.0086,  0.7686,  0.5763, -0.0079, -0.0060, -0.1014,\n",
       "          -0.0067]]),\n",
       " tensor([[-0.0912, -0.0046, -0.0376, -0.1298, -0.0814, -2.9754,  2.6600,\n",
       "          -0.0045, -0.1122, -3.0754, -2.4981, -0.0593, -0.0046,  2.7117,\n",
       "          -0.0140, -0.1364, -2.6567,  0.4836,  2.6338,  2.5638, -0.0651,\n",
       "           2.7031, -0.0156, -0.0062,  2.3480, -0.0064, -0.0144, -0.0183,\n",
       "           1.0475]]),\n",
       " tensor([[-0.2798, -3.1157, -0.1524, -0.2817, -0.0397, -2.8350, -0.0676,\n",
       "          -0.1421, -0.1508,  0.5417, -0.0400, -0.0623, -0.1359, -0.0078,\n",
       "          -0.1177, -1.8881, -0.1323, -0.0912, -0.3391,  0.1625, -0.0639,\n",
       "          -0.0786, -0.0970, -0.1473,  2.6333,  0.6729,  2.9282, -0.1156,\n",
       "           0.0165]]),\n",
       " tensor([[-2.5665, -0.1349, -0.1713, -0.6209, -0.0642, -0.0675, -0.0266,\n",
       "          -0.0881, -0.3960, -0.0084,  2.8306, -0.1483,  2.6023,  0.7135,\n",
       "           0.5456, -2.7839, -0.1151, -0.0527,  2.8386, -1.4310, -0.0343,\n",
       "           2.9087, -0.0774,  2.6830, -0.0095, -0.1023, -0.0840, -0.0101,\n",
       "          -0.1135]]),\n",
       " tensor([[ 0.3703,  0.1481, -0.0088, -0.1310, -0.0719,  1.1921, -0.0814,\n",
       "          -0.0920,  1.7976,  0.7817, -0.0960, -0.1384, -0.0222, -0.0284,\n",
       "           0.1441, -0.4579, -0.1128, -0.1182, -0.0605,  0.2102, -0.0317,\n",
       "          -1.7464,  2.6747,  0.2567, -0.0732, -0.0372, -0.0247, -0.0206,\n",
       "          -0.0553]]),\n",
       " tensor([[-1.6445,  0.7534,  0.0301,  0.8091,  0.2428, -0.0242, -0.1580,\n",
       "          -0.0321, -0.0228, -0.0093, -0.0227,  0.6517, -0.5918, -0.1930,\n",
       "          -0.1247, -0.1150, -0.0953, -0.1177, -0.3309, -0.0142,  0.7474,\n",
       "          -0.0157, -0.0150, -0.0108, -0.0254, -3.0617, -0.1251, -0.1463,\n",
       "          -0.1103]]),\n",
       " tensor([[ 0.5840, -0.1505,  0.0972,  0.7473, -0.0351, -0.1445,  2.6560,\n",
       "          -0.2053, -0.5438, -0.0467, -0.0622, -0.0133, -0.3415, -0.1072,\n",
       "          -0.0268,  1.9515, -0.0527, -0.0152, -0.1738, -0.0211, -0.0129,\n",
       "          -0.0226, -0.0601,  2.7005, -0.0171, -0.0578, -0.1406, -0.0124,\n",
       "          -0.5733]]),\n",
       " tensor([[-0.0787,  0.0487, -0.3854, -0.5202, -0.0146,  0.7344, -0.0252,\n",
       "           0.5503, -0.0095,  0.7573, -0.6053,  0.1793, -0.0023,  0.6650,\n",
       "          -0.0153, -0.0369, -0.1273,  0.6176,  1.0148, -0.0169,  0.7687,\n",
       "          -0.0959,  2.6724,  0.7218, -0.1091, -0.0114, -0.2486,  0.7652,\n",
       "          -0.1368]]),\n",
       " tensor([[ 2.7443, -0.1425, -0.1436, -0.0941, -0.0141, -0.2474,  0.7392,\n",
       "          -0.0328, -0.0333, -0.0282,  0.7559, -0.0641, -0.0422,  0.7561,\n",
       "          -0.4234, -0.8730, -0.1428, -0.1340, -0.1993, -0.0300, -0.2537,\n",
       "          -0.0147, -0.3004,  2.6929, -0.2438, -0.0187, -0.4343,  2.5978,\n",
       "           0.7486]]),\n",
       " tensor([[-0.0437,  2.6779, -0.1513,  0.7509, -0.0101, -0.0792, -0.0329,\n",
       "          -0.0336, -0.0977, -0.0105, -0.1083, -0.0827, -0.0967, -0.1508,\n",
       "          -0.0949, -0.1128, -0.0391, -0.0707, -0.0169, -0.0666, -2.8413,\n",
       "          -0.0377, -0.1510,  1.2475, -0.0119,  1.7388, -0.0182,  0.7336,\n",
       "          -0.0137]]),\n",
       " tensor([[-0.0293,  2.7272, -0.1233, -0.0667, -0.0106, -0.2310, -0.1803,\n",
       "          -0.0101,  2.8521, -0.0843, -0.0169, -0.0983, -0.0214, -0.0520,\n",
       "          -0.1012, -2.3005,  1.5088, -0.0358, -0.1074, -0.0452,  0.5041,\n",
       "          -3.0508, -0.0159, -0.1120, -0.0253, -0.0941, -0.6532, -0.1484,\n",
       "          -0.0470]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can train and test model on the generated data\n",
    "synthentic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert array of tensor to tensors\n",
    "temp = torch.Tensor(99)\n",
    "synthentic_data = torch.cat(synthentic_data, out=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382185</td>\n",
       "      <td>0.031667</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>-0.045023</td>\n",
       "      <td>-0.121752</td>\n",
       "      <td>-0.010788</td>\n",
       "      <td>-0.098568</td>\n",
       "      <td>-0.072385</td>\n",
       "      <td>-3.040942</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031381</td>\n",
       "      <td>-0.132652</td>\n",
       "      <td>-0.124855</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>-0.226160</td>\n",
       "      <td>-0.190359</td>\n",
       "      <td>1.741310</td>\n",
       "      <td>-0.003564</td>\n",
       "      <td>0.406679</td>\n",
       "      <td>1.121134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.764468</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>-0.106571</td>\n",
       "      <td>-0.036397</td>\n",
       "      <td>-3.088446</td>\n",
       "      <td>0.757274</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750312</td>\n",
       "      <td>-0.023725</td>\n",
       "      <td>2.692049</td>\n",
       "      <td>-0.108295</td>\n",
       "      <td>0.242151</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>2.548790</td>\n",
       "      <td>-0.057308</td>\n",
       "      <td>-0.010608</td>\n",
       "      <td>0.774563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.205750</td>\n",
       "      <td>-0.081067</td>\n",
       "      <td>-1.912765</td>\n",
       "      <td>2.544311</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>-0.009490</td>\n",
       "      <td>-0.046518</td>\n",
       "      <td>1.469110</td>\n",
       "      <td>-0.139919</td>\n",
       "      <td>-0.102422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111237</td>\n",
       "      <td>-0.043779</td>\n",
       "      <td>2.451237</td>\n",
       "      <td>1.123174</td>\n",
       "      <td>-0.123534</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>-0.137584</td>\n",
       "      <td>-0.107142</td>\n",
       "      <td>-0.331084</td>\n",
       "      <td>0.013369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.142101</td>\n",
       "      <td>-0.130524</td>\n",
       "      <td>-0.077395</td>\n",
       "      <td>2.510983</td>\n",
       "      <td>-1.664072</td>\n",
       "      <td>-0.060107</td>\n",
       "      <td>2.637323</td>\n",
       "      <td>-2.683736</td>\n",
       "      <td>0.616476</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059340</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>-0.053797</td>\n",
       "      <td>2.527006</td>\n",
       "      <td>0.660812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>-3.277667</td>\n",
       "      <td>0.778206</td>\n",
       "      <td>-0.275299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.134780</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.222020</td>\n",
       "      <td>2.092186</td>\n",
       "      <td>-0.101568</td>\n",
       "      <td>-0.028103</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.461926</td>\n",
       "      <td>-0.091481</td>\n",
       "      <td>-0.788920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831237</td>\n",
       "      <td>-0.001574</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>-0.000547</td>\n",
       "      <td>0.319792</td>\n",
       "      <td>-0.368280</td>\n",
       "      <td>-0.107850</td>\n",
       "      <td>-0.127163</td>\n",
       "      <td>-0.044255</td>\n",
       "      <td>2.096004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.382185  0.031667  0.001428 -0.045023 -0.121752 -0.010788 -0.098568   \n",
       "1  0.764468  0.137504  0.003057 -0.106571 -0.036397 -3.088446  0.757274   \n",
       "2 -0.205750 -0.081067 -1.912765  2.544311  0.213228 -0.009490 -0.046518   \n",
       "3 -0.142101 -0.130524 -0.077395  2.510983 -1.664072 -0.060107  2.637323   \n",
       "4 -0.134780  0.000769  0.222020  2.092186 -0.101568 -0.028103  0.003836   \n",
       "\n",
       "         7         8         9     ...           19        20        21  \\\n",
       "0 -0.072385 -3.040942  0.003393    ...    -0.031381 -0.132652 -0.124855   \n",
       "1 -0.031925  0.004918  0.004422    ...     0.750312 -0.023725  2.692049   \n",
       "2  1.469110 -0.139919 -0.102422    ...    -0.111237 -0.043779  2.451237   \n",
       "3 -2.683736  0.616476  0.003625    ...    -0.059340 -0.001066  0.004026   \n",
       "4  0.461926 -0.091481 -0.788920    ...     0.831237 -0.001574 -0.001212   \n",
       "\n",
       "         22        23        24        25        26        27        28  \n",
       "0  0.004204 -0.226160 -0.190359  1.741310 -0.003564  0.406679  1.121134  \n",
       "1 -0.108295  0.242151  0.004049  2.548790 -0.057308 -0.010608  0.774563  \n",
       "2  1.123174 -0.123534  0.005090 -0.137584 -0.107142 -0.331084  0.013369  \n",
       "3 -0.053797  2.527006  0.660812  0.003906 -3.277667  0.778206 -0.275299  \n",
       "4 -0.000547  0.319792 -0.368280 -0.107850 -0.127163 -0.044255  2.096004  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tensor to PD data frame\n",
    "synthentic_data_df = pd.DataFrame(data=synthentic_data.data.numpy());\n",
    "synthentic_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns of the synthentic dataset\n",
    "cols = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
    "        'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'normAmount']\n",
    "synthentic_data_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382185</td>\n",
       "      <td>0.031667</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>-0.045023</td>\n",
       "      <td>-0.121752</td>\n",
       "      <td>-0.010788</td>\n",
       "      <td>-0.098568</td>\n",
       "      <td>-0.072385</td>\n",
       "      <td>-3.040942</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031381</td>\n",
       "      <td>-0.132652</td>\n",
       "      <td>-0.124855</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>-0.226160</td>\n",
       "      <td>-0.190359</td>\n",
       "      <td>1.741310</td>\n",
       "      <td>-0.003564</td>\n",
       "      <td>0.406679</td>\n",
       "      <td>1.121134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.764468</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>-0.106571</td>\n",
       "      <td>-0.036397</td>\n",
       "      <td>-3.088446</td>\n",
       "      <td>0.757274</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750312</td>\n",
       "      <td>-0.023725</td>\n",
       "      <td>2.692049</td>\n",
       "      <td>-0.108295</td>\n",
       "      <td>0.242151</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>2.548790</td>\n",
       "      <td>-0.057308</td>\n",
       "      <td>-0.010608</td>\n",
       "      <td>0.774563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.205750</td>\n",
       "      <td>-0.081067</td>\n",
       "      <td>-1.912765</td>\n",
       "      <td>2.544311</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>-0.009490</td>\n",
       "      <td>-0.046518</td>\n",
       "      <td>1.469110</td>\n",
       "      <td>-0.139919</td>\n",
       "      <td>-0.102422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111237</td>\n",
       "      <td>-0.043779</td>\n",
       "      <td>2.451237</td>\n",
       "      <td>1.123174</td>\n",
       "      <td>-0.123534</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>-0.137584</td>\n",
       "      <td>-0.107142</td>\n",
       "      <td>-0.331084</td>\n",
       "      <td>0.013369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.142101</td>\n",
       "      <td>-0.130524</td>\n",
       "      <td>-0.077395</td>\n",
       "      <td>2.510983</td>\n",
       "      <td>-1.664072</td>\n",
       "      <td>-0.060107</td>\n",
       "      <td>2.637323</td>\n",
       "      <td>-2.683736</td>\n",
       "      <td>0.616476</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059340</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>-0.053797</td>\n",
       "      <td>2.527006</td>\n",
       "      <td>0.660812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>-3.277667</td>\n",
       "      <td>0.778206</td>\n",
       "      <td>-0.275299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.134780</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.222020</td>\n",
       "      <td>2.092186</td>\n",
       "      <td>-0.101568</td>\n",
       "      <td>-0.028103</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.461926</td>\n",
       "      <td>-0.091481</td>\n",
       "      <td>-0.788920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831237</td>\n",
       "      <td>-0.001574</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>-0.000547</td>\n",
       "      <td>0.319792</td>\n",
       "      <td>-0.368280</td>\n",
       "      <td>-0.107850</td>\n",
       "      <td>-0.127163</td>\n",
       "      <td>-0.044255</td>\n",
       "      <td>2.096004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.382185  0.031667  0.001428 -0.045023 -0.121752 -0.010788 -0.098568   \n",
       "1  0.764468  0.137504  0.003057 -0.106571 -0.036397 -3.088446  0.757274   \n",
       "2 -0.205750 -0.081067 -1.912765  2.544311  0.213228 -0.009490 -0.046518   \n",
       "3 -0.142101 -0.130524 -0.077395  2.510983 -1.664072 -0.060107  2.637323   \n",
       "4 -0.134780  0.000769  0.222020  2.092186 -0.101568 -0.028103  0.003836   \n",
       "\n",
       "         V8        V9       V10     ...           V20       V21       V22  \\\n",
       "0 -0.072385 -3.040942  0.003393     ...     -0.031381 -0.132652 -0.124855   \n",
       "1 -0.031925  0.004918  0.004422     ...      0.750312 -0.023725  2.692049   \n",
       "2  1.469110 -0.139919 -0.102422     ...     -0.111237 -0.043779  2.451237   \n",
       "3 -2.683736  0.616476  0.003625     ...     -0.059340 -0.001066  0.004026   \n",
       "4  0.461926 -0.091481 -0.788920     ...      0.831237 -0.001574 -0.001212   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  normAmount  \n",
       "0  0.004204 -0.226160 -0.190359  1.741310 -0.003564  0.406679    1.121134  \n",
       "1 -0.108295  0.242151  0.004049  2.548790 -0.057308 -0.010608    0.774563  \n",
       "2  1.123174 -0.123534  0.005090 -0.137584 -0.107142 -0.331084    0.013369  \n",
       "3 -0.053797  2.527006  0.660812  0.003906 -3.277667  0.778206   -0.275299  \n",
       "4 -0.000547  0.319792 -0.368280 -0.107850 -0.127163 -0.044255    2.096004  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tensor to PD data frame\n",
    "#synthentic_data_df = pd.DataFrame(data=synthentic_data.data.numpy());\n",
    "synthentic_data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 1 to Class column since they're all synthetic generated fraud data\n",
    "synthentic_data_df['Class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "\n",
    "# Rearrange columns to the right order\n",
    "cols = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
    "        'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'normAmount', 'Class']\n",
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284807, 29)\n",
      "Shape of y: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data.loc[:, data.columns != 'Class'])\n",
    "y = np.array(data.loc[:, data.columns == 'Class'])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(199364, 29)\n",
      "xtest shape\n",
      "(85443, 29)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print('xtrain shape')\n",
    "print(X_train.shape)\n",
    "print('xtest shape')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the synthentic data\n",
    "X_synthentic = np.array(synthentic_data_df.loc[:, synthentic_data_df.columns != 'Class'])\n",
    "y_synthentic = np.array(synthentic_data_df.loc[:, synthentic_data_df.columns == 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_synthentic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add newly generated fraud data to the training data set\n",
    "new_X = np.concatenate((X_train, X_synthentic), axis=0)\n",
    "new_y = np.concatenate((y_train, y_synthentic), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(new_X, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[85288,     8],\n",
       "       [   41,   106]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/output/generator.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-ac5a9421c4e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"generator.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"discriminator.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/output/generator.pt'"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(generator, OUTPUT_PATH + \"generator.pt\")\n",
    "torch.save(discriminator, OUTPUT_PATH + \"discriminator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
